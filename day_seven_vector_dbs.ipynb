{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7e5c60f237924fd883b9caa11306bb26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6514d435f48b43b298c9f853ff4c1022",
              "IPY_MODEL_02503b25e36047a780855202016b04e1",
              "IPY_MODEL_5fecb76c99894a50b2ebb9a9e7984fed"
            ],
            "layout": "IPY_MODEL_4133d081843148c09e39200a46cb65ae"
          }
        },
        "6514d435f48b43b298c9f853ff4c1022": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a729f07ec5c4240b95fd66a82d1b979",
            "placeholder": "​",
            "style": "IPY_MODEL_a48b7f25dd984b0e9ab5597ef8022b43",
            "value": "modules.json: 100%"
          }
        },
        "02503b25e36047a780855202016b04e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e46338424a34a8eb7c0da41d4897943",
            "max": 229,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c897a57d9f964ba39d0561efc2b75e1a",
            "value": 229
          }
        },
        "5fecb76c99894a50b2ebb9a9e7984fed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce69c40eb78a4821aed8906c7a0e40b2",
            "placeholder": "​",
            "style": "IPY_MODEL_b87e99ad8c1542578a6181ad2ee72904",
            "value": " 229/229 [00:00&lt;00:00, 11.4kB/s]"
          }
        },
        "4133d081843148c09e39200a46cb65ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a729f07ec5c4240b95fd66a82d1b979": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a48b7f25dd984b0e9ab5597ef8022b43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e46338424a34a8eb7c0da41d4897943": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c897a57d9f964ba39d0561efc2b75e1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ce69c40eb78a4821aed8906c7a0e40b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b87e99ad8c1542578a6181ad2ee72904": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f60e28f10ec64ed88ad312b76e8152da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab988c3f6a754b41b693319a12d29a23",
              "IPY_MODEL_dbcdaa0912b449a0956c725e744ed0c6",
              "IPY_MODEL_9f4f074c3d5b46cb8cf1a8a99b509687"
            ],
            "layout": "IPY_MODEL_3bada3d393fa4116ac03de73d9040d6e"
          }
        },
        "ab988c3f6a754b41b693319a12d29a23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b56fd794203f47a58955e5c32aef882c",
            "placeholder": "​",
            "style": "IPY_MODEL_6070e6b13174446aa9938a5bdced563c",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "dbcdaa0912b449a0956c725e744ed0c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93def84c0a184f56b6275b05f281a937",
            "max": 122,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c9a977348e7e40b2a8bd6a8a392429a3",
            "value": 122
          }
        },
        "9f4f074c3d5b46cb8cf1a8a99b509687": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80224599f589464bb4f8fa68642ca2db",
            "placeholder": "​",
            "style": "IPY_MODEL_a63472973b51470fbd015d152191b5b7",
            "value": " 122/122 [00:00&lt;00:00, 9.40kB/s]"
          }
        },
        "3bada3d393fa4116ac03de73d9040d6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b56fd794203f47a58955e5c32aef882c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6070e6b13174446aa9938a5bdced563c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93def84c0a184f56b6275b05f281a937": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9a977348e7e40b2a8bd6a8a392429a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "80224599f589464bb4f8fa68642ca2db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a63472973b51470fbd015d152191b5b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "345d52aaff324e2ba4c7b086a04606af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_43c23c69bee341358ab1d60baa7dc06e",
              "IPY_MODEL_7a0d3056b824428195f196f3c298c696",
              "IPY_MODEL_081e4872155a400abdb280215147284e"
            ],
            "layout": "IPY_MODEL_0e79f7185f754670b7ed09b59a4fdbf9"
          }
        },
        "43c23c69bee341358ab1d60baa7dc06e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1a6eb309e164e8896591daacc05ec42",
            "placeholder": "​",
            "style": "IPY_MODEL_4aa293ef792244929c05ec8d7589cf1a",
            "value": "README.md: 100%"
          }
        },
        "7a0d3056b824428195f196f3c298c696": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b235d7c9efa8434c9a7d44345ee2b39c",
            "max": 4050,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9dab5684af1a48ccbda3262c0db8a13f",
            "value": 4050
          }
        },
        "081e4872155a400abdb280215147284e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84dc407e65e442e494efe8c122b7d3e4",
            "placeholder": "​",
            "style": "IPY_MODEL_2a98df0172a14d6c98181d5784467294",
            "value": " 4.05k/4.05k [00:00&lt;00:00, 151kB/s]"
          }
        },
        "0e79f7185f754670b7ed09b59a4fdbf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1a6eb309e164e8896591daacc05ec42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4aa293ef792244929c05ec8d7589cf1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b235d7c9efa8434c9a7d44345ee2b39c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9dab5684af1a48ccbda3262c0db8a13f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "84dc407e65e442e494efe8c122b7d3e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a98df0172a14d6c98181d5784467294": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6c6ac33319c42a7a60a594160aa1826": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e5606b9930224498a5bce66d436d191d",
              "IPY_MODEL_51d769418a9249b7850db345df6614cc",
              "IPY_MODEL_9513d9d0caea4155a10d9eca786c4daa"
            ],
            "layout": "IPY_MODEL_91647c2c230f4354ae5378e46d5413fb"
          }
        },
        "e5606b9930224498a5bce66d436d191d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d638a58af3dc4c99808c9f39915509e8",
            "placeholder": "​",
            "style": "IPY_MODEL_1625cfe2eaae4dcabf305fafac07084f",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "51d769418a9249b7850db345df6614cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a49c75ecf467442887f30043be868615",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_68444ccb1aae4472bbbfe9713b550f64",
            "value": 53
          }
        },
        "9513d9d0caea4155a10d9eca786c4daa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2daf4f21aa62484e902de6866a196ca0",
            "placeholder": "​",
            "style": "IPY_MODEL_401574edc4a045e494cc7e27d650e689",
            "value": " 53.0/53.0 [00:00&lt;00:00, 4.04kB/s]"
          }
        },
        "91647c2c230f4354ae5378e46d5413fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d638a58af3dc4c99808c9f39915509e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1625cfe2eaae4dcabf305fafac07084f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a49c75ecf467442887f30043be868615": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68444ccb1aae4472bbbfe9713b550f64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2daf4f21aa62484e902de6866a196ca0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "401574edc4a045e494cc7e27d650e689": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b4296ecaf5c4b669782ef9362a03a04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a756aab39e2a4c0fb9c783d829c43fce",
              "IPY_MODEL_9118a48ab34b4fec90e5c5f1872bfa29",
              "IPY_MODEL_c068b984576343edad16a2c0b6cffbd7"
            ],
            "layout": "IPY_MODEL_69722ad9acf941089e7f37270c856db7"
          }
        },
        "a756aab39e2a4c0fb9c783d829c43fce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2ce9ada450c439ca7113c1ee4a89b51",
            "placeholder": "​",
            "style": "IPY_MODEL_7bf2191774804e1fa8e498d189a482c2",
            "value": "config.json: 100%"
          }
        },
        "9118a48ab34b4fec90e5c5f1872bfa29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b51cad4bad364d769ff112d1e32c9716",
            "max": 555,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_54166ca064f9416bbb4230791dadc012",
            "value": 555
          }
        },
        "c068b984576343edad16a2c0b6cffbd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf0e114acc1447e8a6ee9c5ed82b3e37",
            "placeholder": "​",
            "style": "IPY_MODEL_95f8d1d4dd24459f93ffddff1d6618be",
            "value": " 555/555 [00:00&lt;00:00, 38.1kB/s]"
          }
        },
        "69722ad9acf941089e7f37270c856db7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2ce9ada450c439ca7113c1ee4a89b51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bf2191774804e1fa8e498d189a482c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b51cad4bad364d769ff112d1e32c9716": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54166ca064f9416bbb4230791dadc012": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bf0e114acc1447e8a6ee9c5ed82b3e37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95f8d1d4dd24459f93ffddff1d6618be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56b27091daa545578682199a744dc8dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_024bd084d07c4a8eb6f4d28824b93001",
              "IPY_MODEL_4ea2d9b8dcbb4f9c93defe68b258dc77",
              "IPY_MODEL_d7ea985dd05f44a5b472a2f01719737f"
            ],
            "layout": "IPY_MODEL_fd44a9d05a754683842c58c2c5272547"
          }
        },
        "024bd084d07c4a8eb6f4d28824b93001": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48e7220e04bc4733a784ee41751133a6",
            "placeholder": "​",
            "style": "IPY_MODEL_cb8bed304d9442e0a0e55d0151db9e7f",
            "value": "model.safetensors: 100%"
          }
        },
        "4ea2d9b8dcbb4f9c93defe68b258dc77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44f9c18836e44086aba9ad4fa2d1a804",
            "max": 265462608,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_930813d3bc0247a9a340ac1f0ee8e75c",
            "value": 265462608
          }
        },
        "d7ea985dd05f44a5b472a2f01719737f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_012040b25ced43d2bef0fe8bf0875414",
            "placeholder": "​",
            "style": "IPY_MODEL_cc4f925ef10b4453aa186d29bd92477c",
            "value": " 265M/265M [00:01&lt;00:00, 160MB/s]"
          }
        },
        "fd44a9d05a754683842c58c2c5272547": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48e7220e04bc4733a784ee41751133a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb8bed304d9442e0a0e55d0151db9e7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44f9c18836e44086aba9ad4fa2d1a804": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "930813d3bc0247a9a340ac1f0ee8e75c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "012040b25ced43d2bef0fe8bf0875414": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc4f925ef10b4453aa186d29bd92477c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "885b985e19244a4ab9ab3d257ec42a97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_52fe622ce7bb4b85a3183dfbb8c31359",
              "IPY_MODEL_b1f8c1397e9b4e1aafa28aa76763cce4",
              "IPY_MODEL_5cf229d463c4414f937b745d838f348c"
            ],
            "layout": "IPY_MODEL_bb824f0985744d1fb2d4870bcdb5343a"
          }
        },
        "52fe622ce7bb4b85a3183dfbb8c31359": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_471792a8d9034665992e820da0109352",
            "placeholder": "​",
            "style": "IPY_MODEL_ee8f5d1171a147bcab12eb073415529a",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "b1f8c1397e9b4e1aafa28aa76763cce4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfccf61e5484460490250f2da948ba65",
            "max": 505,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6d7db75ebc194360bfe0422acd0f7274",
            "value": 505
          }
        },
        "5cf229d463c4414f937b745d838f348c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc17f440f94f4e489254e891e70e2086",
            "placeholder": "​",
            "style": "IPY_MODEL_dab33df0913346658c69fccc9585f614",
            "value": " 505/505 [00:00&lt;00:00, 14.2kB/s]"
          }
        },
        "bb824f0985744d1fb2d4870bcdb5343a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "471792a8d9034665992e820da0109352": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee8f5d1171a147bcab12eb073415529a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfccf61e5484460490250f2da948ba65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d7db75ebc194360bfe0422acd0f7274": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc17f440f94f4e489254e891e70e2086": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dab33df0913346658c69fccc9585f614": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33b1a274123c46f094a6aea9abe81e73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4706cde0ab04e1aa6eef5a064117e37",
              "IPY_MODEL_fe055fc9290e4568aaf6324dd3eb1d17",
              "IPY_MODEL_813808db9fe8419693108ac527cb6de4"
            ],
            "layout": "IPY_MODEL_1ba79150f84344798df84d2e34b20f19"
          }
        },
        "a4706cde0ab04e1aa6eef5a064117e37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df1969b3e54e49cf8f81140df740cfed",
            "placeholder": "​",
            "style": "IPY_MODEL_67416fd2cc734e29b475f1871bf0439d",
            "value": "vocab.txt: 100%"
          }
        },
        "fe055fc9290e4568aaf6324dd3eb1d17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60aec2ec14f94753bc36ac0682757a5b",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2960c7fd80944df68375bba239df95c2",
            "value": 231508
          }
        },
        "813808db9fe8419693108ac527cb6de4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8602cc103f145fc806eb59732209e92",
            "placeholder": "​",
            "style": "IPY_MODEL_b5488f4555cf48b3bfea825e6994dacb",
            "value": " 232k/232k [00:00&lt;00:00, 1.76MB/s]"
          }
        },
        "1ba79150f84344798df84d2e34b20f19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df1969b3e54e49cf8f81140df740cfed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67416fd2cc734e29b475f1871bf0439d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60aec2ec14f94753bc36ac0682757a5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2960c7fd80944df68375bba239df95c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f8602cc103f145fc806eb59732209e92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5488f4555cf48b3bfea825e6994dacb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5816d519590b408a9b73891df665ef02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_821113cf0bfd4ad0825af46f45957deb",
              "IPY_MODEL_8eb0c786928b46588e8ad7c6f149de8c",
              "IPY_MODEL_264c848002814fe7a28df7d48d90ce39"
            ],
            "layout": "IPY_MODEL_8e5eaa7dc0ff44ebab133eeb7874e933"
          }
        },
        "821113cf0bfd4ad0825af46f45957deb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30c9e48e0d884d7094864f5c59a5e556",
            "placeholder": "​",
            "style": "IPY_MODEL_e01aa29fb64a411fa5079c3b5b03cd9e",
            "value": "tokenizer.json: 100%"
          }
        },
        "8eb0c786928b46588e8ad7c6f149de8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3624aaff5cc8461e81156b00fc309c3a",
            "max": 466081,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e2740cd037b641a6938482a2621b1e80",
            "value": 466081
          }
        },
        "264c848002814fe7a28df7d48d90ce39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2733d3a07d448ad8a2e602ca9bb2500",
            "placeholder": "​",
            "style": "IPY_MODEL_42e9294c43834f598706f9d74e1e062c",
            "value": " 466k/466k [00:00&lt;00:00, 6.77MB/s]"
          }
        },
        "8e5eaa7dc0ff44ebab133eeb7874e933": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30c9e48e0d884d7094864f5c59a5e556": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e01aa29fb64a411fa5079c3b5b03cd9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3624aaff5cc8461e81156b00fc309c3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2740cd037b641a6938482a2621b1e80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b2733d3a07d448ad8a2e602ca9bb2500": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42e9294c43834f598706f9d74e1e062c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "019d1a4862b74846bb649144edadbb7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f29887bf49334eeca5caaeb2e0dcfd42",
              "IPY_MODEL_3d36ef1f6f874115ad1876da47b6534d",
              "IPY_MODEL_effbbe915bf24b0ca957e0a6acec0306"
            ],
            "layout": "IPY_MODEL_17ed088235784529a70e90765d207410"
          }
        },
        "f29887bf49334eeca5caaeb2e0dcfd42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69cc002d7ab34a0b81a6e501544e72dd",
            "placeholder": "​",
            "style": "IPY_MODEL_afc0852428e543258e6409221a0dd315",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "3d36ef1f6f874115ad1876da47b6534d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85460a6ba17448f48ce9d7787fea6340",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f871f5830f954a21a972860f080149fb",
            "value": 112
          }
        },
        "effbbe915bf24b0ca957e0a6acec0306": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c37665e5594545b0a1930953e1947ded",
            "placeholder": "​",
            "style": "IPY_MODEL_b0f813bb72544709a2ec018dcb00a7c3",
            "value": " 112/112 [00:00&lt;00:00, 1.63kB/s]"
          }
        },
        "17ed088235784529a70e90765d207410": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69cc002d7ab34a0b81a6e501544e72dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afc0852428e543258e6409221a0dd315": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85460a6ba17448f48ce9d7787fea6340": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f871f5830f954a21a972860f080149fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c37665e5594545b0a1930953e1947ded": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0f813bb72544709a2ec018dcb00a7c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da1463ce69c74596b0d56770f2d821ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ebfa9baa6188486b8cce8cab3b1f26fb",
              "IPY_MODEL_f6396fa38cd54e05b69b46e70d923653",
              "IPY_MODEL_4a0817ec2cd14bffb73e06fed182c719"
            ],
            "layout": "IPY_MODEL_a27a33b471794f06bb1cff4f5b5aaecd"
          }
        },
        "ebfa9baa6188486b8cce8cab3b1f26fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_093638954f8549499bd81711ce9ff48c",
            "placeholder": "​",
            "style": "IPY_MODEL_247861146f3f41d89e7e95f5f1acd8ad",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "f6396fa38cd54e05b69b46e70d923653": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_307e861e1b9c42e597ec5d6dc6c85850",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_083ba16904f44efb9424b4cb62849b39",
            "value": 190
          }
        },
        "4a0817ec2cd14bffb73e06fed182c719": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edf8a68c20694ae99aae6cb746ecda3c",
            "placeholder": "​",
            "style": "IPY_MODEL_cfc7cf2a65f442fe85e30da6fe7fb034",
            "value": " 190/190 [00:00&lt;00:00, 2.58kB/s]"
          }
        },
        "a27a33b471794f06bb1cff4f5b5aaecd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "093638954f8549499bd81711ce9ff48c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "247861146f3f41d89e7e95f5f1acd8ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "307e861e1b9c42e597ec5d6dc6c85850": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "083ba16904f44efb9424b4cb62849b39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "edf8a68c20694ae99aae6cb746ecda3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfc7cf2a65f442fe85e30da6fe7fb034": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd8693bae25a477ba2f51cfd9faba6a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8dad89889c85493a9913f33227d5605f",
              "IPY_MODEL_9c28aa2ff0c64a989b34208cee5f49e6",
              "IPY_MODEL_b81b644fb63e46cd9d4c3a2ee08f2737"
            ],
            "layout": "IPY_MODEL_46420180f5fd47ca8689a728485f0689"
          }
        },
        "8dad89889c85493a9913f33227d5605f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c866a1ed3ea4a47bcb4c97810845215",
            "placeholder": "​",
            "style": "IPY_MODEL_2cf3986ed0714438af8fbb16bcec5af8",
            "value": "Batches: 100%"
          }
        },
        "9c28aa2ff0c64a989b34208cee5f49e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f2b44a1805c40bbbf5acd1ea5878d97",
            "max": 16,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7f3cc29c5a3418b96300239c4d04cac",
            "value": 16
          }
        },
        "b81b644fb63e46cd9d4c3a2ee08f2737": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6fad0c2514040989e00f5fbfc557e83",
            "placeholder": "​",
            "style": "IPY_MODEL_f0ce0ab3ce4f42118f3ad4efa1f3e975",
            "value": " 16/16 [00:04&lt;00:00,  6.56it/s]"
          }
        },
        "46420180f5fd47ca8689a728485f0689": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c866a1ed3ea4a47bcb4c97810845215": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cf3986ed0714438af8fbb16bcec5af8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f2b44a1805c40bbbf5acd1ea5878d97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7f3cc29c5a3418b96300239c4d04cac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d6fad0c2514040989e00f5fbfc557e83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0ce0ab3ce4f42118f3ad4efa1f3e975": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18e6ce328fc14a5e88f2d165a9db30da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21584ef3bcd94ec6be396de345146ea4",
              "IPY_MODEL_00240c2fad544ca89aeded3254136779",
              "IPY_MODEL_bf1b0ef46f8244d5bb8c5ca8e1c911cf"
            ],
            "layout": "IPY_MODEL_5f4ae3a9bd73439d86b8f1f214f4743c"
          }
        },
        "21584ef3bcd94ec6be396de345146ea4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8535350283e44e76b1180df82707323e",
            "placeholder": "​",
            "style": "IPY_MODEL_d213d4a705aa412fbba7b5bde7a75b0c",
            "value": "Batches: 100%"
          }
        },
        "00240c2fad544ca89aeded3254136779": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bacf946f1e842edabc8ad1b0a61015a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_47be727efeb24a9ea0f03165be1af9b1",
            "value": 1
          }
        },
        "bf1b0ef46f8244d5bb8c5ca8e1c911cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1595ae47a27b44b282dedb3f9efc3979",
            "placeholder": "​",
            "style": "IPY_MODEL_097b9d7d7e9c48428701ed138c68a367",
            "value": " 1/1 [00:00&lt;00:00, 20.81it/s]"
          }
        },
        "5f4ae3a9bd73439d86b8f1f214f4743c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8535350283e44e76b1180df82707323e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d213d4a705aa412fbba7b5bde7a75b0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bacf946f1e842edabc8ad1b0a61015a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47be727efeb24a9ea0f03165be1af9b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1595ae47a27b44b282dedb3f9efc3979": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "097b9d7d7e9c48428701ed138c68a367": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed89601230ee4adfb67ab92ed7c7b11a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_31b40ad3e0d6461da26be7c999e51d32",
              "IPY_MODEL_c6c88264a3204ca99c0b1f22bcbb1c7d",
              "IPY_MODEL_3a2a12f6486346908e378c0218bcbf81"
            ],
            "layout": "IPY_MODEL_a04afa9e339f4be59c00172f500c21da"
          }
        },
        "31b40ad3e0d6461da26be7c999e51d32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eeec079649604176a623537ba422914b",
            "placeholder": "​",
            "style": "IPY_MODEL_8d8831b9c9094e4e96fae3e046ae11c1",
            "value": "Batches: 100%"
          }
        },
        "c6c88264a3204ca99c0b1f22bcbb1c7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70c28d2251104537b69589684fa11d92",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_309294dd68d546c4a87f9572a36c3bef",
            "value": 1
          }
        },
        "3a2a12f6486346908e378c0218bcbf81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f9e921d376143f6a6b1881132a12652",
            "placeholder": "​",
            "style": "IPY_MODEL_711255360189422e962698ce3a37fb97",
            "value": " 1/1 [00:00&lt;00:00, 11.47it/s]"
          }
        },
        "a04afa9e339f4be59c00172f500c21da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eeec079649604176a623537ba422914b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d8831b9c9094e4e96fae3e046ae11c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70c28d2251104537b69589684fa11d92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "309294dd68d546c4a87f9572a36c3bef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f9e921d376143f6a6b1881132a12652": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "711255360189422e962698ce3a37fb97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a8fa5d5725c4548bf3dd9fe1ef9e941": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d766bdfec09c4798b2f68bf86e8768a5",
              "IPY_MODEL_aee3483504a040e38728188d526ef9c0",
              "IPY_MODEL_4a247cd16ef943c9a4cce013b756323c"
            ],
            "layout": "IPY_MODEL_42d519fb89194f518c324a0f87aa9207"
          }
        },
        "d766bdfec09c4798b2f68bf86e8768a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1dfdb860acc74d4c856ef4559f034c3a",
            "placeholder": "​",
            "style": "IPY_MODEL_357d13272468457ba824fe4718a19176",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "aee3483504a040e38728188d526ef9c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d03b850ab0964326981e69f9771f7156",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7a35c62f8f64202b11736c41c773a76",
            "value": 190
          }
        },
        "4a247cd16ef943c9a4cce013b756323c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_045c24221ba5424f9636186abab68951",
            "placeholder": "​",
            "style": "IPY_MODEL_bc6eb243da1943c78c3066f2544ff164",
            "value": " 190/190 [00:00&lt;00:00, 11.8kB/s]"
          }
        },
        "42d519fb89194f518c324a0f87aa9207": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1dfdb860acc74d4c856ef4559f034c3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "357d13272468457ba824fe4718a19176": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d03b850ab0964326981e69f9771f7156": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7a35c62f8f64202b11736c41c773a76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "045c24221ba5424f9636186abab68951": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc6eb243da1943c78c3066f2544ff164": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LETIMEI/LeetCode_SQL/blob/main/day_seven_vector_dbs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vector Databases and Embeddings Retrieval\n",
        "In this notebook we will be building a vector database and writing queries to return similar documents. We will be using Facebook's [Faiss](https://github.com/facebookresearch/faiss) database as the store, along with sentence level [DistilBERT](https://huggingface.co/docs/transformers/en/model_doc/distilbert) for embeddings. Our target domain will be academic papers which we will extract from the populuar preprint resource [ArXiv](https://arxiv.org/)."
      ],
      "metadata": {
        "id": "nTPY3s3_IoXh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vgUYaE6ZETh2"
      },
      "outputs": [],
      "source": [
        "# use capture to hide output messages\n",
        "%%capture\n",
        "\n",
        "!pip install accelerate -U\n",
        "!pip install -U sentence-transformers\n",
        "!pip install faiss-gpu\n",
        "!pip install arxiv\n",
        "\n",
        "import faiss\n",
        "import arxiv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.manifold import TSNE"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we need some data! We will be extracting 500 abstracts of academic papers that match the search term _\"text analytics\"_ from ArXiv. To do so we will create a simple client and connect to the API:"
      ],
      "metadata": {
        "id": "r9EMuzlJ6T71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of records\n",
        "n_records = 500\n",
        "\n",
        "# Construct the default API client.\n",
        "client = arxiv.Client()\n",
        "\n",
        "# Search for the 10 most recent articles matching the keyword \"text analytics.\"\n",
        "search = arxiv.Search(\n",
        "  query = \"text analytics\", # search query\n",
        "  max_results = n_records, # number of records to return - defined above\n",
        "  sort_by = arxiv.SortCriterion.SubmittedDate # sort order (submission date)\n",
        ")\n",
        "\n",
        "results = client.results(search) # collect results"
      ],
      "metadata": {
        "id": "MwE0uzuOE2Zi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have some results we can extract the bits we need and save them in a dataframe. Obviously we need the abstracts (documents) but we will also keep the ArXiv unique ID. However, the ArXiv ID is alphanumeric and Faiss wants a purely numeric ID system - so we will finally construct our own ID system as an autoincrement integer."
      ],
      "metadata": {
        "id": "yCnA15EH67Zo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ids = [] # empty list to store ArXiv IDs\n",
        "abstracts = [] # empty list to store abstracts\n",
        "\n",
        "for r in client.results(search): # iterate through the results\n",
        "  ids.append(r.entry_id) # add the ArXiv ID to the list\n",
        "  abstracts.append(r.summary) # add the abstract to the list\n",
        "\n",
        "# create a list of numbers between 0 and n_records\n",
        "uid = np.arange(0, n_records, dtype=int) # create a list of numeric IDs 0-499\n",
        "\n",
        "# combine the data together in a dictionary\n",
        "df_data = {'uid': uid, 'aid': ids, 'abstract': abstracts}\n",
        "\n",
        "# create a dataframe from this dictionary\n",
        "df = pd.DataFrame(df_data)\n",
        "df.head() # top 5 records"
      ],
      "metadata": {
        "id": "tRglddghFIIR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "84033552-d3be-488e-88e3-bb6d4901d9b9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   uid                                aid  \\\n",
              "0    0  http://arxiv.org/abs/2405.05259v1   \n",
              "1    1  http://arxiv.org/abs/2405.05234v1   \n",
              "2    2  http://arxiv.org/abs/2405.05225v1   \n",
              "3    3  http://arxiv.org/abs/2405.05216v1   \n",
              "4    4  http://arxiv.org/abs/2405.05204v1   \n",
              "\n",
              "                                            abstract  \n",
              "0  Event-based semantic segmentation (ESS) is a f...  \n",
              "1  Joint communication and sensing (JCS) is envis...  \n",
              "2  Moderating user-generated content on online pl...  \n",
              "3  The 3D Human Pose Estimation (3D HPE) task use...  \n",
              "4  Objective: To detect and classify features of ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-06683c37-53e3-46dc-a3d0-0145787c5350\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uid</th>\n",
              "      <th>aid</th>\n",
              "      <th>abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>http://arxiv.org/abs/2405.05259v1</td>\n",
              "      <td>Event-based semantic segmentation (ESS) is a f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>http://arxiv.org/abs/2405.05234v1</td>\n",
              "      <td>Joint communication and sensing (JCS) is envis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>http://arxiv.org/abs/2405.05225v1</td>\n",
              "      <td>Moderating user-generated content on online pl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>http://arxiv.org/abs/2405.05216v1</td>\n",
              "      <td>The 3D Human Pose Estimation (3D HPE) task use...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>http://arxiv.org/abs/2405.05204v1</td>\n",
              "      <td>Objective: To detect and classify features of ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-06683c37-53e3-46dc-a3d0-0145787c5350')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-06683c37-53e3-46dc-a3d0-0145787c5350 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-06683c37-53e3-46dc-a3d0-0145787c5350');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d2bee36a-0394-4b83-9a33-c8877d5fc76f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d2bee36a-0394-4b83-9a33-c8877d5fc76f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d2bee36a-0394-4b83-9a33-c8877d5fc76f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 500,\n  \"fields\": [\n    {\n      \"column\": \"uid\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 144,\n        \"min\": 0,\n        \"max\": 499,\n        \"num_unique_values\": 500,\n        \"samples\": [\n          361,\n          73,\n          374\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"aid\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 500,\n        \"samples\": [\n          \"http://arxiv.org/abs/2405.01648v1\",\n          \"http://arxiv.org/abs/2405.04457v1\",\n          \"http://arxiv.org/abs/2405.01461v2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 500,\n        \"samples\": [\n          \"In this work, we address the impact of a small lepton number violation on\\ncharged lepton electric dipole moments - EDMs. Low-scale seesaw models\\nprotected by lepton number symmetry and leading to pseudo-Dirac pairs in the\\nneutrino heavy spectrum provide a natural explanation for the smallness of\\nneutrino masses with potentially testable consequences. Among which, it was\\nthought that the small mass gap in each pair of pseudo-Dirac neutrinos may\\ninduce important contribution to the charged lepton EDMs. Recently, it has been\\nshown that the contribution from some of the Feynman diagrams to charged lepton\\nEDMs exactly cancel by virtue of the Ward-Takahashi identity in quantum\\nelectrodynamics. We thus consider here the Standard Model minimally extended\\nwith pairs of pseudo-Dirac sterile fermions and derive the complete analytical\\nformula at two loops for the charged lepton EDMs. In addition, we numerically\\nevaluate the order of the predicted EDMs consistent with the experimental\\nbounds and constraints such as neutrino oscillation data, charged lepton\\nflavour violating processes, sterile neutrino direct searches, meson decays,\\nsterile neutrino decays, and cosmological and astrophysical observations. We\\nfind that, in the minimal setup accommodating neutrino data (masses and\\nmixings) with only two pseudo-Dirac pairs, the predicted electron EDM is\\n$\\\\mathcal{O}(10^{-36})~e\\\\hspace{0.05cm}\\\\mathrm{cm}$, at most, which is much\\nsmaller than the current experimental bound and even future sensitivity.\\nHopefully, the electron EDM might reach future sensitivity, once extra\\npseudo-Dirac neutrinos are taken into account. The analytical formulae we\\nderive are generic to any model involving pseudo-Dirac pairs in the heavy\\nneutrino spectrum.\",\n          \"Rapid progress in text-to-image generative models coupled with their\\ndeployment for visual content creation has magnified the importance of\\nthoroughly evaluating their performance and identifying potential biases. In\\npursuit of models that generate images that are realistic, diverse, visually\\nappealing, and consistent with the given prompt, researchers and practitioners\\noften turn to automated metrics to facilitate scalable and cost-effective\\nperformance profiling. However, commonly-used metrics often fail to account for\\nthe full diversity of human preference; often even in-depth human evaluations\\nface challenges with subjectivity, especially as interpretations of evaluation\\ncriteria vary across regions and cultures. In this work, we conduct a large,\\ncross-cultural study to study how much annotators in Africa, Europe, and\\nSoutheast Asia vary in their perception of geographic representation, visual\\nappeal, and consistency in real and generated images from state-of-the art\\npublic APIs. We collect over 65,000 image annotations and 20 survey responses.\\nWe contrast human annotations with common automated metrics, finding that human\\npreferences vary notably across geographic location and that current metrics do\\nnot fully account for this diversity. For example, annotators in different\\nlocations often disagree on whether exaggerated, stereotypical depictions of a\\nregion are considered geographically representative. In addition, the utility\\nof automatic evaluations is dependent on assumptions about their set-up, such\\nas the alignment of feature extractors with human perception of object\\nsimilarity or the definition of \\\"appeal\\\" captured in reference datasets used to\\nground evaluations. We recommend steps for improved automatic and human\\nevaluations.\",\n          \"Is the Text to Motion model robust? Recent advancements in Text to Motion\\nmodels primarily stem from more accurate predictions of specific actions.\\nHowever, the text modality typically relies solely on pre-trained Contrastive\\nLanguage-Image Pretraining (CLIP) models. Our research has uncovered a\\nsignificant issue with the text-to-motion model: its predictions often exhibit\\ninconsistent outputs, resulting in vastly different or even incorrect poses\\nwhen presented with semantically similar or identical text inputs. In this\\npaper, we undertake an analysis to elucidate the underlying causes of this\\ninstability, establishing a clear link between the unpredictability of model\\noutputs and the erratic attention patterns of the text encoder module.\\nConsequently, we introduce a formal framework aimed at addressing this issue,\\nwhich we term the Stable Text-to-Motion Framework (SATO). SATO consists of\\nthree modules, each dedicated to stable attention, stable prediction, and\\nmaintaining a balance between accuracy and robustness trade-off. We present a\\nmethodology for constructing an SATO that satisfies the stability of attention\\nand prediction. To verify the stability of the model, we introduced a new\\ntextual synonym perturbation dataset based on HumanML3D and KIT-ML. Results\\nshow that SATO is significantly more stable against synonyms and other slight\\nperturbations while keeping its high accuracy performance.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama_index.core\n",
        "!pip install llama_index.readers.file"
      ],
      "metadata": {
        "id": "RC2yhN0z_RHc",
        "outputId": "2d4fbf6d-53cb-441f-83ca-89b7a4bed6d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama_index.core\n",
            "  Downloading llama_index_core-0.10.35.post1-py3-none-any.whl (15.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama_index.core) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama_index.core) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama_index.core) (3.9.5)\n",
            "Collecting dataclasses-json (from llama_index.core)\n",
            "  Downloading dataclasses_json-0.6.5-py3-none-any.whl (28 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama_index.core)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama_index.core)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama_index.core) (2023.6.0)\n",
            "Collecting httpx (from llama_index.core)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llamaindex-py-client<0.2.0,>=0.1.18 (from llama_index.core)\n",
            "  Downloading llamaindex_py_client-0.1.19-py3-none-any.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama_index.core) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama_index.core) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama_index.core) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama_index.core) (1.25.2)\n",
            "Collecting openai>=1.1.0 (from llama_index.core)\n",
            "  Downloading openai-1.27.0-py3-none-any.whl (314 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.1/314.1 kB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama_index.core) (2.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama_index.core) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama_index.core) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama_index.core) (8.2.3)\n",
            "Collecting tiktoken>=0.3.3 (from llama_index.core)\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama_index.core) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama_index.core) (4.11.0)\n",
            "Collecting typing-inspect>=0.8.0 (from llama_index.core)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama_index.core) (1.14.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama_index.core) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama_index.core) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama_index.core) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama_index.core) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama_index.core) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama_index.core) (4.0.3)\n",
            "Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.10/dist-packages (from llamaindex-py-client<0.2.0,>=0.1.18->llama_index.core) (2.7.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama_index.core) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama_index.core) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx->llama_index.core)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama_index.core) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama_index.core) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama_index.core)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama_index.core) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama_index.core) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama_index.core) (2023.12.25)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama_index.core) (1.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama_index.core) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama_index.core) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama_index.core) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama_index.core)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama_index.core)\n",
            "  Downloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama_index.core) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama_index.core) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama_index.core) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama_index.core) (1.2.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama_index.core) (24.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama_index.core) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama_index.core) (2.18.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama_index.core) (1.16.0)\n",
            "Installing collected packages: dirtyjson, mypy-extensions, marshmallow, h11, deprecated, typing-inspect, tiktoken, httpcore, httpx, dataclasses-json, openai, llamaindex-py-client, llama_index.core\n",
            "Successfully installed dataclasses-json-0.6.5 deprecated-1.2.14 dirtyjson-1.0.8 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 llama_index.core-0.10.35.post1 llamaindex-py-client-0.1.19 marshmallow-3.21.2 mypy-extensions-1.0.0 openai-1.27.0 tiktoken-0.6.0 typing-inspect-0.9.0\n",
            "Collecting llama_index.readers.file\n",
            "  Downloading llama_index_readers_file-0.1.22-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama_index.readers.file) (4.12.3)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from llama_index.readers.file) (0.10.35.post1)\n",
            "Collecting pypdf<5.0.0,>=4.0.1 (from llama_index.readers.file)\n",
            "  Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting striprtf<0.0.27,>=0.0.26 (from llama_index.readers.file)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama_index.readers.file) (2.5)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (0.6.5)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (2023.6.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (0.27.0)\n",
            "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (0.1.19)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (1.25.2)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (1.27.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (2.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (8.2.3)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (4.11.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (1.14.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (4.0.3)\n",
            "Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.10/dist-packages (from llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (2.7.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (0.14.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (2023.12.25)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (1.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (3.21.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (1.2.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (24.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (2.18.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama_index.readers.file) (1.16.0)\n",
            "Installing collected packages: striprtf, pypdf, llama_index.readers.file\n",
            "Successfully installed llama_index.readers.file-0.1.22 pypdf-4.2.0 striprtf-0.0.26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "_k4bBs8_A4rL",
        "outputId": "50fa6f3e-4b57-4cb7-d614-cf5fd47bc3bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3753
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     uid                                aid  \\\n",
              "0      0  http://arxiv.org/abs/2405.05259v1   \n",
              "1      1  http://arxiv.org/abs/2405.05234v1   \n",
              "2      2  http://arxiv.org/abs/2405.05225v1   \n",
              "3      3  http://arxiv.org/abs/2405.05216v1   \n",
              "4      4  http://arxiv.org/abs/2405.05204v1   \n",
              "..   ...                                ...   \n",
              "495  495  http://arxiv.org/abs/2405.00322v2   \n",
              "496  496  http://arxiv.org/abs/2405.00313v1   \n",
              "497  497  http://arxiv.org/abs/2405.00307v1   \n",
              "498  498  http://arxiv.org/abs/2405.00301v1   \n",
              "499  499  http://arxiv.org/abs/2405.00749v1   \n",
              "\n",
              "                                              abstract  \n",
              "0    Event-based semantic segmentation (ESS) is a f...  \n",
              "1    Joint communication and sensing (JCS) is envis...  \n",
              "2    Moderating user-generated content on online pl...  \n",
              "3    The 3D Human Pose Estimation (3D HPE) task use...  \n",
              "4    Objective: To detect and classify features of ...  \n",
              "..                                                 ...  \n",
              "495  Information access systems are getting complex...  \n",
              "496  Denoising diffusion models have recently gaine...  \n",
              "497  Speech emotion recognition (SER) has garnered ...  \n",
              "498  Large language models (LLMs) can generate long...  \n",
              "499  In many practical applications, it is often di...  \n",
              "\n",
              "[500 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f79de0f5-21e7-4eec-9923-77fbd83cb145\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uid</th>\n",
              "      <th>aid</th>\n",
              "      <th>abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>http://arxiv.org/abs/2405.05259v1</td>\n",
              "      <td>Event-based semantic segmentation (ESS) is a f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>http://arxiv.org/abs/2405.05234v1</td>\n",
              "      <td>Joint communication and sensing (JCS) is envis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>http://arxiv.org/abs/2405.05225v1</td>\n",
              "      <td>Moderating user-generated content on online pl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>http://arxiv.org/abs/2405.05216v1</td>\n",
              "      <td>The 3D Human Pose Estimation (3D HPE) task use...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>http://arxiv.org/abs/2405.05204v1</td>\n",
              "      <td>Objective: To detect and classify features of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>495</td>\n",
              "      <td>http://arxiv.org/abs/2405.00322v2</td>\n",
              "      <td>Information access systems are getting complex...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>496</td>\n",
              "      <td>http://arxiv.org/abs/2405.00313v1</td>\n",
              "      <td>Denoising diffusion models have recently gaine...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>497</td>\n",
              "      <td>http://arxiv.org/abs/2405.00307v1</td>\n",
              "      <td>Speech emotion recognition (SER) has garnered ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>498</td>\n",
              "      <td>http://arxiv.org/abs/2405.00301v1</td>\n",
              "      <td>Large language models (LLMs) can generate long...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>499</td>\n",
              "      <td>http://arxiv.org/abs/2405.00749v1</td>\n",
              "      <td>In many practical applications, it is often di...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f79de0f5-21e7-4eec-9923-77fbd83cb145')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f79de0f5-21e7-4eec-9923-77fbd83cb145 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f79de0f5-21e7-4eec-9923-77fbd83cb145');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a3d48088-69f8-41c4-9930-4ed3e6bc5548\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a3d48088-69f8-41c4-9930-4ed3e6bc5548')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a3d48088-69f8-41c4-9930-4ed3e6bc5548 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 500,\n  \"fields\": [\n    {\n      \"column\": \"uid\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 144,\n        \"min\": 0,\n        \"max\": 499,\n        \"num_unique_values\": 500,\n        \"samples\": [\n          361,\n          73,\n          374\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"aid\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 500,\n        \"samples\": [\n          \"http://arxiv.org/abs/2405.01648v1\",\n          \"http://arxiv.org/abs/2405.04457v1\",\n          \"http://arxiv.org/abs/2405.01461v2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 500,\n        \"samples\": [\n          \"In this work, we address the impact of a small lepton number violation on\\ncharged lepton electric dipole moments - EDMs. Low-scale seesaw models\\nprotected by lepton number symmetry and leading to pseudo-Dirac pairs in the\\nneutrino heavy spectrum provide a natural explanation for the smallness of\\nneutrino masses with potentially testable consequences. Among which, it was\\nthought that the small mass gap in each pair of pseudo-Dirac neutrinos may\\ninduce important contribution to the charged lepton EDMs. Recently, it has been\\nshown that the contribution from some of the Feynman diagrams to charged lepton\\nEDMs exactly cancel by virtue of the Ward-Takahashi identity in quantum\\nelectrodynamics. We thus consider here the Standard Model minimally extended\\nwith pairs of pseudo-Dirac sterile fermions and derive the complete analytical\\nformula at two loops for the charged lepton EDMs. In addition, we numerically\\nevaluate the order of the predicted EDMs consistent with the experimental\\nbounds and constraints such as neutrino oscillation data, charged lepton\\nflavour violating processes, sterile neutrino direct searches, meson decays,\\nsterile neutrino decays, and cosmological and astrophysical observations. We\\nfind that, in the minimal setup accommodating neutrino data (masses and\\nmixings) with only two pseudo-Dirac pairs, the predicted electron EDM is\\n$\\\\mathcal{O}(10^{-36})~e\\\\hspace{0.05cm}\\\\mathrm{cm}$, at most, which is much\\nsmaller than the current experimental bound and even future sensitivity.\\nHopefully, the electron EDM might reach future sensitivity, once extra\\npseudo-Dirac neutrinos are taken into account. The analytical formulae we\\nderive are generic to any model involving pseudo-Dirac pairs in the heavy\\nneutrino spectrum.\",\n          \"Rapid progress in text-to-image generative models coupled with their\\ndeployment for visual content creation has magnified the importance of\\nthoroughly evaluating their performance and identifying potential biases. In\\npursuit of models that generate images that are realistic, diverse, visually\\nappealing, and consistent with the given prompt, researchers and practitioners\\noften turn to automated metrics to facilitate scalable and cost-effective\\nperformance profiling. However, commonly-used metrics often fail to account for\\nthe full diversity of human preference; often even in-depth human evaluations\\nface challenges with subjectivity, especially as interpretations of evaluation\\ncriteria vary across regions and cultures. In this work, we conduct a large,\\ncross-cultural study to study how much annotators in Africa, Europe, and\\nSoutheast Asia vary in their perception of geographic representation, visual\\nappeal, and consistency in real and generated images from state-of-the art\\npublic APIs. We collect over 65,000 image annotations and 20 survey responses.\\nWe contrast human annotations with common automated metrics, finding that human\\npreferences vary notably across geographic location and that current metrics do\\nnot fully account for this diversity. For example, annotators in different\\nlocations often disagree on whether exaggerated, stereotypical depictions of a\\nregion are considered geographically representative. In addition, the utility\\nof automatic evaluations is dependent on assumptions about their set-up, such\\nas the alignment of feature extractors with human perception of object\\nsimilarity or the definition of \\\"appeal\\\" captured in reference datasets used to\\nground evaluations. We recommend steps for improved automatic and human\\nevaluations.\",\n          \"Is the Text to Motion model robust? Recent advancements in Text to Motion\\nmodels primarily stem from more accurate predictions of specific actions.\\nHowever, the text modality typically relies solely on pre-trained Contrastive\\nLanguage-Image Pretraining (CLIP) models. Our research has uncovered a\\nsignificant issue with the text-to-motion model: its predictions often exhibit\\ninconsistent outputs, resulting in vastly different or even incorrect poses\\nwhen presented with semantically similar or identical text inputs. In this\\npaper, we undertake an analysis to elucidate the underlying causes of this\\ninstability, establishing a clear link between the unpredictability of model\\noutputs and the erratic attention patterns of the text encoder module.\\nConsequently, we introduce a formal framework aimed at addressing this issue,\\nwhich we term the Stable Text-to-Motion Framework (SATO). SATO consists of\\nthree modules, each dedicated to stable attention, stable prediction, and\\nmaintaining a balance between accuracy and robustness trade-off. We present a\\nmethodology for constructing an SATO that satisfies the stability of attention\\nand prediction. To verify the stability of the model, we introduced a new\\ntextual synonym perturbation dataset based on HumanML3D and KIT-ML. Results\\nshow that SATO is significantly more stable against synonyms and other slight\\nperturbations while keeping its high accuracy performance.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sentence Splitter"
      ],
      "metadata": {
        "id": "Lq_vxZmNCijY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "slLXeRhkyKed",
        "outputId": "113ba794-d270-4397-f3d9-564d044d7e9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "chunk_size = 100  # Optional: Define chunk size for sentences\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "  abstract = row[\"abstract\"]\n",
        "  sentences = sent_tokenize(abstract)\n",
        "\n",
        "  # Optional chunking of sentences\n",
        "  if chunk_size:\n",
        "    chunks = []\n",
        "    for i in range(0, len(sentences), chunk_size):\n",
        "      chunks.append(sentences[i:i+chunk_size])\n",
        "  else:\n",
        "    chunks = [sentences]  # Each sentence becomes a chunk\n",
        "\n",
        "  # Process your chunks here (e.g., print, store in a list)\n",
        "  print(\"Chunks for abstract:\", row[\"abstract\"])\n",
        "  for chunk in chunks:\n",
        "    print(chunk)\n",
        "    # Further process each chunk (e.g., using llama_index)\n"
      ],
      "metadata": {
        "id": "YhBhaV7uAz82",
        "outputId": "a035a75d-c7ac-4db6-9bf6-849e5e0ab1be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m串流輸出內容已截斷至最後 5000 行。\u001b[0m\n",
            "potential of diffusion models in various facets, including the generation of\n",
            "novel facade designs, the enhancement of existing facades, and the realization\n",
            "of personalized customization. Despite their promise, diffusion models\n",
            "encounter obstacles such as computational resource constraints and data\n",
            "imbalances. To address these challenges, the study introduces the innovative\n",
            "Blended Latent Diffusion method for architectural facade editing, accompanied\n",
            "by a comprehensive visual analysis of its viability and efficacy. Through these\n",
            "endeavors, we aims to propel forward the field of architectural facade editing,\n",
            "contributing to its advancement and practical application.\n",
            "['This paper explores the utilization of diffusion models and textual guidance\\nfor achieving localized editing of building facades, addressing the escalating\\ndemand for sophisticated editing methodologies in architectural design and\\nurban planning.', 'Leveraging the robust generative capabilities of diffusion\\nmodels, this study presents a promising avenue for realistically synthesizing\\nand modifying architectural facades.', 'Through iterative diffusion and text\\ndescriptions, these models adeptly capture both the intricate global and local\\nstructures inherent in architectural facades, thus effectively navigating the\\ncomplexity of such designs.', 'Additionally, the paper examines the expansive\\npotential of diffusion models in various facets, including the generation of\\nnovel facade designs, the enhancement of existing facades, and the realization\\nof personalized customization.', 'Despite their promise, diffusion models\\nencounter obstacles such as computational resource constraints and data\\nimbalances.', 'To address these challenges, the study introduces the innovative\\nBlended Latent Diffusion method for architectural facade editing, accompanied\\nby a comprehensive visual analysis of its viability and efficacy.', 'Through these\\nendeavors, we aims to propel forward the field of architectural facade editing,\\ncontributing to its advancement and practical application.']\n",
            "Chunks for abstract: We propose a novel method, VectorPainter, for the task of stylized vector\n",
            "graphics synthesis. Given a text prompt and a reference style image,\n",
            "VectorPainter generates a vector graphic that aligns in content with the text\n",
            "prompt and remains faithful in style to the reference image. We recognize that\n",
            "the key to this task lies in fully leveraging the intrinsic properties of\n",
            "vector graphics. Innovatively, we conceptualize the stylization process as the\n",
            "rearrangement of vectorized strokes extracted from the reference image.\n",
            "VectorPainter employs an optimization-based pipeline. It begins by extracting\n",
            "vectorized strokes from the reference image, which are then used to initialize\n",
            "the synthesis process. To ensure fidelity to the reference style, a novel style\n",
            "preservation loss is introduced. Extensive experiments have been conducted to\n",
            "demonstrate that our method is capable of aligning with the text description\n",
            "while remaining faithful to the reference image.\n",
            "['We propose a novel method, VectorPainter, for the task of stylized vector\\ngraphics synthesis.', 'Given a text prompt and a reference style image,\\nVectorPainter generates a vector graphic that aligns in content with the text\\nprompt and remains faithful in style to the reference image.', 'We recognize that\\nthe key to this task lies in fully leveraging the intrinsic properties of\\nvector graphics.', 'Innovatively, we conceptualize the stylization process as the\\nrearrangement of vectorized strokes extracted from the reference image.', 'VectorPainter employs an optimization-based pipeline.', 'It begins by extracting\\nvectorized strokes from the reference image, which are then used to initialize\\nthe synthesis process.', 'To ensure fidelity to the reference style, a novel style\\npreservation loss is introduced.', 'Extensive experiments have been conducted to\\ndemonstrate that our method is capable of aligning with the text description\\nwhile remaining faithful to the reference image.']\n",
            "Chunks for abstract: We investigate the production of electron-positron pairs from the vacuum in a\n",
            "time-varying, spatially uniform pulsed electric field given by $E(t) = E_0\n",
            "sech^2(t/\\tau)$, with height of $E_0$ and width of $\\tau$. Sah recently\n",
            "discussed the problem of pair production after a finite evolution time [9].\n",
            "This raises questions about the instantaneous appearance of particles in pair\n",
            "production and their behavior at intermediate times when using a formalism that\n",
            "involves solving an evolution equation for a dynamical quantity. Is it possible\n",
            "to make general statements about this behavior? To address these questions, we\n",
            "analytically compute the probability of $(e^+ e^-)$ pair production in momentum\n",
            "space using the exact solution of the one-particle time-dependent Dirac\n",
            "equation, and we compare the result with quantum kinetic theory (QKT). Both\n",
            "approaches allow us to study the particle momentum spectrum at any instant in\n",
            "time and can potentially unveil valuable information regarding quantum\n",
            "non-equilibrium physics. We analyze both approaches' Longitudinal Momentum\n",
            "Spectrum (LMS) of the created particles at finite times. We observe oscillatory\n",
            "structure in the LMS. This oscillation behavior at finite time clearly\n",
            "illustrates the quantum interference effects associated with particle\n",
            "production. It is worth noting that both approaches exhibit quantum\n",
            "interference patterns at finite times, manifested as oscillations observed in\n",
            "the LMS. This reveals that these oscillations are not due to transient\n",
            "excitations and basis-dependent signatures. Again, we emphasize that the\n",
            "oscillations seen in the LMS from both approaches are not artifacts but possess\n",
            "significant physical relevance.\n",
            "['We investigate the production of electron-positron pairs from the vacuum in a\\ntime-varying, spatially uniform pulsed electric field given by $E(t) = E_0\\nsech^2(t/\\\\tau)$, with height of $E_0$ and width of $\\\\tau$.', 'Sah recently\\ndiscussed the problem of pair production after a finite evolution time [9].', 'This raises questions about the instantaneous appearance of particles in pair\\nproduction and their behavior at intermediate times when using a formalism that\\ninvolves solving an evolution equation for a dynamical quantity.', 'Is it possible\\nto make general statements about this behavior?', 'To address these questions, we\\nanalytically compute the probability of $(e^+ e^-)$ pair production in momentum\\nspace using the exact solution of the one-particle time-dependent Dirac\\nequation, and we compare the result with quantum kinetic theory (QKT).', 'Both\\napproaches allow us to study the particle momentum spectrum at any instant in\\ntime and can potentially unveil valuable information regarding quantum\\nnon-equilibrium physics.', \"We analyze both approaches' Longitudinal Momentum\\nSpectrum (LMS) of the created particles at finite times.\", 'We observe oscillatory\\nstructure in the LMS.', 'This oscillation behavior at finite time clearly\\nillustrates the quantum interference effects associated with particle\\nproduction.', 'It is worth noting that both approaches exhibit quantum\\ninterference patterns at finite times, manifested as oscillations observed in\\nthe LMS.', 'This reveals that these oscillations are not due to transient\\nexcitations and basis-dependent signatures.', 'Again, we emphasize that the\\noscillations seen in the LMS from both approaches are not artifacts but possess\\nsignificant physical relevance.']\n",
            "Chunks for abstract: We propose a high-performance glass-plastic hybrid minimalist aspheric\n",
            "panoramic annular lens (ASPAL) to solve several major limitations of the\n",
            "traditional panoramic annular lens (PAL), such as large size, high weight, and\n",
            "complex system. The field of view (FoV) of the ASPAL is\n",
            "360{\\deg}x(35{\\deg}~110{\\deg}) and the imaging quality is close to the\n",
            "diffraction limit. This large FoV ASPAL is composed of only 4 lenses. Moreover,\n",
            "we establish a physical structure model of PAL using the ray tracing method and\n",
            "study the influence of its physical parameters on compactness ratio. In\n",
            "addition, for the evaluation of local tolerances of annular surfaces, we\n",
            "propose a tolerance analysis method suitable for ASPAL. This analytical method\n",
            "can effectively analyze surface irregularities on annular surfaces and provide\n",
            "clear guidance on manufacturing tolerances for ASPAL. Benefiting from\n",
            "high-precision glass molding and injection molding aspheric lens manufacturing\n",
            "techniques, we finally manufactured 20 ASPALs in small batches. The weight of\n",
            "an ASPAL prototype is only 8.5 g. Our framework provides promising insights for\n",
            "the application of panoramic systems in space and weight-constrained\n",
            "environmental sensing scenarios such as intelligent security, micro-UAVs, and\n",
            "micro-robots.\n",
            "['We propose a high-performance glass-plastic hybrid minimalist aspheric\\npanoramic annular lens (ASPAL) to solve several major limitations of the\\ntraditional panoramic annular lens (PAL), such as large size, high weight, and\\ncomplex system.', 'The field of view (FoV) of the ASPAL is\\n360{\\\\deg}x(35{\\\\deg}~110{\\\\deg}) and the imaging quality is close to the\\ndiffraction limit.', 'This large FoV ASPAL is composed of only 4 lenses.', 'Moreover,\\nwe establish a physical structure model of PAL using the ray tracing method and\\nstudy the influence of its physical parameters on compactness ratio.', 'In\\naddition, for the evaluation of local tolerances of annular surfaces, we\\npropose a tolerance analysis method suitable for ASPAL.', 'This analytical method\\ncan effectively analyze surface irregularities on annular surfaces and provide\\nclear guidance on manufacturing tolerances for ASPAL.', 'Benefiting from\\nhigh-precision glass molding and injection molding aspheric lens manufacturing\\ntechniques, we finally manufactured 20 ASPALs in small batches.', 'The weight of\\nan ASPAL prototype is only 8.5 g. Our framework provides promising insights for\\nthe application of panoramic systems in space and weight-constrained\\nenvironmental sensing scenarios such as intelligent security, micro-UAVs, and\\nmicro-robots.']\n",
            "Chunks for abstract: Natural Language Inference (NLI) is a cornerstone of Natural Language\n",
            "Processing (NLP), providing insights into the entailment relationships between\n",
            "text pairings. It is a critical component of Natural Language Understanding\n",
            "(NLU), demonstrating the ability to extract information from spoken or written\n",
            "interactions. NLI is mainly concerned with determining the entailment\n",
            "relationship between two statements, known as the premise and hypothesis. When\n",
            "the premise logically implies the hypothesis, the pair is labeled \"entailment\".\n",
            "If the hypothesis contradicts the premise, the pair receives the\n",
            "\"contradiction\" label. When there is insufficient evidence to establish a\n",
            "connection, the pair is described as \"neutral\". Despite the success of Large\n",
            "Language Models (LLMs) in various tasks, their effectiveness in NLI remains\n",
            "constrained by issues like low-resource domain accuracy, model overconfidence,\n",
            "and difficulty in capturing human judgment disagreements. This study addresses\n",
            "the underexplored area of evaluating LLMs in low-resourced languages such as\n",
            "Bengali. Through a comprehensive evaluation, we assess the performance of\n",
            "prominent LLMs and state-of-the-art (SOTA) models in Bengali NLP tasks,\n",
            "focusing on natural language inference. Utilizing the XNLI dataset, we conduct\n",
            "zero-shot and few-shot evaluations, comparing LLMs like GPT-3.5 Turbo and\n",
            "Gemini 1.5 Pro with models such as BanglaBERT, Bangla BERT Base, DistilBERT,\n",
            "mBERT, and sahajBERT. Our findings reveal that while LLMs can achieve\n",
            "comparable or superior performance to fine-tuned SOTA models in few-shot\n",
            "scenarios, further research is necessary to enhance our understanding of LLMs\n",
            "in languages with modest resources like Bengali. This study underscores the\n",
            "importance of continued efforts in exploring LLM capabilities across diverse\n",
            "linguistic contexts.\n",
            "['Natural Language Inference (NLI) is a cornerstone of Natural Language\\nProcessing (NLP), providing insights into the entailment relationships between\\ntext pairings.', 'It is a critical component of Natural Language Understanding\\n(NLU), demonstrating the ability to extract information from spoken or written\\ninteractions.', 'NLI is mainly concerned with determining the entailment\\nrelationship between two statements, known as the premise and hypothesis.', 'When\\nthe premise logically implies the hypothesis, the pair is labeled \"entailment\".', 'If the hypothesis contradicts the premise, the pair receives the\\n\"contradiction\" label.', 'When there is insufficient evidence to establish a\\nconnection, the pair is described as \"neutral\".', 'Despite the success of Large\\nLanguage Models (LLMs) in various tasks, their effectiveness in NLI remains\\nconstrained by issues like low-resource domain accuracy, model overconfidence,\\nand difficulty in capturing human judgment disagreements.', 'This study addresses\\nthe underexplored area of evaluating LLMs in low-resourced languages such as\\nBengali.', 'Through a comprehensive evaluation, we assess the performance of\\nprominent LLMs and state-of-the-art (SOTA) models in Bengali NLP tasks,\\nfocusing on natural language inference.', 'Utilizing the XNLI dataset, we conduct\\nzero-shot and few-shot evaluations, comparing LLMs like GPT-3.5 Turbo and\\nGemini 1.5 Pro with models such as BanglaBERT, Bangla BERT Base, DistilBERT,\\nmBERT, and sahajBERT.', 'Our findings reveal that while LLMs can achieve\\ncomparable or superior performance to fine-tuned SOTA models in few-shot\\nscenarios, further research is necessary to enhance our understanding of LLMs\\nin languages with modest resources like Bengali.', 'This study underscores the\\nimportance of continued efforts in exploring LLM capabilities across diverse\\nlinguistic contexts.']\n",
            "Chunks for abstract: Language and Vision-Language Models (LLMs/VLMs) have revolutionized the field\n",
            "of AI by their ability to generate human-like text and understand images, but\n",
            "ensuring their reliability is crucial. This paper aims to evaluate the ability\n",
            "of LLMs (GPT4, GPT-3.5, LLaMA2, and PaLM 2) and VLMs (GPT4V and Gemini Pro\n",
            "Vision) to estimate their verbalized uncertainty via prompting. We propose the\n",
            "new Japanese Uncertain Scenes (JUS) dataset, aimed at testing VLM capabilities\n",
            "via difficult queries and object counting, and the Net Calibration Error (NCE)\n",
            "to measure direction of miscalibration. Results show that both LLMs and VLMs\n",
            "have a high calibration error and are overconfident most of the time,\n",
            "indicating a poor capability for uncertainty estimation. Additionally we\n",
            "develop prompts for regression tasks, and we show that VLMs have poor\n",
            "calibration when producing mean/standard deviation and 95% confidence\n",
            "intervals.\n",
            "['Language and Vision-Language Models (LLMs/VLMs) have revolutionized the field\\nof AI by their ability to generate human-like text and understand images, but\\nensuring their reliability is crucial.', 'This paper aims to evaluate the ability\\nof LLMs (GPT4, GPT-3.5, LLaMA2, and PaLM 2) and VLMs (GPT4V and Gemini Pro\\nVision) to estimate their verbalized uncertainty via prompting.', 'We propose the\\nnew Japanese Uncertain Scenes (JUS) dataset, aimed at testing VLM capabilities\\nvia difficult queries and object counting, and the Net Calibration Error (NCE)\\nto measure direction of miscalibration.', 'Results show that both LLMs and VLMs\\nhave a high calibration error and are overconfident most of the time,\\nindicating a poor capability for uncertainty estimation.', 'Additionally we\\ndevelop prompts for regression tasks, and we show that VLMs have poor\\ncalibration when producing mean/standard deviation and 95% confidence\\nintervals.']\n",
            "Chunks for abstract: In this study, we present a model for the behavior of Dirac particles under\n",
            "the tensor effect in the spherical core/shell regime. We examine the change of\n",
            "energy levels corresponding to the particles localized in a space of\n",
            "approximately 1.0 fm in the core region of the quantum sphere, with the well\n",
            "width. It also occurs from the analytical solutions that the two different\n",
            "levels accompany particle states of the same mass. Additionally, the solutions\n",
            "exhibiting anomalous behavior, giving rise to antiparticle-type states, occur\n",
            "at heavier mass.\n",
            "['In this study, we present a model for the behavior of Dirac particles under\\nthe tensor effect in the spherical core/shell regime.', 'We examine the change of\\nenergy levels corresponding to the particles localized in a space of\\napproximately 1.0 fm in the core region of the quantum sphere, with the well\\nwidth.', 'It also occurs from the analytical solutions that the two different\\nlevels accompany particle states of the same mass.', 'Additionally, the solutions\\nexhibiting anomalous behavior, giving rise to antiparticle-type states, occur\\nat heavier mass.']\n",
            "Chunks for abstract: We introduce formulas for the logarithms of Drinfeld modules using a\n",
            "framework recently developed by the second author. We write the logarithm\n",
            "function as the evaluation under a motivic map of a product of rigid analytic\n",
            "trivializations of $t$-motives. We then specialize our formulas to express\n",
            "special values of Goss $L$-functions as Drinfeld periods multiplied by rigid\n",
            "analytic trivializations evaluated under this motivic map. We view these\n",
            "formulas as characteristic-$p$ analogues of integral representations of\n",
            "Hasse-Weil type zeta functions. We also apply this machinery for Drinfeld\n",
            "modules tensored with the tensor powers of the Carlitz module, which serves as\n",
            "the Tate twist of a Drinfeld module.\n",
            "['We introduce formulas for the logarithms of Drinfeld modules using a\\nframework recently developed by the second author.', 'We write the logarithm\\nfunction as the evaluation under a motivic map of a product of rigid analytic\\ntrivializations of $t$-motives.', 'We then specialize our formulas to express\\nspecial values of Goss $L$-functions as Drinfeld periods multiplied by rigid\\nanalytic trivializations evaluated under this motivic map.', 'We view these\\nformulas as characteristic-$p$ analogues of integral representations of\\nHasse-Weil type zeta functions.', 'We also apply this machinery for Drinfeld\\nmodules tensored with the tensor powers of the Carlitz module, which serves as\\nthe Tate twist of a Drinfeld module.']\n",
            "Chunks for abstract: We give a $K$-theoretic and geometric interpretation for a generalized\n",
            "weighted Ehrhart theory of a full-dimensional lattice polytope $P$, depending\n",
            "on a given homogeneous polynomial function $\\varphi$ on $P$, and with Laurent\n",
            "polynomial weights $f_Q(y)\\in \\mathbb{Z}[y^{\\pm 1}]$ associated to the faces $Q\n",
            "\\preceq P$ of the polytope. For this purpose, we calculate equivariant\n",
            "$K$-theoretic Hodge-Chern classes of an equivariant mixed Hodge module\n",
            "$\\mathcal{M}$ on the toric variety $X_P$ associated to $P$ (defined via an\n",
            "equivariant embedding of $X_P$ into an ambient smooth variety). For any integer\n",
            "$\\ell$, we introduce a corresponding equivariant Hodge $\\chi_y$-polynomial\n",
            "$\\chi_y(X_P, \\ell D_P; [\\mathcal{M}])$, with $D_P$ the corresponding ample\n",
            "Cartier divisor on $X_P$ (defined by the facet presentation of $P$). Motivic\n",
            "properties of the Hodge-Chern classes are used to express this equivariant\n",
            "Hodge polynomial in terms of weighted character sums fitting with a generalized\n",
            "weighted Ehrhart theory. The equivariant Hodge polynomials are shown to satisfy\n",
            "a reciprocity and purity formula fitting with the duality for equivariant mixed\n",
            "Hodge modules, and implying the corresponding properties for the generalized\n",
            "weighted Ehrhart polynomials. In the special case of the equivariant\n",
            "intersection cohomology mixed Hodge module, with the weight function\n",
            "corresponding to Stanley's $g$-function of the polar polytope of $P$, we\n",
            "recover in geometric terms a recent combinatorial formula of\n",
            "Beck--Gunnells--Materov.\n",
            "['We give a $K$-theoretic and geometric interpretation for a generalized\\nweighted Ehrhart theory of a full-dimensional lattice polytope $P$, depending\\non a given homogeneous polynomial function $\\\\varphi$ on $P$, and with Laurent\\npolynomial weights $f_Q(y)\\\\in \\\\mathbb{Z}[y^{\\\\pm 1}]$ associated to the faces $Q\\n\\\\preceq P$ of the polytope.', 'For this purpose, we calculate equivariant\\n$K$-theoretic Hodge-Chern classes of an equivariant mixed Hodge module\\n$\\\\mathcal{M}$ on the toric variety $X_P$ associated to $P$ (defined via an\\nequivariant embedding of $X_P$ into an ambient smooth variety).', 'For any integer\\n$\\\\ell$, we introduce a corresponding equivariant Hodge $\\\\chi_y$-polynomial\\n$\\\\chi_y(X_P, \\\\ell D_P; [\\\\mathcal{M}])$, with $D_P$ the corresponding ample\\nCartier divisor on $X_P$ (defined by the facet presentation of $P$).', 'Motivic\\nproperties of the Hodge-Chern classes are used to express this equivariant\\nHodge polynomial in terms of weighted character sums fitting with a generalized\\nweighted Ehrhart theory.', 'The equivariant Hodge polynomials are shown to satisfy\\na reciprocity and purity formula fitting with the duality for equivariant mixed\\nHodge modules, and implying the corresponding properties for the generalized\\nweighted Ehrhart polynomials.', \"In the special case of the equivariant\\nintersection cohomology mixed Hodge module, with the weight function\\ncorresponding to Stanley's $g$-function of the polar polytope of $P$, we\\nrecover in geometric terms a recent combinatorial formula of\\nBeck--Gunnells--Materov.\"]\n",
            "Chunks for abstract: We propose an explanation for the observed excesses around 95 GeV in the\n",
            "di-photon and di-tau invariant mass distributions, as reported by the CMS\n",
            "collaboration at the Large Hadron Collider (LHC). These findings are\n",
            "complemented by a long-standing discrepancy in the $b\\bar{b}$ invariant mass at\n",
            "the Large Electron-Positron (LEP) Collider. Additionally, the ATLAS\n",
            "collaboration has reported a corroborative excess in the di-photon final state\n",
            "within the same mass range, albeit with slightly lower significance. Our\n",
            "approach involves the superposition of CP-even and CP-odd Higgs bosons within\n",
            "the Type-III Two-Higgs Doublet Model (2HDM) to simultaneously explain these\n",
            "excesses at 1$\\sigma$ Confidence Level (C.L.), while remaining consistent with\n",
            "current theoretical and experimental constraints.\n",
            "['We propose an explanation for the observed excesses around 95 GeV in the\\ndi-photon and di-tau invariant mass distributions, as reported by the CMS\\ncollaboration at the Large Hadron Collider (LHC).', 'These findings are\\ncomplemented by a long-standing discrepancy in the $b\\\\bar{b}$ invariant mass at\\nthe Large Electron-Positron (LEP) Collider.', 'Additionally, the ATLAS\\ncollaboration has reported a corroborative excess in the di-photon final state\\nwithin the same mass range, albeit with slightly lower significance.', 'Our\\napproach involves the superposition of CP-even and CP-odd Higgs bosons within\\nthe Type-III Two-Higgs Doublet Model (2HDM) to simultaneously explain these\\nexcesses at 1$\\\\sigma$ Confidence Level (C.L.', '), while remaining consistent with\\ncurrent theoretical and experimental constraints.']\n",
            "Chunks for abstract: People communicate in more than 7,000 languages around the world, with around\n",
            "780 languages spoken in India alone. Despite this linguistic diversity,\n",
            "research on Sentiment Analysis has predominantly focused on English text data,\n",
            "resulting in a disproportionate availability of sentiment resources for\n",
            "English. This paper examines the performance of transformer models in Sentiment\n",
            "Analysis tasks across multilingual datasets and text that has undergone machine\n",
            "translation. By comparing the effectiveness of these models in different\n",
            "linguistic contexts, we gain insights into their performance variations and\n",
            "potential implications for sentiment analysis across diverse languages. We also\n",
            "discuss the shortcomings and potential for future work towards the end.\n",
            "['People communicate in more than 7,000 languages around the world, with around\\n780 languages spoken in India alone.', 'Despite this linguistic diversity,\\nresearch on Sentiment Analysis has predominantly focused on English text data,\\nresulting in a disproportionate availability of sentiment resources for\\nEnglish.', 'This paper examines the performance of transformer models in Sentiment\\nAnalysis tasks across multilingual datasets and text that has undergone machine\\ntranslation.', 'By comparing the effectiveness of these models in different\\nlinguistic contexts, we gain insights into their performance variations and\\npotential implications for sentiment analysis across diverse languages.', 'We also\\ndiscuss the shortcomings and potential for future work towards the end.']\n",
            "Chunks for abstract: In this paper, we study the asymptotic behavior of ground state solutions for\n",
            "the nonlinear Choquard equation with a general local perturbation $$ -\\Delta\n",
            "u+\\varepsilon u=(I_\\alpha \\ast |u|^{p})|u|^{p-2}u+ g(u), \\quad {\\rm in} \\\n",
            "\\mathbb R^N,\n",
            "  \\eqno(P_\\varepsilon)\n",
            "  $$ where $N\\ge 3$ is an integer, $p=\\frac{N+\\alpha}{N}$, or\n",
            "$\\frac{N+\\alpha}{N-2}$, $I_\\alpha$ is the Riesz potential and $\\varepsilon>0$\n",
            "is a parameter. Under some mild conditions on $g(u)$, we show that as\n",
            "$\\varepsilon\\to \\infty$, after {\\em a suitable rescaling} the ground state\n",
            "solutions of $(P_\\varepsilon)$ converge to a particular solution of some limit\n",
            "equations, and establish a sharp asymptotic characterisation of such a\n",
            "rescaling, which depend in a non-trivial way on the asymptotic behavior of the\n",
            "function $g(s)$ at infinity and the space dimension $N$. Based on this study,\n",
            "we also present some results on the existence and asymptotic behaviors of\n",
            "positive normalized solutions of $(P_\\varepsilon)$ with the normalization\n",
            "constraint $\\int_{\\mathbb R^N}|u|^2=a^2$. Particularly, we obtain the\n",
            "asymptotic behavior of positive normalized solutions of such a problem as $a\\to\n",
            "0$ and $a\\to \\infty$.\n",
            "['In this paper, we study the asymptotic behavior of ground state solutions for\\nthe nonlinear Choquard equation with a general local perturbation $$ -\\\\Delta\\nu+\\\\varepsilon u=(I_\\\\alpha \\\\ast |u|^{p})|u|^{p-2}u+ g(u), \\\\quad {\\\\rm in} \\\\\\n\\\\mathbb R^N,\\n  \\\\eqno(P_\\\\varepsilon)\\n  $$ where $N\\\\ge 3$ is an integer, $p=\\\\frac{N+\\\\alpha}{N}$, or\\n$\\\\frac{N+\\\\alpha}{N-2}$, $I_\\\\alpha$ is the Riesz potential and $\\\\varepsilon>0$\\nis a parameter.', 'Under some mild conditions on $g(u)$, we show that as\\n$\\\\varepsilon\\\\to \\\\infty$, after {\\\\em a suitable rescaling} the ground state\\nsolutions of $(P_\\\\varepsilon)$ converge to a particular solution of some limit\\nequations, and establish a sharp asymptotic characterisation of such a\\nrescaling, which depend in a non-trivial way on the asymptotic behavior of the\\nfunction $g(s)$ at infinity and the space dimension $N$.', 'Based on this study,\\nwe also present some results on the existence and asymptotic behaviors of\\npositive normalized solutions of $(P_\\\\varepsilon)$ with the normalization\\nconstraint $\\\\int_{\\\\mathbb R^N}|u|^2=a^2$.', 'Particularly, we obtain the\\nasymptotic behavior of positive normalized solutions of such a problem as $a\\\\to\\n0$ and $a\\\\to \\\\infty$.']\n",
            "Chunks for abstract: By employing an accelerated weighting method, we establish arbitrary\n",
            "polynomial and exponential pointwise convergence for multiple ergodic averages\n",
            "under general conditions in both discrete and continuous settings, involving\n",
            "quasi-periodic and almost periodic cases, which breaks the well known slow\n",
            "convergence rate observed in classical ergodic theory. We also present joint\n",
            "Diophantine rotations as explicit applications. Especially, in the sense that\n",
            "excluding nearly rational rotations with zero measure, we demonstrate that the\n",
            "pointwise exponential convergence is universal via analytic observables, even\n",
            "when multiplicatively averaging over the infinite-dimensional torus $\n",
            "\\mathbb{T}^\\infty $, utilizing a novel truncated approach. Moreover, by\n",
            "constructing counterexamples concerning with multiple ergodicity, we highlight\n",
            "the irremovability of the joint nonresonance and establish the optimality of\n",
            "our weighting method in preserving rapid convergence. We also provide numerical\n",
            "simulations with analysis to further illustrate our results.\n",
            "['By employing an accelerated weighting method, we establish arbitrary\\npolynomial and exponential pointwise convergence for multiple ergodic averages\\nunder general conditions in both discrete and continuous settings, involving\\nquasi-periodic and almost periodic cases, which breaks the well known slow\\nconvergence rate observed in classical ergodic theory.', 'We also present joint\\nDiophantine rotations as explicit applications.', 'Especially, in the sense that\\nexcluding nearly rational rotations with zero measure, we demonstrate that the\\npointwise exponential convergence is universal via analytic observables, even\\nwhen multiplicatively averaging over the infinite-dimensional torus $\\n\\\\mathbb{T}^\\\\infty $, utilizing a novel truncated approach.', 'Moreover, by\\nconstructing counterexamples concerning with multiple ergodicity, we highlight\\nthe irremovability of the joint nonresonance and establish the optimality of\\nour weighting method in preserving rapid convergence.', 'We also provide numerical\\nsimulations with analysis to further illustrate our results.']\n",
            "Chunks for abstract: We expand Conlon's random algebraic construction to show that for any odd\n",
            "number $k \\geq 3$ exists a natural number $c_k$ (the same as Conlon's) such\n",
            "that $\\operatorname{ex}(n^a,n,\\theta_{k,c_k}) = \\Omega_{k,a}((n^{1 +\n",
            "a})^{\\frac{k + 1}{2k}})$, with $a \\in [\\frac{k - 1}{k + 1}, 1)$. Where given a\n",
            "graph $H$, we denote by $\\operatorname{ex}(n,m,H)$ the maximum number of edges\n",
            "an $H-$free bipartite graph can have when the cardinalities of its parts are\n",
            "$n$ and $m$. Also, we denote with $\\theta_{k,l}$ the graph where two vertices\n",
            "are connected through $l$ disjoint paths of length $k$.\n",
            "[\"We expand Conlon's random algebraic construction to show that for any odd\\nnumber $k \\\\geq 3$ exists a natural number $c_k$ (the same as Conlon's) such\\nthat $\\\\operatorname{ex}(n^a,n,\\\\theta_{k,c_k}) = \\\\Omega_{k,a}((n^{1 +\\na})^{\\\\frac{k + 1}{2k}})$, with $a \\\\in [\\\\frac{k - 1}{k + 1}, 1)$.\", 'Where given a\\ngraph $H$, we denote by $\\\\operatorname{ex}(n,m,H)$ the maximum number of edges\\nan $H-$free bipartite graph can have when the cardinalities of its parts are\\n$n$ and $m$.', 'Also, we denote with $\\\\theta_{k,l}$ the graph where two vertices\\nare connected through $l$ disjoint paths of length $k$.']\n",
            "Chunks for abstract: Uni-directional social interactions are ubiquitous in real social networks\n",
            "whereas undirected interactions are intensively studied. We establish a voter\n",
            "model in a dynamical directed network. We analytically obtain the degree\n",
            "distribution of the evolving network at any given time. Furthermore, we find\n",
            "that the average degree is captured by an emergent game. On the other hand, we\n",
            "find that the fate of opinions is captured by another emergent game. Beyond\n",
            "expectation, the two emergent games are typically different due to the\n",
            "unidirectionality of the evolving networks. The Nash equilibrium analysis of\n",
            "the two games facilitates us to give the criterion under which the minority\n",
            "opinion with few disciples initially takes over the population eventually for\n",
            "in-group bias. Our work fosters the understanding of opinion dynamics ranging\n",
            "from methodology to research content.\n",
            "['Uni-directional social interactions are ubiquitous in real social networks\\nwhereas undirected interactions are intensively studied.', 'We establish a voter\\nmodel in a dynamical directed network.', 'We analytically obtain the degree\\ndistribution of the evolving network at any given time.', 'Furthermore, we find\\nthat the average degree is captured by an emergent game.', 'On the other hand, we\\nfind that the fate of opinions is captured by another emergent game.', 'Beyond\\nexpectation, the two emergent games are typically different due to the\\nunidirectionality of the evolving networks.', 'The Nash equilibrium analysis of\\nthe two games facilitates us to give the criterion under which the minority\\nopinion with few disciples initially takes over the population eventually for\\nin-group bias.', 'Our work fosters the understanding of opinion dynamics ranging\\nfrom methodology to research content.']\n",
            "Chunks for abstract: A new approach is given to property $(P_q)$ defined by Catlin for $q=1$ in a\n",
            "global and by Sibony in a local context, subsequently extended by Fu-Straube\n",
            "for $q>1$. This property is known to imply compactness and global regularity in\n",
            "the $\\bar\\partial$-Neumann problem by a result of Kohn-Nirenberg, as well as\n",
            "condition $R$ by a result of Bell-Ligocka. In particular, we provide a\n",
            "self-contained proof of property $(P_q)$ for pseudoconvex hypersurfaces of\n",
            "finite D'Angelo $q$-type, the case originally studied by Catlin. Moreover, our\n",
            "proof covers more general classes of hypersurfaces inspired by a recent work of\n",
            "Huang-Yin. Proofs are broken down into isolated steps, some of which do not\n",
            "require pseudoconvexity.\n",
            "  Our tools include: a new multitype invariant based on distinguished nested\n",
            "sequences of $(1,0)$ subbundles, defined in terms of derivatives of the Levi\n",
            "form; real and complex formal orbits; $k$-jets of functions relative to pairs\n",
            "of formal submanifolds; relative contact orders generalizing the usual contact\n",
            "orders; a new notion of supertangent vector fields having higher than expected\n",
            "relative contact orders; and a formal variant of a result by Diederich-Forn\\ae\n",
            "ss arising as a key step in their proof of Kohn's ideal termination in the\n",
            "real-analytic case.\n",
            "['A new approach is given to property $(P_q)$ defined by Catlin for $q=1$ in a\\nglobal and by Sibony in a local context, subsequently extended by Fu-Straube\\nfor $q>1$.', 'This property is known to imply compactness and global regularity in\\nthe $\\\\bar\\\\partial$-Neumann problem by a result of Kohn-Nirenberg, as well as\\ncondition $R$ by a result of Bell-Ligocka.', \"In particular, we provide a\\nself-contained proof of property $(P_q)$ for pseudoconvex hypersurfaces of\\nfinite D'Angelo $q$-type, the case originally studied by Catlin.\", 'Moreover, our\\nproof covers more general classes of hypersurfaces inspired by a recent work of\\nHuang-Yin.', 'Proofs are broken down into isolated steps, some of which do not\\nrequire pseudoconvexity.', \"Our tools include: a new multitype invariant based on distinguished nested\\nsequences of $(1,0)$ subbundles, defined in terms of derivatives of the Levi\\nform; real and complex formal orbits; $k$-jets of functions relative to pairs\\nof formal submanifolds; relative contact orders generalizing the usual contact\\norders; a new notion of supertangent vector fields having higher than expected\\nrelative contact orders; and a formal variant of a result by Diederich-Forn\\\\ae\\nss arising as a key step in their proof of Kohn's ideal termination in the\\nreal-analytic case.\"]\n",
            "Chunks for abstract: Large language models (LLMs) have provided a lot of exciting new capabilities\n",
            "in software development. However, the opaque nature of these models makes them\n",
            "difficult to reason about and inspect. Their opacity gives rise to potential\n",
            "security risks, as adversaries can train and deploy compromised models to\n",
            "disrupt the software development process in the victims' organization.\n",
            "  This work presents an overview of the current state-of-the-art trojan attacks\n",
            "on large language models of code, with a focus on triggers -- the main design\n",
            "point of trojans -- with the aid of a novel unifying trigger taxonomy\n",
            "framework. We also aim to provide a uniform definition of the fundamental\n",
            "concepts in the area of trojans in Code LLMs. Finally, we draw implications of\n",
            "findings on how code models learn on trigger design.\n",
            "['Large language models (LLMs) have provided a lot of exciting new capabilities\\nin software development.', 'However, the opaque nature of these models makes them\\ndifficult to reason about and inspect.', \"Their opacity gives rise to potential\\nsecurity risks, as adversaries can train and deploy compromised models to\\ndisrupt the software development process in the victims' organization.\", 'This work presents an overview of the current state-of-the-art trojan attacks\\non large language models of code, with a focus on triggers -- the main design\\npoint of trojans -- with the aid of a novel unifying trigger taxonomy\\nframework.', 'We also aim to provide a uniform definition of the fundamental\\nconcepts in the area of trojans in Code LLMs.', 'Finally, we draw implications of\\nfindings on how code models learn on trigger design.']\n",
            "Chunks for abstract: In recent years, AI-Generated Content (AIGC) has witnessed rapid\n",
            "advancements, facilitating the generation of music, images, and other forms of\n",
            "artistic expression across various industries. However, researches on general\n",
            "multi-modal music generation model remain scarce. To fill this gap, we propose\n",
            "a multi-modal music generation framework Mozart's Touch. It could generate\n",
            "aligned music with the cross-modality inputs, such as images, videos and text.\n",
            "Mozart's Touch is composed of three main components: Multi-modal Captioning\n",
            "Module, Large Language Model (LLM) Understanding & Bridging Module, and Music\n",
            "Generation Module. Unlike traditional approaches, Mozart's Touch requires no\n",
            "training or fine-tuning pre-trained models, offering efficiency and\n",
            "transparency through clear, interpretable prompts. We also introduce\n",
            "\"LLM-Bridge\" method to resolve the heterogeneous representation problems\n",
            "between descriptive texts of different modalities. We conduct a series of\n",
            "objective and subjective evaluations on the proposed model, and results\n",
            "indicate that our model surpasses the performance of current state-of-the-art\n",
            "models. Our codes and examples is availble at:\n",
            "https://github.com/WangTooNaive/MozartsTouch\n",
            "['In recent years, AI-Generated Content (AIGC) has witnessed rapid\\nadvancements, facilitating the generation of music, images, and other forms of\\nartistic expression across various industries.', 'However, researches on general\\nmulti-modal music generation model remain scarce.', \"To fill this gap, we propose\\na multi-modal music generation framework Mozart's Touch.\", 'It could generate\\naligned music with the cross-modality inputs, such as images, videos and text.', \"Mozart's Touch is composed of three main components: Multi-modal Captioning\\nModule, Large Language Model (LLM) Understanding & Bridging Module, and Music\\nGeneration Module.\", \"Unlike traditional approaches, Mozart's Touch requires no\\ntraining or fine-tuning pre-trained models, offering efficiency and\\ntransparency through clear, interpretable prompts.\", 'We also introduce\\n\"LLM-Bridge\" method to resolve the heterogeneous representation problems\\nbetween descriptive texts of different modalities.', 'We conduct a series of\\nobjective and subjective evaluations on the proposed model, and results\\nindicate that our model surpasses the performance of current state-of-the-art\\nmodels.', 'Our codes and examples is availble at:\\nhttps://github.com/WangTooNaive/MozartsTouch']\n",
            "Chunks for abstract: Structural balance theory predicts that triads in networks gravitate towards\n",
            "stable configurations. The theory has been verified for undirected graphs.\n",
            "Since real-world networks are often directed, we introduce a novel method for\n",
            "considering both transitivity and sign consistency for evaluating partial\n",
            "balance in signed digraphs. We test our approach on graphs constructed by using\n",
            "different methods for identifying edge signs: natural language processing to\n",
            "infer signs from underlying text data, and self-reported survey data. Our\n",
            "results show that for various social contexts and edge sign detection methods,\n",
            "partial balance of these digraphs are moderately high, ranging from 61% to 96%.\n",
            "Our approach not only enhances the theoretical framework of structural balance\n",
            "but also provides practical insights into the stability of social networks,\n",
            "enabling a deeper understanding of interpersonal and group dynamics across\n",
            "different communication platforms.\n",
            "['Structural balance theory predicts that triads in networks gravitate towards\\nstable configurations.', 'The theory has been verified for undirected graphs.', 'Since real-world networks are often directed, we introduce a novel method for\\nconsidering both transitivity and sign consistency for evaluating partial\\nbalance in signed digraphs.', 'We test our approach on graphs constructed by using\\ndifferent methods for identifying edge signs: natural language processing to\\ninfer signs from underlying text data, and self-reported survey data.', 'Our\\nresults show that for various social contexts and edge sign detection methods,\\npartial balance of these digraphs are moderately high, ranging from 61% to 96%.', 'Our approach not only enhances the theoretical framework of structural balance\\nbut also provides practical insights into the stability of social networks,\\nenabling a deeper understanding of interpersonal and group dynamics across\\ndifferent communication platforms.']\n",
            "Chunks for abstract: Despite the longstanding adage \"an image is worth a thousand words,\" creating\n",
            "accurate and hyper-detailed image descriptions for training Vision-Language\n",
            "models remains challenging. Current datasets typically have web-scraped\n",
            "descriptions that are short, low-granularity, and often contain details\n",
            "unrelated to the visual content. As a result, models trained on such data\n",
            "generate descriptions replete with missing information, visual inconsistencies,\n",
            "and hallucinations. To address these issues, we introduce ImageInWords (IIW), a\n",
            "carefully designed human-in-the-loop annotation framework for curating\n",
            "hyper-detailed image descriptions and a new dataset resulting from this\n",
            "process. We validate the framework through evaluations focused on the quality\n",
            "of the dataset and its utility for fine-tuning with considerations for\n",
            "readability, comprehensiveness, specificity, hallucinations, and\n",
            "human-likeness. Our dataset significantly improves across these dimensions\n",
            "compared to recently released datasets (+66%) and GPT-4V outputs (+48%).\n",
            "Furthermore, models fine-tuned with IIW data excel by +31% against prior work\n",
            "along the same human evaluation dimensions. Given our fine-tuned models, we\n",
            "also evaluate text-to-image generation and vision-language reasoning. Our\n",
            "model's descriptions can generate images closest to the original, as judged by\n",
            "both automated and human metrics. We also find our model produces more\n",
            "compositionally rich descriptions, outperforming the best baseline by up to 6%\n",
            "on ARO, SVO-Probes, and Winoground datasets.\n",
            "['Despite the longstanding adage \"an image is worth a thousand words,\" creating\\naccurate and hyper-detailed image descriptions for training Vision-Language\\nmodels remains challenging.', 'Current datasets typically have web-scraped\\ndescriptions that are short, low-granularity, and often contain details\\nunrelated to the visual content.', 'As a result, models trained on such data\\ngenerate descriptions replete with missing information, visual inconsistencies,\\nand hallucinations.', 'To address these issues, we introduce ImageInWords (IIW), a\\ncarefully designed human-in-the-loop annotation framework for curating\\nhyper-detailed image descriptions and a new dataset resulting from this\\nprocess.', 'We validate the framework through evaluations focused on the quality\\nof the dataset and its utility for fine-tuning with considerations for\\nreadability, comprehensiveness, specificity, hallucinations, and\\nhuman-likeness.', 'Our dataset significantly improves across these dimensions\\ncompared to recently released datasets (+66%) and GPT-4V outputs (+48%).', 'Furthermore, models fine-tuned with IIW data excel by +31% against prior work\\nalong the same human evaluation dimensions.', 'Given our fine-tuned models, we\\nalso evaluate text-to-image generation and vision-language reasoning.', \"Our\\nmodel's descriptions can generate images closest to the original, as judged by\\nboth automated and human metrics.\", 'We also find our model produces more\\ncompositionally rich descriptions, outperforming the best baseline by up to 6%\\non ARO, SVO-Probes, and Winoground datasets.']\n",
            "Chunks for abstract: Motion diffusion models have recently proven successful for text-driven human\n",
            "motion generation. Despite their excellent generation performance, they are\n",
            "challenging to infer in real time due to the multi-step sampling mechanism that\n",
            "involves tens or hundreds of repeat function evaluation iterations. To this\n",
            "end, we investigate a motion latent consistency Training (MLCT) for motion\n",
            "generation to alleviate the computation and time consumption during iteration\n",
            "inference. It applies diffusion pipelines to low-dimensional motion latent\n",
            "spaces to mitigate the computational burden of each function evaluation.\n",
            "Explaining the diffusion process with probabilistic flow ordinary differential\n",
            "equation (PF-ODE) theory, the MLCT allows extremely few steps infer between the\n",
            "prior distribution to the motion latent representation distribution via\n",
            "maintaining consistency of the outputs over the trajectory of PF-ODE.\n",
            "Especially, we introduce a quantization constraint to optimize motion latent\n",
            "representations that are bounded, regular, and well-reconstructed compared to\n",
            "traditional variational constraints. Furthermore, we propose a conditional\n",
            "PF-ODE trajectory simulation method, which improves the conditional generation\n",
            "performance with minimal additional training costs. Extensive experiments on\n",
            "two human motion generation benchmarks show that the proposed model achieves\n",
            "state-of-the-art performance with less than 10\\% time cost.\n",
            "['Motion diffusion models have recently proven successful for text-driven human\\nmotion generation.', 'Despite their excellent generation performance, they are\\nchallenging to infer in real time due to the multi-step sampling mechanism that\\ninvolves tens or hundreds of repeat function evaluation iterations.', 'To this\\nend, we investigate a motion latent consistency Training (MLCT) for motion\\ngeneration to alleviate the computation and time consumption during iteration\\ninference.', 'It applies diffusion pipelines to low-dimensional motion latent\\nspaces to mitigate the computational burden of each function evaluation.', 'Explaining the diffusion process with probabilistic flow ordinary differential\\nequation (PF-ODE) theory, the MLCT allows extremely few steps infer between the\\nprior distribution to the motion latent representation distribution via\\nmaintaining consistency of the outputs over the trajectory of PF-ODE.', 'Especially, we introduce a quantization constraint to optimize motion latent\\nrepresentations that are bounded, regular, and well-reconstructed compared to\\ntraditional variational constraints.', 'Furthermore, we propose a conditional\\nPF-ODE trajectory simulation method, which improves the conditional generation\\nperformance with minimal additional training costs.', 'Extensive experiments on\\ntwo human motion generation benchmarks show that the proposed model achieves\\nstate-of-the-art performance with less than 10\\\\% time cost.']\n",
            "Chunks for abstract: Artificial neural networks trained on large, expert-labelled datasets are\n",
            "considered state-of-the-art for a range of medical image recognition tasks.\n",
            "However, categorically labelled datasets are time-consuming to generate and\n",
            "constrain classification to a pre-defined, fixed set of classes. For\n",
            "neuroradiological applications in particular, this represents a barrier to\n",
            "clinical adoption. To address these challenges, we present a self-supervised\n",
            "text-vision framework that learns to detect clinically relevant abnormalities\n",
            "in brain MRI scans by directly leveraging the rich information contained in\n",
            "accompanying free-text neuroradiology reports. Our training approach consisted\n",
            "of two-steps. First, a dedicated neuroradiological language model - NeuroBERT -\n",
            "was trained to generate fixed-dimensional vector representations of\n",
            "neuroradiology reports (N = 50,523) via domain-specific self-supervised\n",
            "learning tasks. Next, convolutional neural networks (one per MRI sequence)\n",
            "learnt to map individual brain scans to their corresponding text vector\n",
            "representations by optimising a mean square error loss. Once trained, our\n",
            "text-vision framework can be used to detect abnormalities in unreported brain\n",
            "MRI examinations by scoring scans against suitable query sentences (e.g.,\n",
            "'there is an acute stroke', 'there is hydrocephalus' etc.), enabling a range of\n",
            "classification-based applications including automated triage. Potentially, our\n",
            "framework could also serve as a clinical decision support tool, not only by\n",
            "suggesting findings to radiologists and detecting errors in provisional\n",
            "reports, but also by retrieving and displaying examples of pathologies from\n",
            "historical examinations that could be relevant to the current case based on\n",
            "textual descriptors.\n",
            "['Artificial neural networks trained on large, expert-labelled datasets are\\nconsidered state-of-the-art for a range of medical image recognition tasks.', 'However, categorically labelled datasets are time-consuming to generate and\\nconstrain classification to a pre-defined, fixed set of classes.', 'For\\nneuroradiological applications in particular, this represents a barrier to\\nclinical adoption.', 'To address these challenges, we present a self-supervised\\ntext-vision framework that learns to detect clinically relevant abnormalities\\nin brain MRI scans by directly leveraging the rich information contained in\\naccompanying free-text neuroradiology reports.', 'Our training approach consisted\\nof two-steps.', 'First, a dedicated neuroradiological language model - NeuroBERT -\\nwas trained to generate fixed-dimensional vector representations of\\nneuroradiology reports (N = 50,523) via domain-specific self-supervised\\nlearning tasks.', 'Next, convolutional neural networks (one per MRI sequence)\\nlearnt to map individual brain scans to their corresponding text vector\\nrepresentations by optimising a mean square error loss.', \"Once trained, our\\ntext-vision framework can be used to detect abnormalities in unreported brain\\nMRI examinations by scoring scans against suitable query sentences (e.g.,\\n'there is an acute stroke', 'there is hydrocephalus' etc.\", '), enabling a range of\\nclassification-based applications including automated triage.', 'Potentially, our\\nframework could also serve as a clinical decision support tool, not only by\\nsuggesting findings to radiologists and detecting errors in provisional\\nreports, but also by retrieving and displaying examples of pathologies from\\nhistorical examinations that could be relevant to the current case based on\\ntextual descriptors.']\n",
            "Chunks for abstract: Large Language Models (LLMs) have revolutionized natural language processing,\n",
            "but their robustness against adversarial attacks remains a critical concern. We\n",
            "presents a novel white-box style attack approach that exposes vulnerabilities\n",
            "in leading open-source LLMs, including Llama, OPT, and T5. We assess the impact\n",
            "of model size, structure, and fine-tuning strategies on their resistance to\n",
            "adversarial perturbations. Our comprehensive evaluation across five diverse\n",
            "text classification tasks establishes a new benchmark for LLM robustness. The\n",
            "findings of this study have far-reaching implications for the reliable\n",
            "deployment of LLMs in real-world applications and contribute to the advancement\n",
            "of trustworthy AI systems.\n",
            "['Large Language Models (LLMs) have revolutionized natural language processing,\\nbut their robustness against adversarial attacks remains a critical concern.', 'We\\npresents a novel white-box style attack approach that exposes vulnerabilities\\nin leading open-source LLMs, including Llama, OPT, and T5.', 'We assess the impact\\nof model size, structure, and fine-tuning strategies on their resistance to\\nadversarial perturbations.', 'Our comprehensive evaluation across five diverse\\ntext classification tasks establishes a new benchmark for LLM robustness.', 'The\\nfindings of this study have far-reaching implications for the reliable\\ndeployment of LLMs in real-world applications and contribute to the advancement\\nof trustworthy AI systems.']\n",
            "Chunks for abstract: Relevant language describing trends in data can be useful for generating\n",
            "summaries to help with readers' takeaways. However, the language employed in\n",
            "these often template-generated summaries tends to be simple, ranging from\n",
            "describing simple statistical information (e.g., extrema and trends) without\n",
            "additional context and richer language to provide actionable insights. Recent\n",
            "advances in Large Language Models (LLMs) have shown promising capabilities in\n",
            "capturing subtle nuances in language when describing information. This workshop\n",
            "paper specifically explores how LLMs can provide more actionable insights when\n",
            "describing trends by focusing on three dimensions of analytical narrative\n",
            "structure: semantic, rhetorical, and pragmatic. Building on prior research that\n",
            "examines visual and linguistic signatures for univariate line charts, we\n",
            "examine how LLMs can further leverage the semantic dimension of analytical\n",
            "narratives using quantified semantics to describe shapes in trends as people\n",
            "intuitively view them. These semantic descriptions help convey insights in a\n",
            "way that leads to a pragmatic outcome, i.e., a call to action, persuasion,\n",
            "warning vs. alert, and situational awareness. Finally, we identify rhetorical\n",
            "implications for how well these generated narratives align with the perceived\n",
            "shape of the data, thereby empowering users to make informed decisions and take\n",
            "meaningful actions based on these data insights.\n",
            "[\"Relevant language describing trends in data can be useful for generating\\nsummaries to help with readers' takeaways.\", 'However, the language employed in\\nthese often template-generated summaries tends to be simple, ranging from\\ndescribing simple statistical information (e.g., extrema and trends) without\\nadditional context and richer language to provide actionable insights.', 'Recent\\nadvances in Large Language Models (LLMs) have shown promising capabilities in\\ncapturing subtle nuances in language when describing information.', 'This workshop\\npaper specifically explores how LLMs can provide more actionable insights when\\ndescribing trends by focusing on three dimensions of analytical narrative\\nstructure: semantic, rhetorical, and pragmatic.', 'Building on prior research that\\nexamines visual and linguistic signatures for univariate line charts, we\\nexamine how LLMs can further leverage the semantic dimension of analytical\\nnarratives using quantified semantics to describe shapes in trends as people\\nintuitively view them.', 'These semantic descriptions help convey insights in a\\nway that leads to a pragmatic outcome, i.e., a call to action, persuasion,\\nwarning vs. alert, and situational awareness.', 'Finally, we identify rhetorical\\nimplications for how well these generated narratives align with the perceived\\nshape of the data, thereby empowering users to make informed decisions and take\\nmeaningful actions based on these data insights.']\n",
            "Chunks for abstract: Deep reinforcement learning (DRL) has demonstrated remarkable performance in\n",
            "many continuous control tasks. However, a significant obstacle to the\n",
            "real-world application of DRL is the lack of safety guarantees. Although DRL\n",
            "agents can satisfy system safety in expectation through reward shaping,\n",
            "designing agents to consistently meet hard constraints (e.g., safety\n",
            "specifications) at every time step remains a formidable challenge. In contrast,\n",
            "existing work in the field of safe control provides guarantees on persistent\n",
            "satisfaction of hard safety constraints. However, these methods require\n",
            "explicit analytical system dynamics models to synthesize safe control, which\n",
            "are typically inaccessible in DRL settings. In this paper, we present a\n",
            "model-free safe control algorithm, the implicit safe set algorithm, for\n",
            "synthesizing safeguards for DRL agents that ensure provable safety throughout\n",
            "training. The proposed algorithm synthesizes a safety index (barrier\n",
            "certificate) and a subsequent safe control law solely by querying a black-box\n",
            "dynamic function (e.g., a digital twin simulator). Moreover, we theoretically\n",
            "prove that the implicit safe set algorithm guarantees finite time convergence\n",
            "to the safe set and forward invariance for both continuous-time and\n",
            "discrete-time systems. We validate the proposed algorithm on the\n",
            "state-of-the-art Safety Gym benchmark, where it achieves zero safety violations\n",
            "while gaining $95\\% \\pm 9\\%$ cumulative reward compared to state-of-the-art\n",
            "safe DRL methods. Furthermore, the resulting algorithm scales well to\n",
            "high-dimensional systems with parallel computing.\n",
            "['Deep reinforcement learning (DRL) has demonstrated remarkable performance in\\nmany continuous control tasks.', 'However, a significant obstacle to the\\nreal-world application of DRL is the lack of safety guarantees.', 'Although DRL\\nagents can satisfy system safety in expectation through reward shaping,\\ndesigning agents to consistently meet hard constraints (e.g., safety\\nspecifications) at every time step remains a formidable challenge.', 'In contrast,\\nexisting work in the field of safe control provides guarantees on persistent\\nsatisfaction of hard safety constraints.', 'However, these methods require\\nexplicit analytical system dynamics models to synthesize safe control, which\\nare typically inaccessible in DRL settings.', 'In this paper, we present a\\nmodel-free safe control algorithm, the implicit safe set algorithm, for\\nsynthesizing safeguards for DRL agents that ensure provable safety throughout\\ntraining.', 'The proposed algorithm synthesizes a safety index (barrier\\ncertificate) and a subsequent safe control law solely by querying a black-box\\ndynamic function (e.g., a digital twin simulator).', 'Moreover, we theoretically\\nprove that the implicit safe set algorithm guarantees finite time convergence\\nto the safe set and forward invariance for both continuous-time and\\ndiscrete-time systems.', 'We validate the proposed algorithm on the\\nstate-of-the-art Safety Gym benchmark, where it achieves zero safety violations\\nwhile gaining $95\\\\% \\\\pm 9\\\\%$ cumulative reward compared to state-of-the-art\\nsafe DRL methods.', 'Furthermore, the resulting algorithm scales well to\\nhigh-dimensional systems with parallel computing.']\n",
            "Chunks for abstract: Large language models (LLMs) tend to inadequately integrate input context\n",
            "during text generation, relying excessively on encoded prior knowledge in model\n",
            "parameters, potentially resulting in generated text with factual\n",
            "inconsistencies or contextually unfaithful content. LLMs utilize two primary\n",
            "knowledge sources: 1) prior (parametric) knowledge from pretraining, and 2)\n",
            "contextual (non-parametric) knowledge from input prompts. The study addresses\n",
            "the open question of how LLMs effectively balance these knowledge sources\n",
            "during the generation process, specifically in the context of open-domain\n",
            "question answering. To address this issue, we introduce a novel approach\n",
            "integrating contrastive decoding with adversarial irrelevant passages as\n",
            "negative samples to enhance robust context grounding during generation.\n",
            "Notably, our method operates at inference time without requiring further\n",
            "training. We conduct comprehensive experiments to demonstrate its applicability\n",
            "and effectiveness, providing empirical evidence showcasing its superiority over\n",
            "existing methodologies. Our code is publicly available at:\n",
            "https://github.com/amazon-science/ContextualUnderstanding-ContrastiveDecoding.\n",
            "['Large language models (LLMs) tend to inadequately integrate input context\\nduring text generation, relying excessively on encoded prior knowledge in model\\nparameters, potentially resulting in generated text with factual\\ninconsistencies or contextually unfaithful content.', 'LLMs utilize two primary\\nknowledge sources: 1) prior (parametric) knowledge from pretraining, and 2)\\ncontextual (non-parametric) knowledge from input prompts.', 'The study addresses\\nthe open question of how LLMs effectively balance these knowledge sources\\nduring the generation process, specifically in the context of open-domain\\nquestion answering.', 'To address this issue, we introduce a novel approach\\nintegrating contrastive decoding with adversarial irrelevant passages as\\nnegative samples to enhance robust context grounding during generation.', 'Notably, our method operates at inference time without requiring further\\ntraining.', 'We conduct comprehensive experiments to demonstrate its applicability\\nand effectiveness, providing empirical evidence showcasing its superiority over\\nexisting methodologies.', 'Our code is publicly available at:\\nhttps://github.com/amazon-science/ContextualUnderstanding-ContrastiveDecoding.']\n",
            "Chunks for abstract: While Large Language Models (LLMs) have demonstrated significant promise as\n",
            "agents in interactive tasks, their substantial computational requirements and\n",
            "restricted number of calls constrain their practical utility, especially in\n",
            "long-horizon interactive tasks such as decision-making or in scenarios\n",
            "involving continuous ongoing tasks. To address these constraints, we propose a\n",
            "method for transferring the performance of an LLM with billions of parameters\n",
            "to a much smaller language model (770M parameters). Our approach involves\n",
            "constructing a hierarchical agent comprising a planning module, which learns\n",
            "through Knowledge Distillation from an LLM to generate sub-goals, and an\n",
            "execution module, which learns to accomplish these sub-goals using elementary\n",
            "actions. In detail, we leverage an LLM to annotate an oracle path with a\n",
            "sequence of sub-goals towards completing a goal. Subsequently, we utilize this\n",
            "annotated data to fine-tune both the planning and execution modules.\n",
            "Importantly, neither module relies on real-time access to an LLM during\n",
            "inference, significantly reducing the overall cost associated with LLM\n",
            "interactions to a fixed cost. In ScienceWorld, a challenging and multi-task\n",
            "interactive text environment, our method surpasses standard imitation learning\n",
            "based solely on elementary actions by 16.7% (absolute). Our analysis highlights\n",
            "the efficiency of our approach compared to other LLM-based methods. Our code\n",
            "and annotated data for distillation can be found on GitHub.\n",
            "['While Large Language Models (LLMs) have demonstrated significant promise as\\nagents in interactive tasks, their substantial computational requirements and\\nrestricted number of calls constrain their practical utility, especially in\\nlong-horizon interactive tasks such as decision-making or in scenarios\\ninvolving continuous ongoing tasks.', 'To address these constraints, we propose a\\nmethod for transferring the performance of an LLM with billions of parameters\\nto a much smaller language model (770M parameters).', 'Our approach involves\\nconstructing a hierarchical agent comprising a planning module, which learns\\nthrough Knowledge Distillation from an LLM to generate sub-goals, and an\\nexecution module, which learns to accomplish these sub-goals using elementary\\nactions.', 'In detail, we leverage an LLM to annotate an oracle path with a\\nsequence of sub-goals towards completing a goal.', 'Subsequently, we utilize this\\nannotated data to fine-tune both the planning and execution modules.', 'Importantly, neither module relies on real-time access to an LLM during\\ninference, significantly reducing the overall cost associated with LLM\\ninteractions to a fixed cost.', 'In ScienceWorld, a challenging and multi-task\\ninteractive text environment, our method surpasses standard imitation learning\\nbased solely on elementary actions by 16.7% (absolute).', 'Our analysis highlights\\nthe efficiency of our approach compared to other LLM-based methods.', 'Our code\\nand annotated data for distillation can be found on GitHub.']\n",
            "Chunks for abstract: Methods for relation extraction from text mostly focus on high precision, at\n",
            "the cost of limited recall. High recall is crucial, though, to populate long\n",
            "lists of object entities that stand in a specific relation with a given\n",
            "subject. Cues for relevant objects can be spread across many passages in long\n",
            "texts. This poses the challenge of extracting long lists from long texts. We\n",
            "present the L3X method which tackles the problem in two stages: (1)\n",
            "recall-oriented generation using a large language model (LLM) with judicious\n",
            "techniques for retrieval augmentation, and (2) precision-oriented\n",
            "scrutinization to validate or prune candidates. Our L3X method outperforms\n",
            "LLM-only generations by a substantial margin.\n",
            "['Methods for relation extraction from text mostly focus on high precision, at\\nthe cost of limited recall.', 'High recall is crucial, though, to populate long\\nlists of object entities that stand in a specific relation with a given\\nsubject.', 'Cues for relevant objects can be spread across many passages in long\\ntexts.', 'This poses the challenge of extracting long lists from long texts.', 'We\\npresent the L3X method which tackles the problem in two stages: (1)\\nrecall-oriented generation using a large language model (LLM) with judicious\\ntechniques for retrieval augmentation, and (2) precision-oriented\\nscrutinization to validate or prune candidates.', 'Our L3X method outperforms\\nLLM-only generations by a substantial margin.']\n",
            "Chunks for abstract: Placement of electromagnetic signal emitting devices, such as light sources,\n",
            "has important usage in for signal coverage tasks. Automatic placement of these\n",
            "devices is challenging because of the complex interaction of the signal and\n",
            "environment due to reflection, refraction and scattering. In this work, we\n",
            "iteratively improve the placement of these devices by interleaving device\n",
            "placement and sensing actions, correcting errors in the model of the signal\n",
            "propagation. To this end, we propose a novel factor-graph based belief model\n",
            "which combines the measurements taken by the robot and an analytical light\n",
            "propagation model. This model allows accurately modelling the uncertainty of\n",
            "the light propagation with respect to the obstacles, which greatly improves the\n",
            "informative path planning routine. Additionally, we propose a method for\n",
            "determining when to re-plan the emitter placements to balance a trade-off\n",
            "between information about a specific configuration and frequent updating of the\n",
            "configuration. This method incorporates the uncertainty from belief model to\n",
            "adaptively determine when re-configuration is needed. We find that our system\n",
            "has a 9.8% median error reduction compared to a baseline system in simulations\n",
            "in the most difficult environment. We also run on-robot tests and determine\n",
            "that our system performs favorably compared to the baseline.\n",
            "['Placement of electromagnetic signal emitting devices, such as light sources,\\nhas important usage in for signal coverage tasks.', 'Automatic placement of these\\ndevices is challenging because of the complex interaction of the signal and\\nenvironment due to reflection, refraction and scattering.', 'In this work, we\\niteratively improve the placement of these devices by interleaving device\\nplacement and sensing actions, correcting errors in the model of the signal\\npropagation.', 'To this end, we propose a novel factor-graph based belief model\\nwhich combines the measurements taken by the robot and an analytical light\\npropagation model.', 'This model allows accurately modelling the uncertainty of\\nthe light propagation with respect to the obstacles, which greatly improves the\\ninformative path planning routine.', 'Additionally, we propose a method for\\ndetermining when to re-plan the emitter placements to balance a trade-off\\nbetween information about a specific configuration and frequent updating of the\\nconfiguration.', 'This method incorporates the uncertainty from belief model to\\nadaptively determine when re-configuration is needed.', 'We find that our system\\nhas a 9.8% median error reduction compared to a baseline system in simulations\\nin the most difficult environment.', 'We also run on-robot tests and determine\\nthat our system performs favorably compared to the baseline.']\n",
            "Chunks for abstract: Extreme Multi-label Classification (XMC) involves predicting a subset of\n",
            "relevant labels from an extremely large label space, given an input query and\n",
            "labels with textual features. Models developed for this problem have\n",
            "conventionally used modular approach with (i) a Dual Encoder (DE) to embed the\n",
            "queries and label texts, (ii) a One-vs-All classifier to rerank the shortlisted\n",
            "labels mined through meta-classifier training. While such methods have shown\n",
            "empirical success, we observe two key uncharted aspects, (i) DE training\n",
            "typically uses only a single positive relation even for datasets which offer\n",
            "more, (ii) existing approaches fixate on using only OvA reduction of the\n",
            "multi-label problem. This work aims to explore these aspects by proposing\n",
            "UniDEC, a novel end-to-end trainable framework which trains the dual encoder\n",
            "and classifier in together in a unified fashion using a multi-class loss. For\n",
            "the choice of multi-class loss, the work proposes a novel pick-some-label (PSL)\n",
            "reduction of the multi-label problem with leverages multiple (in come cases,\n",
            "all) positives. The proposed framework achieves state-of-the-art results on a\n",
            "single GPU, while achieving on par results with respect to multi-GPU SOTA\n",
            "methods on various XML benchmark datasets, all while using 4-16x lesser compute\n",
            "and being practically scalable even beyond million label scale datasets.\n",
            "['Extreme Multi-label Classification (XMC) involves predicting a subset of\\nrelevant labels from an extremely large label space, given an input query and\\nlabels with textual features.', 'Models developed for this problem have\\nconventionally used modular approach with (i) a Dual Encoder (DE) to embed the\\nqueries and label texts, (ii) a One-vs-All classifier to rerank the shortlisted\\nlabels mined through meta-classifier training.', 'While such methods have shown\\nempirical success, we observe two key uncharted aspects, (i) DE training\\ntypically uses only a single positive relation even for datasets which offer\\nmore, (ii) existing approaches fixate on using only OvA reduction of the\\nmulti-label problem.', 'This work aims to explore these aspects by proposing\\nUniDEC, a novel end-to-end trainable framework which trains the dual encoder\\nand classifier in together in a unified fashion using a multi-class loss.', 'For\\nthe choice of multi-class loss, the work proposes a novel pick-some-label (PSL)\\nreduction of the multi-label problem with leverages multiple (in come cases,\\nall) positives.', 'The proposed framework achieves state-of-the-art results on a\\nsingle GPU, while achieving on par results with respect to multi-GPU SOTA\\nmethods on various XML benchmark datasets, all while using 4-16x lesser compute\\nand being practically scalable even beyond million label scale datasets.']\n",
            "Chunks for abstract: When multitudes of features can plausibly be associated with a response, both\n",
            "privacy considerations and model parsimony suggest grouping them to increase\n",
            "the predictive power of a regression model. Specifically, the identification of\n",
            "groups of predictors significantly associated with the response variable eases\n",
            "further downstream analysis and decision-making. This paper proposes a new data\n",
            "analysis methodology that utilizes the high-dimensional predictor space to\n",
            "construct an implicit network with weighted edges %and weights on the edges to\n",
            "identify significant associations between the response and the predictors.\n",
            "Using a population model for groups of predictors defined via network-wide\n",
            "metrics, a new supervised grouping algorithm is proposed to determine the\n",
            "correct group, with probability tending to one as the sample size diverges to\n",
            "infinity. For this reason, we establish several theoretical properties of the\n",
            "estimates of network-wide metrics. A novel model-assisted bootstrap procedure\n",
            "that substantially decreases computational complexity is developed,\n",
            "facilitating the assessment of uncertainty in the estimates of network-wide\n",
            "metrics. The proposed methods account for several challenges that arise in the\n",
            "high-dimensional data setting, including (i) a large number of predictors, (ii)\n",
            "uncertainty regarding the true statistical model, and (iii) model selection\n",
            "variability. The performance of the proposed methods is demonstrated through\n",
            "numerical experiments, data from sports analytics, and breast cancer data.\n",
            "['When multitudes of features can plausibly be associated with a response, both\\nprivacy considerations and model parsimony suggest grouping them to increase\\nthe predictive power of a regression model.', 'Specifically, the identification of\\ngroups of predictors significantly associated with the response variable eases\\nfurther downstream analysis and decision-making.', 'This paper proposes a new data\\nanalysis methodology that utilizes the high-dimensional predictor space to\\nconstruct an implicit network with weighted edges %and weights on the edges to\\nidentify significant associations between the response and the predictors.', 'Using a population model for groups of predictors defined via network-wide\\nmetrics, a new supervised grouping algorithm is proposed to determine the\\ncorrect group, with probability tending to one as the sample size diverges to\\ninfinity.', 'For this reason, we establish several theoretical properties of the\\nestimates of network-wide metrics.', 'A novel model-assisted bootstrap procedure\\nthat substantially decreases computational complexity is developed,\\nfacilitating the assessment of uncertainty in the estimates of network-wide\\nmetrics.', 'The proposed methods account for several challenges that arise in the\\nhigh-dimensional data setting, including (i) a large number of predictors, (ii)\\nuncertainty regarding the true statistical model, and (iii) model selection\\nvariability.', 'The performance of the proposed methods is demonstrated through\\nnumerical experiments, data from sports analytics, and breast cancer data.']\n",
            "Chunks for abstract: The task of Information Retrieval (IR) requires a system to identify relevant\n",
            "documents based on users' information needs. In real-world scenarios,\n",
            "retrievers are expected to not only rely on the semantic relevance between the\n",
            "documents and the queries but also recognize the nuanced intents or\n",
            "perspectives behind a user query. For example, when asked to verify a claim, a\n",
            "retrieval system is expected to identify evidence from both supporting vs.\n",
            "contradicting perspectives, for the downstream system to make a fair judgment\n",
            "call. In this work, we study whether retrievers can recognize and respond to\n",
            "different perspectives of the queries -- beyond finding relevant documents for\n",
            "a claim, can retrievers distinguish supporting vs. opposing documents? We\n",
            "reform and extend six existing tasks to create a benchmark for retrieval, where\n",
            "we have diverse perspectives described in free-form text, besides root, neutral\n",
            "queries. We show that current retrievers covered in our experiments have\n",
            "limited awareness of subtly different perspectives in queries and can also be\n",
            "biased toward certain perspectives. Motivated by the observation, we further\n",
            "explore the potential to leverage geometric features of retriever\n",
            "representation space to improve the perspective awareness of retrievers in a\n",
            "zero-shot manner. We demonstrate the efficiency and effectiveness of our\n",
            "projection-based methods on the same set of tasks. Further analysis also shows\n",
            "how perspective awareness improves performance on various downstream tasks,\n",
            "with 4.2% higher accuracy on AmbigQA and 29.9% more correlation with designated\n",
            "viewpoints on essay writing, compared to non-perspective-aware baselines.\n",
            "[\"The task of Information Retrieval (IR) requires a system to identify relevant\\ndocuments based on users' information needs.\", 'In real-world scenarios,\\nretrievers are expected to not only rely on the semantic relevance between the\\ndocuments and the queries but also recognize the nuanced intents or\\nperspectives behind a user query.', 'For example, when asked to verify a claim, a\\nretrieval system is expected to identify evidence from both supporting vs.\\ncontradicting perspectives, for the downstream system to make a fair judgment\\ncall.', 'In this work, we study whether retrievers can recognize and respond to\\ndifferent perspectives of the queries -- beyond finding relevant documents for\\na claim, can retrievers distinguish supporting vs. opposing documents?', 'We\\nreform and extend six existing tasks to create a benchmark for retrieval, where\\nwe have diverse perspectives described in free-form text, besides root, neutral\\nqueries.', 'We show that current retrievers covered in our experiments have\\nlimited awareness of subtly different perspectives in queries and can also be\\nbiased toward certain perspectives.', 'Motivated by the observation, we further\\nexplore the potential to leverage geometric features of retriever\\nrepresentation space to improve the perspective awareness of retrievers in a\\nzero-shot manner.', 'We demonstrate the efficiency and effectiveness of our\\nprojection-based methods on the same set of tasks.', 'Further analysis also shows\\nhow perspective awareness improves performance on various downstream tasks,\\nwith 4.2% higher accuracy on AmbigQA and 29.9% more correlation with designated\\nviewpoints on essay writing, compared to non-perspective-aware baselines.']\n",
            "Chunks for abstract: Recently, Large Language Models (LLMs) have been demonstrated to possess\n",
            "impressive capabilities in a variety of domains and tasks. We investigate the\n",
            "issue of prompt design in the multi-turn text-to-SQL task and attempt to\n",
            "enhance the LLMs' reasoning capacity when generating SQL queries. In the\n",
            "conversational context, the current SQL query can be modified from the\n",
            "preceding SQL query with only a few operations due to the context dependency.\n",
            "We introduce our method called CoE-SQL which can prompt LLMs to generate the\n",
            "SQL query based on the previously generated SQL query with an edition chain. We\n",
            "also conduct extensive ablation studies to determine the optimal configuration\n",
            "of our approach. Our approach outperforms different in-context learning\n",
            "baselines stably and achieves state-of-the-art performances on two benchmarks\n",
            "SParC and CoSQL using LLMs, which is also competitive to the SOTA fine-tuned\n",
            "models.\n",
            "['Recently, Large Language Models (LLMs) have been demonstrated to possess\\nimpressive capabilities in a variety of domains and tasks.', \"We investigate the\\nissue of prompt design in the multi-turn text-to-SQL task and attempt to\\nenhance the LLMs' reasoning capacity when generating SQL queries.\", 'In the\\nconversational context, the current SQL query can be modified from the\\npreceding SQL query with only a few operations due to the context dependency.', 'We introduce our method called CoE-SQL which can prompt LLMs to generate the\\nSQL query based on the previously generated SQL query with an edition chain.', 'We\\nalso conduct extensive ablation studies to determine the optimal configuration\\nof our approach.', 'Our approach outperforms different in-context learning\\nbaselines stably and achieves state-of-the-art performances on two benchmarks\\nSParC and CoSQL using LLMs, which is also competitive to the SOTA fine-tuned\\nmodels.']\n",
            "Chunks for abstract: We demonstrate that rotation symmetry is not a necessary requirement for the\n",
            "existence of fractional corner charges in Cn-symmetric higher-order topological\n",
            "crystalline insulators. Instead, it is sufficient to have a latent rotation\n",
            "symmetry, which may be revealed upon performing an isospectral reduction on the\n",
            "system. We introduce the concept of a filling anomaly for latent crystalline\n",
            "symmetric systems, and propose modified topological invariants. The notion of\n",
            "higher- order topology in two dimensions protected by Cn symmetry is thus\n",
            "generalized to a protection by latent symmetry. Our claims are corroborated by\n",
            "concrete examples of models that show non-trivial corner charge in the absence\n",
            "of Cn-symmetry. This work extends the classification of topological crystalline\n",
            "insulators to include latent symmetries.\n",
            "['We demonstrate that rotation symmetry is not a necessary requirement for the\\nexistence of fractional corner charges in Cn-symmetric higher-order topological\\ncrystalline insulators.', 'Instead, it is sufficient to have a latent rotation\\nsymmetry, which may be revealed upon performing an isospectral reduction on the\\nsystem.', 'We introduce the concept of a filling anomaly for latent crystalline\\nsymmetric systems, and propose modified topological invariants.', 'The notion of\\nhigher- order topology in two dimensions protected by Cn symmetry is thus\\ngeneralized to a protection by latent symmetry.', 'Our claims are corroborated by\\nconcrete examples of models that show non-trivial corner charge in the absence\\nof Cn-symmetry.', 'This work extends the classification of topological crystalline\\ninsulators to include latent symmetries.']\n",
            "Chunks for abstract: Retrieval-augmented large language models (LLMs) leverage relevant content\n",
            "retrieved by information retrieval systems to generate correct responses,\n",
            "aiming to alleviate the hallucination problem. However, existing\n",
            "retriever-responder methods typically append relevant documents to the prompt\n",
            "of LLMs to perform text generation tasks without considering the interaction of\n",
            "fine-grained structural semantics between the retrieved documents and the LLMs.\n",
            "This issue is particularly important for accurate response generation as LLMs\n",
            "tend to ``lose in the middle'' when dealing with input prompts augmented with\n",
            "lengthy documents. In this work, we propose a new pipeline named ``Reinforced\n",
            "Retriever-Reorder-Responder'' (R$^4$) to learn document orderings for\n",
            "retrieval-augmented LLMs, thereby further enhancing their generation abilities\n",
            "while the large numbers of parameters of LLMs remain frozen. The reordering\n",
            "learning process is divided into two steps according to the quality of the\n",
            "generated responses: document order adjustment and document representation\n",
            "enhancement. Specifically, document order adjustment aims to organize retrieved\n",
            "document orderings into beginning, middle, and end positions based on graph\n",
            "attention learning, which maximizes the reinforced reward of response quality.\n",
            "Document representation enhancement further refines the representations of\n",
            "retrieved documents for responses of poor quality via document-level gradient\n",
            "adversarial learning. Extensive experiments demonstrate that our proposed\n",
            "pipeline achieves better factual question-answering performance on\n",
            "knowledge-intensive tasks compared to strong baselines across various public\n",
            "datasets. The source codes and trained models will be released upon paper\n",
            "acceptance.\n",
            "['Retrieval-augmented large language models (LLMs) leverage relevant content\\nretrieved by information retrieval systems to generate correct responses,\\naiming to alleviate the hallucination problem.', 'However, existing\\nretriever-responder methods typically append relevant documents to the prompt\\nof LLMs to perform text generation tasks without considering the interaction of\\nfine-grained structural semantics between the retrieved documents and the LLMs.', \"This issue is particularly important for accurate response generation as LLMs\\ntend to ``lose in the middle'' when dealing with input prompts augmented with\\nlengthy documents.\", \"In this work, we propose a new pipeline named ``Reinforced\\nRetriever-Reorder-Responder'' (R$^4$) to learn document orderings for\\nretrieval-augmented LLMs, thereby further enhancing their generation abilities\\nwhile the large numbers of parameters of LLMs remain frozen.\", 'The reordering\\nlearning process is divided into two steps according to the quality of the\\ngenerated responses: document order adjustment and document representation\\nenhancement.', 'Specifically, document order adjustment aims to organize retrieved\\ndocument orderings into beginning, middle, and end positions based on graph\\nattention learning, which maximizes the reinforced reward of response quality.', 'Document representation enhancement further refines the representations of\\nretrieved documents for responses of poor quality via document-level gradient\\nadversarial learning.', 'Extensive experiments demonstrate that our proposed\\npipeline achieves better factual question-answering performance on\\nknowledge-intensive tasks compared to strong baselines across various public\\ndatasets.', 'The source codes and trained models will be released upon paper\\nacceptance.']\n",
            "Chunks for abstract: Interactions of ultra-high energy cosmic-rays (UHECRs) accelerated in\n",
            "astrophysical environments have been shown to shape the energy production rate\n",
            "of nuclei escaping from the confinement zone. To address the influence of\n",
            "hadronic interactions, Hadronic Interaction Models (HIM) come into play. In\n",
            "this context, we present a parameterization capable of capturing the outcomes\n",
            "of two distinct HIMs, namely EPOS-LHC and Sibyll2.3d, in terms of secondary\n",
            "fluxes, including escaping nuclei, neutrinos, photons, and electrons. Our\n",
            "parametrization is systematically evaluated against the source codes, both at\n",
            "fixed energy and mass, as well as in a physical case scenario. The comparison\n",
            "demonstrates that our parameterization aligns well with the source codes,\n",
            "establishing its reliability as a viable alternative for analytical or fast\n",
            "Monte Carlo approaches dedicated to the study of UHECR propagation within\n",
            "source environments. This suggests the potential for utilizing our\n",
            "parameterization as a practical substitute in studies focused on the intricate\n",
            "dynamics of ultra-high energy cosmic rays.\n",
            "['Interactions of ultra-high energy cosmic-rays (UHECRs) accelerated in\\nastrophysical environments have been shown to shape the energy production rate\\nof nuclei escaping from the confinement zone.', 'To address the influence of\\nhadronic interactions, Hadronic Interaction Models (HIM) come into play.', 'In\\nthis context, we present a parameterization capable of capturing the outcomes\\nof two distinct HIMs, namely EPOS-LHC and Sibyll2.3d, in terms of secondary\\nfluxes, including escaping nuclei, neutrinos, photons, and electrons.', 'Our\\nparametrization is systematically evaluated against the source codes, both at\\nfixed energy and mass, as well as in a physical case scenario.', 'The comparison\\ndemonstrates that our parameterization aligns well with the source codes,\\nestablishing its reliability as a viable alternative for analytical or fast\\nMonte Carlo approaches dedicated to the study of UHECR propagation within\\nsource environments.', 'This suggests the potential for utilizing our\\nparameterization as a practical substitute in studies focused on the intricate\\ndynamics of ultra-high energy cosmic rays.']\n",
            "Chunks for abstract: Unmanned aerial vehicles (UAVs) can serve as aerial base stations (ABSs) to\n",
            "provide wireless connectivity for ground users (GUs) in diverse scenarios.\n",
            "However, it is an NP-hard problem with exponential complexity in $M$ and $N$,\n",
            "in order to maximize the coverage rate (CR) of $M$ GUs by jointly placing $N$\n",
            "ABSs with limited coverage range. This problem becomes even more intricate when\n",
            "the coverage range becomes irregular due to site-specific obstructions (e.g.,\n",
            "buildings) on the air-ground channel, and/or when the GUs are in motion. To\n",
            "address the above challenges, we study a multi-ABS movement optimization\n",
            "problem to maximize the average coverage rate of mobile GUs within a\n",
            "site-specific environment. We tackle this challenging problem by 1)\n",
            "constructing the global connectivity map (GCM) which contains the connectivity\n",
            "information between given pairs of ABS/GU locations; 2) partitioning the ABS\n",
            "movement problem into ABS placement sub-problems and formulate each sub-problem\n",
            "into a binary integer linear programing (BILP) problem based on GCM; 3)\n",
            "proposing a fast online algorithm to execute (one-pass) projected stochastic\n",
            "subgradient descent within the dual space to rapidly solve the BILP problem\n",
            "with near-optimal performance. Numerical results demonstrate that our proposed\n",
            "algorithm achieves a high CR performance close to that obtained by the open\n",
            "source solver (SCIP), yet with significantly reduced running time. In addition,\n",
            "the algorithm also notably outperforms one of the state-of-the-art deep\n",
            "reinforcement learning (DRL) methods and the K-means initiated evolutionary\n",
            "algorithm in terms of CR performance and/or time efficiency.\n",
            "['Unmanned aerial vehicles (UAVs) can serve as aerial base stations (ABSs) to\\nprovide wireless connectivity for ground users (GUs) in diverse scenarios.', 'However, it is an NP-hard problem with exponential complexity in $M$ and $N$,\\nin order to maximize the coverage rate (CR) of $M$ GUs by jointly placing $N$\\nABSs with limited coverage range.', 'This problem becomes even more intricate when\\nthe coverage range becomes irregular due to site-specific obstructions (e.g.,\\nbuildings) on the air-ground channel, and/or when the GUs are in motion.', 'To\\naddress the above challenges, we study a multi-ABS movement optimization\\nproblem to maximize the average coverage rate of mobile GUs within a\\nsite-specific environment.', 'We tackle this challenging problem by 1)\\nconstructing the global connectivity map (GCM) which contains the connectivity\\ninformation between given pairs of ABS/GU locations; 2) partitioning the ABS\\nmovement problem into ABS placement sub-problems and formulate each sub-problem\\ninto a binary integer linear programing (BILP) problem based on GCM; 3)\\nproposing a fast online algorithm to execute (one-pass) projected stochastic\\nsubgradient descent within the dual space to rapidly solve the BILP problem\\nwith near-optimal performance.', 'Numerical results demonstrate that our proposed\\nalgorithm achieves a high CR performance close to that obtained by the open\\nsource solver (SCIP), yet with significantly reduced running time.', 'In addition,\\nthe algorithm also notably outperforms one of the state-of-the-art deep\\nreinforcement learning (DRL) methods and the K-means initiated evolutionary\\nalgorithm in terms of CR performance and/or time efficiency.']\n",
            "Chunks for abstract: Conversational information seeking has evolved rapidly in the last few years\n",
            "with the development of Large Language Models (LLMs), providing the basis for\n",
            "interpreting and responding in a naturalistic manner to user requests. The\n",
            "extended TREC Interactive Knowledge Assistance Track (iKAT) collection aims to\n",
            "enable researchers to test and evaluate their Conversational Search Agents\n",
            "(CSA). The collection contains a set of 36 personalized dialogues over 20\n",
            "different topics each coupled with a Personal Text Knowledge Base (PTKB) that\n",
            "defines the bespoke user personas. A total of 344 turns with approximately\n",
            "26,000 passages are provided as assessments on relevance, as well as additional\n",
            "assessments on generated responses over four key dimensions: relevance,\n",
            "completeness, groundedness, and naturalness. The collection challenges CSA to\n",
            "efficiently navigate diverse personal contexts, elicit pertinent persona\n",
            "information, and employ context for relevant conversations. The integration of\n",
            "a PTKB and the emphasis on decisional search tasks contribute to the uniqueness\n",
            "of this test collection, making it an essential benchmark for advancing\n",
            "research in conversational and interactive knowledge assistants.\n",
            "['Conversational information seeking has evolved rapidly in the last few years\\nwith the development of Large Language Models (LLMs), providing the basis for\\ninterpreting and responding in a naturalistic manner to user requests.', 'The\\nextended TREC Interactive Knowledge Assistance Track (iKAT) collection aims to\\nenable researchers to test and evaluate their Conversational Search Agents\\n(CSA).', 'The collection contains a set of 36 personalized dialogues over 20\\ndifferent topics each coupled with a Personal Text Knowledge Base (PTKB) that\\ndefines the bespoke user personas.', 'A total of 344 turns with approximately\\n26,000 passages are provided as assessments on relevance, as well as additional\\nassessments on generated responses over four key dimensions: relevance,\\ncompleteness, groundedness, and naturalness.', 'The collection challenges CSA to\\nefficiently navigate diverse personal contexts, elicit pertinent persona\\ninformation, and employ context for relevant conversations.', 'The integration of\\na PTKB and the emphasis on decisional search tasks contribute to the uniqueness\\nof this test collection, making it an essential benchmark for advancing\\nresearch in conversational and interactive knowledge assistants.']\n",
            "Chunks for abstract: We extend our previous study of the interactions of $\\bar{D}^{(*)} \\Lambda_c\n",
            "- \\bar{D}^{(*)}\\Sigma_c^{(*)}$ within an analytic, unitary, coupled-channel\n",
            "approach by including the $J/\\psi p$ channel and performing fits to the $J/\\psi\n",
            "p$ invariant mass distributions in the $\\Lambda_b^0 \\to J/\\psi p K^-$ decay by\n",
            "the LHCb Collaboration. We take into account the contributions of $t$-channel\n",
            "pseudoscalar and vector meson exchanges and $u$-channel baryon exchanges in\n",
            "this work, and a series of bound states and resonances with different\n",
            "spin-parities are dynamically generated. According to the results, four states\n",
            "have a significant impact on the physical observables, with two having a\n",
            "spin-parity of $1/2^-$ and the other two having $3/2^-$. These states can be\n",
            "associated with the LHCb hidden-charm pentaquarks. We further provide the\n",
            "coupling strength between each pole and different channels, which provides some\n",
            "insights on how to search for them in future experiments. Moreover, we also\n",
            "search for poles in higher partial waves up to $J=7/2$ and find indications for\n",
            "the existence of several states with larger widths.\n",
            "['We extend our previous study of the interactions of $\\\\bar{D}^{(*)} \\\\Lambda_c\\n- \\\\bar{D}^{(*)}\\\\Sigma_c^{(*)}$ within an analytic, unitary, coupled-channel\\napproach by including the $J/\\\\psi p$ channel and performing fits to the $J/\\\\psi\\np$ invariant mass distributions in the $\\\\Lambda_b^0 \\\\to J/\\\\psi p K^-$ decay by\\nthe LHCb Collaboration.', 'We take into account the contributions of $t$-channel\\npseudoscalar and vector meson exchanges and $u$-channel baryon exchanges in\\nthis work, and a series of bound states and resonances with different\\nspin-parities are dynamically generated.', 'According to the results, four states\\nhave a significant impact on the physical observables, with two having a\\nspin-parity of $1/2^-$ and the other two having $3/2^-$.', 'These states can be\\nassociated with the LHCb hidden-charm pentaquarks.', 'We further provide the\\ncoupling strength between each pole and different channels, which provides some\\ninsights on how to search for them in future experiments.', 'Moreover, we also\\nsearch for poles in higher partial waves up to $J=7/2$ and find indications for\\nthe existence of several states with larger widths.']\n",
            "Chunks for abstract: A covering number of a family is the size of the smallest set that intersects\n",
            "all sets from the family. In 1978 Frankl determined for $n\\ge n_0(k)$ the\n",
            "largest intersecting family of $k$-element subsets of $[n]$ with covering\n",
            "number $3$. In this paper, we essentially settle this problem, showing that the\n",
            "same family is extremal for any $k\\ge 100$ and $n>2k$.\n",
            "['A covering number of a family is the size of the smallest set that intersects\\nall sets from the family.', 'In 1978 Frankl determined for $n\\\\ge n_0(k)$ the\\nlargest intersecting family of $k$-element subsets of $[n]$ with covering\\nnumber $3$.', 'In this paper, we essentially settle this problem, showing that the\\nsame family is extremal for any $k\\\\ge 100$ and $n>2k$.']\n",
            "Chunks for abstract: Vico et al. (2016) suggest a fast algorithm for computing volume potentials,\n",
            "beneficial to fields with problems requiring the solution of Poisson's equation\n",
            "with free-space boundary conditions, such as the beam and plasma physics\n",
            "communities. Currently, the standard method for solving the free-space Poisson\n",
            "equation is the algorithm of Hockney and Eastwood (1988), which is second order\n",
            "in convergence at best. The algorithm proposed by Vico et al. converges\n",
            "spectrally for sufficiently smooth functions i.e. faster than any fixed order\n",
            "in the number of grid points. In this paper, we implement a performance\n",
            "portable version of the traditional Hockney-Eastwood and the novel\n",
            "Vico-Greengard Poisson solver as part of the IPPL (Independent Parallel\n",
            "Particle Layer) library. For sufficiently smooth source functions, the\n",
            "Vico-Greengard algorithm achieves higher accuracy than the Hockney-Eastwood\n",
            "method with the same grid size, reducing the computational demands of high\n",
            "resolution simulations since one could use coarser grids to achieve them. More\n",
            "concretely, to get a relative error of $10^{-4}$ between the numerical and\n",
            "analytical solution, one requires only $16^3$ grid points in the former, but\n",
            "$128^3$ in the latter, more than a 99% memory footprint reduction.\n",
            "Additionally, we propose an algorithmic improvement to the Vico-Greengard\n",
            "method which further reduces its memory footprint. This is particularly\n",
            "important for GPUs which have limited memory resources, and should be taken\n",
            "into account when selecting numerical algorithms for performance portable\n",
            "codes. Finally, we showcase performance through GPU and CPU scaling studies on\n",
            "the Perlmutter (NERSC) supercomputer, with efficiencies staying above 50% in\n",
            "the strong scaling case.\n",
            "['Vico et al.', \"(2016) suggest a fast algorithm for computing volume potentials,\\nbeneficial to fields with problems requiring the solution of Poisson's equation\\nwith free-space boundary conditions, such as the beam and plasma physics\\ncommunities.\", 'Currently, the standard method for solving the free-space Poisson\\nequation is the algorithm of Hockney and Eastwood (1988), which is second order\\nin convergence at best.', 'The algorithm proposed by Vico et al.', 'converges\\nspectrally for sufficiently smooth functions i.e.', 'faster than any fixed order\\nin the number of grid points.', 'In this paper, we implement a performance\\nportable version of the traditional Hockney-Eastwood and the novel\\nVico-Greengard Poisson solver as part of the IPPL (Independent Parallel\\nParticle Layer) library.', 'For sufficiently smooth source functions, the\\nVico-Greengard algorithm achieves higher accuracy than the Hockney-Eastwood\\nmethod with the same grid size, reducing the computational demands of high\\nresolution simulations since one could use coarser grids to achieve them.', 'More\\nconcretely, to get a relative error of $10^{-4}$ between the numerical and\\nanalytical solution, one requires only $16^3$ grid points in the former, but\\n$128^3$ in the latter, more than a 99% memory footprint reduction.', 'Additionally, we propose an algorithmic improvement to the Vico-Greengard\\nmethod which further reduces its memory footprint.', 'This is particularly\\nimportant for GPUs which have limited memory resources, and should be taken\\ninto account when selecting numerical algorithms for performance portable\\ncodes.', 'Finally, we showcase performance through GPU and CPU scaling studies on\\nthe Perlmutter (NERSC) supercomputer, with efficiencies staying above 50% in\\nthe strong scaling case.']\n",
            "Chunks for abstract: We propose measurement-producing hierarchy emerging among correlated states\n",
            "by sequential subsystem projective measurements. We start from\n",
            "symmetry-protected-topological (SPT) cluster states with a large symmetry and\n",
            "apply sequential subsystem projective measurements to them and find that\n",
            "generalized cluster SPT states with a reduced symmetry appear in the subsystem\n",
            "of the unmeasured sites. That prescription finally produces\n",
            "Greenberger-Home-Zeilinger states with long-range order in the subsystem\n",
            "composed of periodic unmeasured sites of the original lattice. The\n",
            "symmetry-reduction hierarchical structure from a general large symmetric SPT\n",
            "cluster state is clearly captured by the measurement update flow in the\n",
            "efficient algorithm of stabilizer formalism. This approach is useful not only\n",
            "for the analytical search for the measured state but also for numerical\n",
            "simulation with a large system size. We also numerically verify the\n",
            "symmetry-reduction hierarchy by sequential subsystem projective measurements\n",
            "applied to large systems and large symmetric cluster SPT states.\n",
            "['We propose measurement-producing hierarchy emerging among correlated states\\nby sequential subsystem projective measurements.', 'We start from\\nsymmetry-protected-topological (SPT) cluster states with a large symmetry and\\napply sequential subsystem projective measurements to them and find that\\ngeneralized cluster SPT states with a reduced symmetry appear in the subsystem\\nof the unmeasured sites.', 'That prescription finally produces\\nGreenberger-Home-Zeilinger states with long-range order in the subsystem\\ncomposed of periodic unmeasured sites of the original lattice.', 'The\\nsymmetry-reduction hierarchical structure from a general large symmetric SPT\\ncluster state is clearly captured by the measurement update flow in the\\nefficient algorithm of stabilizer formalism.', 'This approach is useful not only\\nfor the analytical search for the measured state but also for numerical\\nsimulation with a large system size.', 'We also numerically verify the\\nsymmetry-reduction hierarchy by sequential subsystem projective measurements\\napplied to large systems and large symmetric cluster SPT states.']\n",
            "Chunks for abstract: We propose a new model to approximate the wave response of waveguides\n",
            "containing an arbitrary number of small inclusions. The theory is developed to\n",
            "consider any one-dimensional waveguide (longitudinal, flexural, shear,\n",
            "torsional waves or a combination of them by mechanical coupling), containing\n",
            "small inclusions with different material and/or sectional properties. The exact\n",
            "problem is modelled through the formalism of generalised functions, with the\n",
            "Heaviside function accounting for the discontinuous jump in different sectional\n",
            "properties of the inclusions. For asymptotically small inclusions, the exact\n",
            "solution is shown to be equivalent to the Green's function. We hypothesize that\n",
            "these expressions are also valid when the size of the inclusions are small in\n",
            "comparison to the wavelength, allowing us to approximate small inhomogeneities\n",
            "as regular perturbations to the empty-waveguide (the homogeneous waveguide in\n",
            "the absence of scatterers) as point source terms. By approximating solutions\n",
            "through the Green's function, the multiple scattering problem is considerably\n",
            "simplified, allowing us to develop a general methodology in which the solution\n",
            "is expressed for any model for any elastic waveguide. The advantage of our\n",
            "approach is that, by expressing the constitutive equations in first order form\n",
            "as a matrix, the solutions can be expressed in matrix form; therefore, it is\n",
            "trivial to consider models with more degrees of freedom and to arrive at\n",
            "solutions to multiple scattering problems independent of the elastic model\n",
            "used. The theory is validated with two numerical examples, where we perform an\n",
            "error analysis to demonstrate the validity of the approximate solutions, and we\n",
            "propose a parameter quantifying the expected errors in the approximation\n",
            "dependent upon the parameters of the waveguide.\n",
            "['We propose a new model to approximate the wave response of waveguides\\ncontaining an arbitrary number of small inclusions.', 'The theory is developed to\\nconsider any one-dimensional waveguide (longitudinal, flexural, shear,\\ntorsional waves or a combination of them by mechanical coupling), containing\\nsmall inclusions with different material and/or sectional properties.', 'The exact\\nproblem is modelled through the formalism of generalised functions, with the\\nHeaviside function accounting for the discontinuous jump in different sectional\\nproperties of the inclusions.', \"For asymptotically small inclusions, the exact\\nsolution is shown to be equivalent to the Green's function.\", 'We hypothesize that\\nthese expressions are also valid when the size of the inclusions are small in\\ncomparison to the wavelength, allowing us to approximate small inhomogeneities\\nas regular perturbations to the empty-waveguide (the homogeneous waveguide in\\nthe absence of scatterers) as point source terms.', \"By approximating solutions\\nthrough the Green's function, the multiple scattering problem is considerably\\nsimplified, allowing us to develop a general methodology in which the solution\\nis expressed for any model for any elastic waveguide.\", 'The advantage of our\\napproach is that, by expressing the constitutive equations in first order form\\nas a matrix, the solutions can be expressed in matrix form; therefore, it is\\ntrivial to consider models with more degrees of freedom and to arrive at\\nsolutions to multiple scattering problems independent of the elastic model\\nused.', 'The theory is validated with two numerical examples, where we perform an\\nerror analysis to demonstrate the validity of the approximate solutions, and we\\npropose a parameter quantifying the expected errors in the approximation\\ndependent upon the parameters of the waveguide.']\n",
            "Chunks for abstract: Vision-language foundation models like CLIP have shown impressive zero-shot\n",
            "generalization, but finetuning on downstream datasets can cause overfitting and\n",
            "loss of its generalization ability on unseen domains. Although collecting\n",
            "additional data from new domains of interest is possible, this method is often\n",
            "impractical due to the challenges in obtaining annotated data. To address this,\n",
            "we propose a plug-and-play feature augmentation method called LDFS\n",
            "(Language-Guided Diverse Feature Synthesis) to synthesize new domain features\n",
            "and improve existing CLIP fine-tuning strategies. LDFS has three main\n",
            "contributions: 1) To synthesize novel domain features and promote diversity, we\n",
            "propose an instance-conditional feature augmentation strategy based on a\n",
            "textguided feature augmentation loss. 2) To maintain feature quality after\n",
            "augmenting, we introduce a pairwise regularizer to preserve augmented feature\n",
            "coherence within the CLIP feature space. 3) We propose to use stochastic text\n",
            "feature augmentation to reduce the modality gap and further facilitate the\n",
            "process of text-guided feature synthesis. Extensive experiments show LDFS\n",
            "superiority in improving CLIP generalization ability on unseen domains without\n",
            "collecting data from those domains. The code will be made publicly available.\n",
            "['Vision-language foundation models like CLIP have shown impressive zero-shot\\ngeneralization, but finetuning on downstream datasets can cause overfitting and\\nloss of its generalization ability on unseen domains.', 'Although collecting\\nadditional data from new domains of interest is possible, this method is often\\nimpractical due to the challenges in obtaining annotated data.', 'To address this,\\nwe propose a plug-and-play feature augmentation method called LDFS\\n(Language-Guided Diverse Feature Synthesis) to synthesize new domain features\\nand improve existing CLIP fine-tuning strategies.', 'LDFS has three main\\ncontributions: 1) To synthesize novel domain features and promote diversity, we\\npropose an instance-conditional feature augmentation strategy based on a\\ntextguided feature augmentation loss.', '2) To maintain feature quality after\\naugmenting, we introduce a pairwise regularizer to preserve augmented feature\\ncoherence within the CLIP feature space.', '3) We propose to use stochastic text\\nfeature augmentation to reduce the modality gap and further facilitate the\\nprocess of text-guided feature synthesis.', 'Extensive experiments show LDFS\\nsuperiority in improving CLIP generalization ability on unseen domains without\\ncollecting data from those domains.', 'The code will be made publicly available.']\n",
            "Chunks for abstract: Building operations consume 30% of total power consumption and contribute 26%\n",
            "of global power-related emissions. Therefore, monitoring, and early detection\n",
            "of anomalies at the meter level are essential for residential and commercial\n",
            "buildings. This work investigates both supervised and unsupervised approaches\n",
            "and introduces a dynamic anomaly detection system. The system introduces a\n",
            "supervised Light Gradient Boosting machine and an unsupervised autoencoder with\n",
            "a dynamic threshold. This system is designed to provide real-time detection of\n",
            "anomalies at the meter level. The proposed dynamical system comes with a\n",
            "dynamic threshold based on the Mahalanobis distance and moving averages. This\n",
            "approach allows the system to adapt to changes in the data distribution over\n",
            "time. The effectiveness of the proposed system is evaluated using real-life\n",
            "power consumption data collected from smart metering systems. This empirical\n",
            "testing ensures that the system's performance is validated under real-world\n",
            "conditions. By detecting unusual data movements and providing early warnings,\n",
            "the proposed system contributes significantly to visual analytics and decision\n",
            "science. Early detection of anomalies enables timely troubleshooting,\n",
            "preventing financial losses and potential disasters such as fire incidents.\n",
            "['Building operations consume 30% of total power consumption and contribute 26%\\nof global power-related emissions.', 'Therefore, monitoring, and early detection\\nof anomalies at the meter level are essential for residential and commercial\\nbuildings.', 'This work investigates both supervised and unsupervised approaches\\nand introduces a dynamic anomaly detection system.', 'The system introduces a\\nsupervised Light Gradient Boosting machine and an unsupervised autoencoder with\\na dynamic threshold.', 'This system is designed to provide real-time detection of\\nanomalies at the meter level.', 'The proposed dynamical system comes with a\\ndynamic threshold based on the Mahalanobis distance and moving averages.', 'This\\napproach allows the system to adapt to changes in the data distribution over\\ntime.', 'The effectiveness of the proposed system is evaluated using real-life\\npower consumption data collected from smart metering systems.', \"This empirical\\ntesting ensures that the system's performance is validated under real-world\\nconditions.\", 'By detecting unusual data movements and providing early warnings,\\nthe proposed system contributes significantly to visual analytics and decision\\nscience.', 'Early detection of anomalies enables timely troubleshooting,\\npreventing financial losses and potential disasters such as fire incidents.']\n",
            "Chunks for abstract: As generative artificial intelligence (AI), particularly Large Language\n",
            "Models (LLMs), continues to permeate healthcare, it remains crucial to\n",
            "supplement traditional automated evaluations with human expert evaluation.\n",
            "Understanding and evaluating the generated texts is vital for ensuring safety,\n",
            "reliability, and effectiveness. However, the cumbersome, time-consuming, and\n",
            "non-standardized nature of human evaluation presents significant obstacles to\n",
            "the widespread adoption of LLMs in practice. This study reviews existing\n",
            "literature on human evaluation methodologies for LLMs within healthcare. We\n",
            "highlight a notable need for a standardized and consistent human evaluation\n",
            "approach. Our extensive literature search, adhering to the Preferred Reporting\n",
            "Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines, spans\n",
            "publications from January 2018 to February 2024. This review provides a\n",
            "comprehensive overview of the human evaluation approaches used in diverse\n",
            "healthcare applications.This analysis examines the human evaluation of LLMs\n",
            "across various medical specialties, addressing factors such as evaluation\n",
            "dimensions, sample types, and sizes, the selection and recruitment of\n",
            "evaluators, frameworks and metrics, the evaluation process, and statistical\n",
            "analysis of the results. Drawing from diverse evaluation strategies highlighted\n",
            "in these studies, we propose a comprehensive and practical framework for human\n",
            "evaluation of generative LLMs, named QUEST: Quality of Information,\n",
            "Understanding and Reasoning, Expression Style and Persona, Safety and Harm, and\n",
            "Trust and Confidence. This framework aims to improve the reliability,\n",
            "generalizability, and applicability of human evaluation of generative LLMs in\n",
            "different healthcare applications by defining clear evaluation dimensions and\n",
            "offering detailed guidelines.\n",
            "['As generative artificial intelligence (AI), particularly Large Language\\nModels (LLMs), continues to permeate healthcare, it remains crucial to\\nsupplement traditional automated evaluations with human expert evaluation.', 'Understanding and evaluating the generated texts is vital for ensuring safety,\\nreliability, and effectiveness.', 'However, the cumbersome, time-consuming, and\\nnon-standardized nature of human evaluation presents significant obstacles to\\nthe widespread adoption of LLMs in practice.', 'This study reviews existing\\nliterature on human evaluation methodologies for LLMs within healthcare.', 'We\\nhighlight a notable need for a standardized and consistent human evaluation\\napproach.', 'Our extensive literature search, adhering to the Preferred Reporting\\nItems for Systematic Reviews and Meta-Analyses (PRISMA) guidelines, spans\\npublications from January 2018 to February 2024.', 'This review provides a\\ncomprehensive overview of the human evaluation approaches used in diverse\\nhealthcare applications.This analysis examines the human evaluation of LLMs\\nacross various medical specialties, addressing factors such as evaluation\\ndimensions, sample types, and sizes, the selection and recruitment of\\nevaluators, frameworks and metrics, the evaluation process, and statistical\\nanalysis of the results.', 'Drawing from diverse evaluation strategies highlighted\\nin these studies, we propose a comprehensive and practical framework for human\\nevaluation of generative LLMs, named QUEST: Quality of Information,\\nUnderstanding and Reasoning, Expression Style and Persona, Safety and Harm, and\\nTrust and Confidence.', 'This framework aims to improve the reliability,\\ngeneralizability, and applicability of human evaluation of generative LLMs in\\ndifferent healthcare applications by defining clear evaluation dimensions and\\noffering detailed guidelines.']\n",
            "Chunks for abstract: Despite the growing prevalence of large language model (LLM) architectures, a\n",
            "crucial concern persists regarding their energy and power consumption, which\n",
            "still lags far behind the remarkable energy efficiency of the human brain.\n",
            "Recent strides in spiking language models (LM) and transformer architectures\n",
            "aim to address this concern by harnessing the spiking activity of biological\n",
            "neurons to enhance energy/power efficiency. Doubling down on the principles of\n",
            "model quantization and energy efficiency, this paper proposes the development\n",
            "of a novel binary/ternary (1/1.58-bit) spiking LM architecture. Achieving\n",
            "scalability comparable to a deep spiking LM architecture is facilitated by an\n",
            "efficient knowledge distillation technique, wherein knowledge from a\n",
            "non-spiking full-precision \"teacher\" model is transferred to an extremely\n",
            "weight quantized spiking \"student\" LM. Our proposed model represents a\n",
            "significant advancement as the first-of-its-kind 1/1.58-bit spiking LM, and its\n",
            "performance is rigorously evaluated on multiple text classification tasks of\n",
            "the GLUE benchmark.\n",
            "['Despite the growing prevalence of large language model (LLM) architectures, a\\ncrucial concern persists regarding their energy and power consumption, which\\nstill lags far behind the remarkable energy efficiency of the human brain.', 'Recent strides in spiking language models (LM) and transformer architectures\\naim to address this concern by harnessing the spiking activity of biological\\nneurons to enhance energy/power efficiency.', 'Doubling down on the principles of\\nmodel quantization and energy efficiency, this paper proposes the development\\nof a novel binary/ternary (1/1.58-bit) spiking LM architecture.', 'Achieving\\nscalability comparable to a deep spiking LM architecture is facilitated by an\\nefficient knowledge distillation technique, wherein knowledge from a\\nnon-spiking full-precision \"teacher\" model is transferred to an extremely\\nweight quantized spiking \"student\" LM.', 'Our proposed model represents a\\nsignificant advancement as the first-of-its-kind 1/1.58-bit spiking LM, and its\\nperformance is rigorously evaluated on multiple text classification tasks of\\nthe GLUE benchmark.']\n",
            "Chunks for abstract: Random matrix theory is a useful tool in the study of the physics of multiple\n",
            "scattering systems, often striking a balance between computation speed and\n",
            "physical rigour. Propagation of waves through thick disordered media, as arises\n",
            "in for example optical scattering or electron transport, typically necessitates\n",
            "cascading of multiple random matrices drawn from an underlying ensemble for\n",
            "thin media, greatly increasing computational burden. Here we propose a dual\n",
            "pool based bootstrapping approach to speed up statistical studies of scattering\n",
            "in thick random media. We examine how potential matrix reuse in a pool based\n",
            "approach can impact statistical estimates of population averages. Specifically,\n",
            "we discuss how both bias and additional variance in the sample mean estimator\n",
            "are introduced through bootstrapping. In the diffusive scattering regime, the\n",
            "extra estimator variance is shown to originate from samples in which cascaded\n",
            "transfer matrices are permuted matrix products. Through analysis of the\n",
            "combinatorics and cycle structure of permutations we quantify the resulting\n",
            "correlations. Proofs of several analytic formulae enumerating the frequency\n",
            "with which correlations of different strengths occur are derived. Extension to\n",
            "the ballistic regime is briefly considered.\n",
            "['Random matrix theory is a useful tool in the study of the physics of multiple\\nscattering systems, often striking a balance between computation speed and\\nphysical rigour.', 'Propagation of waves through thick disordered media, as arises\\nin for example optical scattering or electron transport, typically necessitates\\ncascading of multiple random matrices drawn from an underlying ensemble for\\nthin media, greatly increasing computational burden.', 'Here we propose a dual\\npool based bootstrapping approach to speed up statistical studies of scattering\\nin thick random media.', 'We examine how potential matrix reuse in a pool based\\napproach can impact statistical estimates of population averages.', 'Specifically,\\nwe discuss how both bias and additional variance in the sample mean estimator\\nare introduced through bootstrapping.', 'In the diffusive scattering regime, the\\nextra estimator variance is shown to originate from samples in which cascaded\\ntransfer matrices are permuted matrix products.', 'Through analysis of the\\ncombinatorics and cycle structure of permutations we quantify the resulting\\ncorrelations.', 'Proofs of several analytic formulae enumerating the frequency\\nwith which correlations of different strengths occur are derived.', 'Extension to\\nthe ballistic regime is briefly considered.']\n",
            "Chunks for abstract: Categorical aspects of the theory of modules over trusses were studied in\n",
            "recent years. The snake lemma and the nine lemma in categories of modules over\n",
            "trusses are formulated in this paper.\n",
            "['Categorical aspects of the theory of modules over trusses were studied in\\nrecent years.', 'The snake lemma and the nine lemma in categories of modules over\\ntrusses are formulated in this paper.']\n",
            "Chunks for abstract: Collective intelligence among gig workers yields considerable advantages,\n",
            "including improved information exchange, deeper social bonds, and stronger\n",
            "advocacy for better labor conditions. Especially as it enables workers to\n",
            "collaboratively pinpoint shared challenges and devise optimal strategies for\n",
            "addressing these issues. However, enabling collective intelligence remains\n",
            "challenging, as existing tools often overestimate gig workers' available time\n",
            "and uniformity in analytical reasoning. To overcome this, we introduce\n",
            "GigSense, a tool that leverages large language models alongside theories of\n",
            "collective intelligence and sensemaking. GigSense enables gig workers to\n",
            "rapidly understand and address shared challenges effectively, irrespective of\n",
            "their diverse backgrounds. Our user study showed that GigSense users\n",
            "outperformed those using a control interface in problem identification and\n",
            "generated solutions more quickly and of higher quality, with better usability\n",
            "experiences reported. GigSense not only empowers gig workers but also opens up\n",
            "new possibilities for supporting workers more broadly, demonstrating the\n",
            "potential of large language model interfaces to enhance collective intelligence\n",
            "efforts in the evolving workplace.\n",
            "['Collective intelligence among gig workers yields considerable advantages,\\nincluding improved information exchange, deeper social bonds, and stronger\\nadvocacy for better labor conditions.', 'Especially as it enables workers to\\ncollaboratively pinpoint shared challenges and devise optimal strategies for\\naddressing these issues.', \"However, enabling collective intelligence remains\\nchallenging, as existing tools often overestimate gig workers' available time\\nand uniformity in analytical reasoning.\", 'To overcome this, we introduce\\nGigSense, a tool that leverages large language models alongside theories of\\ncollective intelligence and sensemaking.', 'GigSense enables gig workers to\\nrapidly understand and address shared challenges effectively, irrespective of\\ntheir diverse backgrounds.', 'Our user study showed that GigSense users\\noutperformed those using a control interface in problem identification and\\ngenerated solutions more quickly and of higher quality, with better usability\\nexperiences reported.', 'GigSense not only empowers gig workers but also opens up\\nnew possibilities for supporting workers more broadly, demonstrating the\\npotential of large language model interfaces to enhance collective intelligence\\nefforts in the evolving workplace.']\n",
            "Chunks for abstract: Large Language Models (LLMs) are trained on massive text corpora, which are\n",
            "encoded with diverse personality traits. This triggers an interesting goal of\n",
            "eliciting a desired personality trait from the LLM, and probing its behavioral\n",
            "preferences. Accordingly, we formalize the persona elicitation task, aiming to\n",
            "customize LLM behaviors to align with a target persona. We present Persona\n",
            "In-Context Learning (PICLe), a novel persona elicitation framework grounded in\n",
            "Bayesian inference. At the core, PICLe introduces a new ICL example selection\n",
            "criterion based on likelihood ratio, which is designed to optimally guide the\n",
            "model in eliciting a specific target persona. We demonstrate the effectiveness\n",
            "of PICLe through extensive comparisons against baseline methods across three\n",
            "contemporary LLMs. Code is available at\n",
            "https://github.com/deeplearning-wisc/picle.\n",
            "['Large Language Models (LLMs) are trained on massive text corpora, which are\\nencoded with diverse personality traits.', 'This triggers an interesting goal of\\neliciting a desired personality trait from the LLM, and probing its behavioral\\npreferences.', 'Accordingly, we formalize the persona elicitation task, aiming to\\ncustomize LLM behaviors to align with a target persona.', 'We present Persona\\nIn-Context Learning (PICLe), a novel persona elicitation framework grounded in\\nBayesian inference.', 'At the core, PICLe introduces a new ICL example selection\\ncriterion based on likelihood ratio, which is designed to optimally guide the\\nmodel in eliciting a specific target persona.', 'We demonstrate the effectiveness\\nof PICLe through extensive comparisons against baseline methods across three\\ncontemporary LLMs.', 'Code is available at\\nhttps://github.com/deeplearning-wisc/picle.']\n",
            "Chunks for abstract: Extreme Multi-label Text Classification (XMC) involves learning a classifier\n",
            "that can assign an input with a subset of most relevant labels from millions of\n",
            "label choices. Recent works in this domain have increasingly focused on a\n",
            "symmetric problem setting where both input instances and label features are\n",
            "short-text in nature. Short-text XMC with label features has found numerous\n",
            "applications in areas such as query-to-ad-phrase matching in search ads,\n",
            "title-based product recommendation, prediction of related searches. In this\n",
            "paper, we propose Gandalf, a novel approach which makes use of a label\n",
            "co-occurrence graph to leverage label features as additional data points to\n",
            "supplement the training distribution. By exploiting the characteristics of the\n",
            "short-text XMC problem, it leverages the label features to construct valid\n",
            "training instances, and uses the label graph for generating the corresponding\n",
            "soft-label targets, hence effectively capturing the label-label correlations.\n",
            "Surprisingly, models trained on these new training instances, although being\n",
            "less than half of the original dataset, can outperform models trained on the\n",
            "original dataset, particularly on the PSP@k metric for tail labels. With this\n",
            "insight, we aim to train existing XMC algorithms on both, the original and new\n",
            "training instances, leading to an average 5% relative improvements for 6\n",
            "state-of-the-art algorithms across 4 benchmark datasets consisting of up to\n",
            "1.3M labels. Gandalf can be applied in a plug-and-play manner to various\n",
            "methods and thus forwards the state-of-the-art in the domain, without incurring\n",
            "any additional computational overheads.\n",
            "['Extreme Multi-label Text Classification (XMC) involves learning a classifier\\nthat can assign an input with a subset of most relevant labels from millions of\\nlabel choices.', 'Recent works in this domain have increasingly focused on a\\nsymmetric problem setting where both input instances and label features are\\nshort-text in nature.', 'Short-text XMC with label features has found numerous\\napplications in areas such as query-to-ad-phrase matching in search ads,\\ntitle-based product recommendation, prediction of related searches.', 'In this\\npaper, we propose Gandalf, a novel approach which makes use of a label\\nco-occurrence graph to leverage label features as additional data points to\\nsupplement the training distribution.', 'By exploiting the characteristics of the\\nshort-text XMC problem, it leverages the label features to construct valid\\ntraining instances, and uses the label graph for generating the corresponding\\nsoft-label targets, hence effectively capturing the label-label correlations.', 'Surprisingly, models trained on these new training instances, although being\\nless than half of the original dataset, can outperform models trained on the\\noriginal dataset, particularly on the PSP@k metric for tail labels.', 'With this\\ninsight, we aim to train existing XMC algorithms on both, the original and new\\ntraining instances, leading to an average 5% relative improvements for 6\\nstate-of-the-art algorithms across 4 benchmark datasets consisting of up to\\n1.3M labels.', 'Gandalf can be applied in a plug-and-play manner to various\\nmethods and thus forwards the state-of-the-art in the domain, without incurring\\nany additional computational overheads.']\n",
            "Chunks for abstract: Vaccination campaigns have both direct and indirect effects that act to\n",
            "control an infectious disease as it spreads through a population. Indirect\n",
            "effects arise when vaccinated individuals block disease transmission in any\n",
            "infection chains they are part of, and this in turn can benefit both vaccinated\n",
            "and unvaccinated individuals. Indirect effects are difficult to quantify in\n",
            "practice, but here, working with the Susceptible-Infected-Recovered (SIR)\n",
            "model, they are analytically calculated in important cases, through pivoting on\n",
            "the Final Size formula for epidemics. Their relationship to herd immunity is\n",
            "also clarified. Furthermore, we identify the important distinction between\n",
            "quantifying indirect effects of vaccination at the \"population level\" versus\n",
            "the \"per capita\" individual level, which often results in radically different\n",
            "conclusions. As an important example, the analysis unpacks why population-level\n",
            "indirect effect can appear significantly larger than its per capita analogue.\n",
            "In addition, we consider a recently proposed epidemiological\n",
            "non-pharamaceutical intervention used over COVID-19, referred to as\n",
            "\"shielding\", and study its impact in our mathematical analysis. The shielding\n",
            "scheme is extended by inclusion of limited vaccination.\n",
            "['Vaccination campaigns have both direct and indirect effects that act to\\ncontrol an infectious disease as it spreads through a population.', 'Indirect\\neffects arise when vaccinated individuals block disease transmission in any\\ninfection chains they are part of, and this in turn can benefit both vaccinated\\nand unvaccinated individuals.', 'Indirect effects are difficult to quantify in\\npractice, but here, working with the Susceptible-Infected-Recovered (SIR)\\nmodel, they are analytically calculated in important cases, through pivoting on\\nthe Final Size formula for epidemics.', 'Their relationship to herd immunity is\\nalso clarified.', 'Furthermore, we identify the important distinction between\\nquantifying indirect effects of vaccination at the \"population level\" versus\\nthe \"per capita\" individual level, which often results in radically different\\nconclusions.', 'As an important example, the analysis unpacks why population-level\\nindirect effect can appear significantly larger than its per capita analogue.', 'In addition, we consider a recently proposed epidemiological\\nnon-pharamaceutical intervention used over COVID-19, referred to as\\n\"shielding\", and study its impact in our mathematical analysis.', 'The shielding\\nscheme is extended by inclusion of limited vaccination.']\n",
            "Chunks for abstract: This paper introduces \"Semantic Scaling,\" a novel method for ideal point\n",
            "estimation from text. I leverage large language models to classify documents\n",
            "based on their expressed stances and extract survey-like data. I then use item\n",
            "response theory to scale subjects from these data. Semantic Scaling\n",
            "significantly improves on existing text-based scaling methods, and allows\n",
            "researchers to explicitly define the ideological dimensions they measure. This\n",
            "represents the first scaling approach that allows such flexibility outside of\n",
            "survey instruments and opens new avenues of inquiry for populations difficult\n",
            "to survey. Additionally, it works with documents of varying length, and\n",
            "produces valid estimates of both mass and elite ideology. I demonstrate that\n",
            "the method can differentiate between policy preferences and in-group/out-group\n",
            "affect. Among the public, Semantic Scaling out-preforms Tweetscores according\n",
            "to human judgement; in Congress, it recaptures the first dimension DW-NOMINATE\n",
            "while allowing for greater flexibility in resolving construct validity\n",
            "challenges.\n",
            "['This paper introduces \"Semantic Scaling,\" a novel method for ideal point\\nestimation from text.', 'I leverage large language models to classify documents\\nbased on their expressed stances and extract survey-like data.', 'I then use item\\nresponse theory to scale subjects from these data.', 'Semantic Scaling\\nsignificantly improves on existing text-based scaling methods, and allows\\nresearchers to explicitly define the ideological dimensions they measure.', 'This\\nrepresents the first scaling approach that allows such flexibility outside of\\nsurvey instruments and opens new avenues of inquiry for populations difficult\\nto survey.', 'Additionally, it works with documents of varying length, and\\nproduces valid estimates of both mass and elite ideology.', 'I demonstrate that\\nthe method can differentiate between policy preferences and in-group/out-group\\naffect.', 'Among the public, Semantic Scaling out-preforms Tweetscores according\\nto human judgement; in Congress, it recaptures the first dimension DW-NOMINATE\\nwhile allowing for greater flexibility in resolving construct validity\\nchallenges.']\n",
            "Chunks for abstract: In this paper we consider an inflating universe with long straight cosmic\n",
            "string along z-axis. We show that the effect of cosmic string can be taken as a\n",
            "perturbation on the background of FRW metric. Then by doing cosmological\n",
            "perturbations on this inflating cosmic string background, we find linearized\n",
            "Einstein field equations. We show that at leading order (ignoring the mixing\n",
            "terms of cosmic string perturbations with gravitational tensor perturbations),\n",
            "the cosmic string appears as an inhomogeneous term on the right hand side of\n",
            "wave equation of tensor perturbations . Then by finding analytical solution of\n",
            "the wave equation for slow-roll inflation, we show how it effects on the\n",
            "spectrum of primordial gravitational waves.\n",
            "['In this paper we consider an inflating universe with long straight cosmic\\nstring along z-axis.', 'We show that the effect of cosmic string can be taken as a\\nperturbation on the background of FRW metric.', 'Then by doing cosmological\\nperturbations on this inflating cosmic string background, we find linearized\\nEinstein field equations.', 'We show that at leading order (ignoring the mixing\\nterms of cosmic string perturbations with gravitational tensor perturbations),\\nthe cosmic string appears as an inhomogeneous term on the right hand side of\\nwave equation of tensor perturbations .', 'Then by finding analytical solution of\\nthe wave equation for slow-roll inflation, we show how it effects on the\\nspectrum of primordial gravitational waves.']\n",
            "Chunks for abstract: The present paper is the second installment, where we compute the generating\n",
            "functional of correlators of collinear twist-$2$ operators that enter the\n",
            "components of unbalanced superfields -- i.e., superfields with an unequal\n",
            "number of dotted and undotted indices in their spinor representation -- in\n",
            "$\\mathcal{N} = 1$ SUSY SU($N$) YM theory in Minkowskian and Euclidean\n",
            "space-time, in the conformal limit and renormalization-group improved form, and\n",
            "to the leading and next-to-leading order in the large-$N$ expansion. The\n",
            "corresponding generating functional of correlators of balanced superfields has\n",
            "been worked out in the first installment. Hence, our large-$N$ calculation sets\n",
            "strong ultraviolet asymptotic constraints on the nonperturbative solution of\n",
            "large-$N$ $\\mathcal{N} = 1$ SUSY YM theory that may be a pivotal guide for the\n",
            "search of such a solution.\n",
            "['The present paper is the second installment, where we compute the generating\\nfunctional of correlators of collinear twist-$2$ operators that enter the\\ncomponents of unbalanced superfields -- i.e., superfields with an unequal\\nnumber of dotted and undotted indices in their spinor representation -- in\\n$\\\\mathcal{N} = 1$ SUSY SU($N$) YM theory in Minkowskian and Euclidean\\nspace-time, in the conformal limit and renormalization-group improved form, and\\nto the leading and next-to-leading order in the large-$N$ expansion.', 'The\\ncorresponding generating functional of correlators of balanced superfields has\\nbeen worked out in the first installment.', 'Hence, our large-$N$ calculation sets\\nstrong ultraviolet asymptotic constraints on the nonperturbative solution of\\nlarge-$N$ $\\\\mathcal{N} = 1$ SUSY YM theory that may be a pivotal guide for the\\nsearch of such a solution.']\n",
            "Chunks for abstract: The ultimate step towards the exploitation of water as a clean and renewable\n",
            "energy source addresses the energies stored in the low frequencies of liquid\n",
            "flows, which demands flexible solutions to adapt to multiple scenarios, from\n",
            "raindrops to waves, including water moving in pipelines and microdevices. Thus,\n",
            "harvesting low-frequency flows is a young concept compared to solar and wind\n",
            "powers, where triboelectric nanogenerators have been revealed as the most\n",
            "promising relevant actors. However, despite widespread attempts by researchers,\n",
            "the drop energy harvesters' output power is still low, mainly because of the\n",
            "limitations in candidates endowed with ideal triboelectric and wetting\n",
            "properties and also the non-optimal and centimetre-scale device architecture\n",
            "that prevents the conversion of the complete kinetic energy of impinging drops.\n",
            "Herein, we disclose a microscale triboelectric nanogenerator that can harvest a\n",
            "high density of electrical power from drops through a single, submillisecond,\n",
            "long-lasting step. The mechanism relies on an instantaneous electrical\n",
            "capacitance variation owing to the high-speed contact of the drops with the\n",
            "electrodes' active area. We discuss the role of the precharged effect of the\n",
            "triboelectric surface in the time characteristic of the conversion event. The\n",
            "capacitive and microscale structure of the device is endowed with a small form\n",
            "factor that allows for the production of densely packed arrays. The proposed\n",
            "architecture can be adjusted to different liquids and scales and is compatible\n",
            "with a variety of triboelectric surfaces, including flexible, transparent, and\n",
            "thin-film approaches.\n",
            "['The ultimate step towards the exploitation of water as a clean and renewable\\nenergy source addresses the energies stored in the low frequencies of liquid\\nflows, which demands flexible solutions to adapt to multiple scenarios, from\\nraindrops to waves, including water moving in pipelines and microdevices.', 'Thus,\\nharvesting low-frequency flows is a young concept compared to solar and wind\\npowers, where triboelectric nanogenerators have been revealed as the most\\npromising relevant actors.', \"However, despite widespread attempts by researchers,\\nthe drop energy harvesters' output power is still low, mainly because of the\\nlimitations in candidates endowed with ideal triboelectric and wetting\\nproperties and also the non-optimal and centimetre-scale device architecture\\nthat prevents the conversion of the complete kinetic energy of impinging drops.\", 'Herein, we disclose a microscale triboelectric nanogenerator that can harvest a\\nhigh density of electrical power from drops through a single, submillisecond,\\nlong-lasting step.', \"The mechanism relies on an instantaneous electrical\\ncapacitance variation owing to the high-speed contact of the drops with the\\nelectrodes' active area.\", 'We discuss the role of the precharged effect of the\\ntriboelectric surface in the time characteristic of the conversion event.', 'The\\ncapacitive and microscale structure of the device is endowed with a small form\\nfactor that allows for the production of densely packed arrays.', 'The proposed\\narchitecture can be adjusted to different liquids and scales and is compatible\\nwith a variety of triboelectric surfaces, including flexible, transparent, and\\nthin-film approaches.']\n",
            "Chunks for abstract: Recent studies show that transformer-based architectures emulate gradient\n",
            "descent during a forward pass, contributing to in-context learning capabilities\n",
            "- an ability where the model adapts to new tasks based on a sequence of prompt\n",
            "examples without being explicitly trained or fine tuned to do so. This work\n",
            "investigates the generalization properties of a single step of gradient descent\n",
            "in the context of linear regression with well-specified models. A random design\n",
            "setting is considered and analytical expressions are derived for the\n",
            "statistical properties of generalization error in a non-asymptotic (finite\n",
            "sample) setting. These expressions are notable for avoiding arbitrary\n",
            "constants, and thus offer robust quantitative information and scaling\n",
            "relationships. These results are contrasted with those from classical least\n",
            "squares regression (for which analogous finite sample bounds are also derived),\n",
            "shedding light on systematic and noise components, as well as optimal step\n",
            "sizes. Additionally, identities involving high-order products of Gaussian\n",
            "random matrices are presented as a byproduct of the analysis.\n",
            "['Recent studies show that transformer-based architectures emulate gradient\\ndescent during a forward pass, contributing to in-context learning capabilities\\n- an ability where the model adapts to new tasks based on a sequence of prompt\\nexamples without being explicitly trained or fine tuned to do so.', 'This work\\ninvestigates the generalization properties of a single step of gradient descent\\nin the context of linear regression with well-specified models.', 'A random design\\nsetting is considered and analytical expressions are derived for the\\nstatistical properties of generalization error in a non-asymptotic (finite\\nsample) setting.', 'These expressions are notable for avoiding arbitrary\\nconstants, and thus offer robust quantitative information and scaling\\nrelationships.', 'These results are contrasted with those from classical least\\nsquares regression (for which analogous finite sample bounds are also derived),\\nshedding light on systematic and noise components, as well as optimal step\\nsizes.', 'Additionally, identities involving high-order products of Gaussian\\nrandom matrices are presented as a byproduct of the analysis.']\n",
            "Chunks for abstract: Sentiment analysis is one of the most widely used techniques in text\n",
            "analysis. Recent advancements with Large Language Models have made it more\n",
            "accurate and accessible than ever, allowing researchers to classify text with\n",
            "only a plain English prompt. However, \"sentiment\" entails a wide variety of\n",
            "concepts depending on the domain and tools used. It has been used to mean\n",
            "emotion, opinions, market movements, or simply a general ``good-bad''\n",
            "dimension. This raises a question: What exactly are language models doing when\n",
            "prompted to label documents by sentiment? This paper first overviews how\n",
            "sentiment is defined across different contexts, highlighting that it is a\n",
            "confounded measurement construct in that it entails multiple variables, such as\n",
            "emotional valence and opinion, without disentangling them. I then test three\n",
            "language models across two data sets with prompts requesting sentiment,\n",
            "valence, and stance classification. I find that sentiment labels most strongly\n",
            "correlate with valence labels. I further find that classification improves when\n",
            "researchers more precisely specify their dimension of interest rather than\n",
            "using the less well-defined concept of sentiment. I conclude by encouraging\n",
            "researchers to move beyond \"sentiment\" when feasible and use a more precise\n",
            "measurement construct.\n",
            "['Sentiment analysis is one of the most widely used techniques in text\\nanalysis.', 'Recent advancements with Large Language Models have made it more\\naccurate and accessible than ever, allowing researchers to classify text with\\nonly a plain English prompt.', 'However, \"sentiment\" entails a wide variety of\\nconcepts depending on the domain and tools used.', \"It has been used to mean\\nemotion, opinions, market movements, or simply a general ``good-bad''\\ndimension.\", 'This raises a question: What exactly are language models doing when\\nprompted to label documents by sentiment?', 'This paper first overviews how\\nsentiment is defined across different contexts, highlighting that it is a\\nconfounded measurement construct in that it entails multiple variables, such as\\nemotional valence and opinion, without disentangling them.', 'I then test three\\nlanguage models across two data sets with prompts requesting sentiment,\\nvalence, and stance classification.', 'I find that sentiment labels most strongly\\ncorrelate with valence labels.', 'I further find that classification improves when\\nresearchers more precisely specify their dimension of interest rather than\\nusing the less well-defined concept of sentiment.', 'I conclude by encouraging\\nresearchers to move beyond \"sentiment\" when feasible and use a more precise\\nmeasurement construct.']\n",
            "Chunks for abstract: Network control theory (NCT) offers a robust analytical framework for\n",
            "understanding the influence of network topology on dynamic behaviors, enabling\n",
            "researchers to decipher how certain patterns of external control measures can\n",
            "steer system dynamics towards desired states. Distinguished from other\n",
            "structure-function methodologies, NCT's predictive capabilities can be coupled\n",
            "with deploying Graph Neural Networks (GNNs), which have demonstrated\n",
            "exceptional utility in various network-based learning tasks. However, the\n",
            "performance of GNNs heavily relies on the expressiveness of node features, and\n",
            "the lack of node features can greatly degrade their performance. Furthermore,\n",
            "many real-world systems may lack node-level information, posing a challenge for\n",
            "GNNs.To tackle this challenge, we introduce a novel approach, NCT-based\n",
            "Enhanced Feature Augmentation (NCT-EFA), that assimilates average\n",
            "controllability, along with other centrality indices, into the feature\n",
            "augmentation pipeline to enhance GNNs performance. Our evaluation of NCT-EFA,\n",
            "on six benchmark GNN models across two experimental setting. solely employing\n",
            "average controllability and in combination with additional centrality metrics.\n",
            "showcases an improved performance reaching as high as 11%. Our results\n",
            "demonstrate that incorporating NCT into feature enrichment can substantively\n",
            "extend the applicability and heighten the performance of GNNs in scenarios\n",
            "where node-level information is unavailable.\n",
            "['Network control theory (NCT) offers a robust analytical framework for\\nunderstanding the influence of network topology on dynamic behaviors, enabling\\nresearchers to decipher how certain patterns of external control measures can\\nsteer system dynamics towards desired states.', \"Distinguished from other\\nstructure-function methodologies, NCT's predictive capabilities can be coupled\\nwith deploying Graph Neural Networks (GNNs), which have demonstrated\\nexceptional utility in various network-based learning tasks.\", 'However, the\\nperformance of GNNs heavily relies on the expressiveness of node features, and\\nthe lack of node features can greatly degrade their performance.', 'Furthermore,\\nmany real-world systems may lack node-level information, posing a challenge for\\nGNNs.To tackle this challenge, we introduce a novel approach, NCT-based\\nEnhanced Feature Augmentation (NCT-EFA), that assimilates average\\ncontrollability, along with other centrality indices, into the feature\\naugmentation pipeline to enhance GNNs performance.', 'Our evaluation of NCT-EFA,\\non six benchmark GNN models across two experimental setting.', 'solely employing\\naverage controllability and in combination with additional centrality metrics.', 'showcases an improved performance reaching as high as 11%.', 'Our results\\ndemonstrate that incorporating NCT into feature enrichment can substantively\\nextend the applicability and heighten the performance of GNNs in scenarios\\nwhere node-level information is unavailable.']\n",
            "Chunks for abstract: Dynamic facility location problems aim at placing one or more valuable\n",
            "resources over a planning horizon to meet customer demand. Existing literature\n",
            "commonly assumes that customer demand quantities are defined independently for\n",
            "each time period. In many planning contexts, however, unmet demand carries over\n",
            "to future time periods. Unmet demand at some time periods may therefore affect\n",
            "decisions of subsequent time periods. This work studies a novel location\n",
            "problem, where the decision maker relocates a single temporary facility over\n",
            "time to capture cumulative customer demand. We propose two mixed-integer\n",
            "programming models for this problem, and show that one of them has a tighter\n",
            "continuous relaxation and allows the representation of more general customer\n",
            "demand behaviour. We characterize the computational complexity for this\n",
            "problem, and analyze which problem characteristics result in NP-hardness. We\n",
            "then propose an exact branch-and-Benders-cut method, and show how optimality\n",
            "cuts can be computed efficiently through an analytical procedure. Computational\n",
            "experiments show that our method is approximately 30 times faster than solving\n",
            "the tighter formulation directly. Our results also quantify the benefit of\n",
            "accounting for cumulative customer demand within the optimization framework,\n",
            "since the corresponding planning solutions perform much better than those\n",
            "obtained by ignoring cumulative demand or employing myopic heuristics.\n",
            "['Dynamic facility location problems aim at placing one or more valuable\\nresources over a planning horizon to meet customer demand.', 'Existing literature\\ncommonly assumes that customer demand quantities are defined independently for\\neach time period.', 'In many planning contexts, however, unmet demand carries over\\nto future time periods.', 'Unmet demand at some time periods may therefore affect\\ndecisions of subsequent time periods.', 'This work studies a novel location\\nproblem, where the decision maker relocates a single temporary facility over\\ntime to capture cumulative customer demand.', 'We propose two mixed-integer\\nprogramming models for this problem, and show that one of them has a tighter\\ncontinuous relaxation and allows the representation of more general customer\\ndemand behaviour.', 'We characterize the computational complexity for this\\nproblem, and analyze which problem characteristics result in NP-hardness.', 'We\\nthen propose an exact branch-and-Benders-cut method, and show how optimality\\ncuts can be computed efficiently through an analytical procedure.', 'Computational\\nexperiments show that our method is approximately 30 times faster than solving\\nthe tighter formulation directly.', 'Our results also quantify the benefit of\\naccounting for cumulative customer demand within the optimization framework,\\nsince the corresponding planning solutions perform much better than those\\nobtained by ignoring cumulative demand or employing myopic heuristics.']\n",
            "Chunks for abstract: Traditional recommender systems such as matrix factorization methods rely on\n",
            "learning a shared dense embedding space to represent both items and user\n",
            "preferences. Sequence models such as RNN, GRUs, and, recently, Transformers\n",
            "have also excelled in the task of sequential recommendation. This task requires\n",
            "understanding the sequential structure present in users' historical\n",
            "interactions to predict the next item they may like. Building upon the success\n",
            "of Large Language Models (LLMs) in a variety of tasks, researchers have\n",
            "recently explored using LLMs that are pretrained on vast corpora of text for\n",
            "sequential recommendation. To use LLMs in sequential recommendations, both the\n",
            "history of user interactions and the model's prediction of the next item are\n",
            "expressed in text form. We propose CALRec, a two-stage LLM finetuning framework\n",
            "that finetunes a pretrained LLM in a two-tower fashion using a mixture of two\n",
            "contrastive losses and a language modeling loss: the LLM is first finetuned on\n",
            "a data mixture from multiple domains followed by another round of target domain\n",
            "finetuning. Our model significantly outperforms many state-of-the-art baselines\n",
            "(+37% in Recall@1 and +24% in NDCG@10) and systematic ablation studies reveal\n",
            "that (i) both stages of finetuning are crucial, and, when combined, we achieve\n",
            "improved performance, and (ii) contrastive alignment is effective among the\n",
            "target domains explored in our experiments.\n",
            "['Traditional recommender systems such as matrix factorization methods rely on\\nlearning a shared dense embedding space to represent both items and user\\npreferences.', 'Sequence models such as RNN, GRUs, and, recently, Transformers\\nhave also excelled in the task of sequential recommendation.', \"This task requires\\nunderstanding the sequential structure present in users' historical\\ninteractions to predict the next item they may like.\", 'Building upon the success\\nof Large Language Models (LLMs) in a variety of tasks, researchers have\\nrecently explored using LLMs that are pretrained on vast corpora of text for\\nsequential recommendation.', \"To use LLMs in sequential recommendations, both the\\nhistory of user interactions and the model's prediction of the next item are\\nexpressed in text form.\", 'We propose CALRec, a two-stage LLM finetuning framework\\nthat finetunes a pretrained LLM in a two-tower fashion using a mixture of two\\ncontrastive losses and a language modeling loss: the LLM is first finetuned on\\na data mixture from multiple domains followed by another round of target domain\\nfinetuning.', 'Our model significantly outperforms many state-of-the-art baselines\\n(+37% in Recall@1 and +24% in NDCG@10) and systematic ablation studies reveal\\nthat (i) both stages of finetuning are crucial, and, when combined, we achieve\\nimproved performance, and (ii) contrastive alignment is effective among the\\ntarget domains explored in our experiments.']\n",
            "Chunks for abstract: Prediction of flow to boreholes or excavations in fractured low-permeability\n",
            "rocks is important for resource extraction and disposal or sequestration\n",
            "activities. Analytical solutions for fluid pressure and flowrate, when\n",
            "available, are powerful, insightful, and efficient tools enabling parameter\n",
            "estimation and uncertainty quantification. A flexible porous media flow\n",
            "solution for arbitrary physical dimension is derived and extended to double\n",
            "porosity for converging radial flow when permeability and porosity decrease\n",
            "radially as a power law away from a borehole or opening. This distribution can\n",
            "arise from damage accumulation due to stress relief associated with drilling or\n",
            "mining. The single-porosity graded conductivity solution was initially found\n",
            "for heat conduction, the arbitrary dimension flow solution comes from\n",
            "hydrology, and the solution with both arbitrary dimension and graded\n",
            "permeability distribution appeared in reservoir engineering. These existing\n",
            "solutions are here combined and extended to two implementations of the\n",
            "double-porosity conceptual model, for both a simpler thin-film mass transfer\n",
            "and more physically realistic diffusion between fracture and matrix. This work\n",
            "presents a new specified-flowrate solution with wellbore storage for the\n",
            "simpler double-porosity model, and a new more physically realistic solution for\n",
            "any wellbore boundary condition. A new closed-form expression is derived for\n",
            "the matrix diffusion solution (applicable to both homogeneous and graded\n",
            "problems), improving on previous infinite series expressions.\n",
            "['Prediction of flow to boreholes or excavations in fractured low-permeability\\nrocks is important for resource extraction and disposal or sequestration\\nactivities.', 'Analytical solutions for fluid pressure and flowrate, when\\navailable, are powerful, insightful, and efficient tools enabling parameter\\nestimation and uncertainty quantification.', 'A flexible porous media flow\\nsolution for arbitrary physical dimension is derived and extended to double\\nporosity for converging radial flow when permeability and porosity decrease\\nradially as a power law away from a borehole or opening.', 'This distribution can\\narise from damage accumulation due to stress relief associated with drilling or\\nmining.', 'The single-porosity graded conductivity solution was initially found\\nfor heat conduction, the arbitrary dimension flow solution comes from\\nhydrology, and the solution with both arbitrary dimension and graded\\npermeability distribution appeared in reservoir engineering.', 'These existing\\nsolutions are here combined and extended to two implementations of the\\ndouble-porosity conceptual model, for both a simpler thin-film mass transfer\\nand more physically realistic diffusion between fracture and matrix.', 'This work\\npresents a new specified-flowrate solution with wellbore storage for the\\nsimpler double-porosity model, and a new more physically realistic solution for\\nany wellbore boundary condition.', 'A new closed-form expression is derived for\\nthe matrix diffusion solution (applicable to both homogeneous and graded\\nproblems), improving on previous infinite series expressions.']\n",
            "Chunks for abstract: The MHD equations, as a collisional fluid model that remains in local\n",
            "thermodynamic equilibrium (LTE), have long been used to describe turbulence in\n",
            "myriad space and astrophysical plasmas. Yet, the vast majority of these\n",
            "plasmas, from the solar wind to the intracluster medium (ICM) of galaxy\n",
            "clusters, are only weakly collisional at best, meaning that significant\n",
            "deviations from LTE are not only possible but common. Recent studies have\n",
            "demonstrated that the kinetic physics inherent to this weakly collisional\n",
            "regime can fundamentally transform the evolution of such plasmas across a wide\n",
            "range of scales. Here we explore the consequences of pressure anisotropy and\n",
            "Larmor-scale instabilities for collisionless, $\\beta \\gg 1$ turbulence,\n",
            "focusing on the role of a self-organizational effect known as\n",
            "`magneto-immutability'. We describe this self-organization analytically through\n",
            "a high-$\\beta$, reduced ordering of the CGL-MHD equations, finding that it is a\n",
            "robust inertial-range effect that dynamically suppresses\n",
            "magnetic-field-strength fluctuations, anisotropic-pressure stresses, and\n",
            "dissipation due to heat fluxes. As a result, the turbulent cascade of\n",
            "Alfv\\'enic fluctuations continues below the putative viscous scale to form a\n",
            "robust, nearly conservative, MHD-like inertial range. These findings are\n",
            "confirmed numerically via Landau-fluid CGL-MHD turbulence simulations that\n",
            "employ a collisional closure to mimic the effects of microinstabilities. We\n",
            "find that microinstabilities occupy a small ($\\sim 5\\%$) volume-filling\n",
            "fraction of the plasma, even when the pressure anisotropy is driven strongly\n",
            "towards its instability thresholds. We discuss these results in the context of\n",
            "recent predictions for ion-versus-electron heating in low-luminosity accretion\n",
            "flows and observations implying suppressed viscosity in ICM turbulence.\n",
            "['The MHD equations, as a collisional fluid model that remains in local\\nthermodynamic equilibrium (LTE), have long been used to describe turbulence in\\nmyriad space and astrophysical plasmas.', 'Yet, the vast majority of these\\nplasmas, from the solar wind to the intracluster medium (ICM) of galaxy\\nclusters, are only weakly collisional at best, meaning that significant\\ndeviations from LTE are not only possible but common.', 'Recent studies have\\ndemonstrated that the kinetic physics inherent to this weakly collisional\\nregime can fundamentally transform the evolution of such plasmas across a wide\\nrange of scales.', \"Here we explore the consequences of pressure anisotropy and\\nLarmor-scale instabilities for collisionless, $\\\\beta \\\\gg 1$ turbulence,\\nfocusing on the role of a self-organizational effect known as\\n`magneto-immutability'.\", 'We describe this self-organization analytically through\\na high-$\\\\beta$, reduced ordering of the CGL-MHD equations, finding that it is a\\nrobust inertial-range effect that dynamically suppresses\\nmagnetic-field-strength fluctuations, anisotropic-pressure stresses, and\\ndissipation due to heat fluxes.', \"As a result, the turbulent cascade of\\nAlfv\\\\'enic fluctuations continues below the putative viscous scale to form a\\nrobust, nearly conservative, MHD-like inertial range.\", 'These findings are\\nconfirmed numerically via Landau-fluid CGL-MHD turbulence simulations that\\nemploy a collisional closure to mimic the effects of microinstabilities.', 'We\\nfind that microinstabilities occupy a small ($\\\\sim 5\\\\%$) volume-filling\\nfraction of the plasma, even when the pressure anisotropy is driven strongly\\ntowards its instability thresholds.', 'We discuss these results in the context of\\nrecent predictions for ion-versus-electron heating in low-luminosity accretion\\nflows and observations implying suppressed viscosity in ICM turbulence.']\n",
            "Chunks for abstract: This paper presents a groundbreaking model for forecasting English Premier\n",
            "League (EPL) player performance using convolutional neural networks (CNNs). We\n",
            "evaluate Ridge regression, LightGBM and CNNs on the task of predicting upcoming\n",
            "player FPL score based on historical FPL data over the previous weeks. Our\n",
            "baseline models, Ridge regression and LightGBM, achieve solid performance and\n",
            "emphasize the importance of recent FPL points, influence, creativity, threat,\n",
            "and playtime in predicting EPL player performances. Our optimal CNN\n",
            "architecture achieves better performance with fewer input features and even\n",
            "outperforms the best previous EPL player performance forecasting models in the\n",
            "literature. The optimal CNN architecture also achieves very strong Spearman\n",
            "correlation with player rankings, indicating its strong implications for\n",
            "supporting the development of FPL artificial intelligence (AI) Agents and\n",
            "providing analysis for FPL managers. We additionally perform transfer learning\n",
            "experiments on soccer news data collected from The Guardian, for the same task\n",
            "of predicting upcoming player score, but do not identify a strong predictive\n",
            "signal in natural language news texts, achieving worse performance compared to\n",
            "both the CNN and baseline models. Overall, our CNN-based approach marks a\n",
            "significant advancement in EPL player performance forecasting and lays the\n",
            "foundation for transfer learning to other EPL prediction tasks such as win-loss\n",
            "odds for sports betting and the development of cutting-edge FPL AI Agents.\n",
            "['This paper presents a groundbreaking model for forecasting English Premier\\nLeague (EPL) player performance using convolutional neural networks (CNNs).', 'We\\nevaluate Ridge regression, LightGBM and CNNs on the task of predicting upcoming\\nplayer FPL score based on historical FPL data over the previous weeks.', 'Our\\nbaseline models, Ridge regression and LightGBM, achieve solid performance and\\nemphasize the importance of recent FPL points, influence, creativity, threat,\\nand playtime in predicting EPL player performances.', 'Our optimal CNN\\narchitecture achieves better performance with fewer input features and even\\noutperforms the best previous EPL player performance forecasting models in the\\nliterature.', 'The optimal CNN architecture also achieves very strong Spearman\\ncorrelation with player rankings, indicating its strong implications for\\nsupporting the development of FPL artificial intelligence (AI) Agents and\\nproviding analysis for FPL managers.', 'We additionally perform transfer learning\\nexperiments on soccer news data collected from The Guardian, for the same task\\nof predicting upcoming player score, but do not identify a strong predictive\\nsignal in natural language news texts, achieving worse performance compared to\\nboth the CNN and baseline models.', 'Overall, our CNN-based approach marks a\\nsignificant advancement in EPL player performance forecasting and lays the\\nfoundation for transfer learning to other EPL prediction tasks such as win-loss\\nodds for sports betting and the development of cutting-edge FPL AI Agents.']\n",
            "Chunks for abstract: We present an analytical formulation of the thermodynamics, free energy and\n",
            "entropy, of any generic Bogoliubov de Genes model which develops exceptional\n",
            "point (EP) bifurcations in its complex spectrum when coupled to reservoirs. We\n",
            "apply our formalism to a non-Hermitian Josephson junction where, despite recent\n",
            "claims, the supercurrent does not exhibit any divergences at EPs. The entropy,\n",
            "on the contrary, shows a universal jump of $1/2\\log 2$ which can be linked to\n",
            "the emergence of Majorana zero modes (MZMs) at EPs. Our method allows us to\n",
            "obtain precise analytical boundaries for the temperatures at which such\n",
            "Majorana entropy steps appear. We propose a generalized Maxwell relation\n",
            "linking supercurrents and entropy which could pave the way towards the direct\n",
            "experimental observation of such steps in e.g. quantum-dot based minimal Kitaev\n",
            "chains.\n",
            "['We present an analytical formulation of the thermodynamics, free energy and\\nentropy, of any generic Bogoliubov de Genes model which develops exceptional\\npoint (EP) bifurcations in its complex spectrum when coupled to reservoirs.', 'We\\napply our formalism to a non-Hermitian Josephson junction where, despite recent\\nclaims, the supercurrent does not exhibit any divergences at EPs.', 'The entropy,\\non the contrary, shows a universal jump of $1/2\\\\log 2$ which can be linked to\\nthe emergence of Majorana zero modes (MZMs) at EPs.', 'Our method allows us to\\nobtain precise analytical boundaries for the temperatures at which such\\nMajorana entropy steps appear.', 'We propose a generalized Maxwell relation\\nlinking supercurrents and entropy which could pave the way towards the direct\\nexperimental observation of such steps in e.g.', 'quantum-dot based minimal Kitaev\\nchains.']\n",
            "Chunks for abstract: Backflow, or retropropagation, is a counterintuitive phenomenon whereby for a\n",
            "forward-propagating wave the energy locally propagates backward. In this study,\n",
            "energy backflow has been examined in connection with (a) (2+1)-dimensional\n",
            "unidirectional scalar and vector-valued monochromatic waves; (b) a (2+1)D\n",
            "scalar spatiotemporal wavepacket constructed by using an appropriate temporal\n",
            "frequency spectrum; (c) a scalar closed-form analytical unidirectional version\n",
            "of the Focus Wave Mode -- a localized pulse propagating luminally and without\n",
            "spread. Furthermore, an extended class of (2+1)D and (3+1)D finite-energy\n",
            "unidirectional spatiotemporally localized wave packets has been derived.\n",
            "['Backflow, or retropropagation, is a counterintuitive phenomenon whereby for a\\nforward-propagating wave the energy locally propagates backward.', 'In this study,\\nenergy backflow has been examined in connection with (a) (2+1)-dimensional\\nunidirectional scalar and vector-valued monochromatic waves; (b) a (2+1)D\\nscalar spatiotemporal wavepacket constructed by using an appropriate temporal\\nfrequency spectrum; (c) a scalar closed-form analytical unidirectional version\\nof the Focus Wave Mode -- a localized pulse propagating luminally and without\\nspread.', 'Furthermore, an extended class of (2+1)D and (3+1)D finite-energy\\nunidirectional spatiotemporally localized wave packets has been derived.']\n",
            "Chunks for abstract: In this work, we investigate the modulational instability of plane wave\n",
            "solutions within a modified Gross-Pitaevskii equation framework. The equation\n",
            "features cubic and quartic nonlinearity. It models the behaviour of\n",
            "quasi-one-dimensional Bose-Einstein condensates in symmetric Bose-Bose mixtures\n",
            "of ultra-dilute cold atoms. Our study demonstrates the pivotal role of the\n",
            "competition between mean-field attractions and quantum fluctuation-induced\n",
            "repulsions. This competition significantly affects the emergence and evolution\n",
            "of modulational instability. By employing linear stability analysis, we\n",
            "identify the essential conditions that lead to modulational instability. We\n",
            "find that the stability of plane wave solutions significantly depends on the\n",
            "interaction among system parameters. Further development of the instability\n",
            "leads to the fragmentation of the BEC into a chain of quantum droplets. We\n",
            "calculated the quantity of quantum droplets generated during the nonlinear\n",
            "phase of the instability. Our analytical results are corroborated by numerical\n",
            "simulations of the modified quasi-1D Gross-Pitaevskii equation. These\n",
            "simulations vividly depict the formation, interaction, and coalescence of\n",
            "droplets during the nonlinear phase of modulational instability. The\n",
            "investigation shows that linear stability analysis of the modified\n",
            "Gross-Pitaevskii equation, considering quantum fluctuations, precisely\n",
            "forecasts modulational instability phenomena across different domains of\n",
            "parameter spaces.\n",
            "['In this work, we investigate the modulational instability of plane wave\\nsolutions within a modified Gross-Pitaevskii equation framework.', 'The equation\\nfeatures cubic and quartic nonlinearity.', 'It models the behaviour of\\nquasi-one-dimensional Bose-Einstein condensates in symmetric Bose-Bose mixtures\\nof ultra-dilute cold atoms.', 'Our study demonstrates the pivotal role of the\\ncompetition between mean-field attractions and quantum fluctuation-induced\\nrepulsions.', 'This competition significantly affects the emergence and evolution\\nof modulational instability.', 'By employing linear stability analysis, we\\nidentify the essential conditions that lead to modulational instability.', 'We\\nfind that the stability of plane wave solutions significantly depends on the\\ninteraction among system parameters.', 'Further development of the instability\\nleads to the fragmentation of the BEC into a chain of quantum droplets.', 'We\\ncalculated the quantity of quantum droplets generated during the nonlinear\\nphase of the instability.', 'Our analytical results are corroborated by numerical\\nsimulations of the modified quasi-1D Gross-Pitaevskii equation.', 'These\\nsimulations vividly depict the formation, interaction, and coalescence of\\ndroplets during the nonlinear phase of modulational instability.', 'The\\ninvestigation shows that linear stability analysis of the modified\\nGross-Pitaevskii equation, considering quantum fluctuations, precisely\\nforecasts modulational instability phenomena across different domains of\\nparameter spaces.']\n",
            "Chunks for abstract: Photon loss rates set an effective upper limit on the size of computations\n",
            "that can be run on current linear optical quantum devices. We present a family\n",
            "of techniques to mitigate the effects of photon loss on both output\n",
            "probabilities and expectation values derived from noisy linear optical circuits\n",
            "composed of an input of $n$ photons, an $m$-mode interferometer, and $m$ single\n",
            "photon detectors. Central to these techniques is the construction of objects\n",
            "called recycled probabilities. Recycled probabilities are constructed from\n",
            "output statistics affected by loss, and are designed to amplify the signal of\n",
            "the ideal (lossless) probabilities. Classical postprocessing techniques then\n",
            "take recycled probabilities as input and output a set of loss-mitigated\n",
            "probabilities, or expectation values. We provide analytical and numerical\n",
            "evidence that these methods can be applied, up to large sample sizes, to\n",
            "produce more accurate outputs than those obtained from postselection - which is\n",
            "currently the standard method of coping with photon loss when sampling from\n",
            "discrete variable linear optical quantum circuits. In contrast, we provide\n",
            "strong evidence that the popular zero noise extrapolation technique cannot\n",
            "improve on on the performance of postselection for any photon loss rate.\n",
            "['Photon loss rates set an effective upper limit on the size of computations\\nthat can be run on current linear optical quantum devices.', 'We present a family\\nof techniques to mitigate the effects of photon loss on both output\\nprobabilities and expectation values derived from noisy linear optical circuits\\ncomposed of an input of $n$ photons, an $m$-mode interferometer, and $m$ single\\nphoton detectors.', 'Central to these techniques is the construction of objects\\ncalled recycled probabilities.', 'Recycled probabilities are constructed from\\noutput statistics affected by loss, and are designed to amplify the signal of\\nthe ideal (lossless) probabilities.', 'Classical postprocessing techniques then\\ntake recycled probabilities as input and output a set of loss-mitigated\\nprobabilities, or expectation values.', 'We provide analytical and numerical\\nevidence that these methods can be applied, up to large sample sizes, to\\nproduce more accurate outputs than those obtained from postselection - which is\\ncurrently the standard method of coping with photon loss when sampling from\\ndiscrete variable linear optical quantum circuits.', 'In contrast, we provide\\nstrong evidence that the popular zero noise extrapolation technique cannot\\nimprove on on the performance of postselection for any photon loss rate.']\n",
            "Chunks for abstract: On a smooth manifold, we associate to any closed differential form a mapping\n",
            "cone algebra. The cohomology of this mapping cone algebra can vary with the de\n",
            "Rham cohomology class of the closed form. We present a novel Morse theoretical\n",
            "description for the mapping cone cohomology. Specifically, we introduce a Morse\n",
            "complex for the mapping cone algebra which is generated by pairs of critical\n",
            "points with the differential defined by gradient flows and an integration of\n",
            "the closed form over spaces of gradient flow lines. We prove that the\n",
            "cohomology of our cone Morse complex is isomorphic to the mapping cone\n",
            "cohomology and hence independent of both the Riemannian metric and the Morse\n",
            "function used to define the complex. We also obtain sharp inequalities that\n",
            "bound the dimension of the mapping cone cohomology in terms of the number of\n",
            "Morse critical points and the properties of the specified closed form. Our\n",
            "results are widely applicable, especially for any manifold equipped with a\n",
            "geometric structure described by a closed differential form. We also obtain a\n",
            "bound on the difference between the number of Morse critical points and the\n",
            "Betti numbers.\n",
            "['On a smooth manifold, we associate to any closed differential form a mapping\\ncone algebra.', 'The cohomology of this mapping cone algebra can vary with the de\\nRham cohomology class of the closed form.', 'We present a novel Morse theoretical\\ndescription for the mapping cone cohomology.', 'Specifically, we introduce a Morse\\ncomplex for the mapping cone algebra which is generated by pairs of critical\\npoints with the differential defined by gradient flows and an integration of\\nthe closed form over spaces of gradient flow lines.', 'We prove that the\\ncohomology of our cone Morse complex is isomorphic to the mapping cone\\ncohomology and hence independent of both the Riemannian metric and the Morse\\nfunction used to define the complex.', 'We also obtain sharp inequalities that\\nbound the dimension of the mapping cone cohomology in terms of the number of\\nMorse critical points and the properties of the specified closed form.', 'Our\\nresults are widely applicable, especially for any manifold equipped with a\\ngeometric structure described by a closed differential form.', 'We also obtain a\\nbound on the difference between the number of Morse critical points and the\\nBetti numbers.']\n",
            "Chunks for abstract: Magnetic hopfions are localized magnetic solitons with a nonzero 3D\n",
            "topological charge (Hopf index). Herein, an analytical calculation of the\n",
            "magnetic hopfion gyrovector is presented and it is shown that it does not\n",
            "vanish even in an infinite sample. The calculation method is based on the\n",
            "concept of the emergent magnetic field. The particular case of the simplest\n",
            "nontrivial toroidal hopfion with the Hopf index $\\|Q_H\\|=1$ in the cylindrical\n",
            "magnetic dot is considered and dependencies of the gyrovector components on the\n",
            "dot sizes are calculated. Nonzero hopfion gyrovector is important in any\n",
            "description of the hopfion dynamics within the collective coordinate Thieles\n",
            "approach.\n",
            "['Magnetic hopfions are localized magnetic solitons with a nonzero 3D\\ntopological charge (Hopf index).', 'Herein, an analytical calculation of the\\nmagnetic hopfion gyrovector is presented and it is shown that it does not\\nvanish even in an infinite sample.', 'The calculation method is based on the\\nconcept of the emergent magnetic field.', 'The particular case of the simplest\\nnontrivial toroidal hopfion with the Hopf index $\\\\|Q_H\\\\|=1$ in the cylindrical\\nmagnetic dot is considered and dependencies of the gyrovector components on the\\ndot sizes are calculated.', 'Nonzero hopfion gyrovector is important in any\\ndescription of the hopfion dynamics within the collective coordinate Thieles\\napproach.']\n",
            "Chunks for abstract: We theoretically demonstrate that the hallmarks of correlation and\n",
            "fermionization in a one-dimensional exciton-polaritons gas can be observed with\n",
            "state-of-the-art technology. Our system consists of a chain of excitonic\n",
            "quantum dots coupled to a photonic waveguide, with a low filling of polaritons.\n",
            "We analytically identify the Tonks-Girardeau, Tavis-Cummings and mean-field\n",
            "limits and relate them to different regimes of the excitonic anharmonicity and\n",
            "photonic bandwidth. Using matrix-product states, we numerically calculate the\n",
            "ground-state energies, correlation functions and dynamic structure factor of\n",
            "the system. In particular, the latter has a finite weight in the Lieb-Liniger\n",
            "hole branch, and the density-density correlator displays Friedel-like\n",
            "oscillations for realistic parameters, which reveal the onset of fermionization\n",
            "close to the Tonks-Girardeau regime. Our work encourages future experiments\n",
            "aimed at observing, for the first time and in spite of the moderate excitonic\n",
            "anharmonicity, strongly correlated exciton-polariton physics.\n",
            "['We theoretically demonstrate that the hallmarks of correlation and\\nfermionization in a one-dimensional exciton-polaritons gas can be observed with\\nstate-of-the-art technology.', 'Our system consists of a chain of excitonic\\nquantum dots coupled to a photonic waveguide, with a low filling of polaritons.', 'We analytically identify the Tonks-Girardeau, Tavis-Cummings and mean-field\\nlimits and relate them to different regimes of the excitonic anharmonicity and\\nphotonic bandwidth.', 'Using matrix-product states, we numerically calculate the\\nground-state energies, correlation functions and dynamic structure factor of\\nthe system.', 'In particular, the latter has a finite weight in the Lieb-Liniger\\nhole branch, and the density-density correlator displays Friedel-like\\noscillations for realistic parameters, which reveal the onset of fermionization\\nclose to the Tonks-Girardeau regime.', 'Our work encourages future experiments\\naimed at observing, for the first time and in spite of the moderate excitonic\\nanharmonicity, strongly correlated exciton-polariton physics.']\n",
            "Chunks for abstract: Identifying transition states -- saddle points on the potential energy\n",
            "surface connecting reactant and product minima -- is central to predicting\n",
            "kinetic barriers and understanding chemical reaction mechanisms. In this work,\n",
            "we train an equivariant neural network potential, NewtonNet, on an ab initio\n",
            "dataset of thousands of organic reactions from which we derive the analytical\n",
            "Hessians from the fully differentiable machine learning (ML) model. By reducing\n",
            "the computational cost by several orders of magnitude relative to the Density\n",
            "Functional Theory (DFT) ab initio source, we can afford to use the learned\n",
            "Hessians at every step for the saddle point optimizations. We have implemented\n",
            "our ML Hessian algorithm in Sella, an open source software package designed to\n",
            "optimize atomic systems to find saddle point structures, in order to compare\n",
            "transition state optimization against quasi-Newton Hessian updates using DFT or\n",
            "the ML model. We show that the full ML Hessian robustly finds the transition\n",
            "states of 240 unseen organic reactions, even when the quality of the initial\n",
            "guess structures are degraded, while reducing the number of optimization steps\n",
            "to convergence by 2--3$\\times$ compared to the quasi-Newton DFT and ML methods.\n",
            "All data generation, NewtonNet model, and ML transition state finding methods\n",
            "are available in an automated workflow.\n",
            "['Identifying transition states -- saddle points on the potential energy\\nsurface connecting reactant and product minima -- is central to predicting\\nkinetic barriers and understanding chemical reaction mechanisms.', 'In this work,\\nwe train an equivariant neural network potential, NewtonNet, on an ab initio\\ndataset of thousands of organic reactions from which we derive the analytical\\nHessians from the fully differentiable machine learning (ML) model.', 'By reducing\\nthe computational cost by several orders of magnitude relative to the Density\\nFunctional Theory (DFT) ab initio source, we can afford to use the learned\\nHessians at every step for the saddle point optimizations.', 'We have implemented\\nour ML Hessian algorithm in Sella, an open source software package designed to\\noptimize atomic systems to find saddle point structures, in order to compare\\ntransition state optimization against quasi-Newton Hessian updates using DFT or\\nthe ML model.', 'We show that the full ML Hessian robustly finds the transition\\nstates of 240 unseen organic reactions, even when the quality of the initial\\nguess structures are degraded, while reducing the number of optimization steps\\nto convergence by 2--3$\\\\times$ compared to the quasi-Newton DFT and ML methods.', 'All data generation, NewtonNet model, and ML transition state finding methods\\nare available in an automated workflow.']\n",
            "Chunks for abstract: Behavioral cloning, or more broadly, learning from demonstrations (LfD) is a\n",
            "priomising direction for robot policy learning in complex scenarios. Albeit\n",
            "being straightforward to implement and data-efficient, behavioral cloning has\n",
            "its own drawbacks, limiting its efficacy in real robot setups. In this work, we\n",
            "take one step towards improving learning from demonstration algorithms by\n",
            "leveraging implicit energy-based policy models. Results suggest that in\n",
            "selected complex robot policy learning scenarios, treating supervised policy\n",
            "learning with an implicit model generally performs better, on average, than\n",
            "commonly used neural network-based explicit models, especially in the cases of\n",
            "approximating potentially discontinuous and multimodal functions.\n",
            "['Behavioral cloning, or more broadly, learning from demonstrations (LfD) is a\\npriomising direction for robot policy learning in complex scenarios.', 'Albeit\\nbeing straightforward to implement and data-efficient, behavioral cloning has\\nits own drawbacks, limiting its efficacy in real robot setups.', 'In this work, we\\ntake one step towards improving learning from demonstration algorithms by\\nleveraging implicit energy-based policy models.', 'Results suggest that in\\nselected complex robot policy learning scenarios, treating supervised policy\\nlearning with an implicit model generally performs better, on average, than\\ncommonly used neural network-based explicit models, especially in the cases of\\napproximating potentially discontinuous and multimodal functions.']\n",
            "Chunks for abstract: We present a novel method for robotic manipulation tasks in human\n",
            "environments that require reasoning about the 3D geometric relationship between\n",
            "a pair of objects. Traditional end-to-end trained policies, which map from\n",
            "pixel observations to low-level robot actions, struggle to reason about complex\n",
            "pose relationships and have difficulty generalizing to unseen object\n",
            "configurations. To address these challenges, we propose a method that learns to\n",
            "reason about the 3D geometric relationship between objects, focusing on the\n",
            "relationship between key parts on one object with respect to key parts on\n",
            "another object. Our standalone model utilizes Weighted SVD to reason about both\n",
            "pose relationships between articulated parts and between free-floating objects.\n",
            "This approach allows the robot to understand the relationship between the oven\n",
            "door and the oven body, as well as the relationship between the lasagna plate\n",
            "and the oven, for example. By considering the 3D geometric relationship between\n",
            "objects, our method enables robots to perform complex manipulation tasks that\n",
            "reason about object-centric representations. We open source the code and\n",
            "demonstrate the results here\n",
            "['We present a novel method for robotic manipulation tasks in human\\nenvironments that require reasoning about the 3D geometric relationship between\\na pair of objects.', 'Traditional end-to-end trained policies, which map from\\npixel observations to low-level robot actions, struggle to reason about complex\\npose relationships and have difficulty generalizing to unseen object\\nconfigurations.', 'To address these challenges, we propose a method that learns to\\nreason about the 3D geometric relationship between objects, focusing on the\\nrelationship between key parts on one object with respect to key parts on\\nanother object.', 'Our standalone model utilizes Weighted SVD to reason about both\\npose relationships between articulated parts and between free-floating objects.', 'This approach allows the robot to understand the relationship between the oven\\ndoor and the oven body, as well as the relationship between the lasagna plate\\nand the oven, for example.', 'By considering the 3D geometric relationship between\\nobjects, our method enables robots to perform complex manipulation tasks that\\nreason about object-centric representations.', 'We open source the code and\\ndemonstrate the results here']\n",
            "Chunks for abstract: This paper introduces a framework for post-processing machine learning models\n",
            "so that their predictions satisfy multi-group fairness guarantees. Based on the\n",
            "celebrated notion of multicalibration, we introduce $(\\mathbf{s},\\mathcal{G},\n",
            "\\alpha)-$GMC (Generalized Multi-Dimensional Multicalibration) for\n",
            "multi-dimensional mappings $\\mathbf{s}$, constraint set $\\mathcal{G}$, and a\n",
            "pre-specified threshold level $\\alpha$. We propose associated algorithms to\n",
            "achieve this notion in general settings. This framework is then applied to\n",
            "diverse scenarios encompassing different fairness concerns, including false\n",
            "negative rate control in image segmentation, prediction set conditional\n",
            "uncertainty quantification in hierarchical classification, and de-biased text\n",
            "generation in language models. We conduct numerical studies on several datasets\n",
            "and tasks.\n",
            "['This paper introduces a framework for post-processing machine learning models\\nso that their predictions satisfy multi-group fairness guarantees.', 'Based on the\\ncelebrated notion of multicalibration, we introduce $(\\\\mathbf{s},\\\\mathcal{G},\\n\\\\alpha)-$GMC (Generalized Multi-Dimensional Multicalibration) for\\nmulti-dimensional mappings $\\\\mathbf{s}$, constraint set $\\\\mathcal{G}$, and a\\npre-specified threshold level $\\\\alpha$.', 'We propose associated algorithms to\\nachieve this notion in general settings.', 'This framework is then applied to\\ndiverse scenarios encompassing different fairness concerns, including false\\nnegative rate control in image segmentation, prediction set conditional\\nuncertainty quantification in hierarchical classification, and de-biased text\\ngeneration in language models.', 'We conduct numerical studies on several datasets\\nand tasks.']\n",
            "Chunks for abstract: Context. Primordial black holes (PBHs) have been proposed as potential\n",
            "candidates for dark matter (DM) and have garnered significant attention in\n",
            "recent years. Aims. Our objective is to delve into the distinct impact of PBHs\n",
            "on gas properties and their potential role in shaping the cosmic structure.\n",
            "Specifically, we aim to analyze the evolving gas properties while considering\n",
            "the presence of accreting PBHs with varying monochromatic masses and in\n",
            "different quantities. By studying the feedback effects produced by this\n",
            "accretion, our final goal is to assess the plausibility of PBHs as candidates\n",
            "for DM. Methods. We develop a semi-analytical model which works on top of the\n",
            "CIELO hydrodynamical simulation around $z\\sim23$. This model enables a\n",
            "comprehensive analysis of the evolution of gas properties influenced by PBHs.\n",
            "Our focus lies on the temperature and hydrogen abundances, placing specific\n",
            "emphasis on the region closest to the halo center. We explore PBH masses of\n",
            "$1$, $33$, and $100~\\Msun$, located within mass windows where a substantial\n",
            "fraction of DM could exist in the form of PBHs. We investigate various DM\n",
            "fractions composed of these PBHs ($f_{\\rm{PBH}}>10^{-4}$). Results. Our\n",
            "findings suggest that the existence of PBHs with masses of $1~\\Msun$ and\n",
            "fractions greater than or equal to approximately $10^{-2}$ would be ruled out\n",
            "due to the significant changes induced in gas properties. The same applies to\n",
            "PBHs with a mass of $33~\\Msun$ and $100~\\Msun$ and fractions greater than\n",
            "approximately $10^{-3}$. These effects are particularly pronounced in the\n",
            "region nearest to the halo center, potentially leading to delayed galaxy\n",
            "formation within haloes.\n",
            "['Context.', 'Primordial black holes (PBHs) have been proposed as potential\\ncandidates for dark matter (DM) and have garnered significant attention in\\nrecent years.', 'Aims.', 'Our objective is to delve into the distinct impact of PBHs\\non gas properties and their potential role in shaping the cosmic structure.', 'Specifically, we aim to analyze the evolving gas properties while considering\\nthe presence of accreting PBHs with varying monochromatic masses and in\\ndifferent quantities.', 'By studying the feedback effects produced by this\\naccretion, our final goal is to assess the plausibility of PBHs as candidates\\nfor DM.', 'Methods.', 'We develop a semi-analytical model which works on top of the\\nCIELO hydrodynamical simulation around $z\\\\sim23$.', 'This model enables a\\ncomprehensive analysis of the evolution of gas properties influenced by PBHs.', 'Our focus lies on the temperature and hydrogen abundances, placing specific\\nemphasis on the region closest to the halo center.', 'We explore PBH masses of\\n$1$, $33$, and $100~\\\\Msun$, located within mass windows where a substantial\\nfraction of DM could exist in the form of PBHs.', 'We investigate various DM\\nfractions composed of these PBHs ($f_{\\\\rm{PBH}}>10^{-4}$).', 'Results.', 'Our\\nfindings suggest that the existence of PBHs with masses of $1~\\\\Msun$ and\\nfractions greater than or equal to approximately $10^{-2}$ would be ruled out\\ndue to the significant changes induced in gas properties.', 'The same applies to\\nPBHs with a mass of $33~\\\\Msun$ and $100~\\\\Msun$ and fractions greater than\\napproximately $10^{-3}$.', 'These effects are particularly pronounced in the\\nregion nearest to the halo center, potentially leading to delayed galaxy\\nformation within haloes.']\n",
            "Chunks for abstract: The complex challenge of detecting sarcasm in Arabic speech on social media\n",
            "is increased by the language diversity and the nature of sarcastic expressions.\n",
            "There is a significant gap in the capability of existing models to effectively\n",
            "interpret sarcasm in Arabic, which mandates the necessity for more\n",
            "sophisticated and precise detection methods. In this paper, we investigate the\n",
            "impact of a fundamental preprocessing component on sarcasm speech detection.\n",
            "While emojis play a crucial role in mitigating the absence effect of body\n",
            "language and facial expressions in modern communication, their impact on\n",
            "automated text analysis, particularly in sarcasm detection, remains\n",
            "underexplored. We investigate the impact of emoji exclusion from datasets on\n",
            "the performance of sarcasm detection models in social media content for Arabic\n",
            "as a vocabulary-super rich language. This investigation includes the adaptation\n",
            "and enhancement of AraBERT pre-training models, specifically by excluding\n",
            "emojis, to improve sarcasm detection capabilities. We use AraBERT pre-training\n",
            "to refine the specified models, demonstrating that the removal of emojis can\n",
            "significantly boost the accuracy of sarcasm detection. This approach\n",
            "facilitates a more refined interpretation of language, eliminating the\n",
            "potential confusion introduced by non-textual elements. The evaluated AraBERT\n",
            "models, through the focused strategy of emoji removal, adeptly navigate the\n",
            "complexities of Arabic sarcasm. This study establishes new benchmarks in Arabic\n",
            "natural language processing and presents valuable insights for social media\n",
            "platforms.\n",
            "['The complex challenge of detecting sarcasm in Arabic speech on social media\\nis increased by the language diversity and the nature of sarcastic expressions.', 'There is a significant gap in the capability of existing models to effectively\\ninterpret sarcasm in Arabic, which mandates the necessity for more\\nsophisticated and precise detection methods.', 'In this paper, we investigate the\\nimpact of a fundamental preprocessing component on sarcasm speech detection.', 'While emojis play a crucial role in mitigating the absence effect of body\\nlanguage and facial expressions in modern communication, their impact on\\nautomated text analysis, particularly in sarcasm detection, remains\\nunderexplored.', 'We investigate the impact of emoji exclusion from datasets on\\nthe performance of sarcasm detection models in social media content for Arabic\\nas a vocabulary-super rich language.', 'This investigation includes the adaptation\\nand enhancement of AraBERT pre-training models, specifically by excluding\\nemojis, to improve sarcasm detection capabilities.', 'We use AraBERT pre-training\\nto refine the specified models, demonstrating that the removal of emojis can\\nsignificantly boost the accuracy of sarcasm detection.', 'This approach\\nfacilitates a more refined interpretation of language, eliminating the\\npotential confusion introduced by non-textual elements.', 'The evaluated AraBERT\\nmodels, through the focused strategy of emoji removal, adeptly navigate the\\ncomplexities of Arabic sarcasm.', 'This study establishes new benchmarks in Arabic\\nnatural language processing and presents valuable insights for social media\\nplatforms.']\n",
            "Chunks for abstract: We present an analytical and computational study characterizing the\n",
            "structural and dynamical properties of an active filament confined in\n",
            "cylindrical channels. We first outline the effects of the interplay between\n",
            "confinement and polar self-propulsion on the conformation of the chains. We\n",
            "observe that the scaling of the polymer size in the channel, quantified by the\n",
            "end-to-end distance, shows different anomalous behaviours at different\n",
            "confinement and activity conditions. Interestingly, we show that the universal\n",
            "relation, describing the ratio between the end-to-end distance of passive\n",
            "polymer chains in cylindrical channels and in bulk is broken by activity.\n",
            "Finally, we show that the long-time diffusion coefficient under confinement can\n",
            "be rationalised by an analytical model, that takes into account the presence of\n",
            "the channel and the elongated nature of the polymer.\n",
            "['We present an analytical and computational study characterizing the\\nstructural and dynamical properties of an active filament confined in\\ncylindrical channels.', 'We first outline the effects of the interplay between\\nconfinement and polar self-propulsion on the conformation of the chains.', 'We\\nobserve that the scaling of the polymer size in the channel, quantified by the\\nend-to-end distance, shows different anomalous behaviours at different\\nconfinement and activity conditions.', 'Interestingly, we show that the universal\\nrelation, describing the ratio between the end-to-end distance of passive\\npolymer chains in cylindrical channels and in bulk is broken by activity.', 'Finally, we show that the long-time diffusion coefficient under confinement can\\nbe rationalised by an analytical model, that takes into account the presence of\\nthe channel and the elongated nature of the polymer.']\n",
            "Chunks for abstract: The Model Parameter Randomisation Test (MPRT) is highly recognised in the\n",
            "eXplainable Artificial Intelligence (XAI) community due to its fundamental\n",
            "evaluative criterion: explanations should be sensitive to the parameters of the\n",
            "model they seek to explain. However, recent studies have raised several\n",
            "methodological concerns for the empirical interpretation of MPRT. In response,\n",
            "we propose two modifications to the original test: Smooth MPRT and Efficient\n",
            "MPRT. The former reduces the impact of noise on evaluation outcomes via\n",
            "sampling, while the latter avoids the need for biased similarity measurements\n",
            "by re-interpreting the test through the increase in explanation complexity\n",
            "after full model randomisation. Our experiments show that these modifications\n",
            "enhance the metric reliability, facilitating a more trustworthy deployment of\n",
            "explanation methods.\n",
            "['The Model Parameter Randomisation Test (MPRT) is highly recognised in the\\neXplainable Artificial Intelligence (XAI) community due to its fundamental\\nevaluative criterion: explanations should be sensitive to the parameters of the\\nmodel they seek to explain.', 'However, recent studies have raised several\\nmethodological concerns for the empirical interpretation of MPRT.', 'In response,\\nwe propose two modifications to the original test: Smooth MPRT and Efficient\\nMPRT.', 'The former reduces the impact of noise on evaluation outcomes via\\nsampling, while the latter avoids the need for biased similarity measurements\\nby re-interpreting the test through the increase in explanation complexity\\nafter full model randomisation.', 'Our experiments show that these modifications\\nenhance the metric reliability, facilitating a more trustworthy deployment of\\nexplanation methods.']\n",
            "Chunks for abstract: The rapid development of Large Language Models (LLMs) has led to a surge in\n",
            "applications that facilitate collaboration among multiple agents, assisting\n",
            "humans in their daily tasks. However, a significant gap remains in assessing to\n",
            "what extent LLM-powered applications genuinely enhance user experience and task\n",
            "execution efficiency. This highlights the need to verify utility of LLM-powered\n",
            "applications, particularly by ensuring alignment between the application's\n",
            "functionality and end-user needs. We introduce AgentEval, a novel framework\n",
            "designed to simplify the utility verification process by automatically\n",
            "proposing a set of criteria tailored to the unique purpose of any given\n",
            "application. This allows for a comprehensive assessment, quantifying the\n",
            "utility of an application against the suggested criteria. We present a\n",
            "comprehensive analysis of the effectiveness and robustness of AgentEval for two\n",
            "open source datasets including Math Problem solving and ALFWorld House-hold\n",
            "related tasks. For reproducibility purposes, we make the data, code and all the\n",
            "logs publicly available at https://bit.ly/3w3yKcS .\n",
            "['The rapid development of Large Language Models (LLMs) has led to a surge in\\napplications that facilitate collaboration among multiple agents, assisting\\nhumans in their daily tasks.', 'However, a significant gap remains in assessing to\\nwhat extent LLM-powered applications genuinely enhance user experience and task\\nexecution efficiency.', \"This highlights the need to verify utility of LLM-powered\\napplications, particularly by ensuring alignment between the application's\\nfunctionality and end-user needs.\", 'We introduce AgentEval, a novel framework\\ndesigned to simplify the utility verification process by automatically\\nproposing a set of criteria tailored to the unique purpose of any given\\napplication.', 'This allows for a comprehensive assessment, quantifying the\\nutility of an application against the suggested criteria.', 'We present a\\ncomprehensive analysis of the effectiveness and robustness of AgentEval for two\\nopen source datasets including Math Problem solving and ALFWorld House-hold\\nrelated tasks.', 'For reproducibility purposes, we make the data, code and all the\\nlogs publicly available at https://bit.ly/3w3yKcS .']\n",
            "Chunks for abstract: A question of F. Kwakkel and V. Markovic on existence of C^1-diffeomorphisms\n",
            "of closed surfaces that permute a dense collection of domains with bounded\n",
            "geometry is answered in the negative. In fact, it is proved that for closed\n",
            "surfaces of genus at least one such diffeomorphisms do not exist regardless of\n",
            "whether they have positive or zero topological entropy.\n",
            "['A question of F. Kwakkel and V. Markovic on existence of C^1-diffeomorphisms\\nof closed surfaces that permute a dense collection of domains with bounded\\ngeometry is answered in the negative.', 'In fact, it is proved that for closed\\nsurfaces of genus at least one such diffeomorphisms do not exist regardless of\\nwhether they have positive or zero topological entropy.']\n",
            "Chunks for abstract: Deciphering the intricacies of the human brain has captivated curiosity for\n",
            "centuries. Recent strides in Brain-Computer Interface (BCI) technology,\n",
            "particularly using motor imagery, have restored motor functions such as\n",
            "reaching, grasping, and walking in paralyzed individuals. However, unraveling\n",
            "natural language from brain signals remains a formidable challenge.\n",
            "Electroencephalography (EEG) is a non-invasive technique used to record\n",
            "electrical activity in the brain by placing electrodes on the scalp. Previous\n",
            "studies of EEG-to-text decoding have achieved high accuracy on small closed\n",
            "vocabularies, but still fall short of high accuracy when dealing with large\n",
            "open vocabularies. We propose a novel method, EEG2TEXT, to improve the accuracy\n",
            "of open vocabulary EEG-to-text decoding. Specifically, EEG2TEXT leverages EEG\n",
            "pre-training to enhance the learning of semantics from EEG signals and proposes\n",
            "a multi-view transformer to model the EEG signal processing by different\n",
            "spatial regions of the brain. Experiments show that EEG2TEXT has superior\n",
            "performance, outperforming the state-of-the-art baseline methods by a large\n",
            "margin of up to 5% in absolute BLEU and ROUGE scores. EEG2TEXT shows great\n",
            "potential for a high-performance open-vocabulary brain-to-text system to\n",
            "facilitate communication.\n",
            "['Deciphering the intricacies of the human brain has captivated curiosity for\\ncenturies.', 'Recent strides in Brain-Computer Interface (BCI) technology,\\nparticularly using motor imagery, have restored motor functions such as\\nreaching, grasping, and walking in paralyzed individuals.', 'However, unraveling\\nnatural language from brain signals remains a formidable challenge.', 'Electroencephalography (EEG) is a non-invasive technique used to record\\nelectrical activity in the brain by placing electrodes on the scalp.', 'Previous\\nstudies of EEG-to-text decoding have achieved high accuracy on small closed\\nvocabularies, but still fall short of high accuracy when dealing with large\\nopen vocabularies.', 'We propose a novel method, EEG2TEXT, to improve the accuracy\\nof open vocabulary EEG-to-text decoding.', 'Specifically, EEG2TEXT leverages EEG\\npre-training to enhance the learning of semantics from EEG signals and proposes\\na multi-view transformer to model the EEG signal processing by different\\nspatial regions of the brain.', 'Experiments show that EEG2TEXT has superior\\nperformance, outperforming the state-of-the-art baseline methods by a large\\nmargin of up to 5% in absolute BLEU and ROUGE scores.', 'EEG2TEXT shows great\\npotential for a high-performance open-vocabulary brain-to-text system to\\nfacilitate communication.']\n",
            "Chunks for abstract: This paper introduces a novel framework for zero-shot learning (ZSL), i.e.,\n",
            "to recognize new categories that are unseen during training, by using a\n",
            "multi-model and multi-alignment integration method. Specifically, we propose\n",
            "three strategies to enhance the model's performance to handle ZSL: 1) Utilizing\n",
            "the extensive knowledge of ChatGPT and the powerful image generation\n",
            "capabilities of DALL-E to create reference images that can precisely describe\n",
            "unseen categories and classification boundaries, thereby alleviating the\n",
            "information bottleneck issue; 2) Integrating the results of text-image\n",
            "alignment and image-image alignment from CLIP, along with the image-image\n",
            "alignment results from DINO, to achieve more accurate predictions; 3)\n",
            "Introducing an adaptive weighting mechanism based on confidence levels to\n",
            "aggregate the outcomes from different prediction methods. Experimental results\n",
            "on multiple datasets, including CIFAR-10, CIFAR-100, and TinyImageNet,\n",
            "demonstrate that our model can significantly improve classification accuracy\n",
            "compared to single-model approaches, achieving AUROC scores above 96% across\n",
            "all test datasets, and notably surpassing 99% on the CIFAR-10 dataset.\n",
            "['This paper introduces a novel framework for zero-shot learning (ZSL), i.e.,\\nto recognize new categories that are unseen during training, by using a\\nmulti-model and multi-alignment integration method.', \"Specifically, we propose\\nthree strategies to enhance the model's performance to handle ZSL: 1) Utilizing\\nthe extensive knowledge of ChatGPT and the powerful image generation\\ncapabilities of DALL-E to create reference images that can precisely describe\\nunseen categories and classification boundaries, thereby alleviating the\\ninformation bottleneck issue; 2) Integrating the results of text-image\\nalignment and image-image alignment from CLIP, along with the image-image\\nalignment results from DINO, to achieve more accurate predictions; 3)\\nIntroducing an adaptive weighting mechanism based on confidence levels to\\naggregate the outcomes from different prediction methods.\", 'Experimental results\\non multiple datasets, including CIFAR-10, CIFAR-100, and TinyImageNet,\\ndemonstrate that our model can significantly improve classification accuracy\\ncompared to single-model approaches, achieving AUROC scores above 96% across\\nall test datasets, and notably surpassing 99% on the CIFAR-10 dataset.']\n",
            "Chunks for abstract: Medical texts are notoriously challenging to read. Properly measuring their\n",
            "readability is the first step towards making them more accessible. In this\n",
            "paper, we present a systematic study on fine-grained readability measurements\n",
            "in the medical domain at both sentence-level and span-level. We introduce a new\n",
            "dataset MedReadMe, which consists of manually annotated readability ratings and\n",
            "fine-grained complex span annotation for 4,520 sentences, featuring two novel\n",
            "\"Google-Easy\" and \"Google-Hard\" categories. It supports our quantitative\n",
            "analysis, which covers 650 linguistic features and automatic complex word and\n",
            "jargon identification. Enabled by our high-quality annotation, we benchmark and\n",
            "improve several state-of-the-art sentence-level readability metrics for the\n",
            "medical domain specifically, which include unsupervised, supervised, and\n",
            "prompting-based methods using recently developed large language models (LLMs).\n",
            "Informed by our fine-grained complex span annotation, we find that adding a\n",
            "single feature, capturing the number of jargon spans, into existing readability\n",
            "formulas can significantly improve their correlation with human judgments. We\n",
            "will publicly release the dataset and code.\n",
            "['Medical texts are notoriously challenging to read.', 'Properly measuring their\\nreadability is the first step towards making them more accessible.', 'In this\\npaper, we present a systematic study on fine-grained readability measurements\\nin the medical domain at both sentence-level and span-level.', 'We introduce a new\\ndataset MedReadMe, which consists of manually annotated readability ratings and\\nfine-grained complex span annotation for 4,520 sentences, featuring two novel\\n\"Google-Easy\" and \"Google-Hard\" categories.', 'It supports our quantitative\\nanalysis, which covers 650 linguistic features and automatic complex word and\\njargon identification.', 'Enabled by our high-quality annotation, we benchmark and\\nimprove several state-of-the-art sentence-level readability metrics for the\\nmedical domain specifically, which include unsupervised, supervised, and\\nprompting-based methods using recently developed large language models (LLMs).', 'Informed by our fine-grained complex span annotation, we find that adding a\\nsingle feature, capturing the number of jargon spans, into existing readability\\nformulas can significantly improve their correlation with human judgments.', 'We\\nwill publicly release the dataset and code.']\n",
            "Chunks for abstract: Multipath-based simultaneous localization and mapping (MP-SLAM) is a\n",
            "promising approach in wireless networks for obtaining position information of\n",
            "transmitters and receivers as well as information on the propagation\n",
            "environment. MP-SLAM models specular reflections of radio frequency (RF)\n",
            "signals at flat surfaces as virtual anchors (VAs), the mirror images of base\n",
            "stations (BSs). Conventional methods for MP-SLAM consider a single mobile\n",
            "terminal (MT) which has to be localized. The availability of additional MTs\n",
            "paves the way for utilizing additional information in the scenario.\n",
            "Specifically enabling MTs to exchange information allows for data fusion over\n",
            "different observations of VAs made by different MTs. Furthermore, cooperative\n",
            "localization becomes possible in addition to multipath-based localization.\n",
            "Utilizing this additional information enables more robust mapping and higher\n",
            "localization accuracy.\n",
            "['Multipath-based simultaneous localization and mapping (MP-SLAM) is a\\npromising approach in wireless networks for obtaining position information of\\ntransmitters and receivers as well as information on the propagation\\nenvironment.', 'MP-SLAM models specular reflections of radio frequency (RF)\\nsignals at flat surfaces as virtual anchors (VAs), the mirror images of base\\nstations (BSs).', 'Conventional methods for MP-SLAM consider a single mobile\\nterminal (MT) which has to be localized.', 'The availability of additional MTs\\npaves the way for utilizing additional information in the scenario.', 'Specifically enabling MTs to exchange information allows for data fusion over\\ndifferent observations of VAs made by different MTs.', 'Furthermore, cooperative\\nlocalization becomes possible in addition to multipath-based localization.', 'Utilizing this additional information enables more robust mapping and higher\\nlocalization accuracy.']\n",
            "Chunks for abstract: In this paper, we present a novel approach for text independent\n",
            "phone-to-audio alignment based on phoneme recognition, representation learning\n",
            "and knowledge transfer. Our method leverages a self-supervised model (wav2vec2)\n",
            "fine-tuned for phoneme recognition using a Connectionist Temporal\n",
            "Classification (CTC) loss, a dimension reduction model and a frame-level\n",
            "phoneme classifier trained thanks to forced-alignment labels (using Montreal\n",
            "Forced Aligner) to produce multi-lingual phonetic representations, thus\n",
            "requiring minimal additional training. We evaluate our model using synthetic\n",
            "native data from the TIMIT dataset and the SCRIBE dataset for American and\n",
            "British English, respectively. Our proposed model outperforms the\n",
            "state-of-the-art (charsiu) in statistical metrics and has applications in\n",
            "language learning and speech processing systems. We leave experiments on other\n",
            "languages for future work but the design of the system makes it easily\n",
            "adaptable to other languages.\n",
            "['In this paper, we present a novel approach for text independent\\nphone-to-audio alignment based on phoneme recognition, representation learning\\nand knowledge transfer.', 'Our method leverages a self-supervised model (wav2vec2)\\nfine-tuned for phoneme recognition using a Connectionist Temporal\\nClassification (CTC) loss, a dimension reduction model and a frame-level\\nphoneme classifier trained thanks to forced-alignment labels (using Montreal\\nForced Aligner) to produce multi-lingual phonetic representations, thus\\nrequiring minimal additional training.', 'We evaluate our model using synthetic\\nnative data from the TIMIT dataset and the SCRIBE dataset for American and\\nBritish English, respectively.', 'Our proposed model outperforms the\\nstate-of-the-art (charsiu) in statistical metrics and has applications in\\nlanguage learning and speech processing systems.', 'We leave experiments on other\\nlanguages for future work but the design of the system makes it easily\\nadaptable to other languages.']\n",
            "Chunks for abstract: The present survey is devoted to results on Trudinger-Moser inequalities in\n",
            "two dimension. We give a brief overview of the history of these celebrated\n",
            "inequalities and, starting from the geometric problem that motivated Moser's\n",
            "original work, we discuss the connection between Onofri's inequality for the\n",
            "unit sphere and sharp inequalities on Euclidean domains. Finally, we present\n",
            "recent results and new insights into nonlocal interaction energy functionals in\n",
            "two dimension, involving logarithmic kernels.\n",
            "['The present survey is devoted to results on Trudinger-Moser inequalities in\\ntwo dimension.', \"We give a brief overview of the history of these celebrated\\ninequalities and, starting from the geometric problem that motivated Moser's\\noriginal work, we discuss the connection between Onofri's inequality for the\\nunit sphere and sharp inequalities on Euclidean domains.\", 'Finally, we present\\nrecent results and new insights into nonlocal interaction energy functionals in\\ntwo dimension, involving logarithmic kernels.']\n",
            "Chunks for abstract: The multi-grid reaction-diffusion master equation (mgRDME) provides a\n",
            "generalization of stochastic compartment-based reaction-diffusion modelling\n",
            "described by the standard reaction-diffusion master equation (RDME). By\n",
            "enabling different resolutions on lattices for biochemical species with\n",
            "different diffusion constants, the mgRDME approach improves both accuracy and\n",
            "efficiency of compartment-based reaction-diffusion simulations. The mgRDME\n",
            "framework is examined through its application to morphogen gradient formation\n",
            "in stochastic reaction-diffusion scenarios, using both an analytically\n",
            "tractable first-order reaction network and a model with a second-order\n",
            "reaction. The results obtained by the mgRDME modelling are compared with the\n",
            "standard RDME model and with the (more detailed) particle-based Brownian\n",
            "dynamics simulations. The dependence of error and numerical cost on the\n",
            "compartment sizes is defined and investigated through a multi-objective\n",
            "optimization problem.\n",
            "['The multi-grid reaction-diffusion master equation (mgRDME) provides a\\ngeneralization of stochastic compartment-based reaction-diffusion modelling\\ndescribed by the standard reaction-diffusion master equation (RDME).', 'By\\nenabling different resolutions on lattices for biochemical species with\\ndifferent diffusion constants, the mgRDME approach improves both accuracy and\\nefficiency of compartment-based reaction-diffusion simulations.', 'The mgRDME\\nframework is examined through its application to morphogen gradient formation\\nin stochastic reaction-diffusion scenarios, using both an analytically\\ntractable first-order reaction network and a model with a second-order\\nreaction.', 'The results obtained by the mgRDME modelling are compared with the\\nstandard RDME model and with the (more detailed) particle-based Brownian\\ndynamics simulations.', 'The dependence of error and numerical cost on the\\ncompartment sizes is defined and investigated through a multi-objective\\noptimization problem.']\n",
            "Chunks for abstract: Linux systems are integral to the infrastructure of modern computing\n",
            "environments, necessitating robust security measures to prevent unauthorized\n",
            "access. Privilege escalation attacks represent a significant threat, typically\n",
            "allowing attackers to elevate their privileges from an initial low-privilege\n",
            "account to the all-powerful root account.\n",
            "  A benchmark set of vulnerable systems is of high importance to evaluate the\n",
            "effectiveness of privilege-escalation techniques performed by both humans and\n",
            "automated tooling. Analyzing their behavior allows defenders to better fortify\n",
            "their entrusted Linux systems and thus protect their infrastructure from\n",
            "potentially devastating attacks.\n",
            "  To address this gap, we developed a comprehensive benchmark for Linux\n",
            "privilege escalation. It provides a standardized platform to evaluate and\n",
            "compare the performance of human and synthetic actors, e.g., hacking scripts or\n",
            "automated tooling.\n",
            "['Linux systems are integral to the infrastructure of modern computing\\nenvironments, necessitating robust security measures to prevent unauthorized\\naccess.', 'Privilege escalation attacks represent a significant threat, typically\\nallowing attackers to elevate their privileges from an initial low-privilege\\naccount to the all-powerful root account.', 'A benchmark set of vulnerable systems is of high importance to evaluate the\\neffectiveness of privilege-escalation techniques performed by both humans and\\nautomated tooling.', 'Analyzing their behavior allows defenders to better fortify\\ntheir entrusted Linux systems and thus protect their infrastructure from\\npotentially devastating attacks.', 'To address this gap, we developed a comprehensive benchmark for Linux\\nprivilege escalation.', 'It provides a standardized platform to evaluate and\\ncompare the performance of human and synthetic actors, e.g., hacking scripts or\\nautomated tooling.']\n",
            "Chunks for abstract: Recent few-shot action recognition (FSAR) methods achieve promising\n",
            "performance by performing semantic matching on learned discriminative features.\n",
            "However, most FSAR methods focus on single-scale (e.g., frame-level,\n",
            "segment-level, \\etc) feature alignment, which ignores that human actions with\n",
            "the same semantic may appear at different velocities. To this end, we develop a\n",
            "novel Multi-Velocity Progressive-alignment (MVP-Shot) framework to\n",
            "progressively learn and align semantic-related action features at\n",
            "multi-velocity levels. Concretely, a Multi-Velocity Feature Alignment (MVFA)\n",
            "module is designed to measure the similarity between features from support and\n",
            "query videos with different velocity scales and then merge all similarity\n",
            "scores in a residual fashion. To avoid the multiple velocity features deviating\n",
            "from the underlying motion semantic, our proposed Progressive Semantic-Tailored\n",
            "Interaction (PSTI) module injects velocity-tailored text information into the\n",
            "video feature via feature interaction on channel and temporal domains at\n",
            "different velocities. The above two modules compensate for each other to\n",
            "predict query categories more accurately under the few-shot settings.\n",
            "Experimental results show our method outperforms current state-of-the-art\n",
            "methods on multiple standard few-shot benchmarks (i.e., HMDB51, UCF101,\n",
            "Kinetics, and SSv2-small).\n",
            "['Recent few-shot action recognition (FSAR) methods achieve promising\\nperformance by performing semantic matching on learned discriminative features.', 'However, most FSAR methods focus on single-scale (e.g., frame-level,\\nsegment-level, \\\\etc) feature alignment, which ignores that human actions with\\nthe same semantic may appear at different velocities.', 'To this end, we develop a\\nnovel Multi-Velocity Progressive-alignment (MVP-Shot) framework to\\nprogressively learn and align semantic-related action features at\\nmulti-velocity levels.', 'Concretely, a Multi-Velocity Feature Alignment (MVFA)\\nmodule is designed to measure the similarity between features from support and\\nquery videos with different velocity scales and then merge all similarity\\nscores in a residual fashion.', 'To avoid the multiple velocity features deviating\\nfrom the underlying motion semantic, our proposed Progressive Semantic-Tailored\\nInteraction (PSTI) module injects velocity-tailored text information into the\\nvideo feature via feature interaction on channel and temporal domains at\\ndifferent velocities.', 'The above two modules compensate for each other to\\npredict query categories more accurately under the few-shot settings.', 'Experimental results show our method outperforms current state-of-the-art\\nmethods on multiple standard few-shot benchmarks (i.e., HMDB51, UCF101,\\nKinetics, and SSv2-small).']\n",
            "Chunks for abstract: Federated Learning (FL) has lately gained traction as it addresses how\n",
            "machine learning models train on distributed datasets. FL was designed for\n",
            "parametric models, namely Deep Neural Networks (DNNs).Thus, it has shown\n",
            "promise on image and text tasks. However, FL for tabular data has received\n",
            "little attention. Tree-Based Models (TBMs) have been considered to perform\n",
            "better on tabular data and they are starting to see FL integrations. In this\n",
            "study, we benchmark federated TBMs and DNNs for horizontal FL, with varying\n",
            "data partitions, on 10 well-known tabular datasets. Our novel benchmark results\n",
            "indicates that current federated boosted TBMs perform better than federated\n",
            "DNNs in different data partitions. Furthermore, a federated XGBoost outperforms\n",
            "all other models. Lastly, we find that federated TBMs perform better than\n",
            "federated parametric models, even when increasing the number of clients\n",
            "significantly.\n",
            "['Federated Learning (FL) has lately gained traction as it addresses how\\nmachine learning models train on distributed datasets.', 'FL was designed for\\nparametric models, namely Deep Neural Networks (DNNs).Thus, it has shown\\npromise on image and text tasks.', 'However, FL for tabular data has received\\nlittle attention.', 'Tree-Based Models (TBMs) have been considered to perform\\nbetter on tabular data and they are starting to see FL integrations.', 'In this\\nstudy, we benchmark federated TBMs and DNNs for horizontal FL, with varying\\ndata partitions, on 10 well-known tabular datasets.', 'Our novel benchmark results\\nindicates that current federated boosted TBMs perform better than federated\\nDNNs in different data partitions.', 'Furthermore, a federated XGBoost outperforms\\nall other models.', 'Lastly, we find that federated TBMs perform better than\\nfederated parametric models, even when increasing the number of clients\\nsignificantly.']\n",
            "Chunks for abstract: We construct initial data suitable for the Kerr stability conjecture, that\n",
            "is, solutions to the constraint equations on a spacelike hypersurface with\n",
            "boundary entering the black hole horizon that are arbitrarily decaying\n",
            "perturbations of a Kerr initial data set. This results from a more general\n",
            "perturbative construction on any asymptotically flat initial data set with the\n",
            "topology of $\\mathbb{R}^3\\setminus\\{r<1\\}$ enjoying some analyticity near and\n",
            "at the boundary. In particular, we design a suitable mixed boundary condition\n",
            "for the elliptic operator of the conformal method in order to exclude the\n",
            "Killing initial data sets (KIDS).\n",
            "['We construct initial data suitable for the Kerr stability conjecture, that\\nis, solutions to the constraint equations on a spacelike hypersurface with\\nboundary entering the black hole horizon that are arbitrarily decaying\\nperturbations of a Kerr initial data set.', 'This results from a more general\\nperturbative construction on any asymptotically flat initial data set with the\\ntopology of $\\\\mathbb{R}^3\\\\setminus\\\\{r<1\\\\}$ enjoying some analyticity near and\\nat the boundary.', 'In particular, we design a suitable mixed boundary condition\\nfor the elliptic operator of the conformal method in order to exclude the\\nKilling initial data sets (KIDS).']\n",
            "Chunks for abstract: For bounded domains $\\Omega$ with Lipschitz boundary $\\Gamma$, we investigate\n",
            "boundary value problems for elliptic operators with variable coefficients of\n",
            "fourth order subject to Wentzell (or dynamic) boundary conditions. Using form\n",
            "methods, we begin by showing general results for an even wider class of\n",
            "operators defined via two (intertwined) quadratic forms by defining very\n",
            "abstract concepts of weak traces. Even in this general setting, we prove\n",
            "generation of an analytic semigroup on the product space $L^2(\\Omega) \\times\n",
            "L^2(\\Gamma)$. Using recent results concerning weak co-normal traces, we apply\n",
            "our abstract theory to the elliptic fourth-order case and are able to fully\n",
            "characterize the domain in terms of Sobolev regularity, also obtaining\n",
            "H\\\"older-regularity of solutions. Finally, we also discuss asymptotic behavior\n",
            "and (eventual) positivity.\n",
            "['For bounded domains $\\\\Omega$ with Lipschitz boundary $\\\\Gamma$, we investigate\\nboundary value problems for elliptic operators with variable coefficients of\\nfourth order subject to Wentzell (or dynamic) boundary conditions.', 'Using form\\nmethods, we begin by showing general results for an even wider class of\\noperators defined via two (intertwined) quadratic forms by defining very\\nabstract concepts of weak traces.', 'Even in this general setting, we prove\\ngeneration of an analytic semigroup on the product space $L^2(\\\\Omega) \\\\times\\nL^2(\\\\Gamma)$.', 'Using recent results concerning weak co-normal traces, we apply\\nour abstract theory to the elliptic fourth-order case and are able to fully\\ncharacterize the domain in terms of Sobolev regularity, also obtaining\\nH\\\\\"older-regularity of solutions.', 'Finally, we also discuss asymptotic behavior\\nand (eventual) positivity.']\n",
            "Chunks for abstract: Bayesian Neural Networks (BNNs) extend traditional neural networks to provide\n",
            "uncertainties associated with their outputs. On the forward pass through a BNN,\n",
            "predictions (and their uncertainties) are made either by Monte Carlo sampling\n",
            "network weights from the learned posterior or by analytically propagating\n",
            "statistical moments through the network. Though flexible, Monte Carlo sampling\n",
            "is computationally expensive and can be infeasible or impractical under\n",
            "resource constraints or for large networks. While moment propagation can\n",
            "ameliorate the computational costs of BNN inference, it can be difficult or\n",
            "impossible for networks with arbitrary nonlinearities, thereby restricting the\n",
            "possible set of network layers permitted with such a scheme. In this work, we\n",
            "demonstrate a simple yet effective approach for propagating statistical moments\n",
            "through arbitrary nonlinearities with only 3 deterministic samples, enabling\n",
            "few-sample variational inference of BNNs without restricting the set of network\n",
            "layers used. Furthermore, we leverage this approach to demonstrate a novel\n",
            "nonlinear activation function that we use to inject physics-informed prior\n",
            "information into output nodes of a BNN.\n",
            "['Bayesian Neural Networks (BNNs) extend traditional neural networks to provide\\nuncertainties associated with their outputs.', 'On the forward pass through a BNN,\\npredictions (and their uncertainties) are made either by Monte Carlo sampling\\nnetwork weights from the learned posterior or by analytically propagating\\nstatistical moments through the network.', 'Though flexible, Monte Carlo sampling\\nis computationally expensive and can be infeasible or impractical under\\nresource constraints or for large networks.', 'While moment propagation can\\nameliorate the computational costs of BNN inference, it can be difficult or\\nimpossible for networks with arbitrary nonlinearities, thereby restricting the\\npossible set of network layers permitted with such a scheme.', 'In this work, we\\ndemonstrate a simple yet effective approach for propagating statistical moments\\nthrough arbitrary nonlinearities with only 3 deterministic samples, enabling\\nfew-sample variational inference of BNNs without restricting the set of network\\nlayers used.', 'Furthermore, we leverage this approach to demonstrate a novel\\nnonlinear activation function that we use to inject physics-informed prior\\ninformation into output nodes of a BNN.']\n",
            "Chunks for abstract: Pathology reports are rich in clinical and pathological details but are often\n",
            "presented in free-text format. The unstructured nature of these reports\n",
            "presents a significant challenge limiting the accessibility of their content.\n",
            "In this work, we present a practical approach based on the use of large\n",
            "multimodal models (LMMs) for automatically extracting information from scanned\n",
            "images of pathology reports with the goal of generating a standardised report\n",
            "specifying the value of different fields along with estimated confidence about\n",
            "the accuracy of the extracted fields. The proposed approach overcomes\n",
            "limitations of existing methods which do not assign confidence scores to\n",
            "extracted fields limiting their practical use. The proposed framework uses two\n",
            "stages of prompting a Large Multimodal Model (LMM) for information extraction\n",
            "and validation. The framework generalises to textual reports from multiple\n",
            "medical centres as well as scanned images of legacy pathology reports. We show\n",
            "that the estimated confidence is an effective indicator of the accuracy of the\n",
            "extracted information that can be used to select only accurately extracted\n",
            "fields. We also show the prognostic significance of structured and unstructured\n",
            "data from pathology reports and show that the automatically extracted field\n",
            "values significant prognostic value for patient stratification. The framework\n",
            "is available for evaluation via the URL: https://labieb.dcs.warwick.ac.uk/.\n",
            "['Pathology reports are rich in clinical and pathological details but are often\\npresented in free-text format.', 'The unstructured nature of these reports\\npresents a significant challenge limiting the accessibility of their content.', 'In this work, we present a practical approach based on the use of large\\nmultimodal models (LMMs) for automatically extracting information from scanned\\nimages of pathology reports with the goal of generating a standardised report\\nspecifying the value of different fields along with estimated confidence about\\nthe accuracy of the extracted fields.', 'The proposed approach overcomes\\nlimitations of existing methods which do not assign confidence scores to\\nextracted fields limiting their practical use.', 'The proposed framework uses two\\nstages of prompting a Large Multimodal Model (LMM) for information extraction\\nand validation.', 'The framework generalises to textual reports from multiple\\nmedical centres as well as scanned images of legacy pathology reports.', 'We show\\nthat the estimated confidence is an effective indicator of the accuracy of the\\nextracted information that can be used to select only accurately extracted\\nfields.', 'We also show the prognostic significance of structured and unstructured\\ndata from pathology reports and show that the automatically extracted field\\nvalues significant prognostic value for patient stratification.', 'The framework\\nis available for evaluation via the URL: https://labieb.dcs.warwick.ac.uk/.']\n",
            "Chunks for abstract: We present the detection of cyanothioketene, NCCHCS, in the laboratory and\n",
            "toward TMC-1. This transient species was produced through a discharge of a gas\n",
            "mixture of CH2CHCN and CS2 using argon as carrier gas, and its rotational\n",
            "spectrum between 9 and 40 GHz was characterized using a Balle-Flygare\n",
            "narrowband-type Fourier-transform microwave spectrometer. A total of 21\n",
            "rotational transitions were detected in the laboratory, all of them exhibiting\n",
            "hyperfine structure induced by the spin of the N nucleus. The spectrum for\n",
            "NCCHCS was predicted in the domain of our line surveys using the derived\n",
            "rotational and distortion constants. The detection in the cold starless core\n",
            "TMC-1 was based on the QUIJOTE line survey performed with the Yebes 40m radio\n",
            "telescope. Twenty-three lines were detected with K_a=0, 1, and 2 and J_u=9 up\n",
            "to 14. The derived column density is (1.2+/-0.1)e11 cm-2 for a rotational\n",
            "temperature of 8.5+/-1 K. The abundance ratio of thioketene and its cyano\n",
            "derivative, H2CCS/NCCHCS, is 6.5+/-1.3. Although ketene is more abundant than\n",
            "thioketene by about 15 times, its cyano derivative NCCHCO surprisingly is not\n",
            "detected with a 3sigma upper level to the column density of 3.0e10 cm-2, which\n",
            "results in an abundance ratio H2CCO/NCCHCO > 430. Hence, the chemistry of CN\n",
            "derivatives seems to be more favored for S-bearing than for O-bearing\n",
            "molecules. We carried out chemical modeling calculations and found that the\n",
            "gas-phase neutral-neutral reactions CCN + H2CS and CN + H2CCS could be a source\n",
            "of NCCHCS in TMC-1.\n",
            "['We present the detection of cyanothioketene, NCCHCS, in the laboratory and\\ntoward TMC-1.', 'This transient species was produced through a discharge of a gas\\nmixture of CH2CHCN and CS2 using argon as carrier gas, and its rotational\\nspectrum between 9 and 40 GHz was characterized using a Balle-Flygare\\nnarrowband-type Fourier-transform microwave spectrometer.', 'A total of 21\\nrotational transitions were detected in the laboratory, all of them exhibiting\\nhyperfine structure induced by the spin of the N nucleus.', 'The spectrum for\\nNCCHCS was predicted in the domain of our line surveys using the derived\\nrotational and distortion constants.', 'The detection in the cold starless core\\nTMC-1 was based on the QUIJOTE line survey performed with the Yebes 40m radio\\ntelescope.', 'Twenty-three lines were detected with K_a=0, 1, and 2 and J_u=9 up\\nto 14.', 'The derived column density is (1.2+/-0.1)e11 cm-2 for a rotational\\ntemperature of 8.5+/-1 K. The abundance ratio of thioketene and its cyano\\nderivative, H2CCS/NCCHCS, is 6.5+/-1.3.', 'Although ketene is more abundant than\\nthioketene by about 15 times, its cyano derivative NCCHCO surprisingly is not\\ndetected with a 3sigma upper level to the column density of 3.0e10 cm-2, which\\nresults in an abundance ratio H2CCO/NCCHCO > 430.', 'Hence, the chemistry of CN\\nderivatives seems to be more favored for S-bearing than for O-bearing\\nmolecules.', 'We carried out chemical modeling calculations and found that the\\ngas-phase neutral-neutral reactions CCN + H2CS and CN + H2CCS could be a source\\nof NCCHCS in TMC-1.']\n",
            "Chunks for abstract: The ability to transmit and receive complex information via language is\n",
            "unique to humans and is the basis of traditions, culture and versatile social\n",
            "interactions. Through the disruptive introduction of transformer based large\n",
            "language models (LLMs) humans are not the only entity to \"understand\" and\n",
            "produce language any more. In the present study, we have performed the first\n",
            "steps to use LLMs as a model to understand fundamental mechanisms of language\n",
            "processing in neural networks, in order to make predictions and generate\n",
            "hypotheses on how the human brain does language processing. Thus, we have used\n",
            "ChatGPT to generate seven different stylistic variations of ten different\n",
            "narratives (Aesop's fables). We used these stories as input for the open source\n",
            "LLM BERT and have analyzed the activation patterns of the hidden units of BERT\n",
            "using multi-dimensional scaling and cluster analysis. We found that the\n",
            "activation vectors of the hidden units cluster according to stylistic\n",
            "variations in earlier layers of BERT (1) than narrative content (4-5). Despite\n",
            "the fact that BERT consists of 12 identical building blocks that are stacked\n",
            "and trained on large text corpora, the different layers perform different\n",
            "tasks. This is a very useful model of the human brain, where self-similar\n",
            "structures, i.e. different areas of the cerebral cortex, can have different\n",
            "functions and are therefore well suited to processing language in a very\n",
            "efficient way. The proposed approach has the potential to open the black box of\n",
            "LLMs on the one hand, and might be a further step to unravel the neural\n",
            "processes underlying human language processing and cognition in general.\n",
            "['The ability to transmit and receive complex information via language is\\nunique to humans and is the basis of traditions, culture and versatile social\\ninteractions.', 'Through the disruptive introduction of transformer based large\\nlanguage models (LLMs) humans are not the only entity to \"understand\" and\\nproduce language any more.', 'In the present study, we have performed the first\\nsteps to use LLMs as a model to understand fundamental mechanisms of language\\nprocessing in neural networks, in order to make predictions and generate\\nhypotheses on how the human brain does language processing.', \"Thus, we have used\\nChatGPT to generate seven different stylistic variations of ten different\\nnarratives (Aesop's fables).\", 'We used these stories as input for the open source\\nLLM BERT and have analyzed the activation patterns of the hidden units of BERT\\nusing multi-dimensional scaling and cluster analysis.', 'We found that the\\nactivation vectors of the hidden units cluster according to stylistic\\nvariations in earlier layers of BERT (1) than narrative content (4-5).', 'Despite\\nthe fact that BERT consists of 12 identical building blocks that are stacked\\nand trained on large text corpora, the different layers perform different\\ntasks.', 'This is a very useful model of the human brain, where self-similar\\nstructures, i.e.', 'different areas of the cerebral cortex, can have different\\nfunctions and are therefore well suited to processing language in a very\\nefficient way.', 'The proposed approach has the potential to open the black box of\\nLLMs on the one hand, and might be a further step to unravel the neural\\nprocesses underlying human language processing and cognition in general.']\n",
            "Chunks for abstract: Social bots play a significant role in many online social networks (OSN) as\n",
            "they imitate human behavior. This fact raises difficult questions about their\n",
            "capabilities and potential risks. Given the recent advances in Generative AI\n",
            "(GenAI), social bots are capable of producing highly realistic and complex\n",
            "content that mimics human creativity. As the malicious social bots emerge to\n",
            "deceive people with their unrealistic content, identifying them and\n",
            "distinguishing the content they produce has become an actual challenge for\n",
            "numerous social platforms. Several approaches to this problem have already been\n",
            "proposed in the literature, but the proposed solutions have not been widely\n",
            "evaluated. To address this issue, we evaluate the behavior of a text-based bot\n",
            "detector in a competitive environment where some scenarios are proposed:\n",
            "\\textit{First}, the tug-of-war between a bot and a bot detector is examined. It\n",
            "is interesting to analyze which party is more likely to prevail and which\n",
            "circumstances influence these expectations. In this regard, we model the\n",
            "problem as a synthetic adversarial game in which a conversational bot and a bot\n",
            "detector are engaged in strategic online interactions. \\textit{Second}, the bot\n",
            "detection model is evaluated under attack examples generated by a social bot;\n",
            "to this end, we poison the dataset with attack examples and evaluate the model\n",
            "performance under this condition. \\textit{Finally}, to investigate the impact\n",
            "of the dataset, a cross-domain analysis is performed. Through our comprehensive\n",
            "evaluation of different categories of social bots using two benchmark datasets,\n",
            "we were able to demonstrate some achivement that could be utilized in future\n",
            "works.\n",
            "['Social bots play a significant role in many online social networks (OSN) as\\nthey imitate human behavior.', 'This fact raises difficult questions about their\\ncapabilities and potential risks.', 'Given the recent advances in Generative AI\\n(GenAI), social bots are capable of producing highly realistic and complex\\ncontent that mimics human creativity.', 'As the malicious social bots emerge to\\ndeceive people with their unrealistic content, identifying them and\\ndistinguishing the content they produce has become an actual challenge for\\nnumerous social platforms.', 'Several approaches to this problem have already been\\nproposed in the literature, but the proposed solutions have not been widely\\nevaluated.', 'To address this issue, we evaluate the behavior of a text-based bot\\ndetector in a competitive environment where some scenarios are proposed:\\n\\\\textit{First}, the tug-of-war between a bot and a bot detector is examined.', 'It\\nis interesting to analyze which party is more likely to prevail and which\\ncircumstances influence these expectations.', 'In this regard, we model the\\nproblem as a synthetic adversarial game in which a conversational bot and a bot\\ndetector are engaged in strategic online interactions.', '\\\\textit{Second}, the bot\\ndetection model is evaluated under attack examples generated by a social bot;\\nto this end, we poison the dataset with attack examples and evaluate the model\\nperformance under this condition.', '\\\\textit{Finally}, to investigate the impact\\nof the dataset, a cross-domain analysis is performed.', 'Through our comprehensive\\nevaluation of different categories of social bots using two benchmark datasets,\\nwe were able to demonstrate some achivement that could be utilized in future\\nworks.']\n",
            "Chunks for abstract: Planar germanium quantum wells have recently been shown to host a hard-gapped\n",
            "superconductor-semiconductor interface. Additionally, quantum dot spin qubits\n",
            "in germanium are well-suited for quantum information processing, with isotopic\n",
            "purification to a nuclear spin-free material expected to yield long coherence\n",
            "times. Therefore, as one of the few group IV materials with the potential to\n",
            "host superconductor-semiconductor hybrid devices, proximitized quantum dots in\n",
            "germanium are a crucial ingredient towards topological superconductivity and\n",
            "novel qubit modalities. Here we demonstrate a quantum dot (QD) in a Ge/SiGe\n",
            "heterostructure proximitized by a platinum germanosilicide (PtGeSi)\n",
            "superconducting lead (SC), forming a SC-QD-SC junction. We show tunability of\n",
            "the QD-SC coupling strength, as well as gate control of the ratio of charging\n",
            "energy and the induced gap. We further exploit this tunability by exhibiting\n",
            "control of the ground state of the system between even and odd parity.\n",
            "Furthermore, we characterize the critical magnetic field strengths, finding a\n",
            "robust critical out-of-plane field of 0.91(5) T. Finally we explore sub-gap\n",
            "spin splitting in the device, observing rich physics in the resulting spectra,\n",
            "that we model using a zero-bandwidth model in the Yu-Shiba-Rusinov limit. The\n",
            "demonstration of controllable proximitization at the nanoscale of a germanium\n",
            "quantum dot opens up the physics of novel spin and superconducting qubits, and\n",
            "Josephson junction arrays in a group IV material.\n",
            "['Planar germanium quantum wells have recently been shown to host a hard-gapped\\nsuperconductor-semiconductor interface.', 'Additionally, quantum dot spin qubits\\nin germanium are well-suited for quantum information processing, with isotopic\\npurification to a nuclear spin-free material expected to yield long coherence\\ntimes.', 'Therefore, as one of the few group IV materials with the potential to\\nhost superconductor-semiconductor hybrid devices, proximitized quantum dots in\\ngermanium are a crucial ingredient towards topological superconductivity and\\nnovel qubit modalities.', 'Here we demonstrate a quantum dot (QD) in a Ge/SiGe\\nheterostructure proximitized by a platinum germanosilicide (PtGeSi)\\nsuperconducting lead (SC), forming a SC-QD-SC junction.', 'We show tunability of\\nthe QD-SC coupling strength, as well as gate control of the ratio of charging\\nenergy and the induced gap.', 'We further exploit this tunability by exhibiting\\ncontrol of the ground state of the system between even and odd parity.', 'Furthermore, we characterize the critical magnetic field strengths, finding a\\nrobust critical out-of-plane field of 0.91(5) T. Finally we explore sub-gap\\nspin splitting in the device, observing rich physics in the resulting spectra,\\nthat we model using a zero-bandwidth model in the Yu-Shiba-Rusinov limit.', 'The\\ndemonstration of controllable proximitization at the nanoscale of a germanium\\nquantum dot opens up the physics of novel spin and superconducting qubits, and\\nJosephson junction arrays in a group IV material.']\n",
            "Chunks for abstract: Current natural language processing (NLP) research tends to focus on only one\n",
            "or, less frequently, two dimensions - e.g., performance, privacy, fairness, or\n",
            "efficiency - at a time, which may lead to suboptimal conclusions and often\n",
            "overlooking the broader goal of achieving trustworthy NLP. Work on adapter\n",
            "modules (Houlsby et al., 2019; Hu et al., 2021) focuses on improving\n",
            "performance and efficiency, with no investigation of unintended consequences on\n",
            "other aspects such as fairness. To address this gap, we conduct experiments on\n",
            "three text classification datasets by either (1) finetuning all parameters or\n",
            "(2) using adapter modules. Regarding performance and efficiency, we confirm\n",
            "prior findings that the accuracy of adapter-enhanced models is roughly on par\n",
            "with that of fully finetuned models, while training time is substantially\n",
            "reduced. Regarding fairness, we show that adapter modules result in mixed\n",
            "fairness across sensitive groups. Further investigation reveals that, when the\n",
            "standard fine-tuned model exhibits limited biases, adapter modules typically do\n",
            "not introduce extra bias. On the other hand, when the finetuned model exhibits\n",
            "increased bias, the impact of adapter modules on bias becomes more\n",
            "unpredictable, introducing the risk of significantly magnifying these biases\n",
            "for certain groups. Our findings highlight the need for a case-by-case\n",
            "evaluation rather than a one-size-fits-all judgment.\n",
            "['Current natural language processing (NLP) research tends to focus on only one\\nor, less frequently, two dimensions - e.g., performance, privacy, fairness, or\\nefficiency - at a time, which may lead to suboptimal conclusions and often\\noverlooking the broader goal of achieving trustworthy NLP.', 'Work on adapter\\nmodules (Houlsby et al., 2019; Hu et al., 2021) focuses on improving\\nperformance and efficiency, with no investigation of unintended consequences on\\nother aspects such as fairness.', 'To address this gap, we conduct experiments on\\nthree text classification datasets by either (1) finetuning all parameters or\\n(2) using adapter modules.', 'Regarding performance and efficiency, we confirm\\nprior findings that the accuracy of adapter-enhanced models is roughly on par\\nwith that of fully finetuned models, while training time is substantially\\nreduced.', 'Regarding fairness, we show that adapter modules result in mixed\\nfairness across sensitive groups.', 'Further investigation reveals that, when the\\nstandard fine-tuned model exhibits limited biases, adapter modules typically do\\nnot introduce extra bias.', 'On the other hand, when the finetuned model exhibits\\nincreased bias, the impact of adapter modules on bias becomes more\\nunpredictable, introducing the risk of significantly magnifying these biases\\nfor certain groups.', 'Our findings highlight the need for a case-by-case\\nevaluation rather than a one-size-fits-all judgment.']\n",
            "Chunks for abstract: A well-known difficulty of perturbative approaches to quantum field theory at\n",
            "finite temperature is the necessity to address theoretical constraints that are\n",
            "not present in the vacuum theory. In this work, we use lattice simulations of\n",
            "scalar correlation functions in massive $\\phi^{4}$ theory to analyse the extent\n",
            "to which these constraints affect the perturbative predictions. We find that\n",
            "the standard perturbative predictions deteriorate even in the absence of\n",
            "infrared divergences at relatively low temperatures, and that this is directly\n",
            "connected to the analytic structure of the propagators used in the expansion.\n",
            "This suggests that the incorporation of non-perturbative thermal effects in the\n",
            "propagators is essential for a consistent perturbative formulation of scalar\n",
            "quantum field theories at finite temperature. By utilising the spectral\n",
            "constraints imposed on finite-temperature correlation functions, we explore how\n",
            "these effects manifest themselves in the lattice data, and discuss why the\n",
            "presence of distinct thermoparticle excitations provides a potential resolution\n",
            "to these issues.\n",
            "['A well-known difficulty of perturbative approaches to quantum field theory at\\nfinite temperature is the necessity to address theoretical constraints that are\\nnot present in the vacuum theory.', 'In this work, we use lattice simulations of\\nscalar correlation functions in massive $\\\\phi^{4}$ theory to analyse the extent\\nto which these constraints affect the perturbative predictions.', 'We find that\\nthe standard perturbative predictions deteriorate even in the absence of\\ninfrared divergences at relatively low temperatures, and that this is directly\\nconnected to the analytic structure of the propagators used in the expansion.', 'This suggests that the incorporation of non-perturbative thermal effects in the\\npropagators is essential for a consistent perturbative formulation of scalar\\nquantum field theories at finite temperature.', 'By utilising the spectral\\nconstraints imposed on finite-temperature correlation functions, we explore how\\nthese effects manifest themselves in the lattice data, and discuss why the\\npresence of distinct thermoparticle excitations provides a potential resolution\\nto these issues.']\n",
            "Chunks for abstract: Realistic modeling of ecological population dynamics requires spatially\n",
            "explicit descriptions that can take into account spatial heterogeneity as well\n",
            "as long-distance dispersal. Here, we present Monte Carlo simulations and\n",
            "numerical renormalization group results for the paradigmatic model, the contact\n",
            "process, in the combined presence of these factors in both one and\n",
            "two-dimensional systems. Our results confirm our analytic arguments stating\n",
            "that the density vanishes smoothly at the extinction threshold, in a way\n",
            "characteristic of infinite-order transitions. This extremely smooth vanishing\n",
            "of the global density entails an enhanced exposure of the population to\n",
            "extinction events. At the same time, a reverse order parameter, the local\n",
            "persistence displays a discontinuity characteristic of mixed-order transitions,\n",
            "as it approaches a non-universal critical value algebraically with an exponent\n",
            "$\\beta_p'<1$.\n",
            "['Realistic modeling of ecological population dynamics requires spatially\\nexplicit descriptions that can take into account spatial heterogeneity as well\\nas long-distance dispersal.', 'Here, we present Monte Carlo simulations and\\nnumerical renormalization group results for the paradigmatic model, the contact\\nprocess, in the combined presence of these factors in both one and\\ntwo-dimensional systems.', 'Our results confirm our analytic arguments stating\\nthat the density vanishes smoothly at the extinction threshold, in a way\\ncharacteristic of infinite-order transitions.', 'This extremely smooth vanishing\\nof the global density entails an enhanced exposure of the population to\\nextinction events.', \"At the same time, a reverse order parameter, the local\\npersistence displays a discontinuity characteristic of mixed-order transitions,\\nas it approaches a non-universal critical value algebraically with an exponent\\n$\\\\beta_p'<1$.\"]\n",
            "Chunks for abstract: Large Language Models (LLMs) are deep learning models designed to generate\n",
            "text based on textual input. Although researchers have been developing these\n",
            "models for more complex tasks such as code generation and general reasoning,\n",
            "few efforts have explored how LLMs can be applied to combinatorial problems. In\n",
            "this research, we investigate the potential of LLMs to solve the Travelling\n",
            "Salesman Problem (TSP). Utilizing GPT-3.5 Turbo, we conducted experiments\n",
            "employing various approaches, including zero-shot in-context learning, few-shot\n",
            "in-context learning, and chain-of-thoughts (CoT). Consequently, we fine-tuned\n",
            "GPT-3.5 Turbo to solve a specific problem size and tested it using a set of\n",
            "various instance sizes. The fine-tuned models demonstrated promising\n",
            "performance on problems identical in size to the training instances and\n",
            "generalized well to larger problems. Furthermore, to improve the performance of\n",
            "the fine-tuned model without incurring additional training costs, we adopted a\n",
            "self-ensemble approach to improve the quality of the solutions.\n",
            "['Large Language Models (LLMs) are deep learning models designed to generate\\ntext based on textual input.', 'Although researchers have been developing these\\nmodels for more complex tasks such as code generation and general reasoning,\\nfew efforts have explored how LLMs can be applied to combinatorial problems.', 'In\\nthis research, we investigate the potential of LLMs to solve the Travelling\\nSalesman Problem (TSP).', 'Utilizing GPT-3.5 Turbo, we conducted experiments\\nemploying various approaches, including zero-shot in-context learning, few-shot\\nin-context learning, and chain-of-thoughts (CoT).', 'Consequently, we fine-tuned\\nGPT-3.5 Turbo to solve a specific problem size and tested it using a set of\\nvarious instance sizes.', 'The fine-tuned models demonstrated promising\\nperformance on problems identical in size to the training instances and\\ngeneralized well to larger problems.', 'Furthermore, to improve the performance of\\nthe fine-tuned model without incurring additional training costs, we adopted a\\nself-ensemble approach to improve the quality of the solutions.']\n",
            "Chunks for abstract: Extensive numerical experiments on the long-term dynamics of planetesimal\n",
            "disks with planets in systems of single stars have been carried out. The\n",
            "planetary chaotic zone clearing timescales $T_\\mathrm{cl}$ as a function of\n",
            "mass parameter $\\mu$ (planet-star mass ratio) have been determined numerically\n",
            "with a high accuracy separately for the outer and inner parts of the chaotic\n",
            "zone. Diffusional components $\\propto \\mu^{-6/7}$ and $\\propto \\mu^{-2}$ have\n",
            "been revealed in the dependence $T_\\mathrm{cl}(\\mu)$. The results obtained are\n",
            "discussed and interpreted in light of existing analytical theories based on the\n",
            "mean motion resonance overlap criterion and in comparison with previous\n",
            "numerical approaches to the problem.\n",
            "['Extensive numerical experiments on the long-term dynamics of planetesimal\\ndisks with planets in systems of single stars have been carried out.', 'The\\nplanetary chaotic zone clearing timescales $T_\\\\mathrm{cl}$ as a function of\\nmass parameter $\\\\mu$ (planet-star mass ratio) have been determined numerically\\nwith a high accuracy separately for the outer and inner parts of the chaotic\\nzone.', 'Diffusional components $\\\\propto \\\\mu^{-6/7}$ and $\\\\propto \\\\mu^{-2}$ have\\nbeen revealed in the dependence $T_\\\\mathrm{cl}(\\\\mu)$.', 'The results obtained are\\ndiscussed and interpreted in light of existing analytical theories based on the\\nmean motion resonance overlap criterion and in comparison with previous\\nnumerical approaches to the problem.']\n",
            "Chunks for abstract: General relativistic Gauss equations for osculating elements for bound orbits\n",
            "under the influence of a perturbing force in an underlying Schwarzschild\n",
            "space-time have been derived in terms of Weierstrass elliptic functions.\n",
            "Thereby, the perturbation forces are restricted to act within the orbital plane\n",
            "only. These equations are analytically solved in linear approximation for\n",
            "several different perturbations such as cosmological constant perturbations,\n",
            "quantum corrections to the Schwarzschild metric, and hybrid\n",
            "Schwarzschild/post-Newtonian $2.5$ order self-forces for binary systems in an\n",
            "effective one-body framework.\n",
            "['General relativistic Gauss equations for osculating elements for bound orbits\\nunder the influence of a perturbing force in an underlying Schwarzschild\\nspace-time have been derived in terms of Weierstrass elliptic functions.', 'Thereby, the perturbation forces are restricted to act within the orbital plane\\nonly.', 'These equations are analytically solved in linear approximation for\\nseveral different perturbations such as cosmological constant perturbations,\\nquantum corrections to the Schwarzschild metric, and hybrid\\nSchwarzschild/post-Newtonian $2.5$ order self-forces for binary systems in an\\neffective one-body framework.']\n",
            "Chunks for abstract: We study the existence of a strong solution to the initial value problem for\n",
            "the magnetohydrodynamic equations in $\\mathbb{R}^N, N\\geq 3$. We obtain a\n",
            "global in-time strong solution without any smallness assumptions on the initial\n",
            "data.\n",
            "['We study the existence of a strong solution to the initial value problem for\\nthe magnetohydrodynamic equations in $\\\\mathbb{R}^N, N\\\\geq 3$.', 'We obtain a\\nglobal in-time strong solution without any smallness assumptions on the initial\\ndata.']\n",
            "Chunks for abstract: This paper studies an online optimal resource reservation problem in\n",
            "communication networks with job transfers where the goal is to minimize the\n",
            "reservation cost while maintaining the blocking cost under a certain budget\n",
            "limit. To tackle this problem, we propose a novel algorithm based on a\n",
            "randomized exponentially weighted method that encompasses long-term\n",
            "constraints. We then analyze the performance of our algorithm by establishing\n",
            "an upper bound for the associated regret and the cumulative constraint\n",
            "violations. Finally, we present numerical experiments where we compare the\n",
            "performance of our algorithm with those of reinforcement learning where we show\n",
            "that our algorithm surpasses it.\n",
            "['This paper studies an online optimal resource reservation problem in\\ncommunication networks with job transfers where the goal is to minimize the\\nreservation cost while maintaining the blocking cost under a certain budget\\nlimit.', 'To tackle this problem, we propose a novel algorithm based on a\\nrandomized exponentially weighted method that encompasses long-term\\nconstraints.', 'We then analyze the performance of our algorithm by establishing\\nan upper bound for the associated regret and the cumulative constraint\\nviolations.', 'Finally, we present numerical experiments where we compare the\\nperformance of our algorithm with those of reinforcement learning where we show\\nthat our algorithm surpasses it.']\n",
            "Chunks for abstract: Local stresses in a tissue, a collective property, regulate cell division and\n",
            "apoptosis. In turn, cell growth and division induce active stresses in the\n",
            "tissue. As a consequence, there is a feedback between cell growth and local\n",
            "stresses. However, how the cell dynamics depend on local stress-dependent cell\n",
            "division and the feedback strength is not fully understood. Here, we probe the\n",
            "consequences of stress-mediated growth and cell division on cell dynamics using\n",
            "agent-based simulations of a two-dimensional growing tissue. We discover a rich\n",
            "dynamical behavior of individual cells, ranging from jamming (mean square\n",
            "displacement, $\\Delta (t) \\sim t^{\\alpha}$ with $\\alpha$ less than unity), to\n",
            "hyperdiffusion ($\\alpha > 2$) depending on cell division rate and the strength\n",
            "of the mechanical feedback. Strikingly, $\\Delta (t)$ is determined by the\n",
            "tissue growth law, which quantifies cell proliferation (number of cells $N(t)$\n",
            "as a function of time). The growth law ($N(t) \\sim t^{\\lambda}$ at long times)\n",
            "is regulated by the critical pressure that controls the strength of the\n",
            "mechanical feedback and the ratio between cell division-apoptosis rates. We\n",
            "show that $\\lambda \\sim \\alpha$, which implies that higher growth rate leads to\n",
            "a greater degree of cell migration. The variations in cell motility are linked\n",
            "to the emergence of highly persistent forces extending over several cell cycle\n",
            "times. Our predictions are testable using cell-tracking imaging techniques.\n",
            "['Local stresses in a tissue, a collective property, regulate cell division and\\napoptosis.', 'In turn, cell growth and division induce active stresses in the\\ntissue.', 'As a consequence, there is a feedback between cell growth and local\\nstresses.', 'However, how the cell dynamics depend on local stress-dependent cell\\ndivision and the feedback strength is not fully understood.', 'Here, we probe the\\nconsequences of stress-mediated growth and cell division on cell dynamics using\\nagent-based simulations of a two-dimensional growing tissue.', 'We discover a rich\\ndynamical behavior of individual cells, ranging from jamming (mean square\\ndisplacement, $\\\\Delta (t) \\\\sim t^{\\\\alpha}$ with $\\\\alpha$ less than unity), to\\nhyperdiffusion ($\\\\alpha > 2$) depending on cell division rate and the strength\\nof the mechanical feedback.', 'Strikingly, $\\\\Delta (t)$ is determined by the\\ntissue growth law, which quantifies cell proliferation (number of cells $N(t)$\\nas a function of time).', 'The growth law ($N(t) \\\\sim t^{\\\\lambda}$ at long times)\\nis regulated by the critical pressure that controls the strength of the\\nmechanical feedback and the ratio between cell division-apoptosis rates.', 'We\\nshow that $\\\\lambda \\\\sim \\\\alpha$, which implies that higher growth rate leads to\\na greater degree of cell migration.', 'The variations in cell motility are linked\\nto the emergence of highly persistent forces extending over several cell cycle\\ntimes.', 'Our predictions are testable using cell-tracking imaging techniques.']\n",
            "Chunks for abstract: Depending on their mechanism of self-propulsion, active particles can exhibit\n",
            "a time-dependent, often periodic, propulsion velocity. The precise propulsion\n",
            "velocity profile determines their mean square displacement and their effective\n",
            "diffusion coefficient at long times. Here we demonstrate that any periodic\n",
            "propulsion profile results in a larger diffusion coefficient than the\n",
            "corresponding case with constant propulsion velocity. We investigate in detail\n",
            "the case of periodic exponentially decaying velocity pulses, expected in\n",
            "propulsion mechanisms based on sudden absorption of finite amounts of energy.\n",
            "We show both analytically and with numerical simulations that in these cases\n",
            "the effective diffusion coefficient can be arbitrarily enhanced with respect to\n",
            "the case with constant velocity equal to the average speed. Our results may\n",
            "help interpret in a new light observations on the diffusion enhancement of\n",
            "active particles.\n",
            "['Depending on their mechanism of self-propulsion, active particles can exhibit\\na time-dependent, often periodic, propulsion velocity.', 'The precise propulsion\\nvelocity profile determines their mean square displacement and their effective\\ndiffusion coefficient at long times.', 'Here we demonstrate that any periodic\\npropulsion profile results in a larger diffusion coefficient than the\\ncorresponding case with constant propulsion velocity.', 'We investigate in detail\\nthe case of periodic exponentially decaying velocity pulses, expected in\\npropulsion mechanisms based on sudden absorption of finite amounts of energy.', 'We show both analytically and with numerical simulations that in these cases\\nthe effective diffusion coefficient can be arbitrarily enhanced with respect to\\nthe case with constant velocity equal to the average speed.', 'Our results may\\nhelp interpret in a new light observations on the diffusion enhancement of\\nactive particles.']\n",
            "Chunks for abstract: Understanding $\\textit{galaxy bias}$ -- that is the statistical relation\n",
            "between matter and galaxies -- is of key importance for extracting cosmological\n",
            "information from galaxy surveys. While the bias function $f$ is usually\n",
            "approximated through a parametric expansion, we show here, that it can also be\n",
            "measured directly from simulations in a non-parameteric way. Our measurements\n",
            "show that the Lagrangian bias function is very close to a Gaussian for halo\n",
            "selections of any mass. Therefore, we newly introduce a Gaussian bias model\n",
            "with several intriguing properties: (1) It predicts only strictly positive\n",
            "probabilities $f > 0$ (unlike expansion models), (2) It has a simple analytic\n",
            "renormalized form and (3) It behaves gracefully in many scenarios where the\n",
            "classical expansion converges poorly. We show that the Gaussian bias model\n",
            "describes the galaxy environment distribution $p(\\delta | \\mathrm{g})$, the\n",
            "scale dependent bias function $f$ and the renormalized bias function $F$ of\n",
            "haloes and galaxies generally equally well or significantly better than a\n",
            "second order expansion with the same number of parameters. We suggest that a\n",
            "Gaussian bias approach may enhance the range of validity of bias schemes where\n",
            "the canonical expansion converges poorly and further, that it may make new\n",
            "applications possible, since it guarantees the positivity of predicted galaxy\n",
            "densities.\n",
            "['Understanding $\\\\textit{galaxy bias}$ -- that is the statistical relation\\nbetween matter and galaxies -- is of key importance for extracting cosmological\\ninformation from galaxy surveys.', 'While the bias function $f$ is usually\\napproximated through a parametric expansion, we show here, that it can also be\\nmeasured directly from simulations in a non-parameteric way.', 'Our measurements\\nshow that the Lagrangian bias function is very close to a Gaussian for halo\\nselections of any mass.', 'Therefore, we newly introduce a Gaussian bias model\\nwith several intriguing properties: (1) It predicts only strictly positive\\nprobabilities $f > 0$ (unlike expansion models), (2) It has a simple analytic\\nrenormalized form and (3) It behaves gracefully in many scenarios where the\\nclassical expansion converges poorly.', 'We show that the Gaussian bias model\\ndescribes the galaxy environment distribution $p(\\\\delta | \\\\mathrm{g})$, the\\nscale dependent bias function $f$ and the renormalized bias function $F$ of\\nhaloes and galaxies generally equally well or significantly better than a\\nsecond order expansion with the same number of parameters.', 'We suggest that a\\nGaussian bias approach may enhance the range of validity of bias schemes where\\nthe canonical expansion converges poorly and further, that it may make new\\napplications possible, since it guarantees the positivity of predicted galaxy\\ndensities.']\n",
            "Chunks for abstract: We investigate the problem of common randomness (CR) generation in the basic\n",
            "two-party communication setting in which a sender and a receiver aim to agree\n",
            "on a common random variable with high probability. The terminals observe\n",
            "independent and identically distributed (i.i.d.) samples of sources with an\n",
            "arbitrary distribution defined on a Polish alphabet and are allowed to\n",
            "communicate as little as possible over a noisy, memoryless channel. We\n",
            "establish single-letter upper and lower bounds on the CR capacity for the\n",
            "specified model. The derived bounds hold with equality except for at most\n",
            "countably many points where discontinuity issues might arise.\n",
            "['We investigate the problem of common randomness (CR) generation in the basic\\ntwo-party communication setting in which a sender and a receiver aim to agree\\non a common random variable with high probability.', 'The terminals observe\\nindependent and identically distributed (i.i.d.)', 'samples of sources with an\\narbitrary distribution defined on a Polish alphabet and are allowed to\\ncommunicate as little as possible over a noisy, memoryless channel.', 'We\\nestablish single-letter upper and lower bounds on the CR capacity for the\\nspecified model.', 'The derived bounds hold with equality except for at most\\ncountably many points where discontinuity issues might arise.']\n",
            "Chunks for abstract: We study the superradiant phase transition of an array of Rydberg atoms in a\n",
            "dissipative microwave cavity. Under the interplay of the cavity field and the\n",
            "long-range Rydberg interaction, the steady state of the system exhibits an\n",
            "interaction-enhanced superradiance, with vanishing critical atom-cavity\n",
            "coupling rates at a discrete set of interaction strengths. We find that, while\n",
            "the phenomenon can be analytically understood in the case of constant\n",
            "all-to-all interaction, the enhanced superradiance persists under the spatially\n",
            "dependent dipolar interaction, but shifted in the critical interaction\n",
            "strengths. The diverging susceptibility at these critical points is captured by\n",
            "emergent quantum Rabi models, each of which comprises a pair of collective\n",
            "atomic states with different numbers of atomic excitations. These collective\n",
            "states become degenerate at the critical interaction strengths, resulting in a\n",
            "superradiant phase for an arbitrarily small atom-cavity coupling.\n",
            "['We study the superradiant phase transition of an array of Rydberg atoms in a\\ndissipative microwave cavity.', 'Under the interplay of the cavity field and the\\nlong-range Rydberg interaction, the steady state of the system exhibits an\\ninteraction-enhanced superradiance, with vanishing critical atom-cavity\\ncoupling rates at a discrete set of interaction strengths.', 'We find that, while\\nthe phenomenon can be analytically understood in the case of constant\\nall-to-all interaction, the enhanced superradiance persists under the spatially\\ndependent dipolar interaction, but shifted in the critical interaction\\nstrengths.', 'The diverging susceptibility at these critical points is captured by\\nemergent quantum Rabi models, each of which comprises a pair of collective\\natomic states with different numbers of atomic excitations.', 'These collective\\nstates become degenerate at the critical interaction strengths, resulting in a\\nsuperradiant phase for an arbitrarily small atom-cavity coupling.']\n",
            "Chunks for abstract: Semi-Lagrangian (SL) schemes are highly efficient for simulating transport\n",
            "equations and are widely used across various applications. Despite their\n",
            "success, designing genuinely multi-dimensional and conservative SL schemes\n",
            "remains a significant challenge. Building on our previous work [Chen et al., J.\n",
            "Comput. Phys., V490 112329, (2023)], we introduce a conservative\n",
            "machine-learning-based SL finite difference (FD) method that allows for\n",
            "extra-large time step evolution. At the core of our approach is a novel\n",
            "dynamical graph neural network designed to handle the complexities associated\n",
            "with tracking accurately upstream points along characteristics. This proposed\n",
            "neural transport solver learns the conservative SL FD discretization directly\n",
            "from data, improving accuracy and efficiency compared to traditional numerical\n",
            "schemes, while significantly simplifying algorithm implementation. We validate\n",
            "the method' s effectiveness and efficiency through numerical tests on benchmark\n",
            "transport equations in both one and two dimensions, as well as the nonlinear\n",
            "Vlasov-Poisson system.\n",
            "['Semi-Lagrangian (SL) schemes are highly efficient for simulating transport\\nequations and are widely used across various applications.', 'Despite their\\nsuccess, designing genuinely multi-dimensional and conservative SL schemes\\nremains a significant challenge.', 'Building on our previous work [Chen et al., J.\\nComput.', 'Phys., V490 112329, (2023)], we introduce a conservative\\nmachine-learning-based SL finite difference (FD) method that allows for\\nextra-large time step evolution.', 'At the core of our approach is a novel\\ndynamical graph neural network designed to handle the complexities associated\\nwith tracking accurately upstream points along characteristics.', 'This proposed\\nneural transport solver learns the conservative SL FD discretization directly\\nfrom data, improving accuracy and efficiency compared to traditional numerical\\nschemes, while significantly simplifying algorithm implementation.', \"We validate\\nthe method' s effectiveness and efficiency through numerical tests on benchmark\\ntransport equations in both one and two dimensions, as well as the nonlinear\\nVlasov-Poisson system.\"]\n",
            "Chunks for abstract: To gain insight into the dynamics of the CN + C2H6 gas-phase reaction,\n",
            "quasi-classical trajectory (QCT) calculations were performed on a\n",
            "full-dimensional analytical potential energy surface. This reaction presents\n",
            "very high exothermicity, -22.20 kcal/mol, and it is practically barrierless,\n",
            "with a barrier height of 0.23 kcal/mol, being an early transition state\n",
            "reaction. The V-shape form of the excitation function is characteristic of\n",
            "non-threshold reactions. The pronounced increase observed at lower energies can\n",
            "be attributed to the substantial increase in the impact parameter within this\n",
            "energy regime. Vibrational excitations by one quantum of stretching and bending\n",
            "modes give rise to excitation functions that present a similar V-shaped\n",
            "profile.\n",
            "['To gain insight into the dynamics of the CN + C2H6 gas-phase reaction,\\nquasi-classical trajectory (QCT) calculations were performed on a\\nfull-dimensional analytical potential energy surface.', 'This reaction presents\\nvery high exothermicity, -22.20 kcal/mol, and it is practically barrierless,\\nwith a barrier height of 0.23 kcal/mol, being an early transition state\\nreaction.', 'The V-shape form of the excitation function is characteristic of\\nnon-threshold reactions.', 'The pronounced increase observed at lower energies can\\nbe attributed to the substantial increase in the impact parameter within this\\nenergy regime.', 'Vibrational excitations by one quantum of stretching and bending\\nmodes give rise to excitation functions that present a similar V-shaped\\nprofile.']\n",
            "Chunks for abstract: This paper introduces OARelatedWork, the first large-scale multi-document\n",
            "summarization dataset for related work generation containing whole related work\n",
            "sections and full-texts of cited papers. The dataset includes 94 450 papers and\n",
            "5 824 689 unique referenced papers. It was designed for the task of\n",
            "automatically generating related work to shift the field toward generating\n",
            "entire related work sections from all available content instead of generating\n",
            "parts of related work sections from abstracts only, which is the current\n",
            "mainstream in this field for abstractive approaches. We show that the estimated\n",
            "upper bound for extractive summarization increases by 217% in the ROUGE-2\n",
            "score, when using full content instead of abstracts. Furthermore, we show the\n",
            "benefits of full content data on naive, oracle, traditional, and\n",
            "transformer-based baselines. Long outputs, such as related work sections, pose\n",
            "challenges for automatic evaluation metrics like BERTScore due to their limited\n",
            "input length. We tackle this issue by proposing and evaluating a meta-metric\n",
            "using BERTScore. Despite operating on smaller blocks, we show this meta-metric\n",
            "correlates with human judgment, comparably to the original BERTScore.\n",
            "['This paper introduces OARelatedWork, the first large-scale multi-document\\nsummarization dataset for related work generation containing whole related work\\nsections and full-texts of cited papers.', 'The dataset includes 94 450 papers and\\n5 824 689 unique referenced papers.', 'It was designed for the task of\\nautomatically generating related work to shift the field toward generating\\nentire related work sections from all available content instead of generating\\nparts of related work sections from abstracts only, which is the current\\nmainstream in this field for abstractive approaches.', 'We show that the estimated\\nupper bound for extractive summarization increases by 217% in the ROUGE-2\\nscore, when using full content instead of abstracts.', 'Furthermore, we show the\\nbenefits of full content data on naive, oracle, traditional, and\\ntransformer-based baselines.', 'Long outputs, such as related work sections, pose\\nchallenges for automatic evaluation metrics like BERTScore due to their limited\\ninput length.', 'We tackle this issue by proposing and evaluating a meta-metric\\nusing BERTScore.', 'Despite operating on smaller blocks, we show this meta-metric\\ncorrelates with human judgment, comparably to the original BERTScore.']\n",
            "Chunks for abstract: We introduce local characteristic decomposition based path-conservative\n",
            "central-upwind schemes for (nonconservative) hyperbolic systems of balance\n",
            "laws. The proposed schemes are made to be well-balanced via a flux\n",
            "globalization approach, in which source terms are incorporated into the fluxes:\n",
            "This helps to enforce the well-balanced property when the resulting\n",
            "quasi-conservative system is solved using the local characteristic\n",
            "decomposition based central-upwind scheme recently introduced in [{\\sc A.\n",
            "Chertock, S. Chu, M. Herty, A. Kurganov, and M.\n",
            "Luk\\'{a}\\v{c}ov\\'{a}-Medvi{\\softd}ov\\'{a}}, J. Comput. Phys., 473 (2023), Paper\n",
            "No. 111718]. Nonconservative product terms are also incorporated into the\n",
            "global fluxes using a path-conservative technique. We illustrate the\n",
            "performance of the developed schemes by applying them to one- and\n",
            "two-dimensional compressible multifluid systems and thermal rotating shallow\n",
            "water equations.\n",
            "['We introduce local characteristic decomposition based path-conservative\\ncentral-upwind schemes for (nonconservative) hyperbolic systems of balance\\nlaws.', \"The proposed schemes are made to be well-balanced via a flux\\nglobalization approach, in which source terms are incorporated into the fluxes:\\nThis helps to enforce the well-balanced property when the resulting\\nquasi-conservative system is solved using the local characteristic\\ndecomposition based central-upwind scheme recently introduced in [{\\\\sc A.\\nChertock, S. Chu, M. Herty, A. Kurganov, and M.\\nLuk\\\\'{a}\\\\v{c}ov\\\\'{a}-Medvi{\\\\softd}ov\\\\'{a}}, J. Comput.\", 'Phys., 473 (2023), Paper\\nNo.', '111718].', 'Nonconservative product terms are also incorporated into the\\nglobal fluxes using a path-conservative technique.', 'We illustrate the\\nperformance of the developed schemes by applying them to one- and\\ntwo-dimensional compressible multifluid systems and thermal rotating shallow\\nwater equations.']\n",
            "Chunks for abstract: For multimodal LLMs, the synergy of visual comprehension (textual output) and\n",
            "generation (visual output) presents an ongoing challenge. This is due to a\n",
            "conflicting objective: for comprehension, an MLLM needs to abstract the\n",
            "visuals; for generation, it needs to preserve the visuals as much as possible.\n",
            "Thus, the objective is a dilemma for visual-tokens. To resolve the conflict, we\n",
            "propose encoding images into morph-tokens to serve a dual purpose: for\n",
            "comprehension, they act as visual prompts instructing MLLM to generate texts;\n",
            "for generation, they take on a different, non-conflicting role as complete\n",
            "visual-tokens for image reconstruction, where the missing visual cues are\n",
            "recovered by the MLLM. Extensive experiments show that morph-tokens can achieve\n",
            "a new SOTA for multimodal comprehension and generation simultaneously. Our\n",
            "project is available at https://github.com/DCDmllm/MorphTokens.\n",
            "['For multimodal LLMs, the synergy of visual comprehension (textual output) and\\ngeneration (visual output) presents an ongoing challenge.', 'This is due to a\\nconflicting objective: for comprehension, an MLLM needs to abstract the\\nvisuals; for generation, it needs to preserve the visuals as much as possible.', 'Thus, the objective is a dilemma for visual-tokens.', 'To resolve the conflict, we\\npropose encoding images into morph-tokens to serve a dual purpose: for\\ncomprehension, they act as visual prompts instructing MLLM to generate texts;\\nfor generation, they take on a different, non-conflicting role as complete\\nvisual-tokens for image reconstruction, where the missing visual cues are\\nrecovered by the MLLM.', 'Extensive experiments show that morph-tokens can achieve\\na new SOTA for multimodal comprehension and generation simultaneously.', 'Our\\nproject is available at https://github.com/DCDmllm/MorphTokens.']\n",
            "Chunks for abstract: Mini data centres have become increasingly prevalent in diverse organizations\n",
            "in recent years. They can be easily deployed at large scale, with high\n",
            "resilience. They are also cost-effective and provide highsecurity protection.\n",
            "On the other hand, IT technologies have resulted in the development of ever\n",
            "more energy-efficient servers, leading to the periodic replacement of\n",
            "older-generation servers in mini data centres. However, the disposal of older\n",
            "servers has resulted in electronic waste that further aggravates the already\n",
            "critical e-waste problem. Furthermore, despite the shift towards more\n",
            "energy-efficient servers, many mini data centres still rely heavily on\n",
            "high-carbon energy sources. This contributes to data centres' overall carbon\n",
            "footprint. All these issues are concerns for sustainability. In order to\n",
            "address this sustainability issue, this paper proposes an approach to extend\n",
            "the lifespan of older-generation servers in mini data centres. This is made\n",
            "possible thanks to a novel solar-powered computing technology, named Genesis,\n",
            "that compensates for the energy overhead generated by older servers. As a\n",
            "result, electronic waste can be reduced while improving system sustainability\n",
            "by reusing functional server hardware. Moreover, Genesis does not require\n",
            "server cooling, which reduces energy and water requirements. Analytical\n",
            "reasoning is applied to compare the efficiency of typical conventional mini\n",
            "data centre designs against alternative Genesis-based designs, in terms of\n",
            "energy, carbon emissions and exploitation costs.\n",
            "['Mini data centres have become increasingly prevalent in diverse organizations\\nin recent years.', 'They can be easily deployed at large scale, with high\\nresilience.', 'They are also cost-effective and provide highsecurity protection.', 'On the other hand, IT technologies have resulted in the development of ever\\nmore energy-efficient servers, leading to the periodic replacement of\\nolder-generation servers in mini data centres.', 'However, the disposal of older\\nservers has resulted in electronic waste that further aggravates the already\\ncritical e-waste problem.', 'Furthermore, despite the shift towards more\\nenergy-efficient servers, many mini data centres still rely heavily on\\nhigh-carbon energy sources.', \"This contributes to data centres' overall carbon\\nfootprint.\", 'All these issues are concerns for sustainability.', 'In order to\\naddress this sustainability issue, this paper proposes an approach to extend\\nthe lifespan of older-generation servers in mini data centres.', 'This is made\\npossible thanks to a novel solar-powered computing technology, named Genesis,\\nthat compensates for the energy overhead generated by older servers.', 'As a\\nresult, electronic waste can be reduced while improving system sustainability\\nby reusing functional server hardware.', 'Moreover, Genesis does not require\\nserver cooling, which reduces energy and water requirements.', 'Analytical\\nreasoning is applied to compare the efficiency of typical conventional mini\\ndata centre designs against alternative Genesis-based designs, in terms of\\nenergy, carbon emissions and exploitation costs.']\n",
            "Chunks for abstract: This paper proposes a computational text classification strategy to identify\n",
            "references to social groups in European party manifestos and beyond. Our\n",
            "methodology uses machine learning techniques, including BERT and large language\n",
            "models, to capture group-based appeals in texts. We propose to combine\n",
            "automated identification of social groups using the Mistral-7B-v0.1 Large\n",
            "Language Model with Embedding Space-based filtering to extend a sample of core\n",
            "social groups to all social groups mentioned in party manifestos. By applying\n",
            "this approach to RRP's and mainstream parties' group images in manifestos, we\n",
            "explore whether electoral dynamics explain similarities in group appeals and\n",
            "potential convergence or divergence in party strategies. Contrary to\n",
            "expectations, increasing RRP support or mainstream parties' vote loss does not\n",
            "necessarily lead to convergence in group appeals. Nonetheless, our methodology\n",
            "enables mapping similarities in group appeals across time and space in 15\n",
            "European countries from 1980 to 2021 and can be transferred to other use cases\n",
            "as well.\n",
            "['This paper proposes a computational text classification strategy to identify\\nreferences to social groups in European party manifestos and beyond.', 'Our\\nmethodology uses machine learning techniques, including BERT and large language\\nmodels, to capture group-based appeals in texts.', 'We propose to combine\\nautomated identification of social groups using the Mistral-7B-v0.1 Large\\nLanguage Model with Embedding Space-based filtering to extend a sample of core\\nsocial groups to all social groups mentioned in party manifestos.', \"By applying\\nthis approach to RRP's and mainstream parties' group images in manifestos, we\\nexplore whether electoral dynamics explain similarities in group appeals and\\npotential convergence or divergence in party strategies.\", \"Contrary to\\nexpectations, increasing RRP support or mainstream parties' vote loss does not\\nnecessarily lead to convergence in group appeals.\", 'Nonetheless, our methodology\\nenables mapping similarities in group appeals across time and space in 15\\nEuropean countries from 1980 to 2021 and can be transferred to other use cases\\nas well.']\n",
            "Chunks for abstract: In this article, we first establish a generalized Bohr inequality and examine\n",
            "its sharpness for a class of analytic functions $f$ in a simply connected\n",
            "domain $\\Omega_\\gamma,$ where $0\\leq \\gamma<1$ with a sequence $\\{\\varphi_n(r)\n",
            "\\}^{\\infty}_{n=0}$ of non-negative continuous functions defined on $[0,1)$ such\n",
            "that the series $\\sum_{n=0}^{\\infty}\\varphi_n(r)$ converges locally uniformly\n",
            "on $[0,1)$. Our results represent twofold generalizations corresponding to\n",
            "those obtained for the classes $\\mathcal{B}(\\mathbb{D})$ and\n",
            "$\\mathcal{B}(\\Omega_{\\gamma})$, where \\begin{align*}\n",
            "  \\Omega_{\\gamma}:=\\biggl\\{z\\in \\mathbb{C}:\n",
            "\\bigg|z+\\dfrac{\\gamma}{1-\\gamma}\\bigg|<\\dfrac{1}{1-\\gamma}\\biggr\\}.\n",
            "\\end{align*} As a convolution counterpart, we determine the Bohr radius for\n",
            "hypergeometric function on $ \\Omega_{\\gamma} $. Lastly, we establish a\n",
            "generalized Bohr inequality and its sharpness for the class of $ K\n",
            "$-quasiconformal, sense-preserving harmonic maps of the form $f=h+\\overline{g}$\n",
            "in $\\Omega_{\\gamma}.$\n",
            "['In this article, we first establish a generalized Bohr inequality and examine\\nits sharpness for a class of analytic functions $f$ in a simply connected\\ndomain $\\\\Omega_\\\\gamma,$ where $0\\\\leq \\\\gamma<1$ with a sequence $\\\\{\\\\varphi_n(r)\\n\\\\}^{\\\\infty}_{n=0}$ of non-negative continuous functions defined on $[0,1)$ such\\nthat the series $\\\\sum_{n=0}^{\\\\infty}\\\\varphi_n(r)$ converges locally uniformly\\non $[0,1)$.', 'Our results represent twofold generalizations corresponding to\\nthose obtained for the classes $\\\\mathcal{B}(\\\\mathbb{D})$ and\\n$\\\\mathcal{B}(\\\\Omega_{\\\\gamma})$, where \\\\begin{align*}\\n  \\\\Omega_{\\\\gamma}:=\\\\biggl\\\\{z\\\\in \\\\mathbb{C}:\\n\\\\bigg|z+\\\\dfrac{\\\\gamma}{1-\\\\gamma}\\\\bigg|<\\\\dfrac{1}{1-\\\\gamma}\\\\biggr\\\\}.', '\\\\end{align*} As a convolution counterpart, we determine the Bohr radius for\\nhypergeometric function on $ \\\\Omega_{\\\\gamma} $.', 'Lastly, we establish a\\ngeneralized Bohr inequality and its sharpness for the class of $ K\\n$-quasiconformal, sense-preserving harmonic maps of the form $f=h+\\\\overline{g}$\\nin $\\\\Omega_{\\\\gamma}.$']\n",
            "Chunks for abstract: Psychological studies have shown that Micro Gestures (MG) are closely linked\n",
            "to human emotions. MG-based emotion understanding has attracted much attention\n",
            "because it allows for emotion understanding through nonverbal body gestures\n",
            "without relying on identity information (e.g., facial and electrocardiogram\n",
            "data). Therefore, it is essential to recognize MG effectively for advanced\n",
            "emotion understanding. However, existing Micro Gesture Recognition (MGR)\n",
            "methods utilize only a single modality (e.g., RGB or skeleton) while\n",
            "overlooking crucial textual information. In this letter, we propose a simple\n",
            "but effective visual-text contrastive learning solution that utilizes text\n",
            "information for MGR. In addition, instead of using handcrafted prompts for\n",
            "visual-text contrastive learning, we propose a novel module called Adaptive\n",
            "prompting to generate context-aware prompts. The experimental results show that\n",
            "the proposed method achieves state-of-the-art performance on two public\n",
            "datasets. Furthermore, based on an empirical study utilizing the results of MGR\n",
            "for emotion understanding, we demonstrate that using the textual results of MGR\n",
            "significantly improves performance by 6%+ compared to directly using video as\n",
            "input.\n",
            "['Psychological studies have shown that Micro Gestures (MG) are closely linked\\nto human emotions.', 'MG-based emotion understanding has attracted much attention\\nbecause it allows for emotion understanding through nonverbal body gestures\\nwithout relying on identity information (e.g., facial and electrocardiogram\\ndata).', 'Therefore, it is essential to recognize MG effectively for advanced\\nemotion understanding.', 'However, existing Micro Gesture Recognition (MGR)\\nmethods utilize only a single modality (e.g., RGB or skeleton) while\\noverlooking crucial textual information.', 'In this letter, we propose a simple\\nbut effective visual-text contrastive learning solution that utilizes text\\ninformation for MGR.', 'In addition, instead of using handcrafted prompts for\\nvisual-text contrastive learning, we propose a novel module called Adaptive\\nprompting to generate context-aware prompts.', 'The experimental results show that\\nthe proposed method achieves state-of-the-art performance on two public\\ndatasets.', 'Furthermore, based on an empirical study utilizing the results of MGR\\nfor emotion understanding, we demonstrate that using the textual results of MGR\\nsignificantly improves performance by 6%+ compared to directly using video as\\ninput.']\n",
            "Chunks for abstract: Large language models (LLMs) increasingly serve as the backbone for\n",
            "classifying text associated with distinct domains and simultaneously several\n",
            "labels (classes). When encountering domain shifts, e.g., classifier of movie\n",
            "reviews from IMDb to Rotten Tomatoes, adapting such an LLM-based multi-label\n",
            "classifier is challenging due to incomplete label sets at the target domain and\n",
            "daunting training overhead. The existing domain adaptation methods address\n",
            "either image multi-label classifiers or text binary classifiers. In this paper,\n",
            "we design DALLMi, Domain Adaptation Large Language Model interpolator, a\n",
            "first-of-its-kind semi-supervised domain adaptation method for text data models\n",
            "based on LLMs, specifically BERT. The core of DALLMi is the novel variation\n",
            "loss and MixUp regularization, which jointly leverage the limited positively\n",
            "labeled and large quantity of unlabeled text and, importantly, their\n",
            "interpolation from the BERT word embeddings. DALLMi also introduces a\n",
            "label-balanced sampling strategy to overcome the imbalance between labeled and\n",
            "unlabeled data. We evaluate DALLMi against the partial-supervised and\n",
            "unsupervised approach on three datasets under different scenarios of label\n",
            "availability for the target domain. Our results show that DALLMi achieves\n",
            "higher mAP than unsupervised and partially-supervised approaches by 19.9% and\n",
            "52.2%, respectively.\n",
            "['Large language models (LLMs) increasingly serve as the backbone for\\nclassifying text associated with distinct domains and simultaneously several\\nlabels (classes).', 'When encountering domain shifts, e.g., classifier of movie\\nreviews from IMDb to Rotten Tomatoes, adapting such an LLM-based multi-label\\nclassifier is challenging due to incomplete label sets at the target domain and\\ndaunting training overhead.', 'The existing domain adaptation methods address\\neither image multi-label classifiers or text binary classifiers.', 'In this paper,\\nwe design DALLMi, Domain Adaptation Large Language Model interpolator, a\\nfirst-of-its-kind semi-supervised domain adaptation method for text data models\\nbased on LLMs, specifically BERT.', 'The core of DALLMi is the novel variation\\nloss and MixUp regularization, which jointly leverage the limited positively\\nlabeled and large quantity of unlabeled text and, importantly, their\\ninterpolation from the BERT word embeddings.', 'DALLMi also introduces a\\nlabel-balanced sampling strategy to overcome the imbalance between labeled and\\nunlabeled data.', 'We evaluate DALLMi against the partial-supervised and\\nunsupervised approach on three datasets under different scenarios of label\\navailability for the target domain.', 'Our results show that DALLMi achieves\\nhigher mAP than unsupervised and partially-supervised approaches by 19.9% and\\n52.2%, respectively.']\n",
            "Chunks for abstract: Large language models have boosted Large Models as a Service (LMaaS) into a\n",
            "thriving business sector. But even model owners offering only API access while\n",
            "keeping model parameters and internal workings private, their Intellectual\n",
            "Property (IP) are still at risk of theft through model extraction attacks. To\n",
            "safeguard the IP of these models and mitigate unfair competition in the\n",
            "language model market, watermarking technology serves as an efficient post-hoc\n",
            "solution for identifying IP infringements. However, existing IP protection\n",
            "watermarking methods either explicitly alter the original output of the\n",
            "language model or implant watermark signals in the model logits. These methods\n",
            "forcefully distort the original distribution of the language model and impact\n",
            "the sampling process, leading to a decline in the quality of the generated\n",
            "text. The existing method also fails to achieve end-to-end adaptive watermark\n",
            "embedding and lack robustness verification in complex scenarios where watermark\n",
            "detection is subject to interference. To overcome these challenges, we propose\n",
            "PromptShield, a plug-and-play IP protection watermarking method to resist model\n",
            "extraction attacks without training additional modules. Leveraging the\n",
            "self-reminding properties inherent in large language models, we encapsulate the\n",
            "user's query with a watermark self-generated instruction, nudging the LLMs to\n",
            "automatically generate watermark words in its output without compromising\n",
            "generation quality. Our method does not require access to the model's internal\n",
            "logits and minimizes alterations to the model's distribution using\n",
            "prompt-guided cues. Comprehensive experimental results consistently demonstrate\n",
            "the effectiveness, harmlessness, and robustness of our watermark. Moreover, Our\n",
            "watermark detection method remains robust and high detection sensitivity even\n",
            "when subjected to interference.\n",
            "['Large language models have boosted Large Models as a Service (LMaaS) into a\\nthriving business sector.', 'But even model owners offering only API access while\\nkeeping model parameters and internal workings private, their Intellectual\\nProperty (IP) are still at risk of theft through model extraction attacks.', 'To\\nsafeguard the IP of these models and mitigate unfair competition in the\\nlanguage model market, watermarking technology serves as an efficient post-hoc\\nsolution for identifying IP infringements.', 'However, existing IP protection\\nwatermarking methods either explicitly alter the original output of the\\nlanguage model or implant watermark signals in the model logits.', 'These methods\\nforcefully distort the original distribution of the language model and impact\\nthe sampling process, leading to a decline in the quality of the generated\\ntext.', 'The existing method also fails to achieve end-to-end adaptive watermark\\nembedding and lack robustness verification in complex scenarios where watermark\\ndetection is subject to interference.', 'To overcome these challenges, we propose\\nPromptShield, a plug-and-play IP protection watermarking method to resist model\\nextraction attacks without training additional modules.', \"Leveraging the\\nself-reminding properties inherent in large language models, we encapsulate the\\nuser's query with a watermark self-generated instruction, nudging the LLMs to\\nautomatically generate watermark words in its output without compromising\\ngeneration quality.\", \"Our method does not require access to the model's internal\\nlogits and minimizes alterations to the model's distribution using\\nprompt-guided cues.\", 'Comprehensive experimental results consistently demonstrate\\nthe effectiveness, harmlessness, and robustness of our watermark.', 'Moreover, Our\\nwatermark detection method remains robust and high detection sensitivity even\\nwhen subjected to interference.']\n",
            "Chunks for abstract: Texting stands out as the most prominent form of communication worldwide.\n",
            "Individual spend significant amount of time writing whole texts to send emails\n",
            "or write something on social media, which is time consuming in this modern era.\n",
            "Word prediction and sentence completion will be suitable and appropriate in the\n",
            "Bangla language to make textual information easier and more convenient. This\n",
            "paper expands the scope of Bangla language processing by introducing a Bi-LSTM\n",
            "model that effectively handles Bangla next-word prediction and Bangla sentence\n",
            "generation, demonstrating its versatility and potential impact. We proposed a\n",
            "new Bi-LSTM model to predict a following word and complete a sentence. We\n",
            "constructed a corpus dataset from various news portals, including bdnews24, BBC\n",
            "News Bangla, and Prothom Alo. The proposed approach achieved superior results\n",
            "in word prediction, reaching 99\\% accuracy for both 4-gram and 5-gram word\n",
            "predictions. Moreover, it demonstrated significant improvement over existing\n",
            "methods, achieving 35\\%, 75\\%, and 95\\% accuracy for uni-gram, bi-gram, and\n",
            "tri-gram word prediction, respectively\n",
            "['Texting stands out as the most prominent form of communication worldwide.', 'Individual spend significant amount of time writing whole texts to send emails\\nor write something on social media, which is time consuming in this modern era.', 'Word prediction and sentence completion will be suitable and appropriate in the\\nBangla language to make textual information easier and more convenient.', 'This\\npaper expands the scope of Bangla language processing by introducing a Bi-LSTM\\nmodel that effectively handles Bangla next-word prediction and Bangla sentence\\ngeneration, demonstrating its versatility and potential impact.', 'We proposed a\\nnew Bi-LSTM model to predict a following word and complete a sentence.', 'We\\nconstructed a corpus dataset from various news portals, including bdnews24, BBC\\nNews Bangla, and Prothom Alo.', 'The proposed approach achieved superior results\\nin word prediction, reaching 99\\\\% accuracy for both 4-gram and 5-gram word\\npredictions.', 'Moreover, it demonstrated significant improvement over existing\\nmethods, achieving 35\\\\%, 75\\\\%, and 95\\\\% accuracy for uni-gram, bi-gram, and\\ntri-gram word prediction, respectively']\n",
            "Chunks for abstract: A metric space $X$ is {\\em injective} if every non-expanding map $f:B\\to X$\n",
            "defined on a subspace $B$ of a metric space $A$ can be extended to a\n",
            "non-expanding map $\\bar f:A\\to X$. We prove that a metric space $X$ is a\n",
            "Lipschitz image of an injective metric space if and only if $X$ is Lipschitz\n",
            "connected in the sense that for every points $x,y\\in X$, there exists a\n",
            "Lipschitz map $f:[0,1]\\to X$ such that $f(0)=x$ and $f(1)=y$. In this case the\n",
            "metric space $X$ carries a well-defined intrinsic metric. A metric space $X$ is\n",
            "a Lipschitz image of a compact injective metric space if and only if $X$ is\n",
            "compact, Lipschitz connected and its intrinsic metric is totally bounded. A\n",
            "metric space $X$ is a Lipschitz image of a separable injective metric space if\n",
            "and only if $X$ is a Lipschitz image of the Urysohn universal metric space if\n",
            "and only if $X$ is analytic, Lipschitz connected and its intrinsic metric is\n",
            "separable.\n",
            "['A metric space $X$ is {\\\\em injective} if every non-expanding map $f:B\\\\to X$\\ndefined on a subspace $B$ of a metric space $A$ can be extended to a\\nnon-expanding map $\\\\bar f:A\\\\to X$.', 'We prove that a metric space $X$ is a\\nLipschitz image of an injective metric space if and only if $X$ is Lipschitz\\nconnected in the sense that for every points $x,y\\\\in X$, there exists a\\nLipschitz map $f:[0,1]\\\\to X$ such that $f(0)=x$ and $f(1)=y$.', 'In this case the\\nmetric space $X$ carries a well-defined intrinsic metric.', 'A metric space $X$ is\\na Lipschitz image of a compact injective metric space if and only if $X$ is\\ncompact, Lipschitz connected and its intrinsic metric is totally bounded.', 'A\\nmetric space $X$ is a Lipschitz image of a separable injective metric space if\\nand only if $X$ is a Lipschitz image of the Urysohn universal metric space if\\nand only if $X$ is analytic, Lipschitz connected and its intrinsic metric is\\nseparable.']\n",
            "Chunks for abstract: Understanding high-order correlations or multi-particle entities in a\n",
            "many-body system is not only of fundamental importance in condensed matter\n",
            "physics, but also critical for many technological applications. So far,\n",
            "higher-order multi-particle irreducible correlations in semiconductors have not\n",
            "been studied beyond the second-order or two-particle case. In this paper, we\n",
            "study the correlation of two electrons and two holes (2e2h) using the four-body\n",
            "Bethe-Salpeter equation (4B-BSE) and applied to the calculation of the\n",
            "helicity-resolved absorption between the two-body and four-body states for a\n",
            "monolayer MoTe2. Surprisingly, we found a rich series of spectral peaks within\n",
            "an energy span of ~40 meV below the exciton that has not been seen before. To\n",
            "understand the origin of the new spectral peaks, the Feynman diagrams of the 4B\n",
            "BSE are recast into the cluster expansion formalism, allowing us to study the\n",
            "individual effects of selected clusters or correlations of various orders. We\n",
            "found that the irreducible clusters of orders up to the 3rd and their\n",
            "factorized combinations cannot explain the spectral features. Importantly, we\n",
            "found that the 4th order irreducible correlation is necessary and sufficient to\n",
            "explain the new features. The 4th order irreducible correlation corresponds to\n",
            "a four-particle irreducible cluster involving two electrons and two holes,\n",
            "alternatively called quadron or quadruplon. The new 4th order correlation or\n",
            "four-particle entity not only enriches our understanding of many-body\n",
            "correlations but also could provide new mechanism for light emission or\n",
            "absorption for possible new optoelectronic devices.\n",
            "['Understanding high-order correlations or multi-particle entities in a\\nmany-body system is not only of fundamental importance in condensed matter\\nphysics, but also critical for many technological applications.', 'So far,\\nhigher-order multi-particle irreducible correlations in semiconductors have not\\nbeen studied beyond the second-order or two-particle case.', 'In this paper, we\\nstudy the correlation of two electrons and two holes (2e2h) using the four-body\\nBethe-Salpeter equation (4B-BSE) and applied to the calculation of the\\nhelicity-resolved absorption between the two-body and four-body states for a\\nmonolayer MoTe2.', 'Surprisingly, we found a rich series of spectral peaks within\\nan energy span of ~40 meV below the exciton that has not been seen before.', 'To\\nunderstand the origin of the new spectral peaks, the Feynman diagrams of the 4B\\nBSE are recast into the cluster expansion formalism, allowing us to study the\\nindividual effects of selected clusters or correlations of various orders.', 'We\\nfound that the irreducible clusters of orders up to the 3rd and their\\nfactorized combinations cannot explain the spectral features.', 'Importantly, we\\nfound that the 4th order irreducible correlation is necessary and sufficient to\\nexplain the new features.', 'The 4th order irreducible correlation corresponds to\\na four-particle irreducible cluster involving two electrons and two holes,\\nalternatively called quadron or quadruplon.', 'The new 4th order correlation or\\nfour-particle entity not only enriches our understanding of many-body\\ncorrelations but also could provide new mechanism for light emission or\\nabsorption for possible new optoelectronic devices.']\n",
            "Chunks for abstract: Magnetic flux trapping in field-cooled (FC) Sn-Pb solders has been recently\n",
            "studied because of the observation of nonvolatile magneto-thermal switching [H.\n",
            "Arima et al., Commun. Mater. 5, 34 (2024)] and anomalous magnetic\n",
            "field-temperature (H-T) phase diagrams [T. Murakami et al., AIP Adv. 13, 125008\n",
            "(2023)]. In this paper, we investigate the origin of the anomalously low\n",
            "specific heat (C) in Sn10-Pb90 and Sn45-Pb55 solders after FC at H = 1500 Oe.\n",
            "We show that the FC solders exhibit self-heating possibly caused by the flux\n",
            "flow during the reduction of trapped fluxes when heating the sample during the\n",
            "C measurements. The T dependence of T rise clearly exhibits unexpectedly large\n",
            "values when the low-C states are observed. In addition, the cause of the\n",
            "transition-like behavior in C-T of FC solders are explained by local heating\n",
            "during H control and flux-jump phenomena.\n",
            "['Magnetic flux trapping in field-cooled (FC) Sn-Pb solders has been recently\\nstudied because of the observation of nonvolatile magneto-thermal switching [H.\\nArima et al., Commun.', 'Mater.', '5, 34 (2024)] and anomalous magnetic\\nfield-temperature (H-T) phase diagrams [T. Murakami et al., AIP Adv.', '13, 125008\\n(2023)].', 'In this paper, we investigate the origin of the anomalously low\\nspecific heat (C) in Sn10-Pb90 and Sn45-Pb55 solders after FC at H = 1500 Oe.', 'We show that the FC solders exhibit self-heating possibly caused by the flux\\nflow during the reduction of trapped fluxes when heating the sample during the\\nC measurements.', 'The T dependence of T rise clearly exhibits unexpectedly large\\nvalues when the low-C states are observed.', 'In addition, the cause of the\\ntransition-like behavior in C-T of FC solders are explained by local heating\\nduring H control and flux-jump phenomena.']\n",
            "Chunks for abstract: This report proposes a robust method for classifying oceanic and atmospheric\n",
            "phenomena using synthetic aperture radar (SAR) imagery. Our proposed method\n",
            "leverages the powerful pre-trained model Swin Transformer v2 Large as the\n",
            "backbone and employs carefully designed data augmentation and exponential\n",
            "moving average during training to enhance the model's generalization capability\n",
            "and stability. In the testing stage, a method called ReAct is utilized to\n",
            "rectify activation values and utilize Energy Score for more accurate\n",
            "measurement of model uncertainty, significantly improving out-of-distribution\n",
            "detection performance. Furthermore, test time augmentation is employed to\n",
            "enhance classification accuracy and prediction stability. Comprehensive\n",
            "experimental results demonstrate that each additional technique significantly\n",
            "improves classification accuracy, confirming their effectiveness in classifying\n",
            "maritime and atmospheric phenomena in SAR imagery.\n",
            "['This report proposes a robust method for classifying oceanic and atmospheric\\nphenomena using synthetic aperture radar (SAR) imagery.', \"Our proposed method\\nleverages the powerful pre-trained model Swin Transformer v2 Large as the\\nbackbone and employs carefully designed data augmentation and exponential\\nmoving average during training to enhance the model's generalization capability\\nand stability.\", 'In the testing stage, a method called ReAct is utilized to\\nrectify activation values and utilize Energy Score for more accurate\\nmeasurement of model uncertainty, significantly improving out-of-distribution\\ndetection performance.', 'Furthermore, test time augmentation is employed to\\nenhance classification accuracy and prediction stability.', 'Comprehensive\\nexperimental results demonstrate that each additional technique significantly\\nimproves classification accuracy, confirming their effectiveness in classifying\\nmaritime and atmospheric phenomena in SAR imagery.']\n",
            "Chunks for abstract: Time series data are ubiquitous across various domains, making time series\n",
            "analysis critically important. Traditional time series models are\n",
            "task-specific, featuring singular functionality and limited generalization\n",
            "capacity. Recently, large language foundation models have unveiled their\n",
            "remarkable capabilities for cross-task transferability, zero-shot/few-shot\n",
            "learning, and decision-making explainability. This success has sparked interest\n",
            "in the exploration of foundation models to solve multiple time series\n",
            "challenges simultaneously. There are two main research lines, namely\n",
            "pre-training foundation models from scratch for time series and adapting large\n",
            "language foundation models for time series. They both contribute to the\n",
            "development of a unified model that is highly generalizable, versatile, and\n",
            "comprehensible for time series analysis. This survey offers a 3E analytical\n",
            "framework for comprehensive examination of related research. Specifically, we\n",
            "examine existing works from three dimensions, namely Effectiveness, Efficiency\n",
            "and Explainability. In each dimension, we focus on discussing how related works\n",
            "devise tailored solution by considering unique challenges in the realm of time\n",
            "series. Furthermore, we provide a domain taxonomy to help followers keep up\n",
            "with the domain-specific advancements. In addition, we introduce extensive\n",
            "resources to facilitate the field's development, including datasets,\n",
            "open-source, time series libraries. A GitHub repository is also maintained for\n",
            "resource updates (https://github.com/start2020/Awesome-TimeSeries-LLM-FM).\n",
            "['Time series data are ubiquitous across various domains, making time series\\nanalysis critically important.', 'Traditional time series models are\\ntask-specific, featuring singular functionality and limited generalization\\ncapacity.', 'Recently, large language foundation models have unveiled their\\nremarkable capabilities for cross-task transferability, zero-shot/few-shot\\nlearning, and decision-making explainability.', 'This success has sparked interest\\nin the exploration of foundation models to solve multiple time series\\nchallenges simultaneously.', 'There are two main research lines, namely\\npre-training foundation models from scratch for time series and adapting large\\nlanguage foundation models for time series.', 'They both contribute to the\\ndevelopment of a unified model that is highly generalizable, versatile, and\\ncomprehensible for time series analysis.', 'This survey offers a 3E analytical\\nframework for comprehensive examination of related research.', 'Specifically, we\\nexamine existing works from three dimensions, namely Effectiveness, Efficiency\\nand Explainability.', 'In each dimension, we focus on discussing how related works\\ndevise tailored solution by considering unique challenges in the realm of time\\nseries.', 'Furthermore, we provide a domain taxonomy to help followers keep up\\nwith the domain-specific advancements.', \"In addition, we introduce extensive\\nresources to facilitate the field's development, including datasets,\\nopen-source, time series libraries.\", 'A GitHub repository is also maintained for\\nresource updates (https://github.com/start2020/Awesome-TimeSeries-LLM-FM).']\n",
            "Chunks for abstract: Concept Bottleneck Models (CBM) map the input image to a high-level\n",
            "human-understandable concept space and then make class predictions based on\n",
            "these concepts. Recent approaches automate the construction of CBM by prompting\n",
            "Large Language Models (LLM) to generate text concepts and then use Vision\n",
            "Language Models (VLM) to obtain concept scores to train a CBM. However, it is\n",
            "desired to build CBMs with concepts defined by human experts instead of LLM\n",
            "generated concepts to make them more trustworthy. In this work, we take a\n",
            "closer inspection on the faithfulness of VLM concept scores for such\n",
            "expert-defined concepts in domains like fine-grain bird species classification\n",
            "and animal classification. Our investigations reveal that frozen VLMs, like\n",
            "CLIP, struggle to correctly associate a concept to the corresponding visual\n",
            "input despite achieving a high classification performance. To address this, we\n",
            "propose a novel Contrastive Semi-Supervised (CSS) learning method which uses a\n",
            "few labeled concept examples to improve concept alignment (activate truthful\n",
            "visual concepts) in CLIP model. Extensive experiments on three benchmark\n",
            "datasets show that our approach substantially increases the concept accuracy\n",
            "and classification accuracy, yet requires only a fraction of the\n",
            "human-annotated concept labels. To further improve the classification\n",
            "performance, we also introduce a new class-level intervention procedure for\n",
            "fine-grain classification problems that identifies the confounding classes and\n",
            "intervenes their concept space to reduce errors.\n",
            "['Concept Bottleneck Models (CBM) map the input image to a high-level\\nhuman-understandable concept space and then make class predictions based on\\nthese concepts.', 'Recent approaches automate the construction of CBM by prompting\\nLarge Language Models (LLM) to generate text concepts and then use Vision\\nLanguage Models (VLM) to obtain concept scores to train a CBM.', 'However, it is\\ndesired to build CBMs with concepts defined by human experts instead of LLM\\ngenerated concepts to make them more trustworthy.', 'In this work, we take a\\ncloser inspection on the faithfulness of VLM concept scores for such\\nexpert-defined concepts in domains like fine-grain bird species classification\\nand animal classification.', 'Our investigations reveal that frozen VLMs, like\\nCLIP, struggle to correctly associate a concept to the corresponding visual\\ninput despite achieving a high classification performance.', 'To address this, we\\npropose a novel Contrastive Semi-Supervised (CSS) learning method which uses a\\nfew labeled concept examples to improve concept alignment (activate truthful\\nvisual concepts) in CLIP model.', 'Extensive experiments on three benchmark\\ndatasets show that our approach substantially increases the concept accuracy\\nand classification accuracy, yet requires only a fraction of the\\nhuman-annotated concept labels.', 'To further improve the classification\\nperformance, we also introduce a new class-level intervention procedure for\\nfine-grain classification problems that identifies the confounding classes and\\nintervenes their concept space to reduce errors.']\n",
            "Chunks for abstract: Soft robotics has emerged as a promising field with the potential to\n",
            "revolutionize industries such as healthcare and manufacturing. However,\n",
            "designing effective soft robots presents challenges, particularly in managing\n",
            "the complex interplay of material properties, structural design, and control\n",
            "strategies. Traditional design methods are often time-consuming and may not\n",
            "yield optimal designs. In this paper, we explore the use of generative AI to\n",
            "create 3D models of soft actuators. We create a dataset of over 70 text-shape\n",
            "pairings of soft pneumatic robot actuator designs, and adapt a latent diffusion\n",
            "model (SDFusion) to learn the data distribution and generate novel designs from\n",
            "it. By employing transfer learning and data augmentation techniques, we\n",
            "significantly improve the performance of the diffusion model. These findings\n",
            "highlight the potential of generative AI in designing complex soft robotic\n",
            "systems, paving the way for future advancements in the field.\n",
            "['Soft robotics has emerged as a promising field with the potential to\\nrevolutionize industries such as healthcare and manufacturing.', 'However,\\ndesigning effective soft robots presents challenges, particularly in managing\\nthe complex interplay of material properties, structural design, and control\\nstrategies.', 'Traditional design methods are often time-consuming and may not\\nyield optimal designs.', 'In this paper, we explore the use of generative AI to\\ncreate 3D models of soft actuators.', 'We create a dataset of over 70 text-shape\\npairings of soft pneumatic robot actuator designs, and adapt a latent diffusion\\nmodel (SDFusion) to learn the data distribution and generate novel designs from\\nit.', 'By employing transfer learning and data augmentation techniques, we\\nsignificantly improve the performance of the diffusion model.', 'These findings\\nhighlight the potential of generative AI in designing complex soft robotic\\nsystems, paving the way for future advancements in the field.']\n",
            "Chunks for abstract: Nonlinearities are crucial for capturing complex input-output relationships\n",
            "especially in deep neural networks. However, nonlinear functions often incur\n",
            "various hardware and compute overheads. Meanwhile, stochastic computing (SC)\n",
            "has emerged as a promising approach to tackle this challenge by trading output\n",
            "precision for hardware simplicity. To this end, this paper proposes a\n",
            "first-of-its-kind stochastic multivariate universal-radix finite-state machine\n",
            "(SMURF) that harnesses SC for hardware-simplistic multivariate nonlinear\n",
            "function generation at high accuracy. We present the finite-state machine (FSM)\n",
            "architecture for SMURF, as well as analytical derivations of sampling gate\n",
            "coefficients for accurately approximating generic nonlinear functions.\n",
            "Experiments demonstrate the superiority of SMURF, requiring only 16.07% area\n",
            "and 14.45% power consumption of Taylor-series approximation, and merely 2.22%\n",
            "area of look-up table (LUT) schemes.\n",
            "['Nonlinearities are crucial for capturing complex input-output relationships\\nespecially in deep neural networks.', 'However, nonlinear functions often incur\\nvarious hardware and compute overheads.', 'Meanwhile, stochastic computing (SC)\\nhas emerged as a promising approach to tackle this challenge by trading output\\nprecision for hardware simplicity.', 'To this end, this paper proposes a\\nfirst-of-its-kind stochastic multivariate universal-radix finite-state machine\\n(SMURF) that harnesses SC for hardware-simplistic multivariate nonlinear\\nfunction generation at high accuracy.', 'We present the finite-state machine (FSM)\\narchitecture for SMURF, as well as analytical derivations of sampling gate\\ncoefficients for accurately approximating generic nonlinear functions.', 'Experiments demonstrate the superiority of SMURF, requiring only 16.07% area\\nand 14.45% power consumption of Taylor-series approximation, and merely 2.22%\\narea of look-up table (LUT) schemes.']\n",
            "Chunks for abstract: The luminosity and spectral energy distribution (SED) of high-$z$ galaxies\n",
            "are sensitive to the stellar population synthesis (SPS) models. In this paper,\n",
            "we study the effects of different SPS models on the measurements of high-$z$\n",
            "galaxies and the budget of ionizing photons during the epoch of reionization,\n",
            "by employing each of them in the semi-analytical galaxy formation model {\\sc\n",
            "L-Galaxies 2020}. We find that the different SPS models lead to $\\lesssim 0.5$\n",
            "dex differences on the amplitudes of UV luminosity functions, while the two\n",
            "modes of the same SPS model with and without the inclusion of binary stars\n",
            "leads to similar UV luminosity functions at $z \\ge 6$. Instead, the binary\n",
            "stars produce $\\sim 40\\%$ more ionizing photons than the single stars, while\n",
            "such differences are smaller than those caused by different SPS models, e.g.\n",
            "the BPASS model produces $\\sim 100\\%$ more ionizing photons than other models.\n",
            "['The luminosity and spectral energy distribution (SED) of high-$z$ galaxies\\nare sensitive to the stellar population synthesis (SPS) models.', 'In this paper,\\nwe study the effects of different SPS models on the measurements of high-$z$\\ngalaxies and the budget of ionizing photons during the epoch of reionization,\\nby employing each of them in the semi-analytical galaxy formation model {\\\\sc\\nL-Galaxies 2020}.', 'We find that the different SPS models lead to $\\\\lesssim 0.5$\\ndex differences on the amplitudes of UV luminosity functions, while the two\\nmodes of the same SPS model with and without the inclusion of binary stars\\nleads to similar UV luminosity functions at $z \\\\ge 6$.', 'Instead, the binary\\nstars produce $\\\\sim 40\\\\%$ more ionizing photons than the single stars, while\\nsuch differences are smaller than those caused by different SPS models, e.g.', 'the BPASS model produces $\\\\sim 100\\\\%$ more ionizing photons than other models.']\n",
            "Chunks for abstract: We present a nonvariational setting for the Neumann problem for the Poisson\n",
            "equation for solutions that are H\\\"{o}lder continuous and that may have\n",
            "infinite Dirichlet integral. We introduce a distributional normal derivative on\n",
            "the boundary for the solutions that extends that for harmonic functions that\n",
            "has been introduced in a previous paper and we solve the nonvariational Neumann\n",
            "problem for data in the interior with a negative Schauder exponent and for data\n",
            "on the boundary that belong to a certain space of distributions on the\n",
            "boundary.\n",
            "['We present a nonvariational setting for the Neumann problem for the Poisson\\nequation for solutions that are H\\\\\"{o}lder continuous and that may have\\ninfinite Dirichlet integral.', 'We introduce a distributional normal derivative on\\nthe boundary for the solutions that extends that for harmonic functions that\\nhas been introduced in a previous paper and we solve the nonvariational Neumann\\nproblem for data in the interior with a negative Schauder exponent and for data\\non the boundary that belong to a certain space of distributions on the\\nboundary.']\n",
            "Chunks for abstract: In this paper, we explore the application of a particular genetic algorithm,\n",
            "the Rank Genetic Algorithm (Rank GA), to address a graph theory problem. The\n",
            "Rank GA was introduced to address the problem of graph coloring, exploring into\n",
            "the specialized field of Chromatic Graph Theory. We successfully improved\n",
            "several of the previously known lower bounds. To validate the effectiveness of\n",
            "these new bounds, we performed an analytical approximation, confirming their\n",
            "validity. The findings underscore the interdisciplinary impact of the use of\n",
            "genetic algorithms in theoretical mathematical research.\n",
            "['In this paper, we explore the application of a particular genetic algorithm,\\nthe Rank Genetic Algorithm (Rank GA), to address a graph theory problem.', 'The\\nRank GA was introduced to address the problem of graph coloring, exploring into\\nthe specialized field of Chromatic Graph Theory.', 'We successfully improved\\nseveral of the previously known lower bounds.', 'To validate the effectiveness of\\nthese new bounds, we performed an analytical approximation, confirming their\\nvalidity.', 'The findings underscore the interdisciplinary impact of the use of\\ngenetic algorithms in theoretical mathematical research.']\n",
            "Chunks for abstract: This paper studies algorithmic decision-making under human's strategic\n",
            "behavior, where a decision maker uses an algorithm to make decisions about\n",
            "human agents, and the latter with information about the algorithm may exert\n",
            "effort strategically and improve to receive favorable decisions. Unlike prior\n",
            "works that assume agents benefit from their efforts immediately, we consider\n",
            "realistic scenarios where the impacts of these efforts are persistent and\n",
            "agents benefit from efforts by making improvements gradually. We first develop\n",
            "a dynamic model to characterize persistent improvements and based on this\n",
            "construct a Stackelberg game to model the interplay between agents and the\n",
            "decision-maker. We analytically characterize the equilibrium strategies and\n",
            "identify conditions under which agents have incentives to improve. With the\n",
            "dynamics, we then study how the decision-maker can design an optimal policy to\n",
            "incentivize the largest improvements inside the agent population. We also\n",
            "extend the model to settings where 1) agents may be dishonest and game the\n",
            "algorithm into making favorable but erroneous decisions; 2) honest efforts are\n",
            "forgettable and not sufficient to guarantee persistent improvements. With the\n",
            "extended models, we further examine conditions under which agents prefer honest\n",
            "efforts over dishonest behavior and the impacts of forgettable efforts.\n",
            "[\"This paper studies algorithmic decision-making under human's strategic\\nbehavior, where a decision maker uses an algorithm to make decisions about\\nhuman agents, and the latter with information about the algorithm may exert\\neffort strategically and improve to receive favorable decisions.\", 'Unlike prior\\nworks that assume agents benefit from their efforts immediately, we consider\\nrealistic scenarios where the impacts of these efforts are persistent and\\nagents benefit from efforts by making improvements gradually.', 'We first develop\\na dynamic model to characterize persistent improvements and based on this\\nconstruct a Stackelberg game to model the interplay between agents and the\\ndecision-maker.', 'We analytically characterize the equilibrium strategies and\\nidentify conditions under which agents have incentives to improve.', 'With the\\ndynamics, we then study how the decision-maker can design an optimal policy to\\nincentivize the largest improvements inside the agent population.', 'We also\\nextend the model to settings where 1) agents may be dishonest and game the\\nalgorithm into making favorable but erroneous decisions; 2) honest efforts are\\nforgettable and not sufficient to guarantee persistent improvements.', 'With the\\nextended models, we further examine conditions under which agents prefer honest\\nefforts over dishonest behavior and the impacts of forgettable efforts.']\n",
            "Chunks for abstract: Text summarization models have typically focused on optimizing aspects of\n",
            "quality such as fluency, relevance, and coherence, particularly in the context\n",
            "of news articles. However, summarization models are increasingly being used to\n",
            "summarize diverse sources of text, such as social media data, that encompass a\n",
            "wide demographic user base. It is thus crucial to assess not only the quality\n",
            "of the generated summaries, but also the extent to which they can fairly\n",
            "represent the opinions of diverse social groups. Position bias, a long-known\n",
            "issue in news summarization, has received limited attention in the context of\n",
            "social multi-document summarization. We deeply investigate this phenomenon by\n",
            "analyzing the effect of group ordering in input documents when summarizing\n",
            "tweets from three distinct linguistic communities: African-American English,\n",
            "Hispanic-aligned Language, and White-aligned Language. Our empirical analysis\n",
            "shows that although the textual quality of the summaries remains consistent\n",
            "regardless of the input document order, in terms of fairness, the results vary\n",
            "significantly depending on how the dialect groups are presented in the input\n",
            "data. Our results suggest that position bias manifests differently in social\n",
            "multi-document summarization, severely impacting the fairness of summarization\n",
            "models.\n",
            "['Text summarization models have typically focused on optimizing aspects of\\nquality such as fluency, relevance, and coherence, particularly in the context\\nof news articles.', 'However, summarization models are increasingly being used to\\nsummarize diverse sources of text, such as social media data, that encompass a\\nwide demographic user base.', 'It is thus crucial to assess not only the quality\\nof the generated summaries, but also the extent to which they can fairly\\nrepresent the opinions of diverse social groups.', 'Position bias, a long-known\\nissue in news summarization, has received limited attention in the context of\\nsocial multi-document summarization.', 'We deeply investigate this phenomenon by\\nanalyzing the effect of group ordering in input documents when summarizing\\ntweets from three distinct linguistic communities: African-American English,\\nHispanic-aligned Language, and White-aligned Language.', 'Our empirical analysis\\nshows that although the textual quality of the summaries remains consistent\\nregardless of the input document order, in terms of fairness, the results vary\\nsignificantly depending on how the dialect groups are presented in the input\\ndata.', 'Our results suggest that position bias manifests differently in social\\nmulti-document summarization, severely impacting the fairness of summarization\\nmodels.']\n",
            "Chunks for abstract: The increased deployment of multi-robot systems (MRS) in various fields has\n",
            "led to the need for analysis of system-level performance. However, creating\n",
            "consistent metrics for MRS is challenging due to the wide range of system and\n",
            "environmental factors, such as team size and environment size. This paper\n",
            "presents a new analytical framework for MRS based on dimensionless variable\n",
            "analysis, a mathematical technique typically used to simplify complex physical\n",
            "systems. This approach effectively condenses the complex parameters influencing\n",
            "MRS performance into a manageable set of dimensionless variables. We form\n",
            "dimensionless variables which encapsulate key parameters of the robot team and\n",
            "task. Then we use these dimensionless variables to fit a parametric model of\n",
            "team performance. Our model successfully identifies critical performance\n",
            "determinants and their interdependencies, providing insight for MRS design and\n",
            "optimization. The application of dimensionless variable analysis to MRS offers\n",
            "a promising method for MRS analysis that effectively reduces complexity,\n",
            "enhances comprehension of system behaviors, and informs the design and\n",
            "management of future MRS deployments.\n",
            "['The increased deployment of multi-robot systems (MRS) in various fields has\\nled to the need for analysis of system-level performance.', 'However, creating\\nconsistent metrics for MRS is challenging due to the wide range of system and\\nenvironmental factors, such as team size and environment size.', 'This paper\\npresents a new analytical framework for MRS based on dimensionless variable\\nanalysis, a mathematical technique typically used to simplify complex physical\\nsystems.', 'This approach effectively condenses the complex parameters influencing\\nMRS performance into a manageable set of dimensionless variables.', 'We form\\ndimensionless variables which encapsulate key parameters of the robot team and\\ntask.', 'Then we use these dimensionless variables to fit a parametric model of\\nteam performance.', 'Our model successfully identifies critical performance\\ndeterminants and their interdependencies, providing insight for MRS design and\\noptimization.', 'The application of dimensionless variable analysis to MRS offers\\na promising method for MRS analysis that effectively reduces complexity,\\nenhances comprehension of system behaviors, and informs the design and\\nmanagement of future MRS deployments.']\n",
            "Chunks for abstract: In the fast-evolving domain of artificial intelligence, large language models\n",
            "(LLMs) such as GPT-3 and GPT-4 are revolutionizing the landscapes of finance,\n",
            "healthcare, and law: domains characterized by their reliance on professional\n",
            "expertise, challenging data acquisition, high-stakes, and stringent regulatory\n",
            "compliance. This survey offers a detailed exploration of the methodologies,\n",
            "applications, challenges, and forward-looking opportunities of LLMs within\n",
            "these high-stakes sectors. We highlight the instrumental role of LLMs in\n",
            "enhancing diagnostic and treatment methodologies in healthcare, innovating\n",
            "financial analytics, and refining legal interpretation and compliance\n",
            "strategies. Moreover, we critically examine the ethics for LLM applications in\n",
            "these fields, pointing out the existing ethical concerns and the need for\n",
            "transparent, fair, and robust AI systems that respect regulatory norms. By\n",
            "presenting a thorough review of current literature and practical applications,\n",
            "we showcase the transformative impact of LLMs, and outline the imperative for\n",
            "interdisciplinary cooperation, methodological advancements, and ethical\n",
            "vigilance. Through this lens, we aim to spark dialogue and inspire future\n",
            "research dedicated to maximizing the benefits of LLMs while mitigating their\n",
            "risks in these precision-dependent sectors. To facilitate future research on\n",
            "LLMs in these critical societal domains, we also initiate a reading list that\n",
            "tracks the latest advancements under this topic, which will be continually\n",
            "updated: \\url{https://github.com/czyssrs/LLM_X_papers}.\n",
            "['In the fast-evolving domain of artificial intelligence, large language models\\n(LLMs) such as GPT-3 and GPT-4 are revolutionizing the landscapes of finance,\\nhealthcare, and law: domains characterized by their reliance on professional\\nexpertise, challenging data acquisition, high-stakes, and stringent regulatory\\ncompliance.', 'This survey offers a detailed exploration of the methodologies,\\napplications, challenges, and forward-looking opportunities of LLMs within\\nthese high-stakes sectors.', 'We highlight the instrumental role of LLMs in\\nenhancing diagnostic and treatment methodologies in healthcare, innovating\\nfinancial analytics, and refining legal interpretation and compliance\\nstrategies.', 'Moreover, we critically examine the ethics for LLM applications in\\nthese fields, pointing out the existing ethical concerns and the need for\\ntransparent, fair, and robust AI systems that respect regulatory norms.', 'By\\npresenting a thorough review of current literature and practical applications,\\nwe showcase the transformative impact of LLMs, and outline the imperative for\\ninterdisciplinary cooperation, methodological advancements, and ethical\\nvigilance.', 'Through this lens, we aim to spark dialogue and inspire future\\nresearch dedicated to maximizing the benefits of LLMs while mitigating their\\nrisks in these precision-dependent sectors.', 'To facilitate future research on\\nLLMs in these critical societal domains, we also initiate a reading list that\\ntracks the latest advancements under this topic, which will be continually\\nupdated: \\\\url{https://github.com/czyssrs/LLM_X_papers}.']\n",
            "Chunks for abstract: An analytical theory is developed for predicting the nonlinear susceptibility\n",
            "of ionic polarization to continuous electromagnetic waves in both bulk and\n",
            "strained thin film ferroelectrics. Using a perturbation method for solving the\n",
            "nonlinear equation of motion for ionic polarization within the framework of\n",
            "Landau-Ginzburg-Devonshire theory, the full second-order nonlinear\n",
            "susceptibility tensor is derived as a function of frequency, temperature, and\n",
            "strain. The theory predicts the coexistence of a significantly enhanced\n",
            "second-order dielectric susceptibility and a relatively low dielectric loss in\n",
            "BaTiO3 films with a strain-stabilized monoclinic ferroelectric phase and in a\n",
            "strained SrTiO3 film near its temperature-driven second-order\n",
            "ferroelectric-to-paraelectric phase transition. This work establishes a\n",
            "theoretical framework for predicting and exploiting nonlinear interactions\n",
            "between THz waves and ferroelectric materials, and more generally, suggests\n",
            "exciting opportunities to strain-engineer nonlinear dynamical properties of\n",
            "ferroelectrics beyond the static and quasi-static limits.\n",
            "['An analytical theory is developed for predicting the nonlinear susceptibility\\nof ionic polarization to continuous electromagnetic waves in both bulk and\\nstrained thin film ferroelectrics.', 'Using a perturbation method for solving the\\nnonlinear equation of motion for ionic polarization within the framework of\\nLandau-Ginzburg-Devonshire theory, the full second-order nonlinear\\nsusceptibility tensor is derived as a function of frequency, temperature, and\\nstrain.', 'The theory predicts the coexistence of a significantly enhanced\\nsecond-order dielectric susceptibility and a relatively low dielectric loss in\\nBaTiO3 films with a strain-stabilized monoclinic ferroelectric phase and in a\\nstrained SrTiO3 film near its temperature-driven second-order\\nferroelectric-to-paraelectric phase transition.', 'This work establishes a\\ntheoretical framework for predicting and exploiting nonlinear interactions\\nbetween THz waves and ferroelectric materials, and more generally, suggests\\nexciting opportunities to strain-engineer nonlinear dynamical properties of\\nferroelectrics beyond the static and quasi-static limits.']\n",
            "Chunks for abstract: Reliability of AI systems is a fundamental concern for the successful\n",
            "deployment and widespread adoption of AI technologies. Unfortunately, the\n",
            "escalating complexity and heterogeneity of AI hardware systems make them\n",
            "inevitably and increasingly susceptible to hardware faults (e.g., bit flips)\n",
            "that can potentially corrupt model parameters. Given this challenge, this paper\n",
            "aims to answer a critical question: How likely is a parameter corruption to\n",
            "result in an incorrect model output? To systematically answer this question, we\n",
            "propose a novel quantitative metric, Parameter Vulnerability Factor (PVF),\n",
            "inspired by architectural vulnerability factor (AVF) in computer architecture\n",
            "community, aiming to standardize the quantification of AI model\n",
            "resilience/vulnerability against parameter corruptions. We define a model\n",
            "parameter's PVF as the probability that a corruption in that particular model\n",
            "parameter will result in an incorrect output. Similar to AVF, this statistical\n",
            "concept can be derived from statistically extensive and meaningful fault\n",
            "injection (FI) experiments. In this paper, we present several use cases on\n",
            "applying PVF to three types of tasks/models during inference -- recommendation\n",
            "(DLRM), vision classification (CNN), and text classification (BERT). PVF can\n",
            "provide pivotal insights to AI hardware designers in balancing the tradeoff\n",
            "between fault protection and performance/efficiency such as mapping vulnerable\n",
            "AI parameter components to well-protected hardware modules. PVF metric is\n",
            "applicable to any AI model and has a potential to help unify and standardize AI\n",
            "vulnerability/resilience evaluation practice.\n",
            "['Reliability of AI systems is a fundamental concern for the successful\\ndeployment and widespread adoption of AI technologies.', 'Unfortunately, the\\nescalating complexity and heterogeneity of AI hardware systems make them\\ninevitably and increasingly susceptible to hardware faults (e.g., bit flips)\\nthat can potentially corrupt model parameters.', 'Given this challenge, this paper\\naims to answer a critical question: How likely is a parameter corruption to\\nresult in an incorrect model output?', 'To systematically answer this question, we\\npropose a novel quantitative metric, Parameter Vulnerability Factor (PVF),\\ninspired by architectural vulnerability factor (AVF) in computer architecture\\ncommunity, aiming to standardize the quantification of AI model\\nresilience/vulnerability against parameter corruptions.', \"We define a model\\nparameter's PVF as the probability that a corruption in that particular model\\nparameter will result in an incorrect output.\", 'Similar to AVF, this statistical\\nconcept can be derived from statistically extensive and meaningful fault\\ninjection (FI) experiments.', 'In this paper, we present several use cases on\\napplying PVF to three types of tasks/models during inference -- recommendation\\n(DLRM), vision classification (CNN), and text classification (BERT).', 'PVF can\\nprovide pivotal insights to AI hardware designers in balancing the tradeoff\\nbetween fault protection and performance/efficiency such as mapping vulnerable\\nAI parameter components to well-protected hardware modules.', 'PVF metric is\\napplicable to any AI model and has a potential to help unify and standardize AI\\nvulnerability/resilience evaluation practice.']\n",
            "Chunks for abstract: The zero-shot capability of Large Language Models (LLMs) has enabled highly\n",
            "flexible, reference-free metrics for various tasks, making LLM evaluators\n",
            "common tools in NLP. However, the robustness of these LLM evaluators remains\n",
            "relatively understudied; existing work mainly pursued optimal performance in\n",
            "terms of correlating LLM scores with human expert scores. In this paper, we\n",
            "conduct a series of analyses using the SummEval dataset and confirm that LLMs\n",
            "are biased evaluators as they: (1) exhibit familiarity bias-a preference for\n",
            "text with lower perplexity, (2) show skewed and biased distributions of\n",
            "ratings, and (3) experience anchoring effects for multi-attribute judgments. We\n",
            "also found that LLMs are inconsistent evaluators, showing low \"inter-sample\"\n",
            "agreement and sensitivity to prompt differences that are insignificant to human\n",
            "understanding of text quality. Furthermore, we share recipes for configuring\n",
            "LLM evaluators to mitigate these limitations. Experimental results on the RoSE\n",
            "dataset demonstrate improvements over the state-of-the-art LLM evaluators.\n",
            "['The zero-shot capability of Large Language Models (LLMs) has enabled highly\\nflexible, reference-free metrics for various tasks, making LLM evaluators\\ncommon tools in NLP.', 'However, the robustness of these LLM evaluators remains\\nrelatively understudied; existing work mainly pursued optimal performance in\\nterms of correlating LLM scores with human expert scores.', 'In this paper, we\\nconduct a series of analyses using the SummEval dataset and confirm that LLMs\\nare biased evaluators as they: (1) exhibit familiarity bias-a preference for\\ntext with lower perplexity, (2) show skewed and biased distributions of\\nratings, and (3) experience anchoring effects for multi-attribute judgments.', 'We\\nalso found that LLMs are inconsistent evaluators, showing low \"inter-sample\"\\nagreement and sensitivity to prompt differences that are insignificant to human\\nunderstanding of text quality.', 'Furthermore, we share recipes for configuring\\nLLM evaluators to mitigate these limitations.', 'Experimental results on the RoSE\\ndataset demonstrate improvements over the state-of-the-art LLM evaluators.']\n",
            "Chunks for abstract: The added mass effect is the contribution to a Brownian particle's effective\n",
            "mass arising from the hydrodynamic flow its motion induces. For a spherical\n",
            "particle in an incompressible fluid, the added mass is half the fluid's\n",
            "displaced mass, but in a compressible fluid its value depends on a competition\n",
            "between timescales. Here we illustrate this behavior with a solvable model of\n",
            "two harmonically coupled Brownian particles of mass $m$, one representing the\n",
            "sphere, the other the immediately surrounding fluid. The measured distribution\n",
            "of the Brownian particle's velocity, $P(\\bar{v})$, follows a Maxwell-Boltzmann\n",
            "distribution with an effective mass $m^*$. Solving analytically for $m^*$, we\n",
            "find that its value is determined by three relevant timescales: the momentum\n",
            "relaxation time, $t_p$, the harmonic oscillation period, $\\tau$, and the\n",
            "velocity measurement time resolution, $\\Delta t$. In limiting cases $\\Delta t\n",
            "\\ll \\tau,t_p$ and $\\tau\\ll\\Delta t\\ll t_p$, our expression for $m^*$ reduces to\n",
            "$m$ and $2m$, respectively. We find similar behavior upon generalizing the\n",
            "model to the case of unequal masses.\n",
            "[\"The added mass effect is the contribution to a Brownian particle's effective\\nmass arising from the hydrodynamic flow its motion induces.\", \"For a spherical\\nparticle in an incompressible fluid, the added mass is half the fluid's\\ndisplaced mass, but in a compressible fluid its value depends on a competition\\nbetween timescales.\", 'Here we illustrate this behavior with a solvable model of\\ntwo harmonically coupled Brownian particles of mass $m$, one representing the\\nsphere, the other the immediately surrounding fluid.', \"The measured distribution\\nof the Brownian particle's velocity, $P(\\\\bar{v})$, follows a Maxwell-Boltzmann\\ndistribution with an effective mass $m^*$.\", 'Solving analytically for $m^*$, we\\nfind that its value is determined by three relevant timescales: the momentum\\nrelaxation time, $t_p$, the harmonic oscillation period, $\\\\tau$, and the\\nvelocity measurement time resolution, $\\\\Delta t$.', 'In limiting cases $\\\\Delta t\\n\\\\ll \\\\tau,t_p$ and $\\\\tau\\\\ll\\\\Delta t\\\\ll t_p$, our expression for $m^*$ reduces to\\n$m$ and $2m$, respectively.', 'We find similar behavior upon generalizing the\\nmodel to the case of unequal masses.']\n",
            "Chunks for abstract: Out-of-distribution (OOD) detection is essential in autonomous driving, to\n",
            "determine when learning-based components encounter unexpected inputs.\n",
            "Traditional detectors typically use encoder models with fixed settings, thus\n",
            "lacking effective human interaction capabilities. With the rise of large\n",
            "foundation models, multimodal inputs offer the possibility of taking human\n",
            "language as a latent representation, thus enabling language-defined OOD\n",
            "detection. In this paper, we use the cosine similarity of image and text\n",
            "representations encoded by the multimodal model CLIP as a new representation to\n",
            "improve the transparency and controllability of latent encodings used for\n",
            "visual anomaly detection. We compare our approach with existing pre-trained\n",
            "encoders that can only produce latent representations that are meaningless from\n",
            "the user's standpoint. Our experiments on realistic driving data show that the\n",
            "language-based latent representation performs better than the traditional\n",
            "representation of the vision encoder and helps improve the detection\n",
            "performance when combined with standard representations.\n",
            "['Out-of-distribution (OOD) detection is essential in autonomous driving, to\\ndetermine when learning-based components encounter unexpected inputs.', 'Traditional detectors typically use encoder models with fixed settings, thus\\nlacking effective human interaction capabilities.', 'With the rise of large\\nfoundation models, multimodal inputs offer the possibility of taking human\\nlanguage as a latent representation, thus enabling language-defined OOD\\ndetection.', 'In this paper, we use the cosine similarity of image and text\\nrepresentations encoded by the multimodal model CLIP as a new representation to\\nimprove the transparency and controllability of latent encodings used for\\nvisual anomaly detection.', \"We compare our approach with existing pre-trained\\nencoders that can only produce latent representations that are meaningless from\\nthe user's standpoint.\", 'Our experiments on realistic driving data show that the\\nlanguage-based latent representation performs better than the traditional\\nrepresentation of the vision encoder and helps improve the detection\\nperformance when combined with standard representations.']\n",
            "Chunks for abstract: This study aims to introduce and address the problem of traffic load\n",
            "estimation in the cell switching concept within the evolving landscape of\n",
            "vertical heterogeneous networks (vHetNets). The problem is that the practice of\n",
            "cell switching faces a significant challenge due to the lack of accurate data\n",
            "on the traffic load of sleeping small base stations (SBSs). This problem makes\n",
            "the majority of the studies in the literature, particularly those employing\n",
            "load-dependent approaches, impractical due to their basic assumption of perfect\n",
            "knowledge of the traffic loads of sleeping SBSs for the next time slot. Rather\n",
            "than developing another advanced cell switching algorithm, this study\n",
            "investigates the impacts of estimation errors and explores possible solutions\n",
            "through established methodologies in a novel vHetNet environment that includes\n",
            "the integration of a high altitude platform (HAPS) as a super macro base\n",
            "station (SMBS) into the terrestrial network. In other words, this study adopts\n",
            "a more foundational perspective, focusing on eliminating a significant obstacle\n",
            "for the application of advanced cell switching algorithms. To this end, we\n",
            "explore the potential of three distinct spatial interpolation-based estimation\n",
            "schemes: random neighboring selection, distance-based selection, and\n",
            "clustering-based selection. Utilizing a real dataset for empirical validations,\n",
            "we evaluate the efficacy of our proposed traffic load estimation schemes. Our\n",
            "results demonstrate that the multi-level clustering (MLC) algorithm performs\n",
            "exceptionally well, with an insignificant difference (i.e., 0.8%) observed\n",
            "between its estimated and actual network power consumption, highlighting its\n",
            "potential to significantly improve energy efficiency in vHetNets.\n",
            "['This study aims to introduce and address the problem of traffic load\\nestimation in the cell switching concept within the evolving landscape of\\nvertical heterogeneous networks (vHetNets).', 'The problem is that the practice of\\ncell switching faces a significant challenge due to the lack of accurate data\\non the traffic load of sleeping small base stations (SBSs).', 'This problem makes\\nthe majority of the studies in the literature, particularly those employing\\nload-dependent approaches, impractical due to their basic assumption of perfect\\nknowledge of the traffic loads of sleeping SBSs for the next time slot.', 'Rather\\nthan developing another advanced cell switching algorithm, this study\\ninvestigates the impacts of estimation errors and explores possible solutions\\nthrough established methodologies in a novel vHetNet environment that includes\\nthe integration of a high altitude platform (HAPS) as a super macro base\\nstation (SMBS) into the terrestrial network.', 'In other words, this study adopts\\na more foundational perspective, focusing on eliminating a significant obstacle\\nfor the application of advanced cell switching algorithms.', 'To this end, we\\nexplore the potential of three distinct spatial interpolation-based estimation\\nschemes: random neighboring selection, distance-based selection, and\\nclustering-based selection.', 'Utilizing a real dataset for empirical validations,\\nwe evaluate the efficacy of our proposed traffic load estimation schemes.', 'Our\\nresults demonstrate that the multi-level clustering (MLC) algorithm performs\\nexceptionally well, with an insignificant difference (i.e., 0.8%) observed\\nbetween its estimated and actual network power consumption, highlighting its\\npotential to significantly improve energy efficiency in vHetNets.']\n",
            "Chunks for abstract: Meta-analyses statistically aggregate the findings of different randomized\n",
            "controlled trials (RCTs) to assess treatment effectiveness. Because this yields\n",
            "robust estimates of treatment effectiveness, results from meta-analyses are\n",
            "considered the strongest form of evidence. However, rigorous evidence syntheses\n",
            "are time-consuming and labor-intensive, requiring manual extraction of data\n",
            "from individual trials to be synthesized. Ideally, language technologies would\n",
            "permit fully automatic meta-analysis, on demand. This requires accurately\n",
            "extracting numerical results from individual trials, which has been beyond the\n",
            "capabilities of natural language processing (NLP) models to date. In this work,\n",
            "we evaluate whether modern large language models (LLMs) can reliably perform\n",
            "this task. We annotate (and release) a modest but granular evaluation dataset\n",
            "of clinical trial reports with numerical findings attached to interventions,\n",
            "comparators, and outcomes. Using this dataset, we evaluate the performance of\n",
            "seven LLMs applied zero-shot for the task of conditionally extracting numerical\n",
            "findings from trial reports. We find that massive LLMs that can accommodate\n",
            "lengthy inputs are tantalizingly close to realizing fully automatic\n",
            "meta-analysis, especially for dichotomous (binary) outcomes (e.g., mortality).\n",
            "However, LLMs -- including ones trained on biomedical texts -- perform poorly\n",
            "when the outcome measures are complex and tallying the results requires\n",
            "inference. This work charts a path toward fully automatic meta-analysis of RCTs\n",
            "via LLMs, while also highlighting the limitations of existing models for this\n",
            "aim.\n",
            "['Meta-analyses statistically aggregate the findings of different randomized\\ncontrolled trials (RCTs) to assess treatment effectiveness.', 'Because this yields\\nrobust estimates of treatment effectiveness, results from meta-analyses are\\nconsidered the strongest form of evidence.', 'However, rigorous evidence syntheses\\nare time-consuming and labor-intensive, requiring manual extraction of data\\nfrom individual trials to be synthesized.', 'Ideally, language technologies would\\npermit fully automatic meta-analysis, on demand.', 'This requires accurately\\nextracting numerical results from individual trials, which has been beyond the\\ncapabilities of natural language processing (NLP) models to date.', 'In this work,\\nwe evaluate whether modern large language models (LLMs) can reliably perform\\nthis task.', 'We annotate (and release) a modest but granular evaluation dataset\\nof clinical trial reports with numerical findings attached to interventions,\\ncomparators, and outcomes.', 'Using this dataset, we evaluate the performance of\\nseven LLMs applied zero-shot for the task of conditionally extracting numerical\\nfindings from trial reports.', 'We find that massive LLMs that can accommodate\\nlengthy inputs are tantalizingly close to realizing fully automatic\\nmeta-analysis, especially for dichotomous (binary) outcomes (e.g., mortality).', 'However, LLMs -- including ones trained on biomedical texts -- perform poorly\\nwhen the outcome measures are complex and tallying the results requires\\ninference.', 'This work charts a path toward fully automatic meta-analysis of RCTs\\nvia LLMs, while also highlighting the limitations of existing models for this\\naim.']\n",
            "Chunks for abstract: The Gapeev-Shiryaev conjecture (originating in Gapeev and Shiryaev (2011) and\n",
            "Gapeev and Shiryaev (2013)) can be broadly stated as follows: Monotonicity of\n",
            "the signal-to-noise ratio implies monotonicity of the optimal stopping\n",
            "boundaries. The conjecture was originally formulated both within (i) sequential\n",
            "testing problems for diffusion processes (where one needs to decide which of\n",
            "the two drifts is being indirectly observed) and (ii) quickest detection\n",
            "problems for diffusion processes (where one needs to detect when the initial\n",
            "drift changes to a new drift). In this paper we present proofs of the\n",
            "Gapeev-Shiryaev conjecture both in (i) the sequential testing setting (under\n",
            "Lipschitz/Holder coefficients of the underlying SDEs) and (ii) the quickest\n",
            "detection setting (under analytic coefficients of the underlying SDEs). The\n",
            "method of proof in the sequential testing setting relies upon a stochastic time\n",
            "change and pathwise comparison arguments. Both arguments break down in the\n",
            "quickest detection setting and get replaced by arguments arising from a\n",
            "stochastic maximum principle for hypoelliptic equations (satisfying Hormander's\n",
            "condition) that is of independent interest. Verification of the Gapeev-Shiryaev\n",
            "conjecture establishes the fact that sequential testing and quickest detection\n",
            "problems with monotone signal-to-noise ratios are amenable to known methods of\n",
            "solution.\n",
            "['The Gapeev-Shiryaev conjecture (originating in Gapeev and Shiryaev (2011) and\\nGapeev and Shiryaev (2013)) can be broadly stated as follows: Monotonicity of\\nthe signal-to-noise ratio implies monotonicity of the optimal stopping\\nboundaries.', 'The conjecture was originally formulated both within (i) sequential\\ntesting problems for diffusion processes (where one needs to decide which of\\nthe two drifts is being indirectly observed) and (ii) quickest detection\\nproblems for diffusion processes (where one needs to detect when the initial\\ndrift changes to a new drift).', 'In this paper we present proofs of the\\nGapeev-Shiryaev conjecture both in (i) the sequential testing setting (under\\nLipschitz/Holder coefficients of the underlying SDEs) and (ii) the quickest\\ndetection setting (under analytic coefficients of the underlying SDEs).', 'The\\nmethod of proof in the sequential testing setting relies upon a stochastic time\\nchange and pathwise comparison arguments.', \"Both arguments break down in the\\nquickest detection setting and get replaced by arguments arising from a\\nstochastic maximum principle for hypoelliptic equations (satisfying Hormander's\\ncondition) that is of independent interest.\", 'Verification of the Gapeev-Shiryaev\\nconjecture establishes the fact that sequential testing and quickest detection\\nproblems with monotone signal-to-noise ratios are amenable to known methods of\\nsolution.']\n",
            "Chunks for abstract: Automatic conversion of free-text radiology reports into structured data\n",
            "using Natural Language Processing (NLP) techniques is crucial for analyzing\n",
            "diseases on a large scale. While effective for tasks in widely spoken languages\n",
            "like English, generative large language models (LLMs) typically underperform\n",
            "with less common languages and can pose potential risks to patient privacy.\n",
            "Fine-tuning local NLP models is hindered by the skewed nature of real-world\n",
            "medical datasets, where rare findings represent a significant data imbalance.\n",
            "We introduce SMP-BERT, a novel prompt learning method that leverages the\n",
            "structured nature of reports to overcome these challenges. In our studies\n",
            "involving a substantial collection of Crohn's disease radiology reports in\n",
            "Hebrew (over 8,000 patients and 10,000 reports), SMP-BERT greatly surpassed\n",
            "traditional fine-tuning methods in performance, notably in detecting infrequent\n",
            "conditions (AUC: 0.99 vs 0.94, F1: 0.84 vs 0.34). SMP-BERT empowers more\n",
            "accurate AI diagnostics available for low-resource languages.\n",
            "['Automatic conversion of free-text radiology reports into structured data\\nusing Natural Language Processing (NLP) techniques is crucial for analyzing\\ndiseases on a large scale.', 'While effective for tasks in widely spoken languages\\nlike English, generative large language models (LLMs) typically underperform\\nwith less common languages and can pose potential risks to patient privacy.', 'Fine-tuning local NLP models is hindered by the skewed nature of real-world\\nmedical datasets, where rare findings represent a significant data imbalance.', 'We introduce SMP-BERT, a novel prompt learning method that leverages the\\nstructured nature of reports to overcome these challenges.', \"In our studies\\ninvolving a substantial collection of Crohn's disease radiology reports in\\nHebrew (over 8,000 patients and 10,000 reports), SMP-BERT greatly surpassed\\ntraditional fine-tuning methods in performance, notably in detecting infrequent\\nconditions (AUC: 0.99 vs 0.94, F1: 0.84 vs 0.34).\", 'SMP-BERT empowers more\\naccurate AI diagnostics available for low-resource languages.']\n",
            "Chunks for abstract: The study of privacy-preserving Natural Language Processing (NLP) has gained\n",
            "rising attention in recent years. One promising avenue studies the integration\n",
            "of Differential Privacy in NLP, which has brought about innovative methods in a\n",
            "variety of application settings. Of particular note are $\\textit{word-level\n",
            "Metric Local Differential Privacy (MLDP)}$ mechanisms, which work to obfuscate\n",
            "potentially sensitive input text by performing word-by-word\n",
            "$\\textit{perturbations}$. Although these methods have shown promising results\n",
            "in empirical tests, there are two major drawbacks: (1) the inevitable loss of\n",
            "utility due to addition of noise, and (2) the computational expensiveness of\n",
            "running these mechanisms on high-dimensional word embeddings. In this work, we\n",
            "aim to address these challenges by proposing $\\texttt{1-Diffractor}$, a new\n",
            "mechanism that boasts high speedups in comparison to previous mechanisms, while\n",
            "still demonstrating strong utility- and privacy-preserving capabilities. We\n",
            "evaluate $\\texttt{1-Diffractor}$ for utility on several NLP tasks, for\n",
            "theoretical and task-based privacy, and for efficiency in terms of speed and\n",
            "memory. $\\texttt{1-Diffractor}$ shows significant improvements in efficiency,\n",
            "while still maintaining competitive utility and privacy scores across all\n",
            "conducted comparative tests against previous MLDP mechanisms. Our code is made\n",
            "available at: https://github.com/sjmeis/Diffractor.\n",
            "['The study of privacy-preserving Natural Language Processing (NLP) has gained\\nrising attention in recent years.', 'One promising avenue studies the integration\\nof Differential Privacy in NLP, which has brought about innovative methods in a\\nvariety of application settings.', 'Of particular note are $\\\\textit{word-level\\nMetric Local Differential Privacy (MLDP)}$ mechanisms, which work to obfuscate\\npotentially sensitive input text by performing word-by-word\\n$\\\\textit{perturbations}$.', 'Although these methods have shown promising results\\nin empirical tests, there are two major drawbacks: (1) the inevitable loss of\\nutility due to addition of noise, and (2) the computational expensiveness of\\nrunning these mechanisms on high-dimensional word embeddings.', 'In this work, we\\naim to address these challenges by proposing $\\\\texttt{1-Diffractor}$, a new\\nmechanism that boasts high speedups in comparison to previous mechanisms, while\\nstill demonstrating strong utility- and privacy-preserving capabilities.', 'We\\nevaluate $\\\\texttt{1-Diffractor}$ for utility on several NLP tasks, for\\ntheoretical and task-based privacy, and for efficiency in terms of speed and\\nmemory.', '$\\\\texttt{1-Diffractor}$ shows significant improvements in efficiency,\\nwhile still maintaining competitive utility and privacy scores across all\\nconducted comparative tests against previous MLDP mechanisms.', 'Our code is made\\navailable at: https://github.com/sjmeis/Diffractor.']\n",
            "Chunks for abstract: Solar radiation pressure can have a substantial long-term effect on the\n",
            "orbits of high area-to-mass ratio spacecraft, such as solar sails. We present a\n",
            "study of the coupling between radiation pressure and the gravitational\n",
            "perturbation due to polar flattening. Removing the short-period terms via\n",
            "perturbation theory yields a time-dependent two-degree-of-freedom Hamiltonian,\n",
            "depending on one physical and one dynamical parameter. While the reduced model\n",
            "is non-integrable in general, assuming coplanar orbits (i.e., both Spacecraft\n",
            "and Sun on the equator) results in an integrable invariant manifold. We discuss\n",
            "the qualitative features of the coplanar dynamics, and find three regions of\n",
            "the parameters space characterized by different regimes of the reduced flow.\n",
            "For each regime, we identify the fixed points and their character. The fixed\n",
            "points represent frozen orbits, configurations for which the long-term\n",
            "perturbations cancel out to the order of the theory. They are advantageous from\n",
            "the point of view of station keeping, allowing the orbit to be maintained with\n",
            "minimal propellant consumption. We complement existing studies of the coplanar\n",
            "dynamics with a more rigorous treatment, deriving the generating function of\n",
            "the canonical transformation that underpins the use of averaged equations.\n",
            "Furthermore, we obtain an analytical expression for the bifurcation lines that\n",
            "separate the regions with different qualitative flow.\n",
            "['Solar radiation pressure can have a substantial long-term effect on the\\norbits of high area-to-mass ratio spacecraft, such as solar sails.', 'We present a\\nstudy of the coupling between radiation pressure and the gravitational\\nperturbation due to polar flattening.', 'Removing the short-period terms via\\nperturbation theory yields a time-dependent two-degree-of-freedom Hamiltonian,\\ndepending on one physical and one dynamical parameter.', 'While the reduced model\\nis non-integrable in general, assuming coplanar orbits (i.e., both Spacecraft\\nand Sun on the equator) results in an integrable invariant manifold.', 'We discuss\\nthe qualitative features of the coplanar dynamics, and find three regions of\\nthe parameters space characterized by different regimes of the reduced flow.', 'For each regime, we identify the fixed points and their character.', 'The fixed\\npoints represent frozen orbits, configurations for which the long-term\\nperturbations cancel out to the order of the theory.', 'They are advantageous from\\nthe point of view of station keeping, allowing the orbit to be maintained with\\nminimal propellant consumption.', 'We complement existing studies of the coplanar\\ndynamics with a more rigorous treatment, deriving the generating function of\\nthe canonical transformation that underpins the use of averaged equations.', 'Furthermore, we obtain an analytical expression for the bifurcation lines that\\nseparate the regions with different qualitative flow.']\n",
            "Chunks for abstract: This paper investigates a broad class of non-Gaussian measures, $ \\mu_\\Psi$,\n",
            "associated with a family of generalized Wright functions, $_m\\Psi_q$. First, we\n",
            "study these measures in Euclidean spaces $\\mathbb{R}^d$, then define them in an\n",
            "abstract nuclear triple $\\mathcal{N}\\subset\\mathcal{H}\\subset\\mathcal{N}'$. We\n",
            "study analyticity, invariance properties, and ergodicity under a particular\n",
            "group of automorphisms. Then we show the existence of an Appell system which\n",
            "allows the extension of the non-Gaussian Hilbert space $L^2(\\mu_\\Psi)$ to the\n",
            "nuclear triple consisting of test functions' and distributions' spaces,\n",
            "$(\\mathcal{N})^{1}\\subset L^2(\\mu_\\Psi)\\subset(\\mathcal{N})_{\\mu_\\Psi}^{-1}$.\n",
            "Thanks to this triple, we can study Donsker's delta as a well-defined object in\n",
            "the space of distributions $(\\mathcal{N})_{\\mu_\\Psi}^{-1}$.\n",
            "['This paper investigates a broad class of non-Gaussian measures, $ \\\\mu_\\\\Psi$,\\nassociated with a family of generalized Wright functions, $_m\\\\Psi_q$.', \"First, we\\nstudy these measures in Euclidean spaces $\\\\mathbb{R}^d$, then define them in an\\nabstract nuclear triple $\\\\mathcal{N}\\\\subset\\\\mathcal{H}\\\\subset\\\\mathcal{N}'$.\", 'We\\nstudy analyticity, invariance properties, and ergodicity under a particular\\ngroup of automorphisms.', \"Then we show the existence of an Appell system which\\nallows the extension of the non-Gaussian Hilbert space $L^2(\\\\mu_\\\\Psi)$ to the\\nnuclear triple consisting of test functions' and distributions' spaces,\\n$(\\\\mathcal{N})^{1}\\\\subset L^2(\\\\mu_\\\\Psi)\\\\subset(\\\\mathcal{N})_{\\\\mu_\\\\Psi}^{-1}$.\", \"Thanks to this triple, we can study Donsker's delta as a well-defined object in\\nthe space of distributions $(\\\\mathcal{N})_{\\\\mu_\\\\Psi}^{-1}$.\"]\n",
            "Chunks for abstract: Recent Large Language Models (LLMs) have shown the ability to generate\n",
            "content that is difficult or impossible to distinguish from human writing. We\n",
            "investigate the ability of differently-sized LLMs to replicate human writing\n",
            "style in short, creative texts in the domain of Showerthoughts, thoughts that\n",
            "may occur during mundane activities. We compare GPT-2 and GPT-Neo fine-tuned on\n",
            "Reddit data as well as GPT-3.5 invoked in a zero-shot manner, against\n",
            "human-authored texts. We measure human preference on the texts across the\n",
            "specific dimensions that account for the quality of creative, witty texts.\n",
            "Additionally, we compare the ability of humans versus fine-tuned RoBERTa\n",
            "classifiers to detect AI-generated texts. We conclude that human evaluators\n",
            "rate the generated texts slightly worse on average regarding their creative\n",
            "quality, but they are unable to reliably distinguish between human-written and\n",
            "AI-generated texts. We further provide a dataset for creative, witty text\n",
            "generation based on Reddit Showerthoughts posts.\n",
            "['Recent Large Language Models (LLMs) have shown the ability to generate\\ncontent that is difficult or impossible to distinguish from human writing.', 'We\\ninvestigate the ability of differently-sized LLMs to replicate human writing\\nstyle in short, creative texts in the domain of Showerthoughts, thoughts that\\nmay occur during mundane activities.', 'We compare GPT-2 and GPT-Neo fine-tuned on\\nReddit data as well as GPT-3.5 invoked in a zero-shot manner, against\\nhuman-authored texts.', 'We measure human preference on the texts across the\\nspecific dimensions that account for the quality of creative, witty texts.', 'Additionally, we compare the ability of humans versus fine-tuned RoBERTa\\nclassifiers to detect AI-generated texts.', 'We conclude that human evaluators\\nrate the generated texts slightly worse on average regarding their creative\\nquality, but they are unable to reliably distinguish between human-written and\\nAI-generated texts.', 'We further provide a dataset for creative, witty text\\ngeneration based on Reddit Showerthoughts posts.']\n",
            "Chunks for abstract: Answering complex logical queries over incomplete knowledge graphs (KGs) is\n",
            "challenging. Most previous works have focused on learning entity/relation\n",
            "embeddings and simulating first-order logic operators with various neural\n",
            "networks. However, they are bottlenecked by the inability to share world\n",
            "knowledge to improve logical reasoning, thus resulting in suboptimal\n",
            "performance. In this paper, we propose a complex logical reasoning schema over\n",
            "knowledge graphs upon large language models (LLMs), containing a\n",
            "curriculum-based logical-aware instruction tuning framework, named LACT.\n",
            "Specifically, we augment the arbitrary first-order logical queries via binary\n",
            "tree decomposition, to stimulate the reasoning capability of LLMs. To address\n",
            "the difficulty gap among different types of complex queries, we design a simple\n",
            "and flexible logic-aware curriculum learning framework. Experiments across\n",
            "widely used datasets demonstrate that LACT has substantial improvements~(brings\n",
            "an average +5.5% MRR score) over advanced methods, achieving the new\n",
            "state-of-the-art. Our code and model will be released at GitHub and huggingface\n",
            "soon.\n",
            "['Answering complex logical queries over incomplete knowledge graphs (KGs) is\\nchallenging.', 'Most previous works have focused on learning entity/relation\\nembeddings and simulating first-order logic operators with various neural\\nnetworks.', 'However, they are bottlenecked by the inability to share world\\nknowledge to improve logical reasoning, thus resulting in suboptimal\\nperformance.', 'In this paper, we propose a complex logical reasoning schema over\\nknowledge graphs upon large language models (LLMs), containing a\\ncurriculum-based logical-aware instruction tuning framework, named LACT.', 'Specifically, we augment the arbitrary first-order logical queries via binary\\ntree decomposition, to stimulate the reasoning capability of LLMs.', 'To address\\nthe difficulty gap among different types of complex queries, we design a simple\\nand flexible logic-aware curriculum learning framework.', 'Experiments across\\nwidely used datasets demonstrate that LACT has substantial improvements~(brings\\nan average +5.5% MRR score) over advanced methods, achieving the new\\nstate-of-the-art.', 'Our code and model will be released at GitHub and huggingface\\nsoon.']\n",
            "Chunks for abstract: In this work, we address the impact of a small lepton number violation on\n",
            "charged lepton electric dipole moments - EDMs. Low-scale seesaw models\n",
            "protected by lepton number symmetry and leading to pseudo-Dirac pairs in the\n",
            "neutrino heavy spectrum provide a natural explanation for the smallness of\n",
            "neutrino masses with potentially testable consequences. Among which, it was\n",
            "thought that the small mass gap in each pair of pseudo-Dirac neutrinos may\n",
            "induce important contribution to the charged lepton EDMs. Recently, it has been\n",
            "shown that the contribution from some of the Feynman diagrams to charged lepton\n",
            "EDMs exactly cancel by virtue of the Ward-Takahashi identity in quantum\n",
            "electrodynamics. We thus consider here the Standard Model minimally extended\n",
            "with pairs of pseudo-Dirac sterile fermions and derive the complete analytical\n",
            "formula at two loops for the charged lepton EDMs. In addition, we numerically\n",
            "evaluate the order of the predicted EDMs consistent with the experimental\n",
            "bounds and constraints such as neutrino oscillation data, charged lepton\n",
            "flavour violating processes, sterile neutrino direct searches, meson decays,\n",
            "sterile neutrino decays, and cosmological and astrophysical observations. We\n",
            "find that, in the minimal setup accommodating neutrino data (masses and\n",
            "mixings) with only two pseudo-Dirac pairs, the predicted electron EDM is\n",
            "$\\mathcal{O}(10^{-36})~e\\hspace{0.05cm}\\mathrm{cm}$, at most, which is much\n",
            "smaller than the current experimental bound and even future sensitivity.\n",
            "Hopefully, the electron EDM might reach future sensitivity, once extra\n",
            "pseudo-Dirac neutrinos are taken into account. The analytical formulae we\n",
            "derive are generic to any model involving pseudo-Dirac pairs in the heavy\n",
            "neutrino spectrum.\n",
            "['In this work, we address the impact of a small lepton number violation on\\ncharged lepton electric dipole moments - EDMs.', 'Low-scale seesaw models\\nprotected by lepton number symmetry and leading to pseudo-Dirac pairs in the\\nneutrino heavy spectrum provide a natural explanation for the smallness of\\nneutrino masses with potentially testable consequences.', 'Among which, it was\\nthought that the small mass gap in each pair of pseudo-Dirac neutrinos may\\ninduce important contribution to the charged lepton EDMs.', 'Recently, it has been\\nshown that the contribution from some of the Feynman diagrams to charged lepton\\nEDMs exactly cancel by virtue of the Ward-Takahashi identity in quantum\\nelectrodynamics.', 'We thus consider here the Standard Model minimally extended\\nwith pairs of pseudo-Dirac sterile fermions and derive the complete analytical\\nformula at two loops for the charged lepton EDMs.', 'In addition, we numerically\\nevaluate the order of the predicted EDMs consistent with the experimental\\nbounds and constraints such as neutrino oscillation data, charged lepton\\nflavour violating processes, sterile neutrino direct searches, meson decays,\\nsterile neutrino decays, and cosmological and astrophysical observations.', 'We\\nfind that, in the minimal setup accommodating neutrino data (masses and\\nmixings) with only two pseudo-Dirac pairs, the predicted electron EDM is\\n$\\\\mathcal{O}(10^{-36})~e\\\\hspace{0.05cm}\\\\mathrm{cm}$, at most, which is much\\nsmaller than the current experimental bound and even future sensitivity.', 'Hopefully, the electron EDM might reach future sensitivity, once extra\\npseudo-Dirac neutrinos are taken into account.', 'The analytical formulae we\\nderive are generic to any model involving pseudo-Dirac pairs in the heavy\\nneutrino spectrum.']\n",
            "Chunks for abstract: Large N quasi-fermionic Chern-Simons-matter theories have an approximate\n",
            "higher-spin symmetry that strongly constrains their correlation functions. In\n",
            "particular, the 3-point functions for generic spins are combinations of 3\n",
            "structures (with specific dependence on the positions and helicities), and the\n",
            "coupling-dependence of the coefficient of each structure is uniquely\n",
            "determined. In the past few years, several relations between different\n",
            "structures were found. In this paper we show that all the relations between the\n",
            "structures follow from (or, conversely, they imply) a specific form written by\n",
            "Skvortsov for the vertices of the dual higher-spin gravity theory on\n",
            "four-dimensional anti-de Sitter space, when written in spinor-helicity\n",
            "variables. The dual bulk theory has a specific limit where it simplifies and\n",
            "becomes a \"chiral higher-spin gravity theory\", and we discuss what can be said\n",
            "about this limit in the dual Chern-Simons-matter theories, where it involves an\n",
            "analytic continuation to complex couplings.\n",
            "['Large N quasi-fermionic Chern-Simons-matter theories have an approximate\\nhigher-spin symmetry that strongly constrains their correlation functions.', 'In\\nparticular, the 3-point functions for generic spins are combinations of 3\\nstructures (with specific dependence on the positions and helicities), and the\\ncoupling-dependence of the coefficient of each structure is uniquely\\ndetermined.', 'In the past few years, several relations between different\\nstructures were found.', 'In this paper we show that all the relations between the\\nstructures follow from (or, conversely, they imply) a specific form written by\\nSkvortsov for the vertices of the dual higher-spin gravity theory on\\nfour-dimensional anti-de Sitter space, when written in spinor-helicity\\nvariables.', 'The dual bulk theory has a specific limit where it simplifies and\\nbecomes a \"chiral higher-spin gravity theory\", and we discuss what can be said\\nabout this limit in the dual Chern-Simons-matter theories, where it involves an\\nanalytic continuation to complex couplings.']\n",
            "Chunks for abstract: The critical point of a topological phase transition is described by a\n",
            "conformal field theory (CFT), where the finite-size corrections to the ground\n",
            "state energy are uniquely related to its central charge. We study the\n",
            "finite-size scaling of the energy of non-Hermitian Su-Schrieffer-Heeger (SSH)\n",
            "model with parity and time-reversal symmetry ($\\mathcal{PT}$) symmetry. We find\n",
            "that under open boundary condition (OBC), the energy scaling $E(L)\\sim c/L$\n",
            "reveals a negative central charge $c=-2$ at the non-Hermitian critical point,\n",
            "indicative of a non-unitary CFT. Furthermore, we discover a universal scaling\n",
            "function capturing the flow of a system from Dirac CFT with $c=1$ to a\n",
            "non-unitary CFT with $c=-2$. The scaling function demonstrates distinct\n",
            "behaviors at topologically non-trivial and trivial sides of critical points.\n",
            "Notably, within the realm of topological criticality, the scaling function\n",
            "exhibits an universal rise-dip-rise pattern, manifesting a characteristic\n",
            "singularity inherent in the non-Hermitian topological critical points. The\n",
            "analytic expression of the scaling function has been derived and is in good\n",
            "agreement with the numerical results.\n",
            "['The critical point of a topological phase transition is described by a\\nconformal field theory (CFT), where the finite-size corrections to the ground\\nstate energy are uniquely related to its central charge.', 'We study the\\nfinite-size scaling of the energy of non-Hermitian Su-Schrieffer-Heeger (SSH)\\nmodel with parity and time-reversal symmetry ($\\\\mathcal{PT}$) symmetry.', 'We find\\nthat under open boundary condition (OBC), the energy scaling $E(L)\\\\sim c/L$\\nreveals a negative central charge $c=-2$ at the non-Hermitian critical point,\\nindicative of a non-unitary CFT.', 'Furthermore, we discover a universal scaling\\nfunction capturing the flow of a system from Dirac CFT with $c=1$ to a\\nnon-unitary CFT with $c=-2$.', 'The scaling function demonstrates distinct\\nbehaviors at topologically non-trivial and trivial sides of critical points.', 'Notably, within the realm of topological criticality, the scaling function\\nexhibits an universal rise-dip-rise pattern, manifesting a characteristic\\nsingularity inherent in the non-Hermitian topological critical points.', 'The\\nanalytic expression of the scaling function has been derived and is in good\\nagreement with the numerical results.']\n",
            "Chunks for abstract: We observe an inverse turbulent-wave cascade, from small to large\n",
            "lengthscales, in a homogeneous 2D Bose gas driven isotropically on a\n",
            "lengthscale much smaller than its size. Starting with an equilibrium condensed\n",
            "gas, at long drive times we observe a nonthermal steady state. At increasing\n",
            "lengthscales, starting from the forcing one, the steady-state momentum\n",
            "distribution features in turn: (i) a power-law spectrum, with an exponent close\n",
            "to the analytical result for a particle cascade in weak-wave turbulence, and\n",
            "(ii) a spectrum intriguingly reminiscent of a nonthermal fixed point associated\n",
            "with universal coarsening in an isolated 2D gas. In further experiments, based\n",
            "on anisotropic driving, we also reveal the qualitative picture of the\n",
            "cascade-formation dynamics.\n",
            "['We observe an inverse turbulent-wave cascade, from small to large\\nlengthscales, in a homogeneous 2D Bose gas driven isotropically on a\\nlengthscale much smaller than its size.', 'Starting with an equilibrium condensed\\ngas, at long drive times we observe a nonthermal steady state.', 'At increasing\\nlengthscales, starting from the forcing one, the steady-state momentum\\ndistribution features in turn: (i) a power-law spectrum, with an exponent close\\nto the analytical result for a particle cascade in weak-wave turbulence, and\\n(ii) a spectrum intriguingly reminiscent of a nonthermal fixed point associated\\nwith universal coarsening in an isolated 2D gas.', 'In further experiments, based\\non anisotropic driving, we also reveal the qualitative picture of the\\ncascade-formation dynamics.']\n",
            "Chunks for abstract: Art reinterpretation is the practice of creating a variation of a reference\n",
            "work, making a paired artwork that exhibits a distinct artistic style. We ask\n",
            "if such an image pair can be used to customize a generative model to capture\n",
            "the demonstrated stylistic difference. We propose Pair Customization, a new\n",
            "customization method that learns stylistic difference from a single image pair\n",
            "and then applies the acquired style to the generation process. Unlike existing\n",
            "methods that learn to mimic a single concept from a collection of images, our\n",
            "method captures the stylistic difference between paired images. This allows us\n",
            "to apply a stylistic change without overfitting to the specific image content\n",
            "in the examples. To address this new task, we employ a joint optimization\n",
            "method that explicitly separates the style and content into distinct LoRA\n",
            "weight spaces. We optimize these style and content weights to reproduce the\n",
            "style and content images while encouraging their orthogonality. During\n",
            "inference, we modify the diffusion process via a new style guidance based on\n",
            "our learned weights. Both qualitative and quantitative experiments show that\n",
            "our method can effectively learn style while avoiding overfitting to image\n",
            "content, highlighting the potential of modeling such stylistic differences from\n",
            "a single image pair.\n",
            "['Art reinterpretation is the practice of creating a variation of a reference\\nwork, making a paired artwork that exhibits a distinct artistic style.', 'We ask\\nif such an image pair can be used to customize a generative model to capture\\nthe demonstrated stylistic difference.', 'We propose Pair Customization, a new\\ncustomization method that learns stylistic difference from a single image pair\\nand then applies the acquired style to the generation process.', 'Unlike existing\\nmethods that learn to mimic a single concept from a collection of images, our\\nmethod captures the stylistic difference between paired images.', 'This allows us\\nto apply a stylistic change without overfitting to the specific image content\\nin the examples.', 'To address this new task, we employ a joint optimization\\nmethod that explicitly separates the style and content into distinct LoRA\\nweight spaces.', 'We optimize these style and content weights to reproduce the\\nstyle and content images while encouraging their orthogonality.', 'During\\ninference, we modify the diffusion process via a new style guidance based on\\nour learned weights.', 'Both qualitative and quantitative experiments show that\\nour method can effectively learn style while avoiding overfitting to image\\ncontent, highlighting the potential of modeling such stylistic differences from\\na single image pair.']\n",
            "Chunks for abstract: Alignment is a standard procedure to fine-tune pre-trained large language\n",
            "models (LLMs) to follow natural language instructions and serve as helpful AI\n",
            "assistants. We have observed, however, that the conventional alignment process\n",
            "fails to enhance the factual accuracy of LLMs, and often leads to the\n",
            "generation of more false facts (i.e. hallucination). In this paper, we study\n",
            "how to make the LLM alignment process more factual, by first identifying\n",
            "factors that lead to hallucination in both alignment steps:\\ supervised\n",
            "fine-tuning (SFT) and reinforcement learning (RL). In particular, we find that\n",
            "training the LLM on new knowledge or unfamiliar texts can encourage\n",
            "hallucination. This makes SFT less factual as it trains on human labeled data\n",
            "that may be novel to the LLM. Furthermore, reward functions used in standard RL\n",
            "can also encourage hallucination, because it guides the LLM to provide more\n",
            "helpful responses on a diverse set of instructions, often preferring longer and\n",
            "more detailed responses. Based on these observations, we propose\n",
            "factuality-aware alignment, comprised of factuality-aware SFT and\n",
            "factuality-aware RL through direct preference optimization. Experiments show\n",
            "that our proposed factuality-aware alignment guides LLMs to output more factual\n",
            "responses while maintaining instruction-following capability.\n",
            "['Alignment is a standard procedure to fine-tune pre-trained large language\\nmodels (LLMs) to follow natural language instructions and serve as helpful AI\\nassistants.', 'We have observed, however, that the conventional alignment process\\nfails to enhance the factual accuracy of LLMs, and often leads to the\\ngeneration of more false facts (i.e.', 'hallucination).', 'In this paper, we study\\nhow to make the LLM alignment process more factual, by first identifying\\nfactors that lead to hallucination in both alignment steps:\\\\ supervised\\nfine-tuning (SFT) and reinforcement learning (RL).', 'In particular, we find that\\ntraining the LLM on new knowledge or unfamiliar texts can encourage\\nhallucination.', 'This makes SFT less factual as it trains on human labeled data\\nthat may be novel to the LLM.', 'Furthermore, reward functions used in standard RL\\ncan also encourage hallucination, because it guides the LLM to provide more\\nhelpful responses on a diverse set of instructions, often preferring longer and\\nmore detailed responses.', 'Based on these observations, we propose\\nfactuality-aware alignment, comprised of factuality-aware SFT and\\nfactuality-aware RL through direct preference optimization.', 'Experiments show\\nthat our proposed factuality-aware alignment guides LLMs to output more factual\\nresponses while maintaining instruction-following capability.']\n",
            "Chunks for abstract: We develop a general theory for multiphoton qubit-resonator interactions\n",
            "enhanced by a qubit drive. The interactions generate qubit-conditional\n",
            "operations in the resonator when the driving is near $n$-photon\n",
            "cross-resonance, namely, the qubit drive is $n$-times the resonator frequency.\n",
            "We pay special attention to the strong driving regime, where the interactions\n",
            "are conditioned on the qubit dressed states. We consider the specific case\n",
            "where $n=2$, which results in qubit-conditional squeezing (QCS). We propose to\n",
            "use the QCS protocol for amplifying resonator displacements and their\n",
            "superpositions. We find the QCS protocol to generate a superposition of\n",
            "orthogonally squeezed states following a properly chosen qubit measurement. We\n",
            "outline quantum information processing applications for these states, including\n",
            "encoding a qubit in a resonator and performing a quantum non-demolition\n",
            "measurement of the qubit inferred from the resonator's second statistical\n",
            "moment. Next, we employ a two-tone drive to engineer an effective $n$-photon\n",
            "Rabi Hamiltonian in any desired coupling regime. In other words, the effective\n",
            "coupling strengths can be tuned over a wide range, thus allowing for the\n",
            "realization of new regimes that have so far been inaccessible. Finally, we\n",
            "propose a multiphoton circuit QED implementation based on a transmon qubit\n",
            "coupled to a resonator via an asymmetric SQUID. We provide realistic parameter\n",
            "estimates for the two-photon operation regime that can host the aforementioned\n",
            "two-photon protocols. We use numerical simulations to show that even in the\n",
            "presence of spurious terms and decoherence, our analytical predictions are\n",
            "robust.\n",
            "['We develop a general theory for multiphoton qubit-resonator interactions\\nenhanced by a qubit drive.', 'The interactions generate qubit-conditional\\noperations in the resonator when the driving is near $n$-photon\\ncross-resonance, namely, the qubit drive is $n$-times the resonator frequency.', 'We pay special attention to the strong driving regime, where the interactions\\nare conditioned on the qubit dressed states.', 'We consider the specific case\\nwhere $n=2$, which results in qubit-conditional squeezing (QCS).', 'We propose to\\nuse the QCS protocol for amplifying resonator displacements and their\\nsuperpositions.', 'We find the QCS protocol to generate a superposition of\\northogonally squeezed states following a properly chosen qubit measurement.', \"We\\noutline quantum information processing applications for these states, including\\nencoding a qubit in a resonator and performing a quantum non-demolition\\nmeasurement of the qubit inferred from the resonator's second statistical\\nmoment.\", 'Next, we employ a two-tone drive to engineer an effective $n$-photon\\nRabi Hamiltonian in any desired coupling regime.', 'In other words, the effective\\ncoupling strengths can be tuned over a wide range, thus allowing for the\\nrealization of new regimes that have so far been inaccessible.', 'Finally, we\\npropose a multiphoton circuit QED implementation based on a transmon qubit\\ncoupled to a resonator via an asymmetric SQUID.', 'We provide realistic parameter\\nestimates for the two-photon operation regime that can host the aforementioned\\ntwo-photon protocols.', 'We use numerical simulations to show that even in the\\npresence of spurious terms and decoherence, our analytical predictions are\\nrobust.']\n",
            "Chunks for abstract: Large-scale Text-to-Image (T2I) diffusion models demonstrate significant\n",
            "generation capabilities based on textual prompts. Based on the T2I diffusion\n",
            "models, text-guided image editing research aims to empower users to manipulate\n",
            "generated images by altering the text prompts. However, existing image editing\n",
            "techniques are prone to editing over unintentional regions that are beyond the\n",
            "intended target area, primarily due to inaccuracies in cross-attention maps. To\n",
            "address this problem, we propose Localization-aware Inversion (LocInv), which\n",
            "exploits segmentation maps or bounding boxes as extra localization priors to\n",
            "refine the cross-attention maps in the denoising phases of the diffusion\n",
            "process. Through the dynamic updating of tokens corresponding to noun words in\n",
            "the textual input, we are compelling the cross-attention maps to closely align\n",
            "with the correct noun and adjective words in the text prompt. Based on this\n",
            "technique, we achieve fine-grained image editing over particular objects while\n",
            "preventing undesired changes to other regions. Our method LocInv, based on the\n",
            "publicly available Stable Diffusion, is extensively evaluated on a subset of\n",
            "the COCO dataset, and consistently obtains superior results both quantitatively\n",
            "and qualitatively.The code will be released at\n",
            "https://github.com/wangkai930418/DPL\n",
            "['Large-scale Text-to-Image (T2I) diffusion models demonstrate significant\\ngeneration capabilities based on textual prompts.', 'Based on the T2I diffusion\\nmodels, text-guided image editing research aims to empower users to manipulate\\ngenerated images by altering the text prompts.', 'However, existing image editing\\ntechniques are prone to editing over unintentional regions that are beyond the\\nintended target area, primarily due to inaccuracies in cross-attention maps.', 'To\\naddress this problem, we propose Localization-aware Inversion (LocInv), which\\nexploits segmentation maps or bounding boxes as extra localization priors to\\nrefine the cross-attention maps in the denoising phases of the diffusion\\nprocess.', 'Through the dynamic updating of tokens corresponding to noun words in\\nthe textual input, we are compelling the cross-attention maps to closely align\\nwith the correct noun and adjective words in the text prompt.', 'Based on this\\ntechnique, we achieve fine-grained image editing over particular objects while\\npreventing undesired changes to other regions.', 'Our method LocInv, based on the\\npublicly available Stable Diffusion, is extensively evaluated on a subset of\\nthe COCO dataset, and consistently obtains superior results both quantitatively\\nand qualitatively.The code will be released at\\nhttps://github.com/wangkai930418/DPL']\n",
            "Chunks for abstract: While most research on controllable text generation has focused on steering\n",
            "base Language Models, the emerging instruction-tuning and prompting paradigm\n",
            "offers an alternate approach to controllability. We compile and release\n",
            "ConGenBench, a testbed of 17 different controllable generation tasks, using a\n",
            "subset of it to benchmark the performance of 9 different baselines and methods\n",
            "on Instruction-tuned Language Models. To our surprise, we find that\n",
            "prompting-based approaches outperform controllable text generation methods on\n",
            "most datasets and tasks, highlighting a need for research on controllable text\n",
            "generation with Instruction-tuned Language Models in specific. Prompt-based\n",
            "approaches match human performance on most stylistic tasks while lagging on\n",
            "structural tasks, foregrounding a need to study more varied constraints and\n",
            "more challenging stylistic tasks. To facilitate such research, we provide an\n",
            "algorithm that uses only a task dataset and a Large Language Model with\n",
            "in-context capabilities to automatically generate a constraint dataset. This\n",
            "method eliminates the fields dependence on pre-curated constraint datasets,\n",
            "hence vastly expanding the range of constraints that can be studied in the\n",
            "future.\n",
            "['While most research on controllable text generation has focused on steering\\nbase Language Models, the emerging instruction-tuning and prompting paradigm\\noffers an alternate approach to controllability.', 'We compile and release\\nConGenBench, a testbed of 17 different controllable generation tasks, using a\\nsubset of it to benchmark the performance of 9 different baselines and methods\\non Instruction-tuned Language Models.', 'To our surprise, we find that\\nprompting-based approaches outperform controllable text generation methods on\\nmost datasets and tasks, highlighting a need for research on controllable text\\ngeneration with Instruction-tuned Language Models in specific.', 'Prompt-based\\napproaches match human performance on most stylistic tasks while lagging on\\nstructural tasks, foregrounding a need to study more varied constraints and\\nmore challenging stylistic tasks.', 'To facilitate such research, we provide an\\nalgorithm that uses only a task dataset and a Large Language Model with\\nin-context capabilities to automatically generate a constraint dataset.', 'This\\nmethod eliminates the fields dependence on pre-curated constraint datasets,\\nhence vastly expanding the range of constraints that can be studied in the\\nfuture.']\n",
            "Chunks for abstract: We present results of the analysis of a set of images obtained in the field\n",
            "of the Milky Way bulge globular cluster NGC 6355 using the Dark Energy Camera,\n",
            "which is attached to the 4m Blanco telescope of the Cerro-Tololo Interamerican\n",
            "Observatory. We dealt with a heavy differential absorption across the observed\n",
            "field, a crowded field star population, and the superposition of field stars on\n",
            "to the cluster color-magnitude diagram main features to produce an intrinsic\n",
            "cluster stars density map. The resulting stellar density map reveals the\n",
            "presence of an extended envelope, a tidal tail, and scattered debris; the tidal\n",
            "tails pointing toward the Milky Way center. Such extra-tidal overdensities,\n",
            "detected above the mean star field density, resulted to be between four and six\n",
            "times larger that the local star field density fluctuation. They have also been\n",
            "recently generated by two independent studies which performed numerical\n",
            "simulations of synthetic tidal tails of Milky Way globular clusters. These\n",
            "results contrast with previous theoretical speculations about the possibility\n",
            "to detect tidal tails of globular clusters with chaotic orbits because they\n",
            "would be washed out after they were generated.\n",
            "['We present results of the analysis of a set of images obtained in the field\\nof the Milky Way bulge globular cluster NGC 6355 using the Dark Energy Camera,\\nwhich is attached to the 4m Blanco telescope of the Cerro-Tololo Interamerican\\nObservatory.', 'We dealt with a heavy differential absorption across the observed\\nfield, a crowded field star population, and the superposition of field stars on\\nto the cluster color-magnitude diagram main features to produce an intrinsic\\ncluster stars density map.', 'The resulting stellar density map reveals the\\npresence of an extended envelope, a tidal tail, and scattered debris; the tidal\\ntails pointing toward the Milky Way center.', 'Such extra-tidal overdensities,\\ndetected above the mean star field density, resulted to be between four and six\\ntimes larger that the local star field density fluctuation.', 'They have also been\\nrecently generated by two independent studies which performed numerical\\nsimulations of synthetic tidal tails of Milky Way globular clusters.', 'These\\nresults contrast with previous theoretical speculations about the possibility\\nto detect tidal tails of globular clusters with chaotic orbits because they\\nwould be washed out after they were generated.']\n",
            "Chunks for abstract: The recent years have witnessed a great array of large multimodal models\n",
            "(LMMs) to effectively solve single-image vision language tasks. However, their\n",
            "abilities to solve multi-image visual language tasks is yet to be improved. The\n",
            "existing multi-image LMMs (e.g. OpenFlamingo, Emu, Idefics, etc) mostly gain\n",
            "their multi-image ability through pre-training on hundreds of millions of noisy\n",
            "interleaved image-text data from web, which is neither efficient nor effective.\n",
            "In this paper, we aim at building strong multi-image LMMs via instruction\n",
            "tuning with academic-level resources. Therefore, we meticulously construct\n",
            "Mantis-Instruct containing 721K instances from 14 multi-image datasets. We\n",
            "design Mantis-Instruct to cover different multi-image skills like co-reference,\n",
            "reasoning, comparing, temporal understanding. We combine Mantis-Instruct with\n",
            "several single-image visual-language datasets to train our model Mantis to\n",
            "handle any interleaved image-text inputs. We evaluate the trained Mantis on\n",
            "five multi-image benchmarks and eight single-image benchmarks. Though only\n",
            "requiring academic-level resources (i.e. 36 hours on 16xA100-40G), Mantis-8B\n",
            "can achieve state-of-the-art performance on all the multi-image benchmarks and\n",
            "beats the existing best multi-image LMM Idefics2-8B by an average of 9 absolute\n",
            "points. We observe that Mantis performs equivalently well on the held-in and\n",
            "held-out evaluation benchmarks. We further evaluate Mantis on single-image\n",
            "benchmarks and demonstrate that Mantis can maintain a strong single-image\n",
            "performance on par with CogVLM and Emu2. Our results are particularly\n",
            "encouraging as it shows that low-cost instruction tuning is indeed much more\n",
            "effective than intensive pre-training in terms of building multi-image LMMs.\n",
            "['The recent years have witnessed a great array of large multimodal models\\n(LMMs) to effectively solve single-image vision language tasks.', 'However, their\\nabilities to solve multi-image visual language tasks is yet to be improved.', 'The\\nexisting multi-image LMMs (e.g.', 'OpenFlamingo, Emu, Idefics, etc) mostly gain\\ntheir multi-image ability through pre-training on hundreds of millions of noisy\\ninterleaved image-text data from web, which is neither efficient nor effective.', 'In this paper, we aim at building strong multi-image LMMs via instruction\\ntuning with academic-level resources.', 'Therefore, we meticulously construct\\nMantis-Instruct containing 721K instances from 14 multi-image datasets.', 'We\\ndesign Mantis-Instruct to cover different multi-image skills like co-reference,\\nreasoning, comparing, temporal understanding.', 'We combine Mantis-Instruct with\\nseveral single-image visual-language datasets to train our model Mantis to\\nhandle any interleaved image-text inputs.', 'We evaluate the trained Mantis on\\nfive multi-image benchmarks and eight single-image benchmarks.', 'Though only\\nrequiring academic-level resources (i.e.', '36 hours on 16xA100-40G), Mantis-8B\\ncan achieve state-of-the-art performance on all the multi-image benchmarks and\\nbeats the existing best multi-image LMM Idefics2-8B by an average of 9 absolute\\npoints.', 'We observe that Mantis performs equivalently well on the held-in and\\nheld-out evaluation benchmarks.', 'We further evaluate Mantis on single-image\\nbenchmarks and demonstrate that Mantis can maintain a strong single-image\\nperformance on par with CogVLM and Emu2.', 'Our results are particularly\\nencouraging as it shows that low-cost instruction tuning is indeed much more\\neffective than intensive pre-training in terms of building multi-image LMMs.']\n",
            "Chunks for abstract: Large Vision-Language models (VLMs) have demonstrated strong reasoning\n",
            "capabilities in tasks requiring a fine-grained understanding of literal images\n",
            "and text, such as visual question-answering or visual entailment. However,\n",
            "there has been little exploration of these models' capabilities when presented\n",
            "with images and captions containing figurative phenomena such as metaphors or\n",
            "humor, the meaning of which is often implicit. To close this gap, we propose a\n",
            "new task and a high-quality dataset: Visual Figurative Language Understanding\n",
            "with Textual Explanations (V-FLUTE). We frame the visual figurative language\n",
            "understanding problem as an explainable visual entailment task, where the model\n",
            "has to predict whether the image (premise) entails a claim (hypothesis) and\n",
            "justify the predicted label with a textual explanation. Using a human-AI\n",
            "collaboration framework, we build a high-quality dataset, V-FLUTE, that\n",
            "contains 6,027 <image, claim, label, explanation> instances spanning five\n",
            "diverse multimodal figurative phenomena: metaphors, similes, idioms, sarcasm,\n",
            "and humor. The figurative phenomena can be present either in the image, the\n",
            "caption, or both. We further conduct both automatic and human evaluations to\n",
            "assess current VLMs' capabilities in understanding figurative phenomena.\n",
            "['Large Vision-Language models (VLMs) have demonstrated strong reasoning\\ncapabilities in tasks requiring a fine-grained understanding of literal images\\nand text, such as visual question-answering or visual entailment.', \"However,\\nthere has been little exploration of these models' capabilities when presented\\nwith images and captions containing figurative phenomena such as metaphors or\\nhumor, the meaning of which is often implicit.\", 'To close this gap, we propose a\\nnew task and a high-quality dataset: Visual Figurative Language Understanding\\nwith Textual Explanations (V-FLUTE).', 'We frame the visual figurative language\\nunderstanding problem as an explainable visual entailment task, where the model\\nhas to predict whether the image (premise) entails a claim (hypothesis) and\\njustify the predicted label with a textual explanation.', 'Using a human-AI\\ncollaboration framework, we build a high-quality dataset, V-FLUTE, that\\ncontains 6,027 <image, claim, label, explanation> instances spanning five\\ndiverse multimodal figurative phenomena: metaphors, similes, idioms, sarcasm,\\nand humor.', 'The figurative phenomena can be present either in the image, the\\ncaption, or both.', \"We further conduct both automatic and human evaluations to\\nassess current VLMs' capabilities in understanding figurative phenomena.\"]\n",
            "Chunks for abstract: AI Foundation models are gaining traction in various applications, including\n",
            "medical fields like radiology. However, medical foundation models are often\n",
            "tested on limited tasks, leaving their generalisability and biases unexplored.\n",
            "We present RayDINO, a large visual encoder trained by self-supervision on 873k\n",
            "chest X-rays. We compare RayDINO to previous state-of-the-art models across\n",
            "nine radiology tasks, from classification and dense segmentation to text\n",
            "generation, and provide an in depth analysis of population, age and sex biases\n",
            "of our model. Our findings suggest that self-supervision allows patient-centric\n",
            "AI proving useful in clinical workflows and interpreting X-rays holistically.\n",
            "With RayDINO and small task-specific adapters, we reach state-of-the-art\n",
            "results and improve generalization to unseen populations while mitigating bias,\n",
            "illustrating the true promise of foundation models: versatility and robustness.\n",
            "['AI Foundation models are gaining traction in various applications, including\\nmedical fields like radiology.', 'However, medical foundation models are often\\ntested on limited tasks, leaving their generalisability and biases unexplored.', 'We present RayDINO, a large visual encoder trained by self-supervision on 873k\\nchest X-rays.', 'We compare RayDINO to previous state-of-the-art models across\\nnine radiology tasks, from classification and dense segmentation to text\\ngeneration, and provide an in depth analysis of population, age and sex biases\\nof our model.', 'Our findings suggest that self-supervision allows patient-centric\\nAI proving useful in clinical workflows and interpreting X-rays holistically.', 'With RayDINO and small task-specific adapters, we reach state-of-the-art\\nresults and improve generalization to unseen populations while mitigating bias,\\nillustrating the true promise of foundation models: versatility and robustness.']\n",
            "Chunks for abstract: Is the Text to Motion model robust? Recent advancements in Text to Motion\n",
            "models primarily stem from more accurate predictions of specific actions.\n",
            "However, the text modality typically relies solely on pre-trained Contrastive\n",
            "Language-Image Pretraining (CLIP) models. Our research has uncovered a\n",
            "significant issue with the text-to-motion model: its predictions often exhibit\n",
            "inconsistent outputs, resulting in vastly different or even incorrect poses\n",
            "when presented with semantically similar or identical text inputs. In this\n",
            "paper, we undertake an analysis to elucidate the underlying causes of this\n",
            "instability, establishing a clear link between the unpredictability of model\n",
            "outputs and the erratic attention patterns of the text encoder module.\n",
            "Consequently, we introduce a formal framework aimed at addressing this issue,\n",
            "which we term the Stable Text-to-Motion Framework (SATO). SATO consists of\n",
            "three modules, each dedicated to stable attention, stable prediction, and\n",
            "maintaining a balance between accuracy and robustness trade-off. We present a\n",
            "methodology for constructing an SATO that satisfies the stability of attention\n",
            "and prediction. To verify the stability of the model, we introduced a new\n",
            "textual synonym perturbation dataset based on HumanML3D and KIT-ML. Results\n",
            "show that SATO is significantly more stable against synonyms and other slight\n",
            "perturbations while keeping its high accuracy performance.\n",
            "['Is the Text to Motion model robust?', 'Recent advancements in Text to Motion\\nmodels primarily stem from more accurate predictions of specific actions.', 'However, the text modality typically relies solely on pre-trained Contrastive\\nLanguage-Image Pretraining (CLIP) models.', 'Our research has uncovered a\\nsignificant issue with the text-to-motion model: its predictions often exhibit\\ninconsistent outputs, resulting in vastly different or even incorrect poses\\nwhen presented with semantically similar or identical text inputs.', 'In this\\npaper, we undertake an analysis to elucidate the underlying causes of this\\ninstability, establishing a clear link between the unpredictability of model\\noutputs and the erratic attention patterns of the text encoder module.', 'Consequently, we introduce a formal framework aimed at addressing this issue,\\nwhich we term the Stable Text-to-Motion Framework (SATO).', 'SATO consists of\\nthree modules, each dedicated to stable attention, stable prediction, and\\nmaintaining a balance between accuracy and robustness trade-off.', 'We present a\\nmethodology for constructing an SATO that satisfies the stability of attention\\nand prediction.', 'To verify the stability of the model, we introduced a new\\ntextual synonym perturbation dataset based on HumanML3D and KIT-ML.', 'Results\\nshow that SATO is significantly more stable against synonyms and other slight\\nperturbations while keeping its high accuracy performance.']\n",
            "Chunks for abstract: This paper introduces UQA, a novel dataset for question answering and text\n",
            "comprehension in Urdu, a low-resource language with over 70 million native\n",
            "speakers. UQA is generated by translating the Stanford Question Answering\n",
            "Dataset (SQuAD2.0), a large-scale English QA dataset, using a technique called\n",
            "EATS (Enclose to Anchor, Translate, Seek), which preserves the answer spans in\n",
            "the translated context paragraphs. The paper describes the process of selecting\n",
            "and evaluating the best translation model among two candidates: Google\n",
            "Translator and Seamless M4T. The paper also benchmarks several state-of-the-art\n",
            "multilingual QA models on UQA, including mBERT, XLM-RoBERTa, and mT5, and\n",
            "reports promising results. For XLM-RoBERTa-XL, we have an F1 score of 85.99 and\n",
            "74.56 EM. UQA is a valuable resource for developing and testing multilingual\n",
            "NLP systems for Urdu and for enhancing the cross-lingual transferability of\n",
            "existing models. Further, the paper demonstrates the effectiveness of EATS for\n",
            "creating high-quality datasets for other languages and domains. The UQA dataset\n",
            "and the code are publicly available at www.github.com/sameearif/UQA.\n",
            "['This paper introduces UQA, a novel dataset for question answering and text\\ncomprehension in Urdu, a low-resource language with over 70 million native\\nspeakers.', 'UQA is generated by translating the Stanford Question Answering\\nDataset (SQuAD2.0), a large-scale English QA dataset, using a technique called\\nEATS (Enclose to Anchor, Translate, Seek), which preserves the answer spans in\\nthe translated context paragraphs.', 'The paper describes the process of selecting\\nand evaluating the best translation model among two candidates: Google\\nTranslator and Seamless M4T.', 'The paper also benchmarks several state-of-the-art\\nmultilingual QA models on UQA, including mBERT, XLM-RoBERTa, and mT5, and\\nreports promising results.', 'For XLM-RoBERTa-XL, we have an F1 score of 85.99 and\\n74.56 EM.', 'UQA is a valuable resource for developing and testing multilingual\\nNLP systems for Urdu and for enhancing the cross-lingual transferability of\\nexisting models.', 'Further, the paper demonstrates the effectiveness of EATS for\\ncreating high-quality datasets for other languages and domains.', 'The UQA dataset\\nand the code are publicly available at www.github.com/sameearif/UQA.']\n",
            "Chunks for abstract: Processing, managing, and analyzing dynamic graphs are the cornerstone in\n",
            "multiple application domains including fraud detection, recommendation system,\n",
            "graph neural network training, etc. This demo presents GTX, a latch-free\n",
            "write-optimized transactional graph data system that supports high throughput\n",
            "read-write transactions while maintaining competitive graph analytics. GTX has\n",
            "a unique latch-free graph storage and a transaction and concurrency control\n",
            "protocol for dynamic power-law graphs. GTX leverages atomic operations to\n",
            "eliminate latches, proposes a delta-based multi-version storage, and designs a\n",
            "hybrid transaction commit protocol to reduce interference between concurrent\n",
            "operations. To further improve its throughput, we design a delta-chains index\n",
            "to support efficient edge lookups. GTX manages concurrency control at\n",
            "delta-chain level, and provides adaptive concurrency according to the workload.\n",
            "Real-world graph access and updates exhibit temporal localities and hotspots.\n",
            "Unlike other transactional graph systems that experience significant\n",
            "performance degradation, GTX is the only system that can adapt to temporal\n",
            "localities and hotspots in graph updates and maintain\n",
            "million-transactions-per-second throughput. GTX is prototyped as a graph\n",
            "library and is evaluated using a graph library evaluation tool using real and\n",
            "synthetic datasets.\n",
            "['Processing, managing, and analyzing dynamic graphs are the cornerstone in\\nmultiple application domains including fraud detection, recommendation system,\\ngraph neural network training, etc.', 'This demo presents GTX, a latch-free\\nwrite-optimized transactional graph data system that supports high throughput\\nread-write transactions while maintaining competitive graph analytics.', 'GTX has\\na unique latch-free graph storage and a transaction and concurrency control\\nprotocol for dynamic power-law graphs.', 'GTX leverages atomic operations to\\neliminate latches, proposes a delta-based multi-version storage, and designs a\\nhybrid transaction commit protocol to reduce interference between concurrent\\noperations.', 'To further improve its throughput, we design a delta-chains index\\nto support efficient edge lookups.', 'GTX manages concurrency control at\\ndelta-chain level, and provides adaptive concurrency according to the workload.', 'Real-world graph access and updates exhibit temporal localities and hotspots.', 'Unlike other transactional graph systems that experience significant\\nperformance degradation, GTX is the only system that can adapt to temporal\\nlocalities and hotspots in graph updates and maintain\\nmillion-transactions-per-second throughput.', 'GTX is prototyped as a graph\\nlibrary and is evaluated using a graph library evaluation tool using real and\\nsynthetic datasets.']\n",
            "Chunks for abstract: This paper explores the novel topic of data breach journalism and data breach\n",
            "news through the case of databreaches.net, a news outlet dedicated to data\n",
            "breaches and related cyber crime. Motivated by the issues in traditional crime\n",
            "news and crime journalism, the case is explored by the means of text mining.\n",
            "According to the results, the outlet has kept a steady publishing pace, mainly\n",
            "focusing on plain and short reporting but with generally high-quality source\n",
            "material for the news articles. Despite these characteristics, the news\n",
            "articles exhibit fairly strong sentiments, which is partially expected due to\n",
            "the presence of emotionally laden crime and the long history of sensationalism\n",
            "in crime news. The news site has also covered the full scope of data breaches,\n",
            "although many of these are fairly traditional, exposing personal identifiers\n",
            "and financial details of the victims. Also hospitals and the healthcare sector\n",
            "stand out. With these results, the paper advances the study of data breaches by\n",
            "considering these from the perspective of media and journalism.\n",
            "['This paper explores the novel topic of data breach journalism and data breach\\nnews through the case of databreaches.net, a news outlet dedicated to data\\nbreaches and related cyber crime.', 'Motivated by the issues in traditional crime\\nnews and crime journalism, the case is explored by the means of text mining.', 'According to the results, the outlet has kept a steady publishing pace, mainly\\nfocusing on plain and short reporting but with generally high-quality source\\nmaterial for the news articles.', 'Despite these characteristics, the news\\narticles exhibit fairly strong sentiments, which is partially expected due to\\nthe presence of emotionally laden crime and the long history of sensationalism\\nin crime news.', 'The news site has also covered the full scope of data breaches,\\nalthough many of these are fairly traditional, exposing personal identifiers\\nand financial details of the victims.', 'Also hospitals and the healthcare sector\\nstand out.', 'With these results, the paper advances the study of data breaches by\\nconsidering these from the perspective of media and journalism.']\n",
            "Chunks for abstract: For recent diffusion-based generative models, maintaining consistent content\n",
            "across a series of generated images, especially those containing subjects and\n",
            "complex details, presents a significant challenge. In this paper, we propose a\n",
            "new way of self-attention calculation, termed Consistent Self-Attention, that\n",
            "significantly boosts the consistency between the generated images and augments\n",
            "prevalent pretrained diffusion-based text-to-image models in a zero-shot\n",
            "manner. To extend our method to long-range video generation, we further\n",
            "introduce a novel semantic space temporal motion prediction module, named\n",
            "Semantic Motion Predictor. It is trained to estimate the motion conditions\n",
            "between two provided images in the semantic spaces. This module converts the\n",
            "generated sequence of images into videos with smooth transitions and consistent\n",
            "subjects that are significantly more stable than the modules based on latent\n",
            "spaces only, especially in the context of long video generation. By merging\n",
            "these two novel components, our framework, referred to as StoryDiffusion, can\n",
            "describe a text-based story with consistent images or videos encompassing a\n",
            "rich variety of contents. The proposed StoryDiffusion encompasses pioneering\n",
            "explorations in visual story generation with the presentation of images and\n",
            "videos, which we hope could inspire more research from the aspect of\n",
            "architectural modifications. Our code is made publicly available at\n",
            "https://github.com/HVision-NKU/StoryDiffusion.\n",
            "['For recent diffusion-based generative models, maintaining consistent content\\nacross a series of generated images, especially those containing subjects and\\ncomplex details, presents a significant challenge.', 'In this paper, we propose a\\nnew way of self-attention calculation, termed Consistent Self-Attention, that\\nsignificantly boosts the consistency between the generated images and augments\\nprevalent pretrained diffusion-based text-to-image models in a zero-shot\\nmanner.', 'To extend our method to long-range video generation, we further\\nintroduce a novel semantic space temporal motion prediction module, named\\nSemantic Motion Predictor.', 'It is trained to estimate the motion conditions\\nbetween two provided images in the semantic spaces.', 'This module converts the\\ngenerated sequence of images into videos with smooth transitions and consistent\\nsubjects that are significantly more stable than the modules based on latent\\nspaces only, especially in the context of long video generation.', 'By merging\\nthese two novel components, our framework, referred to as StoryDiffusion, can\\ndescribe a text-based story with consistent images or videos encompassing a\\nrich variety of contents.', 'The proposed StoryDiffusion encompasses pioneering\\nexplorations in visual story generation with the presentation of images and\\nvideos, which we hope could inspire more research from the aspect of\\narchitectural modifications.', 'Our code is made publicly available at\\nhttps://github.com/HVision-NKU/StoryDiffusion.']\n",
            "Chunks for abstract: This is the fourth in a sequence of four papers, where we prove the\n",
            "arithmetic Siegel--Weil formula in co-rank $1$ for Kudla--Rapoport special\n",
            "cycles on exotic smooth integral models of unitary Shimura varieties of\n",
            "arbitrarily large even arithmetic dimension. Our arithmetic Siegel--Weil\n",
            "formula implies that degrees of Kudla--Rapoport arithmetic special $1$-cycles\n",
            "are encoded in the first derivatives of unitary Eisenstein series Fourier\n",
            "coefficients.\n",
            "  In this paper, we pin down precise normalizations for some $U(m,m)$ Siegel\n",
            "Eisenstein series, give local Siegel--Weil special value formulas with explicit\n",
            "constants, and record a geometric Siegel--Weil result for degrees of complex\n",
            "$0$-cycles. Using this, we complete the proof of our arithmetic Siegel--Weil\n",
            "results by patching together the local main theorems from our companion papers.\n",
            "['This is the fourth in a sequence of four papers, where we prove the\\narithmetic Siegel--Weil formula in co-rank $1$ for Kudla--Rapoport special\\ncycles on exotic smooth integral models of unitary Shimura varieties of\\narbitrarily large even arithmetic dimension.', 'Our arithmetic Siegel--Weil\\nformula implies that degrees of Kudla--Rapoport arithmetic special $1$-cycles\\nare encoded in the first derivatives of unitary Eisenstein series Fourier\\ncoefficients.', 'In this paper, we pin down precise normalizations for some $U(m,m)$ Siegel\\nEisenstein series, give local Siegel--Weil special value formulas with explicit\\nconstants, and record a geometric Siegel--Weil result for degrees of complex\\n$0$-cycles.', 'Using this, we complete the proof of our arithmetic Siegel--Weil\\nresults by patching together the local main theorems from our companion papers.']\n",
            "Chunks for abstract: This is the first in a sequence of four papers, where we prove the arithmetic\n",
            "Siegel--Weil formula in co-rank $1$ for Kudla--Rapoport special cycles on\n",
            "exotic smooth integral models of unitary Shimura varieties of arbitrarily large\n",
            "even arithmetic dimension. Our arithmetic Siegel--Weil formula implies that\n",
            "degrees of Kudla--Rapoport arithmetic special $1$-cycles are encoded in the\n",
            "first derivatives of unitary Eisenstein series Fourier coefficients.\n",
            "  The crucial input is a new local limiting method at all places. In this\n",
            "paper, we formulate and prove the key local theorems at all non-Archimedean\n",
            "places. On the analytic side, the limit relates local Whittaker functions on\n",
            "different groups. On the geometric side at nonsplit non-Archimedean places, the\n",
            "limit relates degrees of $0$-cycles on Rapoport--Zink spaces and local\n",
            "contributions to heights of $1$-cycles in mixed characteristic.\n",
            "['This is the first in a sequence of four papers, where we prove the arithmetic\\nSiegel--Weil formula in co-rank $1$ for Kudla--Rapoport special cycles on\\nexotic smooth integral models of unitary Shimura varieties of arbitrarily large\\neven arithmetic dimension.', 'Our arithmetic Siegel--Weil formula implies that\\ndegrees of Kudla--Rapoport arithmetic special $1$-cycles are encoded in the\\nfirst derivatives of unitary Eisenstein series Fourier coefficients.', 'The crucial input is a new local limiting method at all places.', 'In this\\npaper, we formulate and prove the key local theorems at all non-Archimedean\\nplaces.', 'On the analytic side, the limit relates local Whittaker functions on\\ndifferent groups.', 'On the geometric side at nonsplit non-Archimedean places, the\\nlimit relates degrees of $0$-cycles on Rapoport--Zink spaces and local\\ncontributions to heights of $1$-cycles in mixed characteristic.']\n",
            "Chunks for abstract: This paper introduces GTX a standalone main-memory write-optimized graph\n",
            "system that specializes in structural and graph property updates while\n",
            "maintaining concurrent reads and graph analytics with snapshot isolation-level\n",
            "transactional concurrency. Recent graph libraries target efficient concurrent\n",
            "read and write support while guaranteeing transactional consistency. However,\n",
            "their performance suffers for updates with strong temporal locality over the\n",
            "same vertexes and edges due to vertex-centric lock contentions. GTX introduces\n",
            "a new delta-chain-centric concurrency-control protocol that eliminates\n",
            "traditional mutually exclusive latches. GTX resolves the conflicts caused by\n",
            "vertex-level locking, and adapts to real-life workloads while maintaining\n",
            "sequential access to the graph's adjacency lists storage. This combination of\n",
            "features has been demonstrated to provide good performance in graph analytical\n",
            "queries. GTX's transactions support fast group commit, novel write-write\n",
            "conflict prevention, and lazy garbage collection. Based on extensive\n",
            "experimental and comparative studies, in addition to maintaining competitive\n",
            "concurrent read and analytical performance, GTX demonstrates high throughput\n",
            "over state-of-the-art techniques when handling concurrent transaction+analytics\n",
            "workloads. For write-heavy transactional workloads, GTX performs up to 11x\n",
            "better than the best-performing state-of-the-art systems in transaction\n",
            "throughput. At the same time, GTX does not sacrifice the performance of\n",
            "read-heavy analytical workloads, and has competitive performance similar to\n",
            "state-of-the-art systems.\n",
            "['This paper introduces GTX a standalone main-memory write-optimized graph\\nsystem that specializes in structural and graph property updates while\\nmaintaining concurrent reads and graph analytics with snapshot isolation-level\\ntransactional concurrency.', 'Recent graph libraries target efficient concurrent\\nread and write support while guaranteeing transactional consistency.', 'However,\\ntheir performance suffers for updates with strong temporal locality over the\\nsame vertexes and edges due to vertex-centric lock contentions.', 'GTX introduces\\na new delta-chain-centric concurrency-control protocol that eliminates\\ntraditional mutually exclusive latches.', \"GTX resolves the conflicts caused by\\nvertex-level locking, and adapts to real-life workloads while maintaining\\nsequential access to the graph's adjacency lists storage.\", 'This combination of\\nfeatures has been demonstrated to provide good performance in graph analytical\\nqueries.', \"GTX's transactions support fast group commit, novel write-write\\nconflict prevention, and lazy garbage collection.\", 'Based on extensive\\nexperimental and comparative studies, in addition to maintaining competitive\\nconcurrent read and analytical performance, GTX demonstrates high throughput\\nover state-of-the-art techniques when handling concurrent transaction+analytics\\nworkloads.', 'For write-heavy transactional workloads, GTX performs up to 11x\\nbetter than the best-performing state-of-the-art systems in transaction\\nthroughput.', 'At the same time, GTX does not sacrifice the performance of\\nread-heavy analytical workloads, and has competitive performance similar to\\nstate-of-the-art systems.']\n",
            "Chunks for abstract: We propose a spectroscopic probe of the breaking and localization of Cooper\n",
            "pairs in an atomic Fermi superfluid interacting with a Rydberg impurity. This\n",
            "is achieved by monitoring the formation of diatomic and triatomic\n",
            "ultralong-range molecular species in the superfluid across the BCS - Bose\n",
            "Einstein condensation (BEC) crossover. The triatomic Rydberg molecule in the\n",
            "BEC regime heralds the trapping of a tightly-bound Cooper pair, reminiscent of\n",
            "pion capture in nuclear matter, while the breaking of a Cooper pair on the BCS\n",
            "side by a diatomic Rydberg molecule is evocative of binary-star tidal\n",
            "disruption by a black hole. Spectroscopy of the Fermi superfluid and Rydberg\n",
            "molecules allows for an estimation of the Cooper-pair size while the Rydberg\n",
            "molecule binding energies discern many-body pairing effects.\n",
            "['We propose a spectroscopic probe of the breaking and localization of Cooper\\npairs in an atomic Fermi superfluid interacting with a Rydberg impurity.', 'This\\nis achieved by monitoring the formation of diatomic and triatomic\\nultralong-range molecular species in the superfluid across the BCS - Bose\\nEinstein condensation (BEC) crossover.', 'The triatomic Rydberg molecule in the\\nBEC regime heralds the trapping of a tightly-bound Cooper pair, reminiscent of\\npion capture in nuclear matter, while the breaking of a Cooper pair on the BCS\\nside by a diatomic Rydberg molecule is evocative of binary-star tidal\\ndisruption by a black hole.', 'Spectroscopy of the Fermi superfluid and Rydberg\\nmolecules allows for an estimation of the Cooper-pair size while the Rydberg\\nmolecule binding energies discern many-body pairing effects.']\n",
            "Chunks for abstract: An algorithm for providing analytical solutions to Schr\\\"{o}dinger's equation\n",
            "with non-exactly solvable potentials is elaborated. It represents a symbiosis\n",
            "between the logarithmic expansion method and the techniques of the\n",
            "superymmetric quantum mechanics as extended toward non shape invariant\n",
            "potentials. The complete solution to a given Hamiltonian $H_{0}$ is obtained\n",
            "from the nodeless states of the Hamiltonian $H_{0}$ and of a set of\n",
            "supersymmetric partners $H_{1}, H_{2},..., H_{r}$. The nodeless states (dubbed\n",
            "\"edge\" states) are unique and in general can be ground or excited states. They\n",
            "are solved using the logarithmic expansion which yields an infinite systems of\n",
            "coupled first order hierarchical differential equations, converted later into\n",
            "algebraic equations with recurrence relations which can be solved order by\n",
            "order. We formulate the aforementioned scheme, termed to as \"Supersymmetric\n",
            "Expansion Algorithm'' step by step and apply it to obtain for the first time\n",
            "the complete analytical solutions of the three dimensional Hulth\\'en--, and the\n",
            "one-dimensional anharmonic oscillator potentials.\n",
            "['An algorithm for providing analytical solutions to Schr\\\\\"{o}dinger\\'s equation\\nwith non-exactly solvable potentials is elaborated.', 'It represents a symbiosis\\nbetween the logarithmic expansion method and the techniques of the\\nsuperymmetric quantum mechanics as extended toward non shape invariant\\npotentials.', 'The complete solution to a given Hamiltonian $H_{0}$ is obtained\\nfrom the nodeless states of the Hamiltonian $H_{0}$ and of a set of\\nsupersymmetric partners $H_{1}, H_{2},..., H_{r}$.', 'The nodeless states (dubbed\\n\"edge\" states) are unique and in general can be ground or excited states.', 'They\\nare solved using the logarithmic expansion which yields an infinite systems of\\ncoupled first order hierarchical differential equations, converted later into\\nalgebraic equations with recurrence relations which can be solved order by\\norder.', 'We formulate the aforementioned scheme, termed to as \"Supersymmetric\\nExpansion Algorithm\\'\\' step by step and apply it to obtain for the first time\\nthe complete analytical solutions of the three dimensional Hulth\\\\\\'en--, and the\\none-dimensional anharmonic oscillator potentials.']\n",
            "Chunks for abstract: Complex systems with multiple processes evolving on different temporal scales\n",
            "are naturally described by multilayer networks, where each layer represents a\n",
            "different timescale. In this work, we show how the multilayer structure shapes\n",
            "the generation and propagation of information between layers. We derive a\n",
            "general decomposition of the multilayer probability for continuous stochastic\n",
            "processes described by Fokker-Planck operators. In particular, we focus on\n",
            "Gaussian processes, for which this solution can be obtained analytically. By\n",
            "explicitly computing the mutual information between the layers, we derive the\n",
            "fundamental principles that govern how information is propagated by the\n",
            "topology of the multilayer network. In particular, we unravel how edges between\n",
            "nodes in different layers affect their functional couplings. We find that\n",
            "interactions from fast to slow layers alone do not generate information,\n",
            "leaving the layers statistically independent even if they affect their\n",
            "dynamical evolution. On the other hand, interactions from slow to fast nodes\n",
            "lead to non-zero mutual information, which can then be propagated along\n",
            "specific paths of interactions between layers. We employ our results to study\n",
            "the interplay between information and instability, identifying the critical\n",
            "layers that drive information when pushed to the edge of stability. Our work\n",
            "generalizes previous results obtained in the context of discrete stochastic\n",
            "processes, allowing us to understand how the multilayer nature of complex\n",
            "systems affects their functional structure.\n",
            "['Complex systems with multiple processes evolving on different temporal scales\\nare naturally described by multilayer networks, where each layer represents a\\ndifferent timescale.', 'In this work, we show how the multilayer structure shapes\\nthe generation and propagation of information between layers.', 'We derive a\\ngeneral decomposition of the multilayer probability for continuous stochastic\\nprocesses described by Fokker-Planck operators.', 'In particular, we focus on\\nGaussian processes, for which this solution can be obtained analytically.', 'By\\nexplicitly computing the mutual information between the layers, we derive the\\nfundamental principles that govern how information is propagated by the\\ntopology of the multilayer network.', 'In particular, we unravel how edges between\\nnodes in different layers affect their functional couplings.', 'We find that\\ninteractions from fast to slow layers alone do not generate information,\\nleaving the layers statistically independent even if they affect their\\ndynamical evolution.', 'On the other hand, interactions from slow to fast nodes\\nlead to non-zero mutual information, which can then be propagated along\\nspecific paths of interactions between layers.', 'We employ our results to study\\nthe interplay between information and instability, identifying the critical\\nlayers that drive information when pushed to the edge of stability.', 'Our work\\ngeneralizes previous results obtained in the context of discrete stochastic\\nprocesses, allowing us to understand how the multilayer nature of complex\\nsystems affects their functional structure.']\n",
            "Chunks for abstract: We use (versions of) the von Neumann inequality for Hilbert space\n",
            "contractions to prove several Schwarz-Pick inequalities. Specifically, we\n",
            "derive an alternate proof for a multi-point Schwarz-Pick inequality by Beardon\n",
            "and Minda, along with a generalized version for operators. Connections with\n",
            "model spaces and Peschl's invariant derivatives are established. Finally,\n",
            "Schwarz-Pick inequalities for analytic functions on polydisks and for higher\n",
            "order derivatives are discussed. An enhanced version of the Schwarz-Pick lemma,\n",
            "using the notion of distinguished variety, is obtained for the bidisk.\n",
            "['We use (versions of) the von Neumann inequality for Hilbert space\\ncontractions to prove several Schwarz-Pick inequalities.', 'Specifically, we\\nderive an alternate proof for a multi-point Schwarz-Pick inequality by Beardon\\nand Minda, along with a generalized version for operators.', \"Connections with\\nmodel spaces and Peschl's invariant derivatives are established.\", 'Finally,\\nSchwarz-Pick inequalities for analytic functions on polydisks and for higher\\norder derivatives are discussed.', 'An enhanced version of the Schwarz-Pick lemma,\\nusing the notion of distinguished variety, is obtained for the bidisk.']\n",
            "Chunks for abstract: In subject-driven text-to-image synthesis, the synthesis process tends to be\n",
            "heavily influenced by the reference images provided by users, often overlooking\n",
            "crucial attributes detailed in the text prompt. In this work, we propose\n",
            "Subject-Agnostic Guidance (SAG), a simple yet effective solution to remedy the\n",
            "problem. We show that through constructing a subject-agnostic condition and\n",
            "applying our proposed dual classifier-free guidance, one could obtain outputs\n",
            "consistent with both the given subject and input text prompts. We validate the\n",
            "efficacy of our approach through both optimization-based and encoder-based\n",
            "methods. Additionally, we demonstrate its applicability in second-order\n",
            "customization methods, where an encoder-based model is fine-tuned with\n",
            "DreamBooth. Our approach is conceptually simple and requires only minimal code\n",
            "modifications, but leads to substantial quality improvements, as evidenced by\n",
            "our evaluations and user studies.\n",
            "['In subject-driven text-to-image synthesis, the synthesis process tends to be\\nheavily influenced by the reference images provided by users, often overlooking\\ncrucial attributes detailed in the text prompt.', 'In this work, we propose\\nSubject-Agnostic Guidance (SAG), a simple yet effective solution to remedy the\\nproblem.', 'We show that through constructing a subject-agnostic condition and\\napplying our proposed dual classifier-free guidance, one could obtain outputs\\nconsistent with both the given subject and input text prompts.', 'We validate the\\nefficacy of our approach through both optimization-based and encoder-based\\nmethods.', 'Additionally, we demonstrate its applicability in second-order\\ncustomization methods, where an encoder-based model is fine-tuned with\\nDreamBooth.', 'Our approach is conceptually simple and requires only minimal code\\nmodifications, but leads to substantial quality improvements, as evidenced by\\nour evaluations and user studies.']\n",
            "Chunks for abstract: In this paper we study the weak convergence of self-normalized partial sum\n",
            "processes in the Skorokhod M1 topology for sequences of random variables which\n",
            "exhibit clustering of large values of the same sign. We show that for\n",
            "stationary regularly varying sequences with such properties, their\n",
            "corresponding properly centered self-normalized partial sums processes converge\n",
            "to a stable Levy process. The convergence is established in the space of cadlag\n",
            "functions endowed with Skorohod's M1 topology, which is more suitable\n",
            "especially for cases in which the standard J1 topology fails to induce weak\n",
            "convergence of joint stochastic functionals.\n",
            "['In this paper we study the weak convergence of self-normalized partial sum\\nprocesses in the Skorokhod M1 topology for sequences of random variables which\\nexhibit clustering of large values of the same sign.', 'We show that for\\nstationary regularly varying sequences with such properties, their\\ncorresponding properly centered self-normalized partial sums processes converge\\nto a stable Levy process.', \"The convergence is established in the space of cadlag\\nfunctions endowed with Skorohod's M1 topology, which is more suitable\\nespecially for cases in which the standard J1 topology fails to induce weak\\nconvergence of joint stochastic functionals.\"]\n",
            "Chunks for abstract: Uncertainty in LiDAR measurements, stemming from factors such as range\n",
            "sensing, is crucial for LIO (LiDAR-Inertial Odometry) systems as it affects the\n",
            "accurate weighting in the loss function. While recent LIO systems address\n",
            "uncertainty related to range sensing, the impact of incident angle on\n",
            "uncertainty is often overlooked by the community. Moreover, the existing\n",
            "uncertainty propagation methods suffer from computational inefficiency. This\n",
            "paper proposes a comprehensive point uncertainty model that accounts for both\n",
            "the uncertainties from LiDAR measurements and surface characteristics, along\n",
            "with an efficient local uncertainty analytical method for LiDAR-based state\n",
            "estimation problem. We employ a projection operator that separates the\n",
            "uncertainty into the ray direction and its orthogonal plane. Then, we derive\n",
            "incremental Jacobian matrices of eigenvalues and eigenvectors w.r.t. points,\n",
            "which enables a fast approximation of uncertainty propagation. This approach\n",
            "eliminates the requirement for redundant traversal of points, significantly\n",
            "reducing the time complexity of uncertainty propagation from $\\mathcal{O} (n)$\n",
            "to $\\mathcal{O} (1)$ when a new point is added. Simulations and experiments on\n",
            "public datasets are conducted to validate the accuracy and efficiency of our\n",
            "formulations. The proposed methods have been integrated into a LIO system,\n",
            "which is available at https://github.com/tiev-tongji/LOG-LIO2.\n",
            "['Uncertainty in LiDAR measurements, stemming from factors such as range\\nsensing, is crucial for LIO (LiDAR-Inertial Odometry) systems as it affects the\\naccurate weighting in the loss function.', 'While recent LIO systems address\\nuncertainty related to range sensing, the impact of incident angle on\\nuncertainty is often overlooked by the community.', 'Moreover, the existing\\nuncertainty propagation methods suffer from computational inefficiency.', 'This\\npaper proposes a comprehensive point uncertainty model that accounts for both\\nthe uncertainties from LiDAR measurements and surface characteristics, along\\nwith an efficient local uncertainty analytical method for LiDAR-based state\\nestimation problem.', 'We employ a projection operator that separates the\\nuncertainty into the ray direction and its orthogonal plane.', 'Then, we derive\\nincremental Jacobian matrices of eigenvalues and eigenvectors w.r.t.', 'points,\\nwhich enables a fast approximation of uncertainty propagation.', 'This approach\\neliminates the requirement for redundant traversal of points, significantly\\nreducing the time complexity of uncertainty propagation from $\\\\mathcal{O} (n)$\\nto $\\\\mathcal{O} (1)$ when a new point is added.', 'Simulations and experiments on\\npublic datasets are conducted to validate the accuracy and efficiency of our\\nformulations.', 'The proposed methods have been integrated into a LIO system,\\nwhich is available at https://github.com/tiev-tongji/LOG-LIO2.']\n",
            "Chunks for abstract: Recently, there has been a significant focus on exploring the theoretical\n",
            "aspects of deep learning, especially regarding its performance in\n",
            "classification tasks. Bayesian deep learning has emerged as a unified\n",
            "probabilistic framework, seeking to integrate deep learning with Bayesian\n",
            "methodologies seamlessly. However, there exists a gap in the theoretical\n",
            "understanding of Bayesian approaches in deep learning for classification. This\n",
            "study presents an attempt to bridge that gap. By leveraging PAC-Bayes bounds\n",
            "techniques, we present theoretical results on the prediction or\n",
            "misclassification error of a probabilistic approach utilizing Spike-and-Slab\n",
            "priors for sparse deep learning in classification. We establish non-asymptotic\n",
            "results for the prediction error. Additionally, we demonstrate that, by\n",
            "considering different architectures, our results can achieve minimax optimal\n",
            "rates in both low and high-dimensional settings, up to a logarithmic factor.\n",
            "Moreover, our additional logarithmic term yields slight improvements over\n",
            "previous works. Additionally, we propose and analyze an automated model\n",
            "selection approach aimed at optimally choosing a network architecture with\n",
            "guaranteed optimality.\n",
            "['Recently, there has been a significant focus on exploring the theoretical\\naspects of deep learning, especially regarding its performance in\\nclassification tasks.', 'Bayesian deep learning has emerged as a unified\\nprobabilistic framework, seeking to integrate deep learning with Bayesian\\nmethodologies seamlessly.', 'However, there exists a gap in the theoretical\\nunderstanding of Bayesian approaches in deep learning for classification.', 'This\\nstudy presents an attempt to bridge that gap.', 'By leveraging PAC-Bayes bounds\\ntechniques, we present theoretical results on the prediction or\\nmisclassification error of a probabilistic approach utilizing Spike-and-Slab\\npriors for sparse deep learning in classification.', 'We establish non-asymptotic\\nresults for the prediction error.', 'Additionally, we demonstrate that, by\\nconsidering different architectures, our results can achieve minimax optimal\\nrates in both low and high-dimensional settings, up to a logarithmic factor.', 'Moreover, our additional logarithmic term yields slight improvements over\\nprevious works.', 'Additionally, we propose and analyze an automated model\\nselection approach aimed at optimally choosing a network architecture with\\nguaranteed optimality.']\n",
            "Chunks for abstract: With the recent success of generative models in image and text, the\n",
            "evaluation of generative models has gained a lot of attention. Whereas most\n",
            "generative models are compared in terms of scalar values such as Frechet\n",
            "Inception Distance (FID) or Inception Score (IS), in the last years (Sajjadi et\n",
            "al., 2018) proposed a definition of precision-recall curve to characterize the\n",
            "closeness of two distributions. Since then, various approaches to precision and\n",
            "recall have seen the light (Kynkaanniemi et al., 2019; Naeem et al., 2020; Park\n",
            "& Kim, 2023). They center their attention on the extreme values of precision\n",
            "and recall, but apart from this fact, their ties are elusive. In this paper, we\n",
            "unify most of these approaches under the same umbrella, relying on the work of\n",
            "(Simon et al., 2019). Doing so, we were able not only to recover entire curves,\n",
            "but also to expose the sources of the accounted pitfalls of the concerned\n",
            "metrics. We also provide consistency results that go well beyond the ones\n",
            "presented in the corresponding literature. Last, we study the different\n",
            "behaviors of the curves obtained experimentally.\n",
            "['With the recent success of generative models in image and text, the\\nevaluation of generative models has gained a lot of attention.', 'Whereas most\\ngenerative models are compared in terms of scalar values such as Frechet\\nInception Distance (FID) or Inception Score (IS), in the last years (Sajjadi et\\nal., 2018) proposed a definition of precision-recall curve to characterize the\\ncloseness of two distributions.', 'Since then, various approaches to precision and\\nrecall have seen the light (Kynkaanniemi et al., 2019; Naeem et al., 2020; Park\\n& Kim, 2023).', 'They center their attention on the extreme values of precision\\nand recall, but apart from this fact, their ties are elusive.', 'In this paper, we\\nunify most of these approaches under the same umbrella, relying on the work of\\n(Simon et al., 2019).', 'Doing so, we were able not only to recover entire curves,\\nbut also to expose the sources of the accounted pitfalls of the concerned\\nmetrics.', 'We also provide consistency results that go well beyond the ones\\npresented in the corresponding literature.', 'Last, we study the different\\nbehaviors of the curves obtained experimentally.']\n",
            "Chunks for abstract: Natural language inference (NLI), also known as Recognizing Textual\n",
            "Entailment (RTE), is an important aspect of natural language understanding.\n",
            "Most research now uses machine learning and deep learning to perform this task\n",
            "on specific datasets, meaning their solution is not explainable nor explicit.\n",
            "To address the need for an explainable approach to RTE, we propose a novel\n",
            "pipeline that is based on translating text into an Abstract Meaning\n",
            "Representation (AMR) graph. For this we use a pre-trained AMR parser. We then\n",
            "translate the AMR graph into propositional logic and use a SAT solver for\n",
            "automated reasoning. In text, often commonsense suggests that an entailment (or\n",
            "contradiction) relationship holds between a premise and a claim, but because\n",
            "different wordings are used, this is not identified from their logical\n",
            "representations. To address this, we introduce relaxation methods to allow\n",
            "replacement or forgetting of some propositions. Our experimental results show\n",
            "this pipeline performs well on four RTE datasets.\n",
            "['Natural language inference (NLI), also known as Recognizing Textual\\nEntailment (RTE), is an important aspect of natural language understanding.', 'Most research now uses machine learning and deep learning to perform this task\\non specific datasets, meaning their solution is not explainable nor explicit.', 'To address the need for an explainable approach to RTE, we propose a novel\\npipeline that is based on translating text into an Abstract Meaning\\nRepresentation (AMR) graph.', 'For this we use a pre-trained AMR parser.', 'We then\\ntranslate the AMR graph into propositional logic and use a SAT solver for\\nautomated reasoning.', 'In text, often commonsense suggests that an entailment (or\\ncontradiction) relationship holds between a premise and a claim, but because\\ndifferent wordings are used, this is not identified from their logical\\nrepresentations.', 'To address this, we introduce relaxation methods to allow\\nreplacement or forgetting of some propositions.', 'Our experimental results show\\nthis pipeline performs well on four RTE datasets.']\n",
            "Chunks for abstract: Let $K$ be a convex body in ${\\mathbb R}^n$, and let $\\Pi_1({\\mathbb R}^n)$\n",
            "be the space of polynomials in $n$ variables of degree at most $1$. Given an\n",
            "$(n+1)$-element set $Y\\subset K$ in general position, we let $P_Y$ denote the\n",
            "Lagrange interpolation projector $P_Y: C(K)\\to \\Pi_1({\\mathbb R}^n)$ with nodes\n",
            "in $Y$. In this paper, we study upper and lower bounds for the norm of the\n",
            "optimal Lagrange interpolation projector, i.e., the projector with minimal\n",
            "operator norm where the minimum is taken over all $(n+1)$-element sets of\n",
            "interpolation nodes in $K$. We denote this minimal norm by $\\theta_n(K)$. Our\n",
            "main result, Theorem 5.2, provides an explicit lower bound for the constant\n",
            "$\\theta_n(K)$ for an arbitrary convex body $K\\subset{\\mathbb R}^n$ and an\n",
            "arbitrary $n\\ge 1$. We prove that $\\theta_n(K)\\ge \\chi_n^{-1}\\left({{\\rm\n",
            "vol}(K)}/{{\\rm simp}(K)}\\right)$ where $\\chi_n$ is the Legendre polynomial of\n",
            "degree $n$ and ${\\rm simp}(K)$ is the maximum volume of a simplex contained in\n",
            "$K$. The proof of this result relies on a geometric characterization of the\n",
            "Legendre polynomials in terms of the volumes of certain convex polyhedra. More\n",
            "specifically, we show that for every $\\gamma\\ge 1$ the volume of the set\n",
            "$\\left\\{x=(x_1,...,x_n)\\in{\\mathbb R}^n : \\sum |x_j| +\\left|1- \\sum\n",
            "x_j\\right|\\le\\gamma\\right\\}$ is equal to ${\\chi_n(\\gamma)}/{n!}$. If $K$ is an\n",
            "$n$-dimensional ball, this approach leads us to the equivalence $\\theta_n(K)\n",
            "\\asymp\\sqrt{n}$ which is complemented by the exact formula for $\\theta_n(K)$.\n",
            "If $K$ is an $n$-dimensional cube, we obtain explicit efficient formulae for\n",
            "upper and lower bounds of the constant $\\theta_n(K)$; moreover, for small $n$,\n",
            "these estimates enable us to compute the exact values of this constant.\n",
            "['Let $K$ be a convex body in ${\\\\mathbb R}^n$, and let $\\\\Pi_1({\\\\mathbb R}^n)$\\nbe the space of polynomials in $n$ variables of degree at most $1$.', 'Given an\\n$(n+1)$-element set $Y\\\\subset K$ in general position, we let $P_Y$ denote the\\nLagrange interpolation projector $P_Y: C(K)\\\\to \\\\Pi_1({\\\\mathbb R}^n)$ with nodes\\nin $Y$.', 'In this paper, we study upper and lower bounds for the norm of the\\noptimal Lagrange interpolation projector, i.e., the projector with minimal\\noperator norm where the minimum is taken over all $(n+1)$-element sets of\\ninterpolation nodes in $K$.', 'We denote this minimal norm by $\\\\theta_n(K)$.', 'Our\\nmain result, Theorem 5.2, provides an explicit lower bound for the constant\\n$\\\\theta_n(K)$ for an arbitrary convex body $K\\\\subset{\\\\mathbb R}^n$ and an\\narbitrary $n\\\\ge 1$.', 'We prove that $\\\\theta_n(K)\\\\ge \\\\chi_n^{-1}\\\\left({{\\\\rm\\nvol}(K)}/{{\\\\rm simp}(K)}\\\\right)$ where $\\\\chi_n$ is the Legendre polynomial of\\ndegree $n$ and ${\\\\rm simp}(K)$ is the maximum volume of a simplex contained in\\n$K$.', 'The proof of this result relies on a geometric characterization of the\\nLegendre polynomials in terms of the volumes of certain convex polyhedra.', 'More\\nspecifically, we show that for every $\\\\gamma\\\\ge 1$ the volume of the set\\n$\\\\left\\\\{x=(x_1,...,x_n)\\\\in{\\\\mathbb R}^n : \\\\sum |x_j| +\\\\left|1- \\\\sum\\nx_j\\\\right|\\\\le\\\\gamma\\\\right\\\\}$ is equal to ${\\\\chi_n(\\\\gamma)}/{n!}$.', 'If $K$ is an\\n$n$-dimensional ball, this approach leads us to the equivalence $\\\\theta_n(K)\\n\\\\asymp\\\\sqrt{n}$ which is complemented by the exact formula for $\\\\theta_n(K)$.', 'If $K$ is an $n$-dimensional cube, we obtain explicit efficient formulae for\\nupper and lower bounds of the constant $\\\\theta_n(K)$; moreover, for small $n$,\\nthese estimates enable us to compute the exact values of this constant.']\n",
            "Chunks for abstract: We reobtain and often refine prior criteria due to Kaplansky, McGovern,\n",
            "Roitman, Shchedryk, Wiegand, and Zabavsky--Bilavska and obtain new criteria for\n",
            "a Hermite ring to be an \\textsl{EDR}. We mention three criteria: (1) a Hermite\n",
            "ring $R$ is an \\textsl{EDR} iff for all pairs $(a,c)\\in R^2$, the product\n",
            "homomorphism $U(R/Rac)\\times U\\bigl(R/Rc(1-a)\\bigr)\\to U(R/Rc)$ between groups\n",
            "of units is surjective; (2) a reduced Hermite ring is an \\textsl{EDR} iff it is\n",
            "a pre-Schreier ring and for each $a\\in R$, every zero determinant unimodular\n",
            "$2\\times 2$ matrix with entries in $R/Ra$ lifts to a zero determinant matrix\n",
            "with entries in $R$; (3) a B\\'{e}zout domain $R$ is an \\textsl{EDD} iff for all\n",
            "triples $(a,b,c)\\in R^3$ there exists a unimodular pair $(e,f)\\in R^2$ such\n",
            "that $(a,e)$ and $(be+af,1-a-bc)$ are unimodular pairs. We use these criteria\n",
            "to show that each B\\'{e}zout ring $R$ that is an $(SU)_2$ ring (as introduced\n",
            "by Lorenzini) such that for each nonzero $a\\in R$ there exists no nontrivial\n",
            "self-dual projective $R/Ra$-module of rank $1$ generated by $2$ elements (e.g.,\n",
            "all its elements are squares), is an \\textsl{EDR}.\n",
            "['We reobtain and often refine prior criteria due to Kaplansky, McGovern,\\nRoitman, Shchedryk, Wiegand, and Zabavsky--Bilavska and obtain new criteria for\\na Hermite ring to be an \\\\textsl{EDR}.', \"We mention three criteria: (1) a Hermite\\nring $R$ is an \\\\textsl{EDR} iff for all pairs $(a,c)\\\\in R^2$, the product\\nhomomorphism $U(R/Rac)\\\\times U\\\\bigl(R/Rc(1-a)\\\\bigr)\\\\to U(R/Rc)$ between groups\\nof units is surjective; (2) a reduced Hermite ring is an \\\\textsl{EDR} iff it is\\na pre-Schreier ring and for each $a\\\\in R$, every zero determinant unimodular\\n$2\\\\times 2$ matrix with entries in $R/Ra$ lifts to a zero determinant matrix\\nwith entries in $R$; (3) a B\\\\'{e}zout domain $R$ is an \\\\textsl{EDD} iff for all\\ntriples $(a,b,c)\\\\in R^3$ there exists a unimodular pair $(e,f)\\\\in R^2$ such\\nthat $(a,e)$ and $(be+af,1-a-bc)$ are unimodular pairs.\", \"We use these criteria\\nto show that each B\\\\'{e}zout ring $R$ that is an $(SU)_2$ ring (as introduced\\nby Lorenzini) such that for each nonzero $a\\\\in R$ there exists no nontrivial\\nself-dual projective $R/Ra$-module of rank $1$ generated by $2$ elements (e.g.,\\nall its elements are squares), is an \\\\textsl{EDR}.\"]\n",
            "Chunks for abstract: Nontopological fermionic solitons exist across a diverse range of particle\n",
            "physics models and have rich cosmological implications. This study establishes\n",
            "a general framework for calculating fermionic soliton profiles under arbitrary\n",
            "scalar potentials, utilizing relativistic mean field theory to accurately\n",
            "depict the interaction between the fermion condensate and the background scalar\n",
            "field. Within this framework, the conventional fermion bound states are\n",
            "revealed as a subset of fermionic solitons. In addition, we demonstrate how the\n",
            "analytical formulae in previous studies are derived as special cases of our\n",
            "algorithm, discussing the validity of such approximations. Furthermore, we\n",
            "explore the phenomenology of fermionic solitons, highlighting new formation\n",
            "mechanisms and evolution paths, and reconsidering the possibility of collapse\n",
            "into primordial black holes.\n",
            "['Nontopological fermionic solitons exist across a diverse range of particle\\nphysics models and have rich cosmological implications.', 'This study establishes\\na general framework for calculating fermionic soliton profiles under arbitrary\\nscalar potentials, utilizing relativistic mean field theory to accurately\\ndepict the interaction between the fermion condensate and the background scalar\\nfield.', 'Within this framework, the conventional fermion bound states are\\nrevealed as a subset of fermionic solitons.', 'In addition, we demonstrate how the\\nanalytical formulae in previous studies are derived as special cases of our\\nalgorithm, discussing the validity of such approximations.', 'Furthermore, we\\nexplore the phenomenology of fermionic solitons, highlighting new formation\\nmechanisms and evolution paths, and reconsidering the possibility of collapse\\ninto primordial black holes.']\n",
            "Chunks for abstract: Walking is the most sustainable form of urban mobility, but is compromised by\n",
            "uncomfortable or unhealthy sun exposure, which is an increasing problem due to\n",
            "global warming. Shade from buildings can provide cooling and protection for\n",
            "pedestrians, but the extent of this potential benefit is unknown. Here we\n",
            "explore the potential for shaded walking, using building footprints and street\n",
            "networks from both synthetic and real cities. We introduce a route choice model\n",
            "with a sun avoidance parameter $\\alpha$ and define the CoolWalkability metric\n",
            "to measure opportunities for walking in shade. We derive analytically that on a\n",
            "regular grid with constant building heights, CoolWalkability is independent of\n",
            "$\\alpha$, and that the grid provides no CoolWalkability benefit for\n",
            "shade-seeking individuals compared to the shortest path. However, variations in\n",
            "street geometry and building heights create such benefits. We further uncover\n",
            "that the potential for shaded routing differs between grid-like and irregular\n",
            "street networks, forms local clusters, and is sensitive to the mapped network\n",
            "geometry. Our research identifies the limitations and potential of shade for\n",
            "cool, active travel, and is a first step towards a rigorous understanding of\n",
            "shade provision for sustainable mobility in cities.\n",
            "['Walking is the most sustainable form of urban mobility, but is compromised by\\nuncomfortable or unhealthy sun exposure, which is an increasing problem due to\\nglobal warming.', 'Shade from buildings can provide cooling and protection for\\npedestrians, but the extent of this potential benefit is unknown.', 'Here we\\nexplore the potential for shaded walking, using building footprints and street\\nnetworks from both synthetic and real cities.', 'We introduce a route choice model\\nwith a sun avoidance parameter $\\\\alpha$ and define the CoolWalkability metric\\nto measure opportunities for walking in shade.', 'We derive analytically that on a\\nregular grid with constant building heights, CoolWalkability is independent of\\n$\\\\alpha$, and that the grid provides no CoolWalkability benefit for\\nshade-seeking individuals compared to the shortest path.', 'However, variations in\\nstreet geometry and building heights create such benefits.', 'We further uncover\\nthat the potential for shaded routing differs between grid-like and irregular\\nstreet networks, forms local clusters, and is sensitive to the mapped network\\ngeometry.', 'Our research identifies the limitations and potential of shade for\\ncool, active travel, and is a first step towards a rigorous understanding of\\nshade provision for sustainable mobility in cities.']\n",
            "Chunks for abstract: Perturbative quantum gravity starts from prescribing a background metric.\n",
            "That background metric is then used in order to carry out two separate steps:\n",
            "1. One splits the non-perturbative metric into background and deviation from it\n",
            "(graviton) and expands the action in terms of the graviton which results in an\n",
            "ifinite series of unknown radius of convergence. 2. One constructs a Fock\n",
            "representation for the graviton and performs perturbative graviton quantum\n",
            "field theory on the fixed background as dictated by the perturbative action.\n",
            "The result is a non-renormalisable theory without predictive power.\n",
            "  It is therefore widely believed that a non-perturbative approach is mandatory\n",
            "in order to construct a fundamental, not only effective, predictive quantum\n",
            "field theory of the gravitational interaction. Since perturbation theory is by\n",
            "definition background dependent, the notions of background dependence (BD) and\n",
            "perturbation theory (PT) are often considered as symbiotic, as if they imply\n",
            "each other.\n",
            "  In the present work we point out that there is no such symbiosis, these two\n",
            "notions are in fact logically independent. In particular, one can use BD\n",
            "structures while while not using PT at all. Specifically, we construct BD Fock\n",
            "representations (step 2 above) for the full, non-perturbative metric rather\n",
            "than the graviton (not step 1 above) and therefore never perform a perturbative\n",
            "expansion. Despite the fact that the gravitational Lagrangean is a\n",
            "non-polynomial, not even analytic, function of the metric we show that e.g. the\n",
            "Hamiltonian constraint with any density weight can be defined as a quadratic\n",
            "form with dense form domain in such a representation.\n",
            "['Perturbative quantum gravity starts from prescribing a background metric.', 'That background metric is then used in order to carry out two separate steps:\\n1.', 'One splits the non-perturbative metric into background and deviation from it\\n(graviton) and expands the action in terms of the graviton which results in an\\nifinite series of unknown radius of convergence.', '2.', 'One constructs a Fock\\nrepresentation for the graviton and performs perturbative graviton quantum\\nfield theory on the fixed background as dictated by the perturbative action.', 'The result is a non-renormalisable theory without predictive power.', 'It is therefore widely believed that a non-perturbative approach is mandatory\\nin order to construct a fundamental, not only effective, predictive quantum\\nfield theory of the gravitational interaction.', 'Since perturbation theory is by\\ndefinition background dependent, the notions of background dependence (BD) and\\nperturbation theory (PT) are often considered as symbiotic, as if they imply\\neach other.', 'In the present work we point out that there is no such symbiosis, these two\\nnotions are in fact logically independent.', 'In particular, one can use BD\\nstructures while while not using PT at all.', 'Specifically, we construct BD Fock\\nrepresentations (step 2 above) for the full, non-perturbative metric rather\\nthan the graviton (not step 1 above) and therefore never perform a perturbative\\nexpansion.', 'Despite the fact that the gravitational Lagrangean is a\\nnon-polynomial, not even analytic, function of the metric we show that e.g.', 'the\\nHamiltonian constraint with any density weight can be defined as a quadratic\\nform with dense form domain in such a representation.']\n",
            "Chunks for abstract: In this paper, we are mainly concerned with the well-posed problem of the\n",
            "fractional Keller--Segel system in the framework of variable Lebesgue spaces.\n",
            "Based on carefully examining the algebraical structure of the system, we\n",
            "reduced the fractional Keller--Segel system into the generalized nonlinear heat\n",
            "equation to overcome the difficulties caused by the boundedness of the Riesz\n",
            "potential in a variable Lebesgue spaces, then by mixing some structural\n",
            "properties of the variable Lebesgue spaces with the optimal decay estimates of\n",
            "the fractional heat kernel, we were able to establish two well-posedness\n",
            "results of the fractional Keller--Segel system in this functional setting.\n",
            "['In this paper, we are mainly concerned with the well-posed problem of the\\nfractional Keller--Segel system in the framework of variable Lebesgue spaces.', 'Based on carefully examining the algebraical structure of the system, we\\nreduced the fractional Keller--Segel system into the generalized nonlinear heat\\nequation to overcome the difficulties caused by the boundedness of the Riesz\\npotential in a variable Lebesgue spaces, then by mixing some structural\\nproperties of the variable Lebesgue spaces with the optimal decay estimates of\\nthe fractional heat kernel, we were able to establish two well-posedness\\nresults of the fractional Keller--Segel system in this functional setting.']\n",
            "Chunks for abstract: Reinforcement learning policies are typically represented by black-box neural\n",
            "networks, which are non-interpretable and not well-suited for safety-critical\n",
            "domains. To address both of these issues, we propose constrained normalizing\n",
            "flow policies as interpretable and safe-by-construction policy models. We\n",
            "achieve safety for reinforcement learning problems with instantaneous safety\n",
            "constraints, for which we can exploit domain knowledge by analytically\n",
            "constructing a normalizing flow that ensures constraint satisfaction. The\n",
            "normalizing flow corresponds to an interpretable sequence of transformations on\n",
            "action samples, each ensuring alignment with respect to a particular\n",
            "constraint. Our experiments reveal benefits beyond interpretability in an\n",
            "easier learning objective and maintained constraint satisfaction throughout the\n",
            "entire learning process. Our approach leverages constraints over reward\n",
            "engineering while offering enhanced interpretability, safety, and direct means\n",
            "of providing domain knowledge to the agent without relying on complex reward\n",
            "functions.\n",
            "['Reinforcement learning policies are typically represented by black-box neural\\nnetworks, which are non-interpretable and not well-suited for safety-critical\\ndomains.', 'To address both of these issues, we propose constrained normalizing\\nflow policies as interpretable and safe-by-construction policy models.', 'We\\nachieve safety for reinforcement learning problems with instantaneous safety\\nconstraints, for which we can exploit domain knowledge by analytically\\nconstructing a normalizing flow that ensures constraint satisfaction.', 'The\\nnormalizing flow corresponds to an interpretable sequence of transformations on\\naction samples, each ensuring alignment with respect to a particular\\nconstraint.', 'Our experiments reveal benefits beyond interpretability in an\\neasier learning objective and maintained constraint satisfaction throughout the\\nentire learning process.', 'Our approach leverages constraints over reward\\nengineering while offering enhanced interpretability, safety, and direct means\\nof providing domain knowledge to the agent without relying on complex reward\\nfunctions.']\n",
            "Chunks for abstract: Humans seemingly incorporate potential touch signals in their perception. Our\n",
            "goal is to equip robots with a similar capability, which we term Imagine2touch.\n",
            "Imagine2touch aims to predict the expected touch signal based on a visual patch\n",
            "representing the area to be touched. We use ReSkin, an inexpensive and compact\n",
            "touch sensor to collect the required dataset through random touching of five\n",
            "basic geometric shapes, and one tool. We train Imagine2touch on two out of\n",
            "those shapes and validate it on the ood. tool. We demonstrate the efficacy of\n",
            "Imagine2touch through its application to the downstream task of object\n",
            "recognition. In this task, we evaluate Imagine2touch performance in two\n",
            "experiments, together comprising 5 out of training distribution objects.\n",
            "Imagine2touch achieves an object recognition accuracy of 58% after ten touches\n",
            "per object, surpassing a proprioception baseline.\n",
            "['Humans seemingly incorporate potential touch signals in their perception.', 'Our\\ngoal is to equip robots with a similar capability, which we term Imagine2touch.', 'Imagine2touch aims to predict the expected touch signal based on a visual patch\\nrepresenting the area to be touched.', 'We use ReSkin, an inexpensive and compact\\ntouch sensor to collect the required dataset through random touching of five\\nbasic geometric shapes, and one tool.', 'We train Imagine2touch on two out of\\nthose shapes and validate it on the ood.', 'tool.', 'We demonstrate the efficacy of\\nImagine2touch through its application to the downstream task of object\\nrecognition.', 'In this task, we evaluate Imagine2touch performance in two\\nexperiments, together comprising 5 out of training distribution objects.', 'Imagine2touch achieves an object recognition accuracy of 58% after ten touches\\nper object, surpassing a proprioception baseline.']\n",
            "Chunks for abstract: We perform a nonperturbative lattice study of the electroweak phase\n",
            "transition in the real singlet scalar extension of the Standard Model.We\n",
            "consider both the heavy and light singlet-like scalar regimes at non-zero\n",
            "singlet-doublet mixing angle. After reviewing features of the lattice method\n",
            "relevant for phase transition studies, we analyze the dependence of phase\n",
            "transition thermodynamics on phenomenologically relevant parameters. In the\n",
            "heavy singlet-like scalar regime, we find that the transition is crossover for\n",
            "small doublet-singlet mixing angles, despite the presence of an energy barrier\n",
            "in the tree-level potential. The transition becomes first order for\n",
            "sufficiently large mixing angles. We find two-loop perturbation theory to agree\n",
            "closely with the lattice results for all thermodynamical quantities considered\n",
            "here (critical temperature, order parameter discontinuity, latent heat) when\n",
            "the transition is strongly first order. For the light singlet-like scalar\n",
            "regime relevant to exotic Higgs decays, we update previous one-loop\n",
            "perturbative results using the two-loop loop dimensionally reduced effective\n",
            "field theory and assess the nature of the transition with lattice simulations\n",
            "at set of benchmark parameter points. For fixed singlet-like scalar mass the\n",
            "transition becomes crossover when the magnitude of the Higgs-singlet portal\n",
            "coupling is small. We perform our simulations in the high-temperature effective\n",
            "theory, which we briefly review, and present analytic expressions for the\n",
            "relevant lattice-continuum relations.\n",
            "['We perform a nonperturbative lattice study of the electroweak phase\\ntransition in the real singlet scalar extension of the Standard Model.We\\nconsider both the heavy and light singlet-like scalar regimes at non-zero\\nsinglet-doublet mixing angle.', 'After reviewing features of the lattice method\\nrelevant for phase transition studies, we analyze the dependence of phase\\ntransition thermodynamics on phenomenologically relevant parameters.', 'In the\\nheavy singlet-like scalar regime, we find that the transition is crossover for\\nsmall doublet-singlet mixing angles, despite the presence of an energy barrier\\nin the tree-level potential.', 'The transition becomes first order for\\nsufficiently large mixing angles.', 'We find two-loop perturbation theory to agree\\nclosely with the lattice results for all thermodynamical quantities considered\\nhere (critical temperature, order parameter discontinuity, latent heat) when\\nthe transition is strongly first order.', 'For the light singlet-like scalar\\nregime relevant to exotic Higgs decays, we update previous one-loop\\nperturbative results using the two-loop loop dimensionally reduced effective\\nfield theory and assess the nature of the transition with lattice simulations\\nat set of benchmark parameter points.', 'For fixed singlet-like scalar mass the\\ntransition becomes crossover when the magnitude of the Higgs-singlet portal\\ncoupling is small.', 'We perform our simulations in the high-temperature effective\\ntheory, which we briefly review, and present analytic expressions for the\\nrelevant lattice-continuum relations.']\n",
            "Chunks for abstract: Shot charts in basketball analytics provide an indispensable tool for\n",
            "evaluating players' shooting performance by visually representing the\n",
            "distribution of field goal attempts across different court locations. However,\n",
            "conventional methods often overlook the bounded nature of the basketball court,\n",
            "leading to inaccurate representations, particularly along the boundaries and\n",
            "corners. In this paper, we propose a novel model-based approach to shot chart\n",
            "estimation and visualization that explicitly considers the physical boundaries\n",
            "of the basketball court. By employing Gaussian mixtures for bounded data, our\n",
            "methodology allows to obtain more accurate estimation of shot density\n",
            "distributions for both made and missed shots. Bayes' rule is then applied to\n",
            "derive estimates for the probability of successful shooting from any given\n",
            "locations, and to identify the regions with the highest expected scores. To\n",
            "illustrate the efficacy of our proposal, we apply it to data from the 2022-23\n",
            "NBA regular season, showing its usefulness through detailed analyses of shot\n",
            "patterns for two prominent players.\n",
            "[\"Shot charts in basketball analytics provide an indispensable tool for\\nevaluating players' shooting performance by visually representing the\\ndistribution of field goal attempts across different court locations.\", 'However,\\nconventional methods often overlook the bounded nature of the basketball court,\\nleading to inaccurate representations, particularly along the boundaries and\\ncorners.', 'In this paper, we propose a novel model-based approach to shot chart\\nestimation and visualization that explicitly considers the physical boundaries\\nof the basketball court.', 'By employing Gaussian mixtures for bounded data, our\\nmethodology allows to obtain more accurate estimation of shot density\\ndistributions for both made and missed shots.', \"Bayes' rule is then applied to\\nderive estimates for the probability of successful shooting from any given\\nlocations, and to identify the regions with the highest expected scores.\", 'To\\nillustrate the efficacy of our proposal, we apply it to data from the 2022-23\\nNBA regular season, showing its usefulness through detailed analyses of shot\\npatterns for two prominent players.']\n",
            "Chunks for abstract: A new algebra, hitherto not encountered in the usual Lie algebraic varieties\n",
            "or supervarieties, is introduced. The paper explores the rich and novel\n",
            "structure of the algebra, and it compares it on the one hand with the\n",
            "Jordan-Lie Superalgebras studied by Okubo and Kamiya, and on the other, with\n",
            "the four usual Euclidean division rings of the reals (R), the complexes (C),\n",
            "the quaternions (H) and the octonions (O), key algebraic properties of which\n",
            "the algebra is seen to combine, alter, extend and generalise. A potential\n",
            "physical application of the algebra is briefly alluded to at the end.\n",
            "['A new algebra, hitherto not encountered in the usual Lie algebraic varieties\\nor supervarieties, is introduced.', 'The paper explores the rich and novel\\nstructure of the algebra, and it compares it on the one hand with the\\nJordan-Lie Superalgebras studied by Okubo and Kamiya, and on the other, with\\nthe four usual Euclidean division rings of the reals (R), the complexes (C),\\nthe quaternions (H) and the octonions (O), key algebraic properties of which\\nthe algebra is seen to combine, alter, extend and generalise.', 'A potential\\nphysical application of the algebra is briefly alluded to at the end.']\n",
            "Chunks for abstract: This paper presents the TartuNLP team submission to EvaLatin 2024 shared task\n",
            "of the emotion polarity detection for historical Latin texts. Our system relies\n",
            "on two distinct approaches to annotating training data for supervised learning:\n",
            "1) creating heuristics-based labels by adopting the polarity lexicon provided\n",
            "by the organizers and 2) generating labels with GPT4. We employed parameter\n",
            "efficient fine-tuning using the adapters framework and experimented with both\n",
            "monolingual and cross-lingual knowledge transfer for training language and task\n",
            "adapters. Our submission with the LLM-generated labels achieved the overall\n",
            "first place in the emotion polarity detection task. Our results show that\n",
            "LLM-based annotations show promising results on texts in Latin.\n",
            "['This paper presents the TartuNLP team submission to EvaLatin 2024 shared task\\nof the emotion polarity detection for historical Latin texts.', 'Our system relies\\non two distinct approaches to annotating training data for supervised learning:\\n1) creating heuristics-based labels by adopting the polarity lexicon provided\\nby the organizers and 2) generating labels with GPT4.', 'We employed parameter\\nefficient fine-tuning using the adapters framework and experimented with both\\nmonolingual and cross-lingual knowledge transfer for training language and task\\nadapters.', 'Our submission with the LLM-generated labels achieved the overall\\nfirst place in the emotion polarity detection task.', 'Our results show that\\nLLM-based annotations show promising results on texts in Latin.']\n",
            "Chunks for abstract: An accurate detection and tracking of devices such as guiding catheters in\n",
            "live X-ray image acquisitions is an essential prerequisite for endovascular\n",
            "cardiac interventions. This information is leveraged for procedural guidance,\n",
            "e.g., directing stent placements. To ensure procedural safety and efficacy,\n",
            "there is a need for high robustness no failures during tracking. To achieve\n",
            "that, one needs to efficiently tackle challenges, such as: device obscuration\n",
            "by contrast agent or other external devices or wires, changes in field-of-view\n",
            "or acquisition angle, as well as the continuous movement due to cardiac and\n",
            "respiratory motion. To overcome the aforementioned challenges, we propose a\n",
            "novel approach to learn spatio-temporal features from a very large data cohort\n",
            "of over 16 million interventional X-ray frames using self-supervision for image\n",
            "sequence data. Our approach is based on a masked image modeling technique that\n",
            "leverages frame interpolation based reconstruction to learn fine inter-frame\n",
            "temporal correspondences. The features encoded in the resulting model are\n",
            "fine-tuned downstream. Our approach achieves state-of-the-art performance and\n",
            "in particular robustness compared to ultra optimized reference solutions (that\n",
            "use multi-stage feature fusion, multi-task and flow regularization). The\n",
            "experiments show that our method achieves 66.31% reduction in maximum tracking\n",
            "error against reference solutions (23.20% when flow regularization is used);\n",
            "achieving a success score of 97.95% at a 3x faster inference speed of 42\n",
            "frames-per-second (on GPU). The results encourage the use of our approach in\n",
            "various other tasks within interventional image analytics that require\n",
            "effective understanding of spatio-temporal semantics.\n",
            "['An accurate detection and tracking of devices such as guiding catheters in\\nlive X-ray image acquisitions is an essential prerequisite for endovascular\\ncardiac interventions.', 'This information is leveraged for procedural guidance,\\ne.g., directing stent placements.', 'To ensure procedural safety and efficacy,\\nthere is a need for high robustness no failures during tracking.', 'To achieve\\nthat, one needs to efficiently tackle challenges, such as: device obscuration\\nby contrast agent or other external devices or wires, changes in field-of-view\\nor acquisition angle, as well as the continuous movement due to cardiac and\\nrespiratory motion.', 'To overcome the aforementioned challenges, we propose a\\nnovel approach to learn spatio-temporal features from a very large data cohort\\nof over 16 million interventional X-ray frames using self-supervision for image\\nsequence data.', 'Our approach is based on a masked image modeling technique that\\nleverages frame interpolation based reconstruction to learn fine inter-frame\\ntemporal correspondences.', 'The features encoded in the resulting model are\\nfine-tuned downstream.', 'Our approach achieves state-of-the-art performance and\\nin particular robustness compared to ultra optimized reference solutions (that\\nuse multi-stage feature fusion, multi-task and flow regularization).', 'The\\nexperiments show that our method achieves 66.31% reduction in maximum tracking\\nerror against reference solutions (23.20% when flow regularization is used);\\nachieving a success score of 97.95% at a 3x faster inference speed of 42\\nframes-per-second (on GPU).', 'The results encourage the use of our approach in\\nvarious other tasks within interventional image analytics that require\\neffective understanding of spatio-temporal semantics.']\n",
            "Chunks for abstract: Recent text and image foundation models are incredibly impressive, and these\n",
            "models are attracting an ever-increasing portion of research resources. In this\n",
            "position piece we aim to shift the ML research community's priorities ever so\n",
            "slightly to a different modality: tabular data. Tabular data is the dominant\n",
            "modality in many fields, yet it is given hardly any research attention and\n",
            "significantly lags behind in terms of scale and power. We believe the time is\n",
            "now to start developing tabular foundation models, or what we coin a Large\n",
            "Tabular Model (LTM). LTMs could revolutionise the way science and ML use\n",
            "tabular data: not as single datasets that are analyzed in a vacuum, but\n",
            "contextualized with respect to related datasets. The potential impact is\n",
            "far-reaching: from few-shot tabular models to automating data science; from\n",
            "out-of-distribution synthetic data to empowering multidisciplinary scientific\n",
            "discovery. We intend to excite reflections on the modalities we study, and\n",
            "convince some researchers to study large tabular models.\n",
            "['Recent text and image foundation models are incredibly impressive, and these\\nmodels are attracting an ever-increasing portion of research resources.', \"In this\\nposition piece we aim to shift the ML research community's priorities ever so\\nslightly to a different modality: tabular data.\", 'Tabular data is the dominant\\nmodality in many fields, yet it is given hardly any research attention and\\nsignificantly lags behind in terms of scale and power.', 'We believe the time is\\nnow to start developing tabular foundation models, or what we coin a Large\\nTabular Model (LTM).', 'LTMs could revolutionise the way science and ML use\\ntabular data: not as single datasets that are analyzed in a vacuum, but\\ncontextualized with respect to related datasets.', 'The potential impact is\\nfar-reaching: from few-shot tabular models to automating data science; from\\nout-of-distribution synthetic data to empowering multidisciplinary scientific\\ndiscovery.', 'We intend to excite reflections on the modalities we study, and\\nconvince some researchers to study large tabular models.']\n",
            "Chunks for abstract: There are two paradigms in Federated Learning (FL): parallel FL (PFL), where\n",
            "models are trained in a parallel manner across clients; and sequential FL\n",
            "(SFL), where models are trained in a sequential manner across clients. In\n",
            "contrast to that of PFL, the convergence theory of SFL on heterogeneous data is\n",
            "still lacking. To resolve the theoretical dilemma of SFL, we establish sharp\n",
            "convergence guarantees for SFL on heterogeneous data with both upper and lower\n",
            "bounds. Specifically, we derive the upper bounds for strongly convex, general\n",
            "convex and non-convex objective functions, and construct the matching lower\n",
            "bounds for the strongly convex and general convex objective functions. Then, we\n",
            "compare the upper bounds of SFL with those of PFL, showing that SFL outperforms\n",
            "PFL (at least, when the level of heterogeneity is relatively high).\n",
            "Experimental results on quadratic functions and real data sets validate the\n",
            "counterintuitive comparison result.\n",
            "['There are two paradigms in Federated Learning (FL): parallel FL (PFL), where\\nmodels are trained in a parallel manner across clients; and sequential FL\\n(SFL), where models are trained in a sequential manner across clients.', 'In\\ncontrast to that of PFL, the convergence theory of SFL on heterogeneous data is\\nstill lacking.', 'To resolve the theoretical dilemma of SFL, we establish sharp\\nconvergence guarantees for SFL on heterogeneous data with both upper and lower\\nbounds.', 'Specifically, we derive the upper bounds for strongly convex, general\\nconvex and non-convex objective functions, and construct the matching lower\\nbounds for the strongly convex and general convex objective functions.', 'Then, we\\ncompare the upper bounds of SFL with those of PFL, showing that SFL outperforms\\nPFL (at least, when the level of heterogeneity is relatively high).', 'Experimental results on quadratic functions and real data sets validate the\\ncounterintuitive comparison result.']\n",
            "Chunks for abstract: Sports analysis and viewing play a pivotal role in the current sports domain,\n",
            "offering significant value not only to coaches and athletes but also to fans\n",
            "and the media. In recent years, the rapid development of virtual reality (VR)\n",
            "and augmented reality (AR) technologies have introduced a new platform for\n",
            "watching games. Visualization of sports competitions in VR/AR represents a\n",
            "revolutionary technology, providing audiences with a novel immersive viewing\n",
            "experience. However, there is still a lack of related research in this area. In\n",
            "this work, we present for the first time a comprehensive system for sports\n",
            "competition analysis and real-time visualization on VR/AR platforms. First, we\n",
            "utilize multiview LiDARs and cameras to collect multimodal game data.\n",
            "Subsequently, we propose a framework for multi-player tracking and pose\n",
            "estimation based on a limited amount of supervised data, which extracts precise\n",
            "player positions and movements from point clouds and images. Moreover, we\n",
            "perform avatar modeling of players to obtain their 3D models. Ultimately, using\n",
            "these 3D player data, we conduct competition analysis and real-time\n",
            "visualization on VR/AR. Extensive quantitative experiments demonstrate the\n",
            "accuracy and robustness of our multi-player tracking and pose estimation\n",
            "framework. The visualization results showcase the immense potential of our\n",
            "sports visualization system on the domain of watching games on VR/AR devices.\n",
            "The multimodal competition dataset we collected and all related code will be\n",
            "released soon.\n",
            "['Sports analysis and viewing play a pivotal role in the current sports domain,\\noffering significant value not only to coaches and athletes but also to fans\\nand the media.', 'In recent years, the rapid development of virtual reality (VR)\\nand augmented reality (AR) technologies have introduced a new platform for\\nwatching games.', 'Visualization of sports competitions in VR/AR represents a\\nrevolutionary technology, providing audiences with a novel immersive viewing\\nexperience.', 'However, there is still a lack of related research in this area.', 'In\\nthis work, we present for the first time a comprehensive system for sports\\ncompetition analysis and real-time visualization on VR/AR platforms.', 'First, we\\nutilize multiview LiDARs and cameras to collect multimodal game data.', 'Subsequently, we propose a framework for multi-player tracking and pose\\nestimation based on a limited amount of supervised data, which extracts precise\\nplayer positions and movements from point clouds and images.', 'Moreover, we\\nperform avatar modeling of players to obtain their 3D models.', 'Ultimately, using\\nthese 3D player data, we conduct competition analysis and real-time\\nvisualization on VR/AR.', 'Extensive quantitative experiments demonstrate the\\naccuracy and robustness of our multi-player tracking and pose estimation\\nframework.', 'The visualization results showcase the immense potential of our\\nsports visualization system on the domain of watching games on VR/AR devices.', 'The multimodal competition dataset we collected and all related code will be\\nreleased soon.']\n",
            "Chunks for abstract: Whistleblowing is essential for ensuring transparency and accountability in\n",
            "both public and private sectors. However, (potential) whistleblowers often fear\n",
            "or face retaliation, even when reporting anonymously. The specific content of\n",
            "their disclosures and their distinct writing style may re-identify them as the\n",
            "source. Legal measures, such as the EU WBD, are limited in their scope and\n",
            "effectiveness. Therefore, computational methods to prevent re-identification\n",
            "are important complementary tools for encouraging whistleblowers to come\n",
            "forward. However, current text sanitization tools follow a one-size-fits-all\n",
            "approach and take an overly limited view of anonymity. They aim to mitigate\n",
            "identification risk by replacing typical high-risk words (such as person names\n",
            "and other NE labels) and combinations thereof with placeholders. Such an\n",
            "approach, however, is inadequate for the whistleblowing scenario since it\n",
            "neglects further re-identification potential in textual features, including\n",
            "writing style. Therefore, we propose, implement, and evaluate a novel\n",
            "classification and mitigation strategy for rewriting texts that involves the\n",
            "whistleblower in the assessment of the risk and utility. Our prototypical tool\n",
            "semi-automatically evaluates risk at the word/term level and applies\n",
            "risk-adapted anonymization techniques to produce a grammatically disjointed yet\n",
            "appropriately sanitized text. We then use a LLM that we fine-tuned for\n",
            "paraphrasing to render this text coherent and style-neutral. We evaluate our\n",
            "tool's effectiveness using court cases from the ECHR and excerpts from a\n",
            "real-world whistleblower testimony and measure the protection against\n",
            "authorship attribution (AA) attacks and utility loss statistically using the\n",
            "popular IMDb62 movie reviews dataset. Our method can significantly reduce AA\n",
            "accuracy from 98.81% to 31.22%, while preserving up to 73.1% of the original\n",
            "content's semantics.\n",
            "['Whistleblowing is essential for ensuring transparency and accountability in\\nboth public and private sectors.', 'However, (potential) whistleblowers often fear\\nor face retaliation, even when reporting anonymously.', 'The specific content of\\ntheir disclosures and their distinct writing style may re-identify them as the\\nsource.', 'Legal measures, such as the EU WBD, are limited in their scope and\\neffectiveness.', 'Therefore, computational methods to prevent re-identification\\nare important complementary tools for encouraging whistleblowers to come\\nforward.', 'However, current text sanitization tools follow a one-size-fits-all\\napproach and take an overly limited view of anonymity.', 'They aim to mitigate\\nidentification risk by replacing typical high-risk words (such as person names\\nand other NE labels) and combinations thereof with placeholders.', 'Such an\\napproach, however, is inadequate for the whistleblowing scenario since it\\nneglects further re-identification potential in textual features, including\\nwriting style.', 'Therefore, we propose, implement, and evaluate a novel\\nclassification and mitigation strategy for rewriting texts that involves the\\nwhistleblower in the assessment of the risk and utility.', 'Our prototypical tool\\nsemi-automatically evaluates risk at the word/term level and applies\\nrisk-adapted anonymization techniques to produce a grammatically disjointed yet\\nappropriately sanitized text.', 'We then use a LLM that we fine-tuned for\\nparaphrasing to render this text coherent and style-neutral.', \"We evaluate our\\ntool's effectiveness using court cases from the ECHR and excerpts from a\\nreal-world whistleblower testimony and measure the protection against\\nauthorship attribution (AA) attacks and utility loss statistically using the\\npopular IMDb62 movie reviews dataset.\", \"Our method can significantly reduce AA\\naccuracy from 98.81% to 31.22%, while preserving up to 73.1% of the original\\ncontent's semantics.\"]\n",
            "Chunks for abstract: Atmospheric tomography, the problem of reconstructing atmospheric turbulence\n",
            "profiles from wavefront sensor measurements, is an integral part of many\n",
            "adaptive optics systems used for enhancing the image quality of ground-based\n",
            "telescopes. Singular-value and frame decompositions of the underlying\n",
            "atmospheric tomography operator can reveal useful analytical information on\n",
            "this inverse problem, as well as serve as the basis of efficient numerical\n",
            "reconstruction algorithms. In this paper, we extend existing singular value\n",
            "decompositions to more realistic Sobolev settings including weighted inner\n",
            "products, and derive an explicit representation of a frame-based (approximate)\n",
            "solution operator. These investigations form the basis of efficient numerical\n",
            "solution methods, which we analyze via numerical simulations for the\n",
            "challenging, real-world Adaptive Optics system of the Extremely Large Telescope\n",
            "using the entirely MATLAB-based simulation tool MOST.\n",
            "['Atmospheric tomography, the problem of reconstructing atmospheric turbulence\\nprofiles from wavefront sensor measurements, is an integral part of many\\nadaptive optics systems used for enhancing the image quality of ground-based\\ntelescopes.', 'Singular-value and frame decompositions of the underlying\\natmospheric tomography operator can reveal useful analytical information on\\nthis inverse problem, as well as serve as the basis of efficient numerical\\nreconstruction algorithms.', 'In this paper, we extend existing singular value\\ndecompositions to more realistic Sobolev settings including weighted inner\\nproducts, and derive an explicit representation of a frame-based (approximate)\\nsolution operator.', 'These investigations form the basis of efficient numerical\\nsolution methods, which we analyze via numerical simulations for the\\nchallenging, real-world Adaptive Optics system of the Extremely Large Telescope\\nusing the entirely MATLAB-based simulation tool MOST.']\n",
            "Chunks for abstract: We focus on real-time air quality monitoring systems that rely on devices\n",
            "installed on automobiles in this research. We investigate an opportunistic\n",
            "communication model in which devices can send the measured data directly to the\n",
            "air quality server through a 4G communication channel or via Wi-Fi to adjacent\n",
            "devices or the so-called Road Side Units deployed along the road. We aim to\n",
            "reduce 4G costs while assuring data latency, where the data latency is defined\n",
            "as the amount of time it takes for data to reach the server. We propose an\n",
            "offloading scheme that leverages Q-learning to accomplish the purpose. The\n",
            "experiment results show that our offloading method significantly cuts down\n",
            "around 40-50% of the 4G communication cost while keeping the latency of 99.5%\n",
            "packets smaller than the required threshold.\n",
            "['We focus on real-time air quality monitoring systems that rely on devices\\ninstalled on automobiles in this research.', 'We investigate an opportunistic\\ncommunication model in which devices can send the measured data directly to the\\nair quality server through a 4G communication channel or via Wi-Fi to adjacent\\ndevices or the so-called Road Side Units deployed along the road.', 'We aim to\\nreduce 4G costs while assuring data latency, where the data latency is defined\\nas the amount of time it takes for data to reach the server.', 'We propose an\\noffloading scheme that leverages Q-learning to accomplish the purpose.', 'The\\nexperiment results show that our offloading method significantly cuts down\\naround 40-50% of the 4G communication cost while keeping the latency of 99.5%\\npackets smaller than the required threshold.']\n",
            "Chunks for abstract: This paper presents Callico, a web-based open source platform designed to\n",
            "simplify the annotation process in document recognition projects. The move\n",
            "towards data-centric AI in machine learning and deep learning underscores the\n",
            "importance of high-quality data, and the need for specialised tools that\n",
            "increase the efficiency and effectiveness of generating such data. For document\n",
            "image annotation, Callico offers dual-display annotation for digitised\n",
            "documents, enabling simultaneous visualisation and annotation of scanned images\n",
            "and text. This capability is critical for OCR and HTR model training, document\n",
            "layout analysis, named entity recognition, form-based key value annotation or\n",
            "hierarchical structure annotation with element grouping. The platform supports\n",
            "collaborative annotation with versatile features backed by a commitment to open\n",
            "source development, high-quality code standards and easy deployment via Docker.\n",
            "Illustrative use cases - including the transcription of the Belfort municipal\n",
            "registers, the indexing of French World War II prisoners for the ICRC, and the\n",
            "extraction of personal information from the Socface project's census lists -\n",
            "demonstrate Callico's applicability and utility.\n",
            "['This paper presents Callico, a web-based open source platform designed to\\nsimplify the annotation process in document recognition projects.', 'The move\\ntowards data-centric AI in machine learning and deep learning underscores the\\nimportance of high-quality data, and the need for specialised tools that\\nincrease the efficiency and effectiveness of generating such data.', 'For document\\nimage annotation, Callico offers dual-display annotation for digitised\\ndocuments, enabling simultaneous visualisation and annotation of scanned images\\nand text.', 'This capability is critical for OCR and HTR model training, document\\nlayout analysis, named entity recognition, form-based key value annotation or\\nhierarchical structure annotation with element grouping.', 'The platform supports\\ncollaborative annotation with versatile features backed by a commitment to open\\nsource development, high-quality code standards and easy deployment via Docker.', \"Illustrative use cases - including the transcription of the Belfort municipal\\nregisters, the indexing of French World War II prisoners for the ICRC, and the\\nextraction of personal information from the Socface project's census lists -\\ndemonstrate Callico's applicability and utility.\"]\n",
            "Chunks for abstract: Simulating soil reflectance spectra is invaluable for soil-plant radiative\n",
            "modeling and training machine learning models, yet it is difficult as the\n",
            "intricate relationships between soil structure and its constituents. To address\n",
            "this, a fully data-driven soil optics generative model (SOGM) for simulation of\n",
            "soil reflectance spectra based on soil property inputs was developed. The model\n",
            "is trained on an extensive dataset comprising nearly 180,000 soil\n",
            "spectra-property pairs from 17 datasets. It generates soil reflectance spectra\n",
            "from text-based inputs describing soil properties and their values rather than\n",
            "only numerical values and labels in binary vector format. The generative model\n",
            "can simulate output spectra based on an incomplete set of input properties.\n",
            "SOGM is based on the denoising diffusion probabilistic model (DDPM). Two\n",
            "additional sub-models were also built to complement the SOGM: a spectral\n",
            "padding model that can fill in the gaps for spectra shorter than the full\n",
            "visible-near-infrared range (VIS-NIR; 400 to 2499 nm), and a wet soil spectra\n",
            "model that can estimate the effects of water content on soil reflectance\n",
            "spectra given the dry spectrum predicted by the SOGM. The SOGM was up-scaled by\n",
            "coupling with the Helios 3D plant modeling software, which allowed for\n",
            "generation of synthetic aerial images of simulated soil and plant scenes. It\n",
            "can also be easily integrated with soil-plant radiation model used for remote\n",
            "sensin research like PROSAIL. The testing results of the SOGM on new datasets\n",
            "that not included in model training proved that the model can generate\n",
            "reasonable soil reflectance spectra based on available property inputs. The\n",
            "presented models are openly accessible on:\n",
            "https://github.com/GEMINI-Breeding/SOGM_soil_spectra_simulation.\n",
            "['Simulating soil reflectance spectra is invaluable for soil-plant radiative\\nmodeling and training machine learning models, yet it is difficult as the\\nintricate relationships between soil structure and its constituents.', 'To address\\nthis, a fully data-driven soil optics generative model (SOGM) for simulation of\\nsoil reflectance spectra based on soil property inputs was developed.', 'The model\\nis trained on an extensive dataset comprising nearly 180,000 soil\\nspectra-property pairs from 17 datasets.', 'It generates soil reflectance spectra\\nfrom text-based inputs describing soil properties and their values rather than\\nonly numerical values and labels in binary vector format.', 'The generative model\\ncan simulate output spectra based on an incomplete set of input properties.', 'SOGM is based on the denoising diffusion probabilistic model (DDPM).', 'Two\\nadditional sub-models were also built to complement the SOGM: a spectral\\npadding model that can fill in the gaps for spectra shorter than the full\\nvisible-near-infrared range (VIS-NIR; 400 to 2499 nm), and a wet soil spectra\\nmodel that can estimate the effects of water content on soil reflectance\\nspectra given the dry spectrum predicted by the SOGM.', 'The SOGM was up-scaled by\\ncoupling with the Helios 3D plant modeling software, which allowed for\\ngeneration of synthetic aerial images of simulated soil and plant scenes.', 'It\\ncan also be easily integrated with soil-plant radiation model used for remote\\nsensin research like PROSAIL.', 'The testing results of the SOGM on new datasets\\nthat not included in model training proved that the model can generate\\nreasonable soil reflectance spectra based on available property inputs.', 'The\\npresented models are openly accessible on:\\nhttps://github.com/GEMINI-Breeding/SOGM_soil_spectra_simulation.']\n",
            "Chunks for abstract: Recent advancements in deep learning have demonstrated remarkable performance\n",
            "comparable to human capabilities across various supervised computer vision\n",
            "tasks. However, the prevalent assumption of having an extensive pool of\n",
            "training data encompassing all classes prior to model training often diverges\n",
            "from real-world scenarios, where limited data availability for novel classes is\n",
            "the norm. The challenge emerges in seamlessly integrating new classes with few\n",
            "samples into the training data, demanding the model to adeptly accommodate\n",
            "these additions without compromising its performance on base classes. To\n",
            "address this exigency, the research community has introduced several solutions\n",
            "under the realm of few-shot class incremental learning (FSCIL).\n",
            "  In this study, we introduce an innovative FSCIL framework that utilizes\n",
            "language regularizer and subspace regularizer. During base training, the\n",
            "language regularizer helps incorporate semantic information extracted from a\n",
            "Vision-Language model. The subspace regularizer helps in facilitating the\n",
            "model's acquisition of nuanced connections between image and text semantics\n",
            "inherent to base classes during incremental training. Our proposed framework\n",
            "not only empowers the model to embrace novel classes with limited data, but\n",
            "also ensures the preservation of performance on base classes. To substantiate\n",
            "the efficacy of our approach, we conduct comprehensive experiments on three\n",
            "distinct FSCIL benchmarks, where our framework attains state-of-the-art\n",
            "performance.\n",
            "['Recent advancements in deep learning have demonstrated remarkable performance\\ncomparable to human capabilities across various supervised computer vision\\ntasks.', 'However, the prevalent assumption of having an extensive pool of\\ntraining data encompassing all classes prior to model training often diverges\\nfrom real-world scenarios, where limited data availability for novel classes is\\nthe norm.', 'The challenge emerges in seamlessly integrating new classes with few\\nsamples into the training data, demanding the model to adeptly accommodate\\nthese additions without compromising its performance on base classes.', 'To\\naddress this exigency, the research community has introduced several solutions\\nunder the realm of few-shot class incremental learning (FSCIL).', 'In this study, we introduce an innovative FSCIL framework that utilizes\\nlanguage regularizer and subspace regularizer.', 'During base training, the\\nlanguage regularizer helps incorporate semantic information extracted from a\\nVision-Language model.', \"The subspace regularizer helps in facilitating the\\nmodel's acquisition of nuanced connections between image and text semantics\\ninherent to base classes during incremental training.\", 'Our proposed framework\\nnot only empowers the model to embrace novel classes with limited data, but\\nalso ensures the preservation of performance on base classes.', 'To substantiate\\nthe efficacy of our approach, we conduct comprehensive experiments on three\\ndistinct FSCIL benchmarks, where our framework attains state-of-the-art\\nperformance.']\n",
            "Chunks for abstract: We investigate a system of geometric evolution equations describing a\n",
            "curvature and torsion driven motion of a family of 3D curves in the normal and\n",
            "binormal directions. We explore the direct Lagrangian approach for treating the\n",
            "geometric flow of such interacting curves. Using the abstract theory of\n",
            "nonlinear analytic semi-flows, we are able to prove local existence,\n",
            "uniqueness, and continuation of classical H\\\"older smooth solutions to the\n",
            "governing system of non-linear parabolic equations modelling $n$ evolving\n",
            "curves with mutual nonlocal interactions. We present several computational\n",
            "studies of the flow that combine the normal or binormal velocity and\n",
            "considering nonlocal interaction.\n",
            "['We investigate a system of geometric evolution equations describing a\\ncurvature and torsion driven motion of a family of 3D curves in the normal and\\nbinormal directions.', 'We explore the direct Lagrangian approach for treating the\\ngeometric flow of such interacting curves.', 'Using the abstract theory of\\nnonlinear analytic semi-flows, we are able to prove local existence,\\nuniqueness, and continuation of classical H\\\\\"older smooth solutions to the\\ngoverning system of non-linear parabolic equations modelling $n$ evolving\\ncurves with mutual nonlocal interactions.', 'We present several computational\\nstudies of the flow that combine the normal or binormal velocity and\\nconsidering nonlocal interaction.']\n",
            "Chunks for abstract: The enhanced power graph of a group $G$ is a graph with vertex set $G,$ where\n",
            "two distinct vertices $x$ and $y$ are adjacent if and only if there exists an\n",
            "element $w$ in $G$ such that both $x$ and $y$ are powers of $w.$ In this paper,\n",
            "we determine the vertex connectivity of the enhanced power graph of any finite\n",
            "nilpotent group.\n",
            "['The enhanced power graph of a group $G$ is a graph with vertex set $G,$ where\\ntwo distinct vertices $x$ and $y$ are adjacent if and only if there exists an\\nelement $w$ in $G$ such that both $x$ and $y$ are powers of $w.$ In this paper,\\nwe determine the vertex connectivity of the enhanced power graph of any finite\\nnilpotent group.']\n",
            "Chunks for abstract: Centred Kernel Alignment (CKA) has recently emerged as a popular metric to\n",
            "compare activations from biological and artificial neural networks (ANNs) in\n",
            "order to quantify the alignment between internal representations derived from\n",
            "stimuli sets (e.g. images, text, video) that are presented to both systems. In\n",
            "this paper we highlight issues that the community should take into account if\n",
            "using CKA as an alignment metric with neural data. Neural data are in the\n",
            "low-data high-dimensionality domain, which is one of the cases where (biased)\n",
            "CKA results in high similarity scores even for pairs of random matrices. Using\n",
            "fMRI and MEG data from the THINGS project, we show that if biased CKA is\n",
            "applied to representations of different sizes in the low-data\n",
            "high-dimensionality domain, they are not directly comparable due to biased\n",
            "CKA's sensitivity to differing feature-sample ratios and not stimuli-driven\n",
            "responses. This situation can arise both when comparing a pre-selected area of\n",
            "interest (e.g. ROI) to multiple ANN layers, as well as when determining to\n",
            "which ANN layer multiple regions of interest (ROIs) / sensor groups of\n",
            "different dimensionality are most similar. We show that biased CKA can be\n",
            "artificially driven to its maximum value when using independent random data of\n",
            "different sample-feature ratios. We further show that shuffling sample-feature\n",
            "pairs of real neural data does not drastically alter biased CKA similarity in\n",
            "comparison to unshuffled data, indicating an undesirable lack of sensitivity to\n",
            "stimuli-driven neural responses. Positive alignment of true stimuli-driven\n",
            "responses is only achieved by using debiased CKA. Lastly, we report findings\n",
            "that suggest biased CKA is sensitive to the inherent structure of neural data,\n",
            "only differing from shuffled data when debiased CKA detects stimuli-driven\n",
            "alignment.\n",
            "['Centred Kernel Alignment (CKA) has recently emerged as a popular metric to\\ncompare activations from biological and artificial neural networks (ANNs) in\\norder to quantify the alignment between internal representations derived from\\nstimuli sets (e.g.', 'images, text, video) that are presented to both systems.', 'In\\nthis paper we highlight issues that the community should take into account if\\nusing CKA as an alignment metric with neural data.', 'Neural data are in the\\nlow-data high-dimensionality domain, which is one of the cases where (biased)\\nCKA results in high similarity scores even for pairs of random matrices.', \"Using\\nfMRI and MEG data from the THINGS project, we show that if biased CKA is\\napplied to representations of different sizes in the low-data\\nhigh-dimensionality domain, they are not directly comparable due to biased\\nCKA's sensitivity to differing feature-sample ratios and not stimuli-driven\\nresponses.\", 'This situation can arise both when comparing a pre-selected area of\\ninterest (e.g.', 'ROI) to multiple ANN layers, as well as when determining to\\nwhich ANN layer multiple regions of interest (ROIs) / sensor groups of\\ndifferent dimensionality are most similar.', 'We show that biased CKA can be\\nartificially driven to its maximum value when using independent random data of\\ndifferent sample-feature ratios.', 'We further show that shuffling sample-feature\\npairs of real neural data does not drastically alter biased CKA similarity in\\ncomparison to unshuffled data, indicating an undesirable lack of sensitivity to\\nstimuli-driven neural responses.', 'Positive alignment of true stimuli-driven\\nresponses is only achieved by using debiased CKA.', 'Lastly, we report findings\\nthat suggest biased CKA is sensitive to the inherent structure of neural data,\\nonly differing from shuffled data when debiased CKA detects stimuli-driven\\nalignment.']\n",
            "Chunks for abstract: Identifying layers within text-to-image models which control visual\n",
            "attributes can facilitate efficient model editing through closed-form updates.\n",
            "Recent work, leveraging causal tracing show that early Stable-Diffusion\n",
            "variants confine knowledge primarily to the first layer of the CLIP\n",
            "text-encoder, while it diffuses throughout the UNet.Extending this framework,\n",
            "we observe that for recent models (e.g., SD-XL, DeepFloyd), causal tracing\n",
            "fails in pinpointing localized knowledge, highlighting challenges in model\n",
            "editing. To address this issue, we introduce the concept of Mechanistic\n",
            "Localization in text-to-image models, where knowledge about various visual\n",
            "attributes (e.g., \"style\", \"objects\", \"facts\") can be mechanistically localized\n",
            "to a small fraction of layers in the UNet, thus facilitating efficient model\n",
            "editing. We localize knowledge using our method LocoGen which measures the\n",
            "direct effect of intermediate layers to output generation by performing\n",
            "interventions in the cross-attention layers of the UNet. We then employ\n",
            "LocoEdit, a fast closed-form editing method across popular open-source\n",
            "text-to-image models (including the latest SD-XL)and explore the possibilities\n",
            "of neuron-level model editing. Using Mechanistic Localization, our work offers\n",
            "a better view of successes and failures in localization-based text-to-image\n",
            "model editing. Code will be available at\n",
            "https://github.com/samyadeepbasu/LocoGen.\n",
            "['Identifying layers within text-to-image models which control visual\\nattributes can facilitate efficient model editing through closed-form updates.', 'Recent work, leveraging causal tracing show that early Stable-Diffusion\\nvariants confine knowledge primarily to the first layer of the CLIP\\ntext-encoder, while it diffuses throughout the UNet.Extending this framework,\\nwe observe that for recent models (e.g., SD-XL, DeepFloyd), causal tracing\\nfails in pinpointing localized knowledge, highlighting challenges in model\\nediting.', 'To address this issue, we introduce the concept of Mechanistic\\nLocalization in text-to-image models, where knowledge about various visual\\nattributes (e.g., \"style\", \"objects\", \"facts\") can be mechanistically localized\\nto a small fraction of layers in the UNet, thus facilitating efficient model\\nediting.', 'We localize knowledge using our method LocoGen which measures the\\ndirect effect of intermediate layers to output generation by performing\\ninterventions in the cross-attention layers of the UNet.', 'We then employ\\nLocoEdit, a fast closed-form editing method across popular open-source\\ntext-to-image models (including the latest SD-XL)and explore the possibilities\\nof neuron-level model editing.', 'Using Mechanistic Localization, our work offers\\na better view of successes and failures in localization-based text-to-image\\nmodel editing.', 'Code will be available at\\nhttps://github.com/samyadeepbasu/LocoGen.']\n",
            "Chunks for abstract: In this work we compute numerical bounds on the mass $\\mu$ of superradiantly\n",
            "unstable scalar fields in a Kerr black hole background using the continued\n",
            "fraction method. We show that the normalized upper bound on the mass $\\mu$\n",
            "increases with the angular momentum number $\\ell$ and the azimuthal number $m$,\n",
            "approaching the most stringent analytical bound known to date when $\\ell=m \\gg\n",
            "1$. We also provide an analytical fit to the numerically determined mass bound\n",
            "as a function of the dimensionless spin parameter $a/M$ of the black hole with\n",
            "an accuracy of the order $0.1\\%$ for the fundamental mode with $\\ell=m=1$, and\n",
            "of the order $1\\%$ for higher-order modes (up to $\\ell=m=20$). We argue that\n",
            "this analytical fit is particularly useful in astrophysical scenarios, since\n",
            "the lowest $\\ell=m$ modes are capable of producing the strongest observable\n",
            "imprints of superradiance.\n",
            "['In this work we compute numerical bounds on the mass $\\\\mu$ of superradiantly\\nunstable scalar fields in a Kerr black hole background using the continued\\nfraction method.', 'We show that the normalized upper bound on the mass $\\\\mu$\\nincreases with the angular momentum number $\\\\ell$ and the azimuthal number $m$,\\napproaching the most stringent analytical bound known to date when $\\\\ell=m \\\\gg\\n1$.', 'We also provide an analytical fit to the numerically determined mass bound\\nas a function of the dimensionless spin parameter $a/M$ of the black hole with\\nan accuracy of the order $0.1\\\\%$ for the fundamental mode with $\\\\ell=m=1$, and\\nof the order $1\\\\%$ for higher-order modes (up to $\\\\ell=m=20$).', 'We argue that\\nthis analytical fit is particularly useful in astrophysical scenarios, since\\nthe lowest $\\\\ell=m$ modes are capable of producing the strongest observable\\nimprints of superradiance.']\n",
            "Chunks for abstract: Despite the remarkable success of Large Language Models (LLMs) in text\n",
            "understanding and generation, their potential for text clustering tasks remains\n",
            "underexplored. We observed that powerful closed-source LLMs provide good\n",
            "quality clusterings of entity sets but are not scalable due to the massive\n",
            "compute power required and the associated costs. Thus, we propose CACTUS\n",
            "(Context-Aware ClusTering with aUgmented triplet losS), a systematic approach\n",
            "that leverages open-source LLMs for efficient and effective supervised\n",
            "clustering of entity subsets, particularly focusing on text-based entities.\n",
            "Existing text clustering methods fail to effectively capture the context\n",
            "provided by the entity subset. Moreover, though there are several language\n",
            "modeling based approaches for clustering, very few are designed for the task of\n",
            "supervised clustering. This paper introduces a novel approach towards\n",
            "clustering entity subsets using LLMs by capturing context via a scalable\n",
            "inter-entity attention mechanism. We propose a novel augmented triplet loss\n",
            "function tailored for supervised clustering, which addresses the inherent\n",
            "challenges of directly applying the triplet loss to this problem. Furthermore,\n",
            "we introduce a self-supervised clustering task based on text augmentation\n",
            "techniques to improve the generalization of our model. For evaluation, we\n",
            "collect ground truth clusterings from a closed-source LLM and transfer this\n",
            "knowledge to an open-source LLM under the supervised clustering framework,\n",
            "allowing a faster and cheaper open-source model to perform the same task.\n",
            "Experiments on various e-commerce query and product clustering datasets\n",
            "demonstrate that our proposed approach significantly outperforms existing\n",
            "unsupervised and supervised baselines under various external clustering\n",
            "evaluation metrics.\n",
            "['Despite the remarkable success of Large Language Models (LLMs) in text\\nunderstanding and generation, their potential for text clustering tasks remains\\nunderexplored.', 'We observed that powerful closed-source LLMs provide good\\nquality clusterings of entity sets but are not scalable due to the massive\\ncompute power required and the associated costs.', 'Thus, we propose CACTUS\\n(Context-Aware ClusTering with aUgmented triplet losS), a systematic approach\\nthat leverages open-source LLMs for efficient and effective supervised\\nclustering of entity subsets, particularly focusing on text-based entities.', 'Existing text clustering methods fail to effectively capture the context\\nprovided by the entity subset.', 'Moreover, though there are several language\\nmodeling based approaches for clustering, very few are designed for the task of\\nsupervised clustering.', 'This paper introduces a novel approach towards\\nclustering entity subsets using LLMs by capturing context via a scalable\\ninter-entity attention mechanism.', 'We propose a novel augmented triplet loss\\nfunction tailored for supervised clustering, which addresses the inherent\\nchallenges of directly applying the triplet loss to this problem.', 'Furthermore,\\nwe introduce a self-supervised clustering task based on text augmentation\\ntechniques to improve the generalization of our model.', 'For evaluation, we\\ncollect ground truth clusterings from a closed-source LLM and transfer this\\nknowledge to an open-source LLM under the supervised clustering framework,\\nallowing a faster and cheaper open-source model to perform the same task.', 'Experiments on various e-commerce query and product clustering datasets\\ndemonstrate that our proposed approach significantly outperforms existing\\nunsupervised and supervised baselines under various external clustering\\nevaluation metrics.']\n",
            "Chunks for abstract: Large Language Models (LLMs) have enabled new ways to satisfy information\n",
            "needs. Although great strides have been made in applying them to settings like\n",
            "document ranking and short-form text generation, they still struggle to compose\n",
            "complete, accurate, and verifiable long-form reports. Reports with these\n",
            "qualities are necessary to satisfy the complex, nuanced, or multi-faceted\n",
            "information needs of users. In this perspective paper, we draw together\n",
            "opinions from industry and academia, and from a variety of related research\n",
            "areas, to present our vision for automatic report generation, and -- critically\n",
            "-- a flexible framework by which such reports can be evaluated. In contrast\n",
            "with other summarization tasks, automatic report generation starts with a\n",
            "detailed description of an information need, stating the necessary background,\n",
            "requirements, and scope of the report. Further, the generated reports should be\n",
            "complete, accurate, and verifiable. These qualities, which are desirable -- if\n",
            "not required -- in many analytic report-writing settings, require rethinking\n",
            "how to build and evaluate systems that exhibit these qualities. To foster new\n",
            "efforts in building these systems, we present an evaluation framework that\n",
            "draws on ideas found in various evaluations. To test completeness and accuracy,\n",
            "the framework uses nuggets of information, expressed as questions and answers,\n",
            "that need to be part of any high-quality generated report. Additionally,\n",
            "evaluation of citations that map claims made in the report to their source\n",
            "documents ensures verifiability.\n",
            "['Large Language Models (LLMs) have enabled new ways to satisfy information\\nneeds.', 'Although great strides have been made in applying them to settings like\\ndocument ranking and short-form text generation, they still struggle to compose\\ncomplete, accurate, and verifiable long-form reports.', 'Reports with these\\nqualities are necessary to satisfy the complex, nuanced, or multi-faceted\\ninformation needs of users.', 'In this perspective paper, we draw together\\nopinions from industry and academia, and from a variety of related research\\nareas, to present our vision for automatic report generation, and -- critically\\n-- a flexible framework by which such reports can be evaluated.', 'In contrast\\nwith other summarization tasks, automatic report generation starts with a\\ndetailed description of an information need, stating the necessary background,\\nrequirements, and scope of the report.', 'Further, the generated reports should be\\ncomplete, accurate, and verifiable.', 'These qualities, which are desirable -- if\\nnot required -- in many analytic report-writing settings, require rethinking\\nhow to build and evaluate systems that exhibit these qualities.', 'To foster new\\nefforts in building these systems, we present an evaluation framework that\\ndraws on ideas found in various evaluations.', 'To test completeness and accuracy,\\nthe framework uses nuggets of information, expressed as questions and answers,\\nthat need to be part of any high-quality generated report.', 'Additionally,\\nevaluation of citations that map claims made in the report to their source\\ndocuments ensures verifiability.']\n",
            "Chunks for abstract: Multilingual information retrieval (MLIR) considers the problem of ranking\n",
            "documents in several languages for a query expressed in a language that may\n",
            "differ from any of those languages. Recent work has observed that approaches\n",
            "such as combining ranked lists representing a single document language each or\n",
            "using multilingual pretrained language models demonstrate a preference for one\n",
            "language over others. This results in systematic unfair treatment of documents\n",
            "in different languages. This work proposes a language fairness metric to\n",
            "evaluate whether documents across different languages are fairly ranked through\n",
            "statistical equivalence testing using the Kruskal-Wallis test. In contrast to\n",
            "most prior work in group fairness, we do not consider any language to be an\n",
            "unprotected group. Thus our proposed measure, PEER (Probability of\n",
            "EqualExpected Rank), is the first fairness metric specifically designed to\n",
            "capture the language fairness of MLIR systems. We demonstrate the behavior of\n",
            "PEER on artificial ranked lists. We also evaluate real MLIR systems on two\n",
            "publicly available benchmarks and show that the PEER scores align with prior\n",
            "analytical findings on MLIR fairness. Our implementation is compatible with\n",
            "ir-measures and is available at http://github.com/hltcoe/peer_measure.\n",
            "['Multilingual information retrieval (MLIR) considers the problem of ranking\\ndocuments in several languages for a query expressed in a language that may\\ndiffer from any of those languages.', 'Recent work has observed that approaches\\nsuch as combining ranked lists representing a single document language each or\\nusing multilingual pretrained language models demonstrate a preference for one\\nlanguage over others.', 'This results in systematic unfair treatment of documents\\nin different languages.', 'This work proposes a language fairness metric to\\nevaluate whether documents across different languages are fairly ranked through\\nstatistical equivalence testing using the Kruskal-Wallis test.', 'In contrast to\\nmost prior work in group fairness, we do not consider any language to be an\\nunprotected group.', 'Thus our proposed measure, PEER (Probability of\\nEqualExpected Rank), is the first fairness metric specifically designed to\\ncapture the language fairness of MLIR systems.', 'We demonstrate the behavior of\\nPEER on artificial ranked lists.', 'We also evaluate real MLIR systems on two\\npublicly available benchmarks and show that the PEER scores align with prior\\nanalytical findings on MLIR fairness.', 'Our implementation is compatible with\\nir-measures and is available at http://github.com/hltcoe/peer_measure.']\n",
            "Chunks for abstract: PLAID, an efficient implementation of the ColBERT late interaction bi-encoder\n",
            "using pretrained language models for ranking, consistently achieves\n",
            "state-of-the-art performance in monolingual, cross-language, and multilingual\n",
            "retrieval. PLAID differs from ColBERT by assigning terms to clusters and\n",
            "representing those terms as cluster centroids plus compressed residual vectors.\n",
            "While PLAID is effective in batch experiments, its performance degrades in\n",
            "streaming settings where documents arrive over time because representations of\n",
            "new tokens may be poorly modeled by the earlier tokens used to select cluster\n",
            "centroids. PLAID Streaming Hierarchical Indexing that Runs on Terabytes of\n",
            "Temporal Text (PLAID SHIRTTT) addresses this concern using multi-phase\n",
            "incremental indexing based on hierarchical sharding. Experiments on ClueWeb09\n",
            "and the multilingual NeuCLIR collection demonstrate the effectiveness of this\n",
            "approach both for the largest collection indexed to date by the ColBERT\n",
            "architecture and in the multilingual setting, respectively.\n",
            "['PLAID, an efficient implementation of the ColBERT late interaction bi-encoder\\nusing pretrained language models for ranking, consistently achieves\\nstate-of-the-art performance in monolingual, cross-language, and multilingual\\nretrieval.', 'PLAID differs from ColBERT by assigning terms to clusters and\\nrepresenting those terms as cluster centroids plus compressed residual vectors.', 'While PLAID is effective in batch experiments, its performance degrades in\\nstreaming settings where documents arrive over time because representations of\\nnew tokens may be poorly modeled by the earlier tokens used to select cluster\\ncentroids.', 'PLAID Streaming Hierarchical Indexing that Runs on Terabytes of\\nTemporal Text (PLAID SHIRTTT) addresses this concern using multi-phase\\nincremental indexing based on hierarchical sharding.', 'Experiments on ClueWeb09\\nand the multilingual NeuCLIR collection demonstrate the effectiveness of this\\napproach both for the largest collection indexed to date by the ColBERT\\narchitecture and in the multilingual setting, respectively.']\n",
            "Chunks for abstract: Radiology report generation aims to automatically generate detailed and\n",
            "coherent descriptive reports alongside radiology images. Previous work mainly\n",
            "focused on refining fine-grained image features or leveraging external\n",
            "knowledge. However, the precise alignment of fine-grained image features with\n",
            "corresponding text descriptions has not been considered. This paper presents a\n",
            "novel method called Fine-grained Image-Text Aligner (FITA) to construct\n",
            "fine-grained alignment for image and text features. It has three novel designs:\n",
            "Image Feature Refiner (IFR), Text Feature Refiner (TFR) and Contrastive Aligner\n",
            "(CA). IFR and TFR aim to learn fine-grained image and text features,\n",
            "respectively. We achieve this by leveraging saliency maps to effectively fuse\n",
            "symptoms with corresponding abnormal visual regions, and by utilizing a\n",
            "meticulously constructed triplet set for training. Finally, CA module aligns\n",
            "fine-grained image and text features using contrastive loss for precise\n",
            "alignment. Results show that our method surpasses existing methods on the\n",
            "widely used benchmark\n",
            "['Radiology report generation aims to automatically generate detailed and\\ncoherent descriptive reports alongside radiology images.', 'Previous work mainly\\nfocused on refining fine-grained image features or leveraging external\\nknowledge.', 'However, the precise alignment of fine-grained image features with\\ncorresponding text descriptions has not been considered.', 'This paper presents a\\nnovel method called Fine-grained Image-Text Aligner (FITA) to construct\\nfine-grained alignment for image and text features.', 'It has three novel designs:\\nImage Feature Refiner (IFR), Text Feature Refiner (TFR) and Contrastive Aligner\\n(CA).', 'IFR and TFR aim to learn fine-grained image and text features,\\nrespectively.', 'We achieve this by leveraging saliency maps to effectively fuse\\nsymptoms with corresponding abnormal visual regions, and by utilizing a\\nmeticulously constructed triplet set for training.', 'Finally, CA module aligns\\nfine-grained image and text features using contrastive loss for precise\\nalignment.', 'Results show that our method surpasses existing methods on the\\nwidely used benchmark']\n",
            "Chunks for abstract: Recent advancements in automatic 3D avatar generation guided by text have\n",
            "made significant progress. However, existing methods have limitations such as\n",
            "oversaturation and low-quality output. To address these challenges, we propose\n",
            "X-Oscar, a progressive framework for generating high-quality animatable avatars\n",
            "from text prompts. It follows a sequential Geometry->Texture->Animation\n",
            "paradigm, simplifying optimization through step-by-step generation. To tackle\n",
            "oversaturation, we introduce Adaptive Variational Parameter (AVP), representing\n",
            "avatars as an adaptive distribution during training. Additionally, we present\n",
            "Avatar-aware Score Distillation Sampling (ASDS), a novel technique that\n",
            "incorporates avatar-aware noise into rendered images for improved generation\n",
            "quality during optimization. Extensive evaluations confirm the superiority of\n",
            "X-Oscar over existing text-to-3D and text-to-avatar approaches. Our anonymous\n",
            "project page: https://xmu-xiaoma666.github.io/Projects/X-Oscar/.\n",
            "['Recent advancements in automatic 3D avatar generation guided by text have\\nmade significant progress.', 'However, existing methods have limitations such as\\noversaturation and low-quality output.', 'To address these challenges, we propose\\nX-Oscar, a progressive framework for generating high-quality animatable avatars\\nfrom text prompts.', 'It follows a sequential Geometry->Texture->Animation\\nparadigm, simplifying optimization through step-by-step generation.', 'To tackle\\noversaturation, we introduce Adaptive Variational Parameter (AVP), representing\\navatars as an adaptive distribution during training.', 'Additionally, we present\\nAvatar-aware Score Distillation Sampling (ASDS), a novel technique that\\nincorporates avatar-aware noise into rendered images for improved generation\\nquality during optimization.', 'Extensive evaluations confirm the superiority of\\nX-Oscar over existing text-to-3D and text-to-avatar approaches.', 'Our anonymous\\nproject page: https://xmu-xiaoma666.github.io/Projects/X-Oscar/.']\n",
            "Chunks for abstract: Step Chemical Reaction Networks (step CRNs) are an augmentation of the\n",
            "Chemical Reaction Network (CRN) model where additional species may be\n",
            "introduced to the system in a sequence of ``steps.'' We study step CRN systems\n",
            "using a weak subset of reaction rules, \\emph{void} rules, in which molecular\n",
            "species can only be deleted. We demonstrate that step CRNs with only void rules\n",
            "of size (2,0) can simulate threshold formulas (TFs) under linear resources.\n",
            "These limited systems can also simulate threshold \\emph{circuits} (TCs) by\n",
            "modifying the volume of the system to be exponential. We then prove a matching\n",
            "exponential lower bound on the required volume for simulating threshold\n",
            "circuits in a step CRN with (2,0)-size rules under a restricted\n",
            "\\emph{gate-wise} simulation, thus showing our construction is optimal for\n",
            "simulating circuits in this way.\n",
            "[\"Step Chemical Reaction Networks (step CRNs) are an augmentation of the\\nChemical Reaction Network (CRN) model where additional species may be\\nintroduced to the system in a sequence of ``steps.''\", 'We study step CRN systems\\nusing a weak subset of reaction rules, \\\\emph{void} rules, in which molecular\\nspecies can only be deleted.', 'We demonstrate that step CRNs with only void rules\\nof size (2,0) can simulate threshold formulas (TFs) under linear resources.', 'These limited systems can also simulate threshold \\\\emph{circuits} (TCs) by\\nmodifying the volume of the system to be exponential.', 'We then prove a matching\\nexponential lower bound on the required volume for simulating threshold\\ncircuits in a step CRN with (2,0)-size rules under a restricted\\n\\\\emph{gate-wise} simulation, thus showing our construction is optimal for\\nsimulating circuits in this way.']\n",
            "Chunks for abstract: In this paper, we investigate the gravitational collapse to form the black\n",
            "hole in the acceleratingly expanding universe in the frame of\n",
            "Einstein--Gauss-Bonnet theory having two scalar fields and we study the\n",
            "propagation of the gravitational wave (GW). The collapsing spacetime can be\n",
            "obtained by using the formulation of the ``reconstruction'', that is, we find a\n",
            "model that realises the desired or given geometry. In the reconstructed models,\n",
            "ghosts often appear, which could be eliminated by imposing constraints. We show\n",
            "that the standard cosmological solutions or self-gravitating objects such as a\n",
            "planet, the Sun, various types of stars, etc., in Einstein's gravity, are also\n",
            "solutions in this model. Using the dynamical value of Gauss-Bonnet coupling,\n",
            "the propagation of the high-frequency GW is investigated. The propagating speed\n",
            "changes due to the coupling during the period of the black hole formation. The\n",
            "speed at which the GW propagates The speed at which the GW propagates going\n",
            "into the black hole is different from that of the wave going out.\n",
            "['In this paper, we investigate the gravitational collapse to form the black\\nhole in the acceleratingly expanding universe in the frame of\\nEinstein--Gauss-Bonnet theory having two scalar fields and we study the\\npropagation of the gravitational wave (GW).', \"The collapsing spacetime can be\\nobtained by using the formulation of the ``reconstruction'', that is, we find a\\nmodel that realises the desired or given geometry.\", 'In the reconstructed models,\\nghosts often appear, which could be eliminated by imposing constraints.', \"We show\\nthat the standard cosmological solutions or self-gravitating objects such as a\\nplanet, the Sun, various types of stars, etc., in Einstein's gravity, are also\\nsolutions in this model.\", 'Using the dynamical value of Gauss-Bonnet coupling,\\nthe propagation of the high-frequency GW is investigated.', 'The propagating speed\\nchanges due to the coupling during the period of the black hole formation.', 'The\\nspeed at which the GW propagates The speed at which the GW propagates going\\ninto the black hole is different from that of the wave going out.']\n",
            "Chunks for abstract: We present a novel approach for modeling bounded count time series data, by\n",
            "deriving accurate upper and lower bounds for the variance of a bounded count\n",
            "random variable while maintaining a fixed mean. Leveraging these bounds, we\n",
            "propose semiparametric mean and variance joint (MVJ) models utilizing a\n",
            "clipped-Laplace link function. These models offer a flexible and feasible\n",
            "structure for both mean and variance, accommodating various scenarios of\n",
            "under-dispersion, equi-dispersion, or over-dispersion in bounded time series.\n",
            "The proposed MVJ models feature a linear mean structure with positive\n",
            "regression coefficients summing to one and allow for negative regression\n",
            "cefficients and autocorrelations. We demonstrate that the autocorrelation\n",
            "structure of MVJ models mirrors that of an autoregressive moving-average (ARMA)\n",
            "process, provided the proposed clipped-Laplace link functions with nonnegative\n",
            "regression coefficients summing to one are utilized. We establish conditions\n",
            "ensuring the stationarity and ergodicity properties of the MVJ process, along\n",
            "with demonstrating the consistency and asymptotic normality of the conditional\n",
            "least squares estimators. To aid model selection and diagnostics, we introduce\n",
            "two model selection criteria and apply two model diagnostics statistics.\n",
            "Finally, we conduct simulations and real data analyses to investigate the\n",
            "finite-sample properties of the proposed MVJ models, providing insights into\n",
            "their efficacy and applicability in practical scenarios.\n",
            "['We present a novel approach for modeling bounded count time series data, by\\nderiving accurate upper and lower bounds for the variance of a bounded count\\nrandom variable while maintaining a fixed mean.', 'Leveraging these bounds, we\\npropose semiparametric mean and variance joint (MVJ) models utilizing a\\nclipped-Laplace link function.', 'These models offer a flexible and feasible\\nstructure for both mean and variance, accommodating various scenarios of\\nunder-dispersion, equi-dispersion, or over-dispersion in bounded time series.', 'The proposed MVJ models feature a linear mean structure with positive\\nregression coefficients summing to one and allow for negative regression\\ncefficients and autocorrelations.', 'We demonstrate that the autocorrelation\\nstructure of MVJ models mirrors that of an autoregressive moving-average (ARMA)\\nprocess, provided the proposed clipped-Laplace link functions with nonnegative\\nregression coefficients summing to one are utilized.', 'We establish conditions\\nensuring the stationarity and ergodicity properties of the MVJ process, along\\nwith demonstrating the consistency and asymptotic normality of the conditional\\nleast squares estimators.', 'To aid model selection and diagnostics, we introduce\\ntwo model selection criteria and apply two model diagnostics statistics.', 'Finally, we conduct simulations and real data analyses to investigate the\\nfinite-sample properties of the proposed MVJ models, providing insights into\\ntheir efficacy and applicability in practical scenarios.']\n",
            "Chunks for abstract: This paper presents a new algorithm member for accelerating first-order\n",
            "methods for bilevel optimization, namely the \\emph{(Perturbed) Restarted\n",
            "Accelerated Fully First-order methods for Bilevel Approximation}, abbreviated\n",
            "as \\texttt{(P)RAF${}^2$BA}. The algorithm leverages \\emph{fully} first-order\n",
            "oracles and seeks approximate stationary points in nonconvex-strongly-convex\n",
            "bilevel optimization, enhancing oracle complexity for efficient optimization.\n",
            "Theoretical guarantees for finding approximate first-order stationary points\n",
            "and second-order stationary points at the state-of-the-art query complexities\n",
            "are established, showcasing their effectiveness in solving complex optimization\n",
            "tasks. Empirical studies for real-world problems are provided to further\n",
            "validate the outperformance of our proposed algorithms. The significance of\n",
            "\\texttt{(P)RAF${}^2$BA} in optimizing nonconvex-strongly-convex bilevel\n",
            "optimization problems is underscored by its state-of-the-art convergence rates\n",
            "and computational efficiency.\n",
            "['This paper presents a new algorithm member for accelerating first-order\\nmethods for bilevel optimization, namely the \\\\emph{(Perturbed) Restarted\\nAccelerated Fully First-order methods for Bilevel Approximation}, abbreviated\\nas \\\\texttt{(P)RAF${}^2$BA}.', 'The algorithm leverages \\\\emph{fully} first-order\\noracles and seeks approximate stationary points in nonconvex-strongly-convex\\nbilevel optimization, enhancing oracle complexity for efficient optimization.', 'Theoretical guarantees for finding approximate first-order stationary points\\nand second-order stationary points at the state-of-the-art query complexities\\nare established, showcasing their effectiveness in solving complex optimization\\ntasks.', 'Empirical studies for real-world problems are provided to further\\nvalidate the outperformance of our proposed algorithms.', 'The significance of\\n\\\\texttt{(P)RAF${}^2$BA} in optimizing nonconvex-strongly-convex bilevel\\noptimization problems is underscored by its state-of-the-art convergence rates\\nand computational efficiency.']\n",
            "Chunks for abstract: The problem of light waves interaction with charged particles becomes more\n",
            "and more complex starting with the case of plane waves, where the analytical\n",
            "solution is well known, to more natural, though more complicated situations\n",
            "which include focused or structured laser beams. Internal structure may\n",
            "introduce a new degree of freedom and qualitatively change the dynamics of\n",
            "interacting particles. For certain conditions, namely for the dilute plasma,\n",
            "description of single-particle dynamics in the focused structured laser beams\n",
            "is the first step and may serve as a good approximation on the way of\n",
            "understanding the global plasma response. Moreover, the general problem of\n",
            "integrability in complex systems starts from consideration of the integrals of\n",
            "motion for a single particle. The primary goal of this work is an understanding\n",
            "of the physics of the orbital angular momentum (OAM) absorption by a single\n",
            "particle in a focused structured light. A theoretical model of the process,\n",
            "including solutions of Maxwell equations with the required accuracy and a\n",
            "high-order perturbative approach to electron motion in external electromagnetic\n",
            "fields, is developed and its predictions are examined with numerical\n",
            "simulations for several exemplary electromagnetic field configurations. In\n",
            "particular, it was found that for the particles distributed initially with the\n",
            "azimuthal symmetry around the beam propagation direction, the transferred OAM\n",
            "has a smallness of the fourth order of the applied field amplitude, and\n",
            "requires an accurate consideration of the temporal laser pulse envelope.\n",
            "['The problem of light waves interaction with charged particles becomes more\\nand more complex starting with the case of plane waves, where the analytical\\nsolution is well known, to more natural, though more complicated situations\\nwhich include focused or structured laser beams.', 'Internal structure may\\nintroduce a new degree of freedom and qualitatively change the dynamics of\\ninteracting particles.', 'For certain conditions, namely for the dilute plasma,\\ndescription of single-particle dynamics in the focused structured laser beams\\nis the first step and may serve as a good approximation on the way of\\nunderstanding the global plasma response.', 'Moreover, the general problem of\\nintegrability in complex systems starts from consideration of the integrals of\\nmotion for a single particle.', 'The primary goal of this work is an understanding\\nof the physics of the orbital angular momentum (OAM) absorption by a single\\nparticle in a focused structured light.', 'A theoretical model of the process,\\nincluding solutions of Maxwell equations with the required accuracy and a\\nhigh-order perturbative approach to electron motion in external electromagnetic\\nfields, is developed and its predictions are examined with numerical\\nsimulations for several exemplary electromagnetic field configurations.', 'In\\nparticular, it was found that for the particles distributed initially with the\\nazimuthal symmetry around the beam propagation direction, the transferred OAM\\nhas a smallness of the fourth order of the applied field amplitude, and\\nrequires an accurate consideration of the temporal laser pulse envelope.']\n",
            "Chunks for abstract: Over the last decade, similar to other application domains, social media\n",
            "content has been proven very effective in disaster informatics. However, due to\n",
            "the unstructured nature of the data, several challenges are associated with\n",
            "disaster analysis in social media content. To fully explore the potential of\n",
            "social media content in disaster informatics, access to relevant content and\n",
            "the correct geo-location information is very critical. In this paper, we\n",
            "propose a three-step solution to tackling these challenges. Firstly, the\n",
            "proposed solution aims to classify social media posts into relevant and\n",
            "irrelevant posts followed by the automatic extraction of location information\n",
            "from the posts' text through Named Entity Recognition (NER) analysis. Finally,\n",
            "to quickly analyze the topics covered in large volumes of social media posts,\n",
            "we perform topic modeling resulting in a list of top keywords, that highlight\n",
            "the issues discussed in the tweet. For the Relevant Classification of Twitter\n",
            "Posts (RCTP), we proposed a merit-based fusion framework combining the\n",
            "capabilities of four different models namely BERT, RoBERTa, Distil BERT, and\n",
            "ALBERT obtaining the highest F1-score of 0.933 on a benchmark dataset. For the\n",
            "Location Extraction from Twitter Text (LETT), we evaluated four models namely\n",
            "BERT, RoBERTa, Distil BERTA, and Electra in an NER framework obtaining the\n",
            "highest F1-score of 0.960. For topic modeling, we used the BERTopic library to\n",
            "discover the hidden topic patterns in the relevant tweets. The experimental\n",
            "results of all the components of the proposed end-to-end solution are very\n",
            "encouraging and hint at the potential of social media content and NLP in\n",
            "disaster management.\n",
            "['Over the last decade, similar to other application domains, social media\\ncontent has been proven very effective in disaster informatics.', 'However, due to\\nthe unstructured nature of the data, several challenges are associated with\\ndisaster analysis in social media content.', 'To fully explore the potential of\\nsocial media content in disaster informatics, access to relevant content and\\nthe correct geo-location information is very critical.', 'In this paper, we\\npropose a three-step solution to tackling these challenges.', \"Firstly, the\\nproposed solution aims to classify social media posts into relevant and\\nirrelevant posts followed by the automatic extraction of location information\\nfrom the posts' text through Named Entity Recognition (NER) analysis.\", 'Finally,\\nto quickly analyze the topics covered in large volumes of social media posts,\\nwe perform topic modeling resulting in a list of top keywords, that highlight\\nthe issues discussed in the tweet.', 'For the Relevant Classification of Twitter\\nPosts (RCTP), we proposed a merit-based fusion framework combining the\\ncapabilities of four different models namely BERT, RoBERTa, Distil BERT, and\\nALBERT obtaining the highest F1-score of 0.933 on a benchmark dataset.', 'For the\\nLocation Extraction from Twitter Text (LETT), we evaluated four models namely\\nBERT, RoBERTa, Distil BERTA, and Electra in an NER framework obtaining the\\nhighest F1-score of 0.960.', 'For topic modeling, we used the BERTopic library to\\ndiscover the hidden topic patterns in the relevant tweets.', 'The experimental\\nresults of all the components of the proposed end-to-end solution are very\\nencouraging and hint at the potential of social media content and NLP in\\ndisaster management.']\n",
            "Chunks for abstract: Traditional language models operate autoregressively, i.e., they predict one\n",
            "token at a time. Rapid explosion in model sizes has resulted in high inference\n",
            "times. In this work, we propose DynaMo, a suite of multi-token prediction\n",
            "language models that reduce net inference times. Our models\n",
            "$\\textit{dynamically}$ predict multiple tokens based on their confidence in the\n",
            "predicted joint probability distribution. We propose a lightweight technique to\n",
            "train these models, leveraging the weights of traditional autoregressive\n",
            "counterparts. Moreover, we propose novel ways to enhance the estimated joint\n",
            "probability to improve text generation quality, namely co-occurrence weighted\n",
            "masking and adaptive thresholding. We also propose systematic qualitative and\n",
            "quantitative methods to rigorously test the quality of generated text for\n",
            "non-autoregressive generation. One of the models in our suite, DynaMo-7.3B-T3,\n",
            "achieves same-quality generated text as the baseline (Pythia-6.9B) while\n",
            "achieving 2.57$\\times$ speed-up with only 5.87% and 2.67% parameter and\n",
            "training time overheads, respectively.\n",
            "['Traditional language models operate autoregressively, i.e., they predict one\\ntoken at a time.', 'Rapid explosion in model sizes has resulted in high inference\\ntimes.', 'In this work, we propose DynaMo, a suite of multi-token prediction\\nlanguage models that reduce net inference times.', 'Our models\\n$\\\\textit{dynamically}$ predict multiple tokens based on their confidence in the\\npredicted joint probability distribution.', 'We propose a lightweight technique to\\ntrain these models, leveraging the weights of traditional autoregressive\\ncounterparts.', 'Moreover, we propose novel ways to enhance the estimated joint\\nprobability to improve text generation quality, namely co-occurrence weighted\\nmasking and adaptive thresholding.', 'We also propose systematic qualitative and\\nquantitative methods to rigorously test the quality of generated text for\\nnon-autoregressive generation.', 'One of the models in our suite, DynaMo-7.3B-T3,\\nachieves same-quality generated text as the baseline (Pythia-6.9B) while\\nachieving 2.57$\\\\times$ speed-up with only 5.87% and 2.67% parameter and\\ntraining time overheads, respectively.']\n",
            "Chunks for abstract: The Kerr nonlinearity allows for exact analytic soliton solutions in 1+1D.\n",
            "While nothing excludes that these solitons form in naturally-occurring\n",
            "real-world 3D settings as solitary walls or stripes, their observation has\n",
            "previously been considered unfeasible because of the strong transverse\n",
            "instability intrinsic to the extended nonlinear perturbation. We report the\n",
            "observation of solitons that are fully compatible with the 1+1D Kerr paradigm\n",
            "limit hosted in a 2+1D system. The waves are stripe spatial solitons in bulk\n",
            "copper doped potassium-lithium-tantalate-niobate (KLTN) supported by the\n",
            "unsaturated photorefractive screening nonlinearity. The parameters of the\n",
            "stripe solitons fit well, in the whole existence domain, with the 1+1D\n",
            "existence curve that we derive for the first time in closed form starting from\n",
            "the saturable model of propagation. Transverse instability, that accompanies\n",
            "the solitons embedded in the 3D system, is found to have a gain length much\n",
            "longer than the crystal. Findings establish our system as a versatile platform\n",
            "for investigating exact soliton solutions in bulk settings and in exploring the\n",
            "role of dimensionality at the transition from integrable to non-integrable\n",
            "regimes of propagation.\n",
            "['The Kerr nonlinearity allows for exact analytic soliton solutions in 1+1D.', 'While nothing excludes that these solitons form in naturally-occurring\\nreal-world 3D settings as solitary walls or stripes, their observation has\\npreviously been considered unfeasible because of the strong transverse\\ninstability intrinsic to the extended nonlinear perturbation.', 'We report the\\nobservation of solitons that are fully compatible with the 1+1D Kerr paradigm\\nlimit hosted in a 2+1D system.', 'The waves are stripe spatial solitons in bulk\\ncopper doped potassium-lithium-tantalate-niobate (KLTN) supported by the\\nunsaturated photorefractive screening nonlinearity.', 'The parameters of the\\nstripe solitons fit well, in the whole existence domain, with the 1+1D\\nexistence curve that we derive for the first time in closed form starting from\\nthe saturable model of propagation.', 'Transverse instability, that accompanies\\nthe solitons embedded in the 3D system, is found to have a gain length much\\nlonger than the crystal.', 'Findings establish our system as a versatile platform\\nfor investigating exact soliton solutions in bulk settings and in exploring the\\nrole of dimensionality at the transition from integrable to non-integrable\\nregimes of propagation.']\n",
            "Chunks for abstract: This paper investigates the differentiable dynamic modeling of mobile\n",
            "manipulators to facilitate efficient motion planning and physical design of\n",
            "actuators, where the actuator design is parameterized by physically meaningful\n",
            "motor geometry parameters. These parameters impact the manipulator's link mass,\n",
            "inertia, center-of-mass, torque constraints, and angular velocity constraints,\n",
            "influencing control authority in motion planning and trajectory tracking\n",
            "control. A motor's maximum torque/speed and how the design parameters affect\n",
            "the dynamics are modeled analytically, facilitating differentiable and\n",
            "analytical dynamic modeling. Additionally, an integrated locomotion and\n",
            "manipulation planning problem is formulated with direct collocation\n",
            "discretization, using the proposed differentiable dynamics and motor\n",
            "parameterization. Such dynamics are required to capture the dynamic coupling\n",
            "between the base and the manipulator. Numerical experiments demonstrate the\n",
            "effectiveness of differentiable dynamics in speeding up optimization and\n",
            "advantages in task completion time and energy consumption over established\n",
            "sequential motion planning approach. Finally, this paper introduces a\n",
            "simultaneous actuator design and motion planning framework, providing numerical\n",
            "results to validate the proposed differentiable modeling approach for co-design\n",
            "problems.\n",
            "['This paper investigates the differentiable dynamic modeling of mobile\\nmanipulators to facilitate efficient motion planning and physical design of\\nactuators, where the actuator design is parameterized by physically meaningful\\nmotor geometry parameters.', \"These parameters impact the manipulator's link mass,\\ninertia, center-of-mass, torque constraints, and angular velocity constraints,\\ninfluencing control authority in motion planning and trajectory tracking\\ncontrol.\", \"A motor's maximum torque/speed and how the design parameters affect\\nthe dynamics are modeled analytically, facilitating differentiable and\\nanalytical dynamic modeling.\", 'Additionally, an integrated locomotion and\\nmanipulation planning problem is formulated with direct collocation\\ndiscretization, using the proposed differentiable dynamics and motor\\nparameterization.', 'Such dynamics are required to capture the dynamic coupling\\nbetween the base and the manipulator.', 'Numerical experiments demonstrate the\\neffectiveness of differentiable dynamics in speeding up optimization and\\nadvantages in task completion time and energy consumption over established\\nsequential motion planning approach.', 'Finally, this paper introduces a\\nsimultaneous actuator design and motion planning framework, providing numerical\\nresults to validate the proposed differentiable modeling approach for co-design\\nproblems.']\n",
            "Chunks for abstract: Scientists conduct large-scale simulations to compute derived\n",
            "quantities-of-interest (QoI) from primary data. Often, QoI are linked to\n",
            "specific features, regions, or time intervals, such that data can be adaptively\n",
            "reduced without compromising the integrity of QoI. For many spatiotemporal\n",
            "applications, these QoI are binary in nature and represent presence or absence\n",
            "of a physical phenomenon. We present a pipelined compression approach that\n",
            "first uses neural-network-based techniques to derive regions where QoI are\n",
            "highly likely to be present. Then, we employ a Guaranteed Autoencoder (GAE) to\n",
            "compress data with differential error bounds. GAE uses QoI information to apply\n",
            "low-error compression to only these regions. This results in overall high\n",
            "compression ratios while still achieving downstream goals of simulation or data\n",
            "collections. Experimental results are presented for climate data generated from\n",
            "the E3SM Simulation model for downstream quantities such as tropical cyclone\n",
            "and atmospheric river detection and tracking. These results show that our\n",
            "approach is superior to comparable methods in the literature.\n",
            "['Scientists conduct large-scale simulations to compute derived\\nquantities-of-interest (QoI) from primary data.', 'Often, QoI are linked to\\nspecific features, regions, or time intervals, such that data can be adaptively\\nreduced without compromising the integrity of QoI.', 'For many spatiotemporal\\napplications, these QoI are binary in nature and represent presence or absence\\nof a physical phenomenon.', 'We present a pipelined compression approach that\\nfirst uses neural-network-based techniques to derive regions where QoI are\\nhighly likely to be present.', 'Then, we employ a Guaranteed Autoencoder (GAE) to\\ncompress data with differential error bounds.', 'GAE uses QoI information to apply\\nlow-error compression to only these regions.', 'This results in overall high\\ncompression ratios while still achieving downstream goals of simulation or data\\ncollections.', 'Experimental results are presented for climate data generated from\\nthe E3SM Simulation model for downstream quantities such as tropical cyclone\\nand atmospheric river detection and tracking.', 'These results show that our\\napproach is superior to comparable methods in the literature.']\n",
            "Chunks for abstract: We are witnessing a revolution in conditional image synthesis with the recent\n",
            "success of large scale text-to-image generation methods. This success also\n",
            "opens up new opportunities in controlling the generation and editing process\n",
            "using multi-modal input. While spatial control using cues such as depth,\n",
            "sketch, and other images has attracted a lot of research, we argue that another\n",
            "equally effective modality is audio since sound and sight are two main\n",
            "components of human perception. Hence, we propose a method to enable\n",
            "audio-conditioning in large scale image diffusion models. Our method first maps\n",
            "features obtained from audio clips to tokens that can be injected into the\n",
            "diffusion model in a fashion similar to text tokens. We introduce additional\n",
            "audio-image cross attention layers which we finetune while freezing the weights\n",
            "of the original layers of the diffusion model. In addition to audio conditioned\n",
            "image generation, our method can also be utilized in conjuction with diffusion\n",
            "based editing methods to enable audio conditioned image editing. We demonstrate\n",
            "our method on a wide range of audio and image datasets. We perform extensive\n",
            "comparisons with recent methods and show favorable performance.\n",
            "['We are witnessing a revolution in conditional image synthesis with the recent\\nsuccess of large scale text-to-image generation methods.', 'This success also\\nopens up new opportunities in controlling the generation and editing process\\nusing multi-modal input.', 'While spatial control using cues such as depth,\\nsketch, and other images has attracted a lot of research, we argue that another\\nequally effective modality is audio since sound and sight are two main\\ncomponents of human perception.', 'Hence, we propose a method to enable\\naudio-conditioning in large scale image diffusion models.', 'Our method first maps\\nfeatures obtained from audio clips to tokens that can be injected into the\\ndiffusion model in a fashion similar to text tokens.', 'We introduce additional\\naudio-image cross attention layers which we finetune while freezing the weights\\nof the original layers of the diffusion model.', 'In addition to audio conditioned\\nimage generation, our method can also be utilized in conjuction with diffusion\\nbased editing methods to enable audio conditioned image editing.', 'We demonstrate\\nour method on a wide range of audio and image datasets.', 'We perform extensive\\ncomparisons with recent methods and show favorable performance.']\n",
            "Chunks for abstract: We establish upper bounds on the size of the largest subset of\n",
            "$\\{1,2,\\dots,N\\}$ lacking nonzero differences of the form\n",
            "$h(p_1,\\dots,p_{\\ell})$, where $h\\in \\mathbb{Z}[x_1,\\dots,x_{\\ell}]$ is a fixed\n",
            "polynomial satisfying appropriate conditions and $p_1,\\dots,p_{\\ell}$ are\n",
            "prime. The bounds are of the same type as the best-known analogs for\n",
            "unrestricted integer inputs, due to Bloom-Maynard and Arala for $\\ell=1$, and\n",
            "to the authors for $\\ell \\geq 2$.\n",
            "['We establish upper bounds on the size of the largest subset of\\n$\\\\{1,2,\\\\dots,N\\\\}$ lacking nonzero differences of the form\\n$h(p_1,\\\\dots,p_{\\\\ell})$, where $h\\\\in \\\\mathbb{Z}[x_1,\\\\dots,x_{\\\\ell}]$ is a fixed\\npolynomial satisfying appropriate conditions and $p_1,\\\\dots,p_{\\\\ell}$ are\\nprime.', 'The bounds are of the same type as the best-known analogs for\\nunrestricted integer inputs, due to Bloom-Maynard and Arala for $\\\\ell=1$, and\\nto the authors for $\\\\ell \\\\geq 2$.']\n",
            "Chunks for abstract: Reducing Carbon dioxide (CO2) emission is vital at both global and national\n",
            "levels, given their significant role in exacerbating climate change. CO2\n",
            "emission, stemming from a variety of industrial and economic activities, are\n",
            "major contributors to the greenhouse effect and global warming, posing\n",
            "substantial obstacles in addressing climate issues. It's imperative to forecast\n",
            "CO2 emission trends and classify countries based on their emission patterns to\n",
            "effectively mitigate worldwide carbon emission. This paper presents an in-depth\n",
            "comparative study on the determinants of CO2 emission in twenty countries with\n",
            "high Human Development Index (HDI), exploring factors related to economy,\n",
            "environment, energy use, and renewable resources over a span of 25 years. The\n",
            "study unfolds in two distinct phases: initially, statistical techniques such as\n",
            "Ordinary Least Squares (OLS), fixed effects, and random effects models are\n",
            "applied to pinpoint significant determinants of CO2 emission. Following this,\n",
            "the study leverages supervised and unsupervised machine learning (ML) methods\n",
            "to further scrutinize and understand the factors influencing CO2 emission.\n",
            "Seasonal AutoRegressive Integrated Moving Average with eXogenous variables\n",
            "(SARIMAX), a supervised ML model, is first used to predict emission trends from\n",
            "historical data, offering practical insights for policy formulation.\n",
            "Subsequently, Dynamic Time Warping (DTW), an unsupervised learning approach, is\n",
            "used to group countries by similar emission patterns. The dual-phase approach\n",
            "utilized in this study significantly improves the accuracy of CO2 emission\n",
            "predictions while also providing a deeper insight into global emission trends.\n",
            "By adopting this thorough analytical framework, nations can develop more\n",
            "focused and effective carbon reduction policies, playing a vital role in the\n",
            "global initiative to combat climate change.\n",
            "['Reducing Carbon dioxide (CO2) emission is vital at both global and national\\nlevels, given their significant role in exacerbating climate change.', 'CO2\\nemission, stemming from a variety of industrial and economic activities, are\\nmajor contributors to the greenhouse effect and global warming, posing\\nsubstantial obstacles in addressing climate issues.', \"It's imperative to forecast\\nCO2 emission trends and classify countries based on their emission patterns to\\neffectively mitigate worldwide carbon emission.\", 'This paper presents an in-depth\\ncomparative study on the determinants of CO2 emission in twenty countries with\\nhigh Human Development Index (HDI), exploring factors related to economy,\\nenvironment, energy use, and renewable resources over a span of 25 years.', 'The\\nstudy unfolds in two distinct phases: initially, statistical techniques such as\\nOrdinary Least Squares (OLS), fixed effects, and random effects models are\\napplied to pinpoint significant determinants of CO2 emission.', 'Following this,\\nthe study leverages supervised and unsupervised machine learning (ML) methods\\nto further scrutinize and understand the factors influencing CO2 emission.', 'Seasonal AutoRegressive Integrated Moving Average with eXogenous variables\\n(SARIMAX), a supervised ML model, is first used to predict emission trends from\\nhistorical data, offering practical insights for policy formulation.', 'Subsequently, Dynamic Time Warping (DTW), an unsupervised learning approach, is\\nused to group countries by similar emission patterns.', 'The dual-phase approach\\nutilized in this study significantly improves the accuracy of CO2 emission\\npredictions while also providing a deeper insight into global emission trends.', 'By adopting this thorough analytical framework, nations can develop more\\nfocused and effective carbon reduction policies, playing a vital role in the\\nglobal initiative to combat climate change.']\n",
            "Chunks for abstract: The belief that AI technology is on the cusp of causing a generalized social\n",
            "crisis became a popular one in 2023. Interestingly, some of these worries were\n",
            "voiced from within the tech sector itself. While there was no doubt an element\n",
            "of hype and exaggeration to some of these accounts, they do reflect the fact\n",
            "that there are troubling ramifications to this technology stack. This\n",
            "conjunction of shared concerns about social, political, and personal futures\n",
            "presaged by current developments in machine learning and data science presents\n",
            "the academic discipline of computing with a rare opportunity for\n",
            "self-examination and reconfiguration. This position paper endeavors to do so in\n",
            "four sections. The first expands on the nature of the AI crisis for computing.\n",
            "The second articulates possible critical responses to this crisis and advocates\n",
            "for a broader analytic focus on power relations. The third section presents a\n",
            "novel characterization of academic computing's epistemological field, one which\n",
            "includes not only the discipline's usual instrumental forms of knowledge but\n",
            "reflexive knowledge as well. This reflexive dimension integrates both the\n",
            "critical and public functions of the discipline as equal intellectual partners\n",
            "and a necessary component of any contemporary academic field. The final section\n",
            "will advocate for a conceptual archetype--the Public Computer Intellectual--as\n",
            "a way of practically imagining the expanded possibilities of academic practice\n",
            "in our discipline, one that provides both self-critique and an outward-facing\n",
            "orientation towards the public good. It will argue that the computer education\n",
            "research community can play a vital role in this regard.\n",
            "['The belief that AI technology is on the cusp of causing a generalized social\\ncrisis became a popular one in 2023.', 'Interestingly, some of these worries were\\nvoiced from within the tech sector itself.', 'While there was no doubt an element\\nof hype and exaggeration to some of these accounts, they do reflect the fact\\nthat there are troubling ramifications to this technology stack.', 'This\\nconjunction of shared concerns about social, political, and personal futures\\npresaged by current developments in machine learning and data science presents\\nthe academic discipline of computing with a rare opportunity for\\nself-examination and reconfiguration.', 'This position paper endeavors to do so in\\nfour sections.', 'The first expands on the nature of the AI crisis for computing.', 'The second articulates possible critical responses to this crisis and advocates\\nfor a broader analytic focus on power relations.', \"The third section presents a\\nnovel characterization of academic computing's epistemological field, one which\\nincludes not only the discipline's usual instrumental forms of knowledge but\\nreflexive knowledge as well.\", 'This reflexive dimension integrates both the\\ncritical and public functions of the discipline as equal intellectual partners\\nand a necessary component of any contemporary academic field.', 'The final section\\nwill advocate for a conceptual archetype--the Public Computer Intellectual--as\\na way of practically imagining the expanded possibilities of academic practice\\nin our discipline, one that provides both self-critique and an outward-facing\\norientation towards the public good.', 'It will argue that the computer education\\nresearch community can play a vital role in this regard.']\n",
            "Chunks for abstract: We investigate the 3-sphere partition functions of various 3d $\\mathcal{N}=2$\n",
            "holographic SCFTs arising from the $N$ stack of M2-branes in the 't Hooft limit\n",
            "both analytically and numerically. We first employ a saddle point approximation\n",
            "to evaluate the free energy $F=-\\log Z$ at the planar level, tracking the first\n",
            "subleading corrections in the large 't Hooft coupling $\\lambda$ expansion.\n",
            "Subsequently, we improve these results by determining the planar free energy to\n",
            "all orders in the large $\\lambda$ expansion via numerical analysis. Remarkably,\n",
            "the resulting planar free energies turn out to take a universal form,\n",
            "supporting a prediction that these $S^3$ partition functions are all given in\n",
            "terms of an Airy function even beyond the special cases where the Airy formulae\n",
            "were derived analytically in the literature; in this context we also present\n",
            "new Airy conjectures in several examples. The subleading behaviors we captured\n",
            "encode a part of quantum corrections to the M-theory path integrals around dual\n",
            "asymptotically Euclidean AdS$_4$ backgrounds with the corresponding internal\n",
            "manifolds through holographic duality.\n",
            "[\"We investigate the 3-sphere partition functions of various 3d $\\\\mathcal{N}=2$\\nholographic SCFTs arising from the $N$ stack of M2-branes in the 't Hooft limit\\nboth analytically and numerically.\", \"We first employ a saddle point approximation\\nto evaluate the free energy $F=-\\\\log Z$ at the planar level, tracking the first\\nsubleading corrections in the large 't Hooft coupling $\\\\lambda$ expansion.\", 'Subsequently, we improve these results by determining the planar free energy to\\nall orders in the large $\\\\lambda$ expansion via numerical analysis.', 'Remarkably,\\nthe resulting planar free energies turn out to take a universal form,\\nsupporting a prediction that these $S^3$ partition functions are all given in\\nterms of an Airy function even beyond the special cases where the Airy formulae\\nwere derived analytically in the literature; in this context we also present\\nnew Airy conjectures in several examples.', 'The subleading behaviors we captured\\nencode a part of quantum corrections to the M-theory path integrals around dual\\nasymptotically Euclidean AdS$_4$ backgrounds with the corresponding internal\\nmanifolds through holographic duality.']\n",
            "Chunks for abstract: In the problem of quickest change detection (QCD), a change occurs at some\n",
            "unknown time in the distribution of a sequence of independent observations.\n",
            "This work studies a QCD problem where the change is either a bad change, which\n",
            "we aim to detect, or a confusing change, which is not of our interest. Our\n",
            "objective is to detect a bad change as quickly as possible while avoiding\n",
            "raising a false alarm for pre-change or a confusing change. We identify a\n",
            "specific set of pre-change, bad change, and confusing change distributions that\n",
            "pose challenges beyond the capabilities of standard Cumulative Sum (CuSum)\n",
            "procedures. Proposing novel CuSum-based detection procedures, S-CuSum and\n",
            "J-CuSum, leveraging two CuSum statistics, we offer solutions applicable across\n",
            "all kinds of pre-change, bad change, and confusing change distributions. For\n",
            "both S-CuSum and J-CuSum, we provide analytical performance guarantees and\n",
            "validate them by numerical results. Furthermore, both procedures are\n",
            "computationally efficient as they only require simple recursive updates.\n",
            "['In the problem of quickest change detection (QCD), a change occurs at some\\nunknown time in the distribution of a sequence of independent observations.', 'This work studies a QCD problem where the change is either a bad change, which\\nwe aim to detect, or a confusing change, which is not of our interest.', 'Our\\nobjective is to detect a bad change as quickly as possible while avoiding\\nraising a false alarm for pre-change or a confusing change.', 'We identify a\\nspecific set of pre-change, bad change, and confusing change distributions that\\npose challenges beyond the capabilities of standard Cumulative Sum (CuSum)\\nprocedures.', 'Proposing novel CuSum-based detection procedures, S-CuSum and\\nJ-CuSum, leveraging two CuSum statistics, we offer solutions applicable across\\nall kinds of pre-change, bad change, and confusing change distributions.', 'For\\nboth S-CuSum and J-CuSum, we provide analytical performance guarantees and\\nvalidate them by numerical results.', 'Furthermore, both procedures are\\ncomputationally efficient as they only require simple recursive updates.']\n",
            "Chunks for abstract: In this paper, we present Sim-Grasp, a robust 6-DOF two-finger grasping\n",
            "system that integrates advanced language models for enhanced object\n",
            "manipulation in cluttered environments. We introduce the Sim-Grasp-Dataset,\n",
            "which includes 1,550 objects across 500 scenarios with 7.9 million annotated\n",
            "labels, and develop Sim-GraspNet to generate grasp poses from point clouds. The\n",
            "Sim-Grasp-Polices achieve grasping success rates of 97.14% for single objects\n",
            "and 87.43% and 83.33% for mixed clutter scenarios of Levels 1-2 and Levels 3-4\n",
            "objects, respectively. By incorporating language models for target\n",
            "identification through text and box prompts, Sim-Grasp enables both\n",
            "object-agnostic and target picking, pushing the boundaries of intelligent\n",
            "robotic systems.\n",
            "['In this paper, we present Sim-Grasp, a robust 6-DOF two-finger grasping\\nsystem that integrates advanced language models for enhanced object\\nmanipulation in cluttered environments.', 'We introduce the Sim-Grasp-Dataset,\\nwhich includes 1,550 objects across 500 scenarios with 7.9 million annotated\\nlabels, and develop Sim-GraspNet to generate grasp poses from point clouds.', 'The\\nSim-Grasp-Polices achieve grasping success rates of 97.14% for single objects\\nand 87.43% and 83.33% for mixed clutter scenarios of Levels 1-2 and Levels 3-4\\nobjects, respectively.', 'By incorporating language models for target\\nidentification through text and box prompts, Sim-Grasp enables both\\nobject-agnostic and target picking, pushing the boundaries of intelligent\\nrobotic systems.']\n",
            "Chunks for abstract: Digital phased arrays have often been disregarded for millimeter-wave\n",
            "communications since the analog-to-digital converters (ADCs) are power-hungry.\n",
            "In this paper, we provide a different perspective on this matter by\n",
            "demonstrating analytically and numerically how the ADC resolution can be\n",
            "reduced when using digital phased arrays. We perform a theoretical analysis of\n",
            "the quantization noise characteristics for an OFDM signal received and\n",
            "processed by a digital phased array, using Gaussian approximation of the OFDM\n",
            "signal. In particular, we quantify the quantization noise suppression factor\n",
            "analytically and numerically. This factor describes how much the coherent\n",
            "combining reduces the quantization noise as a function of the number of\n",
            "antennas, which allows for reducing the ADC bit resolution. For instance in a\n",
            "8-16 antenna digital phased array the ADC resolution can be reduced with 1-2\n",
            "bits compared to the ADC required for an analog phased array.\n",
            "['Digital phased arrays have often been disregarded for millimeter-wave\\ncommunications since the analog-to-digital converters (ADCs) are power-hungry.', 'In this paper, we provide a different perspective on this matter by\\ndemonstrating analytically and numerically how the ADC resolution can be\\nreduced when using digital phased arrays.', 'We perform a theoretical analysis of\\nthe quantization noise characteristics for an OFDM signal received and\\nprocessed by a digital phased array, using Gaussian approximation of the OFDM\\nsignal.', 'In particular, we quantify the quantization noise suppression factor\\nanalytically and numerically.', 'This factor describes how much the coherent\\ncombining reduces the quantization noise as a function of the number of\\nantennas, which allows for reducing the ADC bit resolution.', 'For instance in a\\n8-16 antenna digital phased array the ADC resolution can be reduced with 1-2\\nbits compared to the ADC required for an analog phased array.']\n",
            "Chunks for abstract: We propose WIBA, a novel framework and suite of methods that enable the\n",
            "comprehensive understanding of \"What Is Being Argued\" across contexts. Our\n",
            "approach develops a comprehensive framework that detects: (a) the existence,\n",
            "(b) the topic, and (c) the stance of an argument, correctly accounting for the\n",
            "logical dependence among the three tasks. Our algorithm leverages the\n",
            "fine-tuning and prompt-engineering of Large Language Models. We evaluate our\n",
            "approach and show that it performs well in all the three capabilities. First,\n",
            "we develop and release an Argument Detection model that can classify a piece of\n",
            "text as an argument with an F1 score between 79% and 86% on three different\n",
            "benchmark datasets. Second, we release a language model that can identify the\n",
            "topic being argued in a sentence, be it implicit or explicit, with an average\n",
            "similarity score of 71%, outperforming current naive methods by nearly 40%.\n",
            "Finally, we develop a method for Argument Stance Classification, and evaluate\n",
            "the capability of our approach, showing it achieves a classification F1 score\n",
            "between 71% and 78% across three diverse benchmark datasets. Our evaluation\n",
            "demonstrates that WIBA allows the comprehensive understanding of What Is Being\n",
            "Argued in large corpora across diverse contexts, which is of core interest to\n",
            "many applications in linguistics, communication, and social and computer\n",
            "science. To facilitate accessibility to the advancements outlined in this work,\n",
            "we release WIBA as a free open access platform (wiba.dev).\n",
            "['We propose WIBA, a novel framework and suite of methods that enable the\\ncomprehensive understanding of \"What Is Being Argued\" across contexts.', 'Our\\napproach develops a comprehensive framework that detects: (a) the existence,\\n(b) the topic, and (c) the stance of an argument, correctly accounting for the\\nlogical dependence among the three tasks.', 'Our algorithm leverages the\\nfine-tuning and prompt-engineering of Large Language Models.', 'We evaluate our\\napproach and show that it performs well in all the three capabilities.', 'First,\\nwe develop and release an Argument Detection model that can classify a piece of\\ntext as an argument with an F1 score between 79% and 86% on three different\\nbenchmark datasets.', 'Second, we release a language model that can identify the\\ntopic being argued in a sentence, be it implicit or explicit, with an average\\nsimilarity score of 71%, outperforming current naive methods by nearly 40%.', 'Finally, we develop a method for Argument Stance Classification, and evaluate\\nthe capability of our approach, showing it achieves a classification F1 score\\nbetween 71% and 78% across three diverse benchmark datasets.', 'Our evaluation\\ndemonstrates that WIBA allows the comprehensive understanding of What Is Being\\nArgued in large corpora across diverse contexts, which is of core interest to\\nmany applications in linguistics, communication, and social and computer\\nscience.', 'To facilitate accessibility to the advancements outlined in this work,\\nwe release WIBA as a free open access platform (wiba.dev).']\n",
            "Chunks for abstract: We prove a reverse Lieb--Thirring inequality with a sharp constant for the\n",
            "matrix Schr\\\"odinger equation on the half-line.\n",
            "['We prove a reverse Lieb--Thirring inequality with a sharp constant for the\\nmatrix Schr\\\\\"odinger equation on the half-line.']\n",
            "Chunks for abstract: Large-scale text-to-image models that can generate high-quality and diverse\n",
            "images based on textual prompts have shown remarkable success. These models aim\n",
            "ultimately to create complex scenes, and addressing the challenge of\n",
            "multi-subject generation is a critical step towards this goal. However, the\n",
            "existing state-of-the-art diffusion models face difficulty when generating\n",
            "images that involve multiple subjects. When presented with a prompt containing\n",
            "more than one subject, these models may omit some subjects or merge them\n",
            "together. To address this challenge, we propose a novel approach based on a\n",
            "guiding principle. We allow the diffusion model to initially propose a layout,\n",
            "and then we rearrange the layout grid. This is achieved by enforcing\n",
            "cross-attention maps (XAMs) to adhere to proposed masks and by migrating pixels\n",
            "from latent maps to new locations determined by us. We introduce new loss terms\n",
            "aimed at reducing XAM entropy for clearer spatial definition of subjects,\n",
            "reduce the overlap between XAMs, and ensure that XAMs align with their\n",
            "respective masks. We contrast our approach with several alternative methods and\n",
            "show that it more faithfully captures the desired concepts across a variety of\n",
            "text prompts.\n",
            "['Large-scale text-to-image models that can generate high-quality and diverse\\nimages based on textual prompts have shown remarkable success.', 'These models aim\\nultimately to create complex scenes, and addressing the challenge of\\nmulti-subject generation is a critical step towards this goal.', 'However, the\\nexisting state-of-the-art diffusion models face difficulty when generating\\nimages that involve multiple subjects.', 'When presented with a prompt containing\\nmore than one subject, these models may omit some subjects or merge them\\ntogether.', 'To address this challenge, we propose a novel approach based on a\\nguiding principle.', 'We allow the diffusion model to initially propose a layout,\\nand then we rearrange the layout grid.', 'This is achieved by enforcing\\ncross-attention maps (XAMs) to adhere to proposed masks and by migrating pixels\\nfrom latent maps to new locations determined by us.', 'We introduce new loss terms\\naimed at reducing XAM entropy for clearer spatial definition of subjects,\\nreduce the overlap between XAMs, and ensure that XAMs align with their\\nrespective masks.', 'We contrast our approach with several alternative methods and\\nshow that it more faithfully captures the desired concepts across a variety of\\ntext prompts.']\n",
            "Chunks for abstract: We present determinations of the gas-phase and stellar metallicities of a\n",
            "sample of 65 star-forming galaxies at $z \\simeq 3.5$ using rest-frame\n",
            "far-ultraviolet (FUV) spectroscopy from the VANDELS survey in combination with\n",
            "follow-up rest-frame optical spectroscopy from VLT/KMOS and Keck/MOSFIRE. We\n",
            "infer gas-phase oxygen abundances ($Z_{\\mathrm{g}}$; tracing O/H) via strong\n",
            "optical nebular lines and stellar iron abundances ($Z_{\\star}$; tracing Fe/H)\n",
            "from full spectral fitting to the FUV continuum. Our sample spans the stellar\n",
            "mass range $8.5 < \\mathrm{log}(M_{\\star}/\\mathrm{M}_{\\odot}) < 10.5$ and shows\n",
            "clear evidence for both a stellar and gas-phase mass-metallicity relation\n",
            "(MZR). We find that our O and Fe abundance estimates both exhibit a similar\n",
            "mass-dependence, such that $\\mathrm{Fe/H}\\propto M_{\\star}^{0.30\\pm0.11}$ and\n",
            "$\\mathrm{O/H}\\propto M_{\\star}^{0.32\\pm0.09}$. At fixed $M_{\\star}$ we find\n",
            "that, relative to their solar values, O abundances are systematically larger\n",
            "than Fe abundances (i.e., $\\alpha$-enhancement).We estimate an average\n",
            "enhancement of $\\mathrm{(O/Fe)} = 2.65 \\pm 0.16 \\times \\mathrm{(O/Fe)_\\odot}$\n",
            "which appears to be independent of $M_{\\star}$. We employ analytic chemical\n",
            "evolution models to place a novel constraint on the strength of galactic-level\n",
            "outflows via the mass-outflow factor ($\\eta$). We show that outflow\n",
            "efficiencies that scale as $\\eta \\propto M_{\\star}^{-0.32}$ can simultaneously\n",
            "explain the functional form of of the stellar and gas-phase MZR, as well as the\n",
            "degree of $\\alpha$-enhancement at fixed Fe/H. Our results add further evidence\n",
            "to support a picture in which $\\alpha$-enhanced abundance ratios are ubiquitous\n",
            "in high-redshift star-forming galaxies, as expected for young systems whose\n",
            "interstellar medium is primarily enriched by core-collapse supernovae.\n",
            "['We present determinations of the gas-phase and stellar metallicities of a\\nsample of 65 star-forming galaxies at $z \\\\simeq 3.5$ using rest-frame\\nfar-ultraviolet (FUV) spectroscopy from the VANDELS survey in combination with\\nfollow-up rest-frame optical spectroscopy from VLT/KMOS and Keck/MOSFIRE.', 'We\\ninfer gas-phase oxygen abundances ($Z_{\\\\mathrm{g}}$; tracing O/H) via strong\\noptical nebular lines and stellar iron abundances ($Z_{\\\\star}$; tracing Fe/H)\\nfrom full spectral fitting to the FUV continuum.', 'Our sample spans the stellar\\nmass range $8.5 < \\\\mathrm{log}(M_{\\\\star}/\\\\mathrm{M}_{\\\\odot}) < 10.5$ and shows\\nclear evidence for both a stellar and gas-phase mass-metallicity relation\\n(MZR).', 'We find that our O and Fe abundance estimates both exhibit a similar\\nmass-dependence, such that $\\\\mathrm{Fe/H}\\\\propto M_{\\\\star}^{0.30\\\\pm0.11}$ and\\n$\\\\mathrm{O/H}\\\\propto M_{\\\\star}^{0.32\\\\pm0.09}$.', 'At fixed $M_{\\\\star}$ we find\\nthat, relative to their solar values, O abundances are systematically larger\\nthan Fe abundances (i.e., $\\\\alpha$-enhancement).We estimate an average\\nenhancement of $\\\\mathrm{(O/Fe)} = 2.65 \\\\pm 0.16 \\\\times \\\\mathrm{(O/Fe)_\\\\odot}$\\nwhich appears to be independent of $M_{\\\\star}$.', 'We employ analytic chemical\\nevolution models to place a novel constraint on the strength of galactic-level\\noutflows via the mass-outflow factor ($\\\\eta$).', 'We show that outflow\\nefficiencies that scale as $\\\\eta \\\\propto M_{\\\\star}^{-0.32}$ can simultaneously\\nexplain the functional form of of the stellar and gas-phase MZR, as well as the\\ndegree of $\\\\alpha$-enhancement at fixed Fe/H.', 'Our results add further evidence\\nto support a picture in which $\\\\alpha$-enhanced abundance ratios are ubiquitous\\nin high-redshift star-forming galaxies, as expected for young systems whose\\ninterstellar medium is primarily enriched by core-collapse supernovae.']\n",
            "Chunks for abstract: We propose a simple fit function, $L_{\\nu_i}(t) = C\\, t^{-\\alpha}\\,\n",
            "e^{-(t/\\tau)^{n}}$, to parametrize the luminosities of neutrinos and\n",
            "antineutrinos of all flavors during the protoneutron star (PNS) cooling phase\n",
            "at post-bounce times $t \\gtrsim 1$ s. This fit is based on results from a set\n",
            "of neutrino-hydrodynamics simulations of core-collapse supernovae in spherical\n",
            "symmetry. The simulations were performed with an energy-dependent transport for\n",
            "six neutrino species and took into account the effects of convection and muons\n",
            "in the dense and hot PNS interior. We provide values of the fit parameters $C$,\n",
            "$\\alpha$, $\\tau$, and $n$ for different neutron star masses and equations of\n",
            "state as well as correlations between these fit parameters. Our functional\n",
            "description is useful for analytic supernova modeling, for characterizing the\n",
            "neutrino light curves in large underground neutrino detectors, and as a tool to\n",
            "extract information from measured signals on the mass and equation of state of\n",
            "the PNS and on secondary signal components on top of the PNS's neutrino\n",
            "emission.\n",
            "['We propose a simple fit function, $L_{\\\\nu_i}(t) = C\\\\, t^{-\\\\alpha}\\\\,\\ne^{-(t/\\\\tau)^{n}}$, to parametrize the luminosities of neutrinos and\\nantineutrinos of all flavors during the protoneutron star (PNS) cooling phase\\nat post-bounce times $t \\\\gtrsim 1$ s. This fit is based on results from a set\\nof neutrino-hydrodynamics simulations of core-collapse supernovae in spherical\\nsymmetry.', 'The simulations were performed with an energy-dependent transport for\\nsix neutrino species and took into account the effects of convection and muons\\nin the dense and hot PNS interior.', 'We provide values of the fit parameters $C$,\\n$\\\\alpha$, $\\\\tau$, and $n$ for different neutron star masses and equations of\\nstate as well as correlations between these fit parameters.', \"Our functional\\ndescription is useful for analytic supernova modeling, for characterizing the\\nneutrino light curves in large underground neutrino detectors, and as a tool to\\nextract information from measured signals on the mass and equation of state of\\nthe PNS and on secondary signal components on top of the PNS's neutrino\\nemission.\"]\n",
            "Chunks for abstract: Generative models have enabled intuitive image creation and manipulation\n",
            "using natural language. In particular, diffusion models have recently shown\n",
            "remarkable results for natural image editing. In this work, we propose to apply\n",
            "diffusion techniques to edit textures, a specific class of images that are an\n",
            "essential part of 3D content creation pipelines. We analyze existing editing\n",
            "methods and show that they are not directly applicable to textures, since their\n",
            "common underlying approach, manipulating attention maps, is unsuitable for the\n",
            "texture domain. To address this, we propose a novel approach that instead\n",
            "manipulates CLIP image embeddings to condition the diffusion generation. We\n",
            "define editing directions using simple text prompts (e.g., \"aged wood\" to \"new\n",
            "wood\") and map these to CLIP image embedding space using a texture prior, with\n",
            "a sampling-based approach that gives us identity-preserving directions in CLIP\n",
            "space. To further improve identity preservation, we project these directions to\n",
            "a CLIP subspace that minimizes identity variations resulting from entangled\n",
            "texture attributes. Our editing pipeline facilitates the creation of arbitrary\n",
            "sliders using natural language prompts only, with no ground-truth annotated\n",
            "data necessary.\n",
            "['Generative models have enabled intuitive image creation and manipulation\\nusing natural language.', 'In particular, diffusion models have recently shown\\nremarkable results for natural image editing.', 'In this work, we propose to apply\\ndiffusion techniques to edit textures, a specific class of images that are an\\nessential part of 3D content creation pipelines.', 'We analyze existing editing\\nmethods and show that they are not directly applicable to textures, since their\\ncommon underlying approach, manipulating attention maps, is unsuitable for the\\ntexture domain.', 'To address this, we propose a novel approach that instead\\nmanipulates CLIP image embeddings to condition the diffusion generation.', 'We\\ndefine editing directions using simple text prompts (e.g., \"aged wood\" to \"new\\nwood\") and map these to CLIP image embedding space using a texture prior, with\\na sampling-based approach that gives us identity-preserving directions in CLIP\\nspace.', 'To further improve identity preservation, we project these directions to\\na CLIP subspace that minimizes identity variations resulting from entangled\\ntexture attributes.', 'Our editing pipeline facilitates the creation of arbitrary\\nsliders using natural language prompts only, with no ground-truth annotated\\ndata necessary.']\n",
            "Chunks for abstract: Semantic textual relatedness is a broader concept of semantic similarity. It\n",
            "measures the extent to which two chunks of text convey similar meaning or\n",
            "topics, or share related concepts or contexts. This notion of relatedness can\n",
            "be applied in various applications, such as document clustering and\n",
            "summarizing. SemRel-2024, a shared task in SemEval-2024, aims at reducing the\n",
            "gap in the semantic relatedness task by providing datasets for fourteen\n",
            "languages and dialects including Arabic. This paper reports on our\n",
            "participation in Track A (Algerian and Moroccan dialects) and Track B (Modern\n",
            "Standard Arabic). A BERT-based model is augmented and fine-tuned for regression\n",
            "scoring in supervised track (A), while BERT-based cosine similarity is employed\n",
            "for unsupervised track (B). Our system ranked 1st in SemRel-2024 for MSA with a\n",
            "Spearman correlation score of 0.49. We ranked 5th for Moroccan and 12th for\n",
            "Algerian with scores of 0.83 and 0.53, respectively.\n",
            "['Semantic textual relatedness is a broader concept of semantic similarity.', 'It\\nmeasures the extent to which two chunks of text convey similar meaning or\\ntopics, or share related concepts or contexts.', 'This notion of relatedness can\\nbe applied in various applications, such as document clustering and\\nsummarizing.', 'SemRel-2024, a shared task in SemEval-2024, aims at reducing the\\ngap in the semantic relatedness task by providing datasets for fourteen\\nlanguages and dialects including Arabic.', 'This paper reports on our\\nparticipation in Track A (Algerian and Moroccan dialects) and Track B (Modern\\nStandard Arabic).', 'A BERT-based model is augmented and fine-tuned for regression\\nscoring in supervised track (A), while BERT-based cosine similarity is employed\\nfor unsupervised track (B).', 'Our system ranked 1st in SemRel-2024 for MSA with a\\nSpearman correlation score of 0.49.', 'We ranked 5th for Moroccan and 12th for\\nAlgerian with scores of 0.83 and 0.53, respectively.']\n",
            "Chunks for abstract: For long document summarization, discourse structure is important to discern\n",
            "the key content of the text and the differences in importance level between\n",
            "sentences. Unfortunately, the integration of rhetorical structure theory (RST)\n",
            "into parameter-efficient fine-tuning strategies for long document summarization\n",
            "remains unexplored. Therefore, this paper introduces RST-LoRA and proposes four\n",
            "RST-aware variants to explicitly incorporate RST into the LoRA model. Our\n",
            "empirical evaluation demonstrates that incorporating the type and uncertainty\n",
            "of rhetorical relations can complementarily enhance the performance of LoRA in\n",
            "summarization tasks. Furthermore, the best-performing variant we introduced\n",
            "outperforms the vanilla LoRA and full-parameter fine-tuning models, as\n",
            "confirmed by multiple automatic and human evaluations, and even surpasses\n",
            "previous state-of-the-art methods.\n",
            "['For long document summarization, discourse structure is important to discern\\nthe key content of the text and the differences in importance level between\\nsentences.', 'Unfortunately, the integration of rhetorical structure theory (RST)\\ninto parameter-efficient fine-tuning strategies for long document summarization\\nremains unexplored.', 'Therefore, this paper introduces RST-LoRA and proposes four\\nRST-aware variants to explicitly incorporate RST into the LoRA model.', 'Our\\nempirical evaluation demonstrates that incorporating the type and uncertainty\\nof rhetorical relations can complementarily enhance the performance of LoRA in\\nsummarization tasks.', 'Furthermore, the best-performing variant we introduced\\noutperforms the vanilla LoRA and full-parameter fine-tuning models, as\\nconfirmed by multiple automatic and human evaluations, and even surpasses\\nprevious state-of-the-art methods.']\n",
            "Chunks for abstract: In this work, we develop a computational framework that aims at\n",
            "simultaneously optimizing the shape and the slip velocity of an axisymmetric\n",
            "microswimmer suspended in a viscous fluid. We consider shapes of a given\n",
            "reduced volume that maximize the swimming efficiency, i.e., the\n",
            "(size-independent) ratio of the power loss arising from towing the rigid body\n",
            "of the same shape and size at the same translation velocity to the actual power\n",
            "loss incurred by swimming via the slip velocity. The optimal slip and\n",
            "efficiency (with shape fixed) are here given in terms of two Stokes flow\n",
            "solutions, and we then establish shape sensitivity formulas of adjoint-solution\n",
            "that provide objective function derivatives with respect to any set of shape\n",
            "parameters on the sole basis of the above two flow solutions. Our computational\n",
            "treatment relies on a fast and accurate boundary integral solver for solving\n",
            "all Stokes flow problems. We validate our analytic shape derivative formulas\n",
            "via comparisons against finite-difference gradient evaluations, and present\n",
            "several shape optimization examples.\n",
            "['In this work, we develop a computational framework that aims at\\nsimultaneously optimizing the shape and the slip velocity of an axisymmetric\\nmicroswimmer suspended in a viscous fluid.', 'We consider shapes of a given\\nreduced volume that maximize the swimming efficiency, i.e., the\\n(size-independent) ratio of the power loss arising from towing the rigid body\\nof the same shape and size at the same translation velocity to the actual power\\nloss incurred by swimming via the slip velocity.', 'The optimal slip and\\nefficiency (with shape fixed) are here given in terms of two Stokes flow\\nsolutions, and we then establish shape sensitivity formulas of adjoint-solution\\nthat provide objective function derivatives with respect to any set of shape\\nparameters on the sole basis of the above two flow solutions.', 'Our computational\\ntreatment relies on a fast and accurate boundary integral solver for solving\\nall Stokes flow problems.', 'We validate our analytic shape derivative formulas\\nvia comparisons against finite-difference gradient evaluations, and present\\nseveral shape optimization examples.']\n",
            "Chunks for abstract: We present the two-loop mixed strong-electroweak virtual corrections to the\n",
            "charged current Drell-Yan process. The final-state collinear singularities are\n",
            "regularised by the lepton mass. The evaluation of all the relevant Feynman\n",
            "integrals, including those with up to two different internal massive lines, has\n",
            "been worked out relying on semi-analytical techniques, using complex-valued\n",
            "masses. We can provide, at any arbitrary phase-space point, the solution as a\n",
            "power series in the $W$-boson mass, around a reference value. Starting from\n",
            "these expansions, we can prepare a numerical grid for any value of the\n",
            "$W$-boson mass within their radius of convergence in a negligible amount of\n",
            "time.\n",
            "['We present the two-loop mixed strong-electroweak virtual corrections to the\\ncharged current Drell-Yan process.', 'The final-state collinear singularities are\\nregularised by the lepton mass.', 'The evaluation of all the relevant Feynman\\nintegrals, including those with up to two different internal massive lines, has\\nbeen worked out relying on semi-analytical techniques, using complex-valued\\nmasses.', 'We can provide, at any arbitrary phase-space point, the solution as a\\npower series in the $W$-boson mass, around a reference value.', 'Starting from\\nthese expansions, we can prepare a numerical grid for any value of the\\n$W$-boson mass within their radius of convergence in a negligible amount of\\ntime.']\n",
            "Chunks for abstract: In this paper, we prove that for a given surjective holomorphic endomorphism\n",
            "$f$ of a compact K\\\"ahler manifold $X$ and for some integer $p$ with $1\\le p\\le\n",
            "k$, there exists a proper invariant analytic subset $E$ for $f$ such that if\n",
            "$S$ is smooth in a neighborhood of $E$, the sequence\n",
            "$d_p^{-n}(f^n)^*(S-\\alpha_S)$ converges to $0$ exponentially fast in the sense\n",
            "of currents where $d_p$ denotes the dynamical degree of order $p$ and\n",
            "$\\alpha_S$ is a closed smooth form in the de Rham cohomology class of $S$.\n",
            "['In this paper, we prove that for a given surjective holomorphic endomorphism\\n$f$ of a compact K\\\\\"ahler manifold $X$ and for some integer $p$ with $1\\\\le p\\\\le\\nk$, there exists a proper invariant analytic subset $E$ for $f$ such that if\\n$S$ is smooth in a neighborhood of $E$, the sequence\\n$d_p^{-n}(f^n)^*(S-\\\\alpha_S)$ converges to $0$ exponentially fast in the sense\\nof currents where $d_p$ denotes the dynamical degree of order $p$ and\\n$\\\\alpha_S$ is a closed smooth form in the de Rham cohomology class of $S$.']\n",
            "Chunks for abstract: Compact autonomous marine vehicles, both surface and submersible, are now\n",
            "commonly used to conduct observations of ocean velocities using Acoustic\n",
            "Doppler Current Profilers (ADCPs). However, in the inevitable presence of\n",
            "surface waves, ADCP measurements conducted by these platforms are susceptible\n",
            "to biases stemming from wave-coherent orbital motion and platform tilting. In\n",
            "typical ocean conditions, the magnitude of the bias can reach tens of\n",
            "centimeters per second. This paper presents analytical derivation of the\n",
            "depth-dependent bias formulas for a variety of scenarios, encompassing surface\n",
            "and subsurface platforms, upward- and downward-looking ADCPs, free-drifting and\n",
            "self-propelled vehicles. The bias is shown to be a function of the wave field\n",
            "properties, platform response dynamics, and the ADCP configuration\n",
            "(particularly, orientation and beam angle). In all cases, the wave-induced\n",
            "biases show parametric scaling similar to that of the Stokes drift, albeit with\n",
            "a number of critical nuances. Analytical derivations are validated with a\n",
            "semi-analytical model, which can also be used to estimate the biases for more\n",
            "complex measurement configurations. Further analysis reveals unexpected\n",
            "fundamental differences between the upward- and downward-looking ADCP\n",
            "configurations, offering insights for experimental design aimed at minimizing\n",
            "and mitigating wave-induced biases in autonomous oceanographic observations.\n",
            "['Compact autonomous marine vehicles, both surface and submersible, are now\\ncommonly used to conduct observations of ocean velocities using Acoustic\\nDoppler Current Profilers (ADCPs).', 'However, in the inevitable presence of\\nsurface waves, ADCP measurements conducted by these platforms are susceptible\\nto biases stemming from wave-coherent orbital motion and platform tilting.', 'In\\ntypical ocean conditions, the magnitude of the bias can reach tens of\\ncentimeters per second.', 'This paper presents analytical derivation of the\\ndepth-dependent bias formulas for a variety of scenarios, encompassing surface\\nand subsurface platforms, upward- and downward-looking ADCPs, free-drifting and\\nself-propelled vehicles.', 'The bias is shown to be a function of the wave field\\nproperties, platform response dynamics, and the ADCP configuration\\n(particularly, orientation and beam angle).', 'In all cases, the wave-induced\\nbiases show parametric scaling similar to that of the Stokes drift, albeit with\\na number of critical nuances.', 'Analytical derivations are validated with a\\nsemi-analytical model, which can also be used to estimate the biases for more\\ncomplex measurement configurations.', 'Further analysis reveals unexpected\\nfundamental differences between the upward- and downward-looking ADCP\\nconfigurations, offering insights for experimental design aimed at minimizing\\nand mitigating wave-induced biases in autonomous oceanographic observations.']\n",
            "Chunks for abstract: Let $\\mathfrak q$ be a finite-dimensional Lie algebra, $\\vartheta\\in\n",
            "Aut(\\mathfrak q)$ a finite order automorphism, and $\\mathfrak q_0$ the\n",
            "subalgebra of fixed points of $\\vartheta$. Using $\\vartheta$ one can construct\n",
            "a pencil $\\mathcal P$ of compatible Poisson brackets on $S(\\mathfrak q)$, and\n",
            "thereby a `large' Poisson-commutative subalgebra $Z(\\mathfrak q,\\vartheta)$\n",
            "consisting of $\\mathfrak q_0$-invariants in $S(\\mathfrak q)$. We study one\n",
            "particular bracket $\\{\\,\\,,\\,\\}_{\\infty}\\in\\mathcal P$ and the related Poisson\n",
            "centre ${\\mathcal Z}_\\infty$. It is shown that ${\\mathcal Z}_\\infty$ is a\n",
            "polynomial ring, if $\\mathfrak q$ is reductive.\n",
            "['Let $\\\\mathfrak q$ be a finite-dimensional Lie algebra, $\\\\vartheta\\\\in\\nAut(\\\\mathfrak q)$ a finite order automorphism, and $\\\\mathfrak q_0$ the\\nsubalgebra of fixed points of $\\\\vartheta$.', \"Using $\\\\vartheta$ one can construct\\na pencil $\\\\mathcal P$ of compatible Poisson brackets on $S(\\\\mathfrak q)$, and\\nthereby a `large' Poisson-commutative subalgebra $Z(\\\\mathfrak q,\\\\vartheta)$\\nconsisting of $\\\\mathfrak q_0$-invariants in $S(\\\\mathfrak q)$.\", 'We study one\\nparticular bracket $\\\\{\\\\,\\\\,,\\\\,\\\\}_{\\\\infty}\\\\in\\\\mathcal P$ and the related Poisson\\ncentre ${\\\\mathcal Z}_\\\\infty$.', 'It is shown that ${\\\\mathcal Z}_\\\\infty$ is a\\npolynomial ring, if $\\\\mathfrak q$ is reductive.']\n",
            "Chunks for abstract: This paper presents a succinct derivation of the training and generalization\n",
            "performance of a variety of high-dimensional ridge regression models using the\n",
            "basic tools of random matrix theory and free probability. We provide an\n",
            "introduction and review of recent results on these topics, aimed at readers\n",
            "with backgrounds in physics and deep learning. Analytic formulas for the\n",
            "training and generalization errors are obtained in a few lines of algebra\n",
            "directly from the properties of the $S$-transform of free probability. This\n",
            "allows for a straightforward identification of the sources of power-law scaling\n",
            "in model performance. We compute the generalization error of a broad class of\n",
            "random feature models. We find that in all models, the $S$-transform\n",
            "corresponds to the train-test generalization gap, and yields an analogue of the\n",
            "generalized-cross-validation estimator. Using these techniques, we derive\n",
            "fine-grained bias-variance decompositions for a very general class of random\n",
            "feature models with structured covariates. These novel results allow us to\n",
            "discover a scaling regime for random feature models where the variance due to\n",
            "the features limits performance in the overparameterized setting. We also\n",
            "demonstrate how anisotropic weight structure in random feature models can limit\n",
            "performance and lead to nontrivial exponents for finite-width corrections in\n",
            "the overparameterized setting. Our results extend and provide a unifying\n",
            "perspective on earlier models of neural scaling laws.\n",
            "['This paper presents a succinct derivation of the training and generalization\\nperformance of a variety of high-dimensional ridge regression models using the\\nbasic tools of random matrix theory and free probability.', 'We provide an\\nintroduction and review of recent results on these topics, aimed at readers\\nwith backgrounds in physics and deep learning.', 'Analytic formulas for the\\ntraining and generalization errors are obtained in a few lines of algebra\\ndirectly from the properties of the $S$-transform of free probability.', 'This\\nallows for a straightforward identification of the sources of power-law scaling\\nin model performance.', 'We compute the generalization error of a broad class of\\nrandom feature models.', 'We find that in all models, the $S$-transform\\ncorresponds to the train-test generalization gap, and yields an analogue of the\\ngeneralized-cross-validation estimator.', 'Using these techniques, we derive\\nfine-grained bias-variance decompositions for a very general class of random\\nfeature models with structured covariates.', 'These novel results allow us to\\ndiscover a scaling regime for random feature models where the variance due to\\nthe features limits performance in the overparameterized setting.', 'We also\\ndemonstrate how anisotropic weight structure in random feature models can limit\\nperformance and lead to nontrivial exponents for finite-width corrections in\\nthe overparameterized setting.', 'Our results extend and provide a unifying\\nperspective on earlier models of neural scaling laws.']\n",
            "Chunks for abstract: This thesis results from an intensive study on the canonical metrics on the\n",
            "Teichm\\\"{u}ller spaces and the moduli spaces of Riemann surfaces. There are\n",
            "several renowned classical metrics on $T_g$ and $\\mathcal{M}_g$, including the\n",
            "Weil-Petersson metric, the Teichm\\\"{u}ller metric, the Kobayashi metric, the\n",
            "Bergman metric, the Carath\\'{e}odory metric and the K\\\"{a}hler-Einstein metric.\n",
            "The Teichm\\\"{u}ller metric, the Kobayashi metric and the Carath\\'{e}odory\n",
            "metric are only (complete) Finsler metrics, but they are effective tools in the\n",
            "study of hyperbolic property of $\\mathcal{M}_g$. The Weil-Petersson metric is\n",
            "an incomplete K\\\"{a}hler metric, while the Bergman metric and the\n",
            "K\\\"{a}hler-Einstein metric are complete K\\\"{a}hler metrics. However, McMullen\n",
            "introduced a new complete K\\\"{a}hler metric, called the McMullen metric, by\n",
            "perturbing the Weil-Petersson metric. This metric is indeed equivalent to the\n",
            "Teichm\\\"{u}ller metric. Recently, Liu-Sun-Yau proved that the equivalence of\n",
            "the K\\\"{a}hler-Einstein metric to the Teichm\\\"{u}ller metric, and hence gave a\n",
            "positive answer to a conjecture proposed by Yau. Their approach in the proof is\n",
            "to introduce two new complete K\\\"{a}hler metrics, namely, the Ricci metric and\n",
            "the perturbed Ricci metric, and then establish the equivalence of the Ricci\n",
            "metric to the K\\\"{a}hler-Einstein metric and the equivalence of the Ricci\n",
            "metric to the McMullen metric. The main purpose of this thesis is to survey the\n",
            "properties of these various metrics and the geometry of $T_g$ and\n",
            "$\\mathcal{M}_g$ induced by these metrics.\n",
            "['This thesis results from an intensive study on the canonical metrics on the\\nTeichm\\\\\"{u}ller spaces and the moduli spaces of Riemann surfaces.', 'There are\\nseveral renowned classical metrics on $T_g$ and $\\\\mathcal{M}_g$, including the\\nWeil-Petersson metric, the Teichm\\\\\"{u}ller metric, the Kobayashi metric, the\\nBergman metric, the Carath\\\\\\'{e}odory metric and the K\\\\\"{a}hler-Einstein metric.', 'The Teichm\\\\\"{u}ller metric, the Kobayashi metric and the Carath\\\\\\'{e}odory\\nmetric are only (complete) Finsler metrics, but they are effective tools in the\\nstudy of hyperbolic property of $\\\\mathcal{M}_g$.', 'The Weil-Petersson metric is\\nan incomplete K\\\\\"{a}hler metric, while the Bergman metric and the\\nK\\\\\"{a}hler-Einstein metric are complete K\\\\\"{a}hler metrics.', 'However, McMullen\\nintroduced a new complete K\\\\\"{a}hler metric, called the McMullen metric, by\\nperturbing the Weil-Petersson metric.', 'This metric is indeed equivalent to the\\nTeichm\\\\\"{u}ller metric.', 'Recently, Liu-Sun-Yau proved that the equivalence of\\nthe K\\\\\"{a}hler-Einstein metric to the Teichm\\\\\"{u}ller metric, and hence gave a\\npositive answer to a conjecture proposed by Yau.', 'Their approach in the proof is\\nto introduce two new complete K\\\\\"{a}hler metrics, namely, the Ricci metric and\\nthe perturbed Ricci metric, and then establish the equivalence of the Ricci\\nmetric to the K\\\\\"{a}hler-Einstein metric and the equivalence of the Ricci\\nmetric to the McMullen metric.', 'The main purpose of this thesis is to survey the\\nproperties of these various metrics and the geometry of $T_g$ and\\n$\\\\mathcal{M}_g$ induced by these metrics.']\n",
            "Chunks for abstract: Gender bias research has been pivotal in revealing undesirable behaviors in\n",
            "large language models, exposing serious gender stereotypes associated with\n",
            "occupations, and emotions. A key observation in prior work is that models\n",
            "reinforce stereotypes as a consequence of the gendered correlations that are\n",
            "present in the training data. In this paper, we focus on bias where the effect\n",
            "from training data is unclear, and instead address the question: Do language\n",
            "models still exhibit gender bias in non-stereotypical settings? To do so, we\n",
            "introduce UnStereoEval (USE), a novel framework tailored for investigating\n",
            "gender bias in stereotype-free scenarios. USE defines a sentence-level score\n",
            "based on pretraining data statistics to determine if the sentence contain\n",
            "minimal word-gender associations. To systematically benchmark the fairness of\n",
            "popular language models in stereotype-free scenarios, we utilize USE to\n",
            "automatically generate benchmarks without any gender-related language. By\n",
            "leveraging USE's sentence-level score, we also repurpose prior gender bias\n",
            "benchmarks (Winobias and Winogender) for non-stereotypical evaluation.\n",
            "Surprisingly, we find low fairness across all 28 tested models. Concretely,\n",
            "models demonstrate fair behavior in only 9%-41% of stereotype-free sentences,\n",
            "suggesting that bias does not solely stem from the presence of gender-related\n",
            "words. These results raise important questions about where underlying model\n",
            "biases come from and highlight the need for more systematic and comprehensive\n",
            "bias evaluation. We release the full dataset and code at\n",
            "https://ucinlp.github.io/unstereo-eval.\n",
            "['Gender bias research has been pivotal in revealing undesirable behaviors in\\nlarge language models, exposing serious gender stereotypes associated with\\noccupations, and emotions.', 'A key observation in prior work is that models\\nreinforce stereotypes as a consequence of the gendered correlations that are\\npresent in the training data.', 'In this paper, we focus on bias where the effect\\nfrom training data is unclear, and instead address the question: Do language\\nmodels still exhibit gender bias in non-stereotypical settings?', 'To do so, we\\nintroduce UnStereoEval (USE), a novel framework tailored for investigating\\ngender bias in stereotype-free scenarios.', 'USE defines a sentence-level score\\nbased on pretraining data statistics to determine if the sentence contain\\nminimal word-gender associations.', 'To systematically benchmark the fairness of\\npopular language models in stereotype-free scenarios, we utilize USE to\\nautomatically generate benchmarks without any gender-related language.', \"By\\nleveraging USE's sentence-level score, we also repurpose prior gender bias\\nbenchmarks (Winobias and Winogender) for non-stereotypical evaluation.\", 'Surprisingly, we find low fairness across all 28 tested models.', 'Concretely,\\nmodels demonstrate fair behavior in only 9%-41% of stereotype-free sentences,\\nsuggesting that bias does not solely stem from the presence of gender-related\\nwords.', 'These results raise important questions about where underlying model\\nbiases come from and highlight the need for more systematic and comprehensive\\nbias evaluation.', 'We release the full dataset and code at\\nhttps://ucinlp.github.io/unstereo-eval.']\n",
            "Chunks for abstract: Extremal Type II $\\mathbb{Z}_{8}$-codes are a class of self-dual\n",
            "$\\mathbb{Z}_{8}$-codes with Euclidean weights divisible by $16$ and the largest\n",
            "possible minimum Euclidean weight for a given length. We introduce a doubling\n",
            "method for constructing a Type II $\\mathbb{Z}_{2k}$-code of length $n$ from a\n",
            "known Type II $\\mathbb{Z}_{2k}$-code of length $n$. Based on this method, we\n",
            "develop an algorithm to construct new extremal Type II $\\mathbb{Z}_8$-codes\n",
            "starting from an extremal Type II $\\mathbb{Z}_8$-code of type\n",
            "$(\\frac{n}{2},0,0)$ with an extremal $\\mathbb{Z}_4$-residue code and length\n",
            "$24, 32$ or $40$.\n",
            "  We construct at least ten new extremal Type II $\\mathbb{Z}_8$-codes of length\n",
            "$32$ and type $(15,1,1)$. Extremal Type II $\\mathbb{Z}_8$-codes of length $32$\n",
            "of this type were not known before. Moreover, the binary residue codes of the\n",
            "constructed extremal $\\mathbb{Z}_8$-codes are optimal $[32,15]$ binary codes.\n",
            "['Extremal Type II $\\\\mathbb{Z}_{8}$-codes are a class of self-dual\\n$\\\\mathbb{Z}_{8}$-codes with Euclidean weights divisible by $16$ and the largest\\npossible minimum Euclidean weight for a given length.', 'We introduce a doubling\\nmethod for constructing a Type II $\\\\mathbb{Z}_{2k}$-code of length $n$ from a\\nknown Type II $\\\\mathbb{Z}_{2k}$-code of length $n$.', 'Based on this method, we\\ndevelop an algorithm to construct new extremal Type II $\\\\mathbb{Z}_8$-codes\\nstarting from an extremal Type II $\\\\mathbb{Z}_8$-code of type\\n$(\\\\frac{n}{2},0,0)$ with an extremal $\\\\mathbb{Z}_4$-residue code and length\\n$24, 32$ or $40$.', 'We construct at least ten new extremal Type II $\\\\mathbb{Z}_8$-codes of length\\n$32$ and type $(15,1,1)$.', 'Extremal Type II $\\\\mathbb{Z}_8$-codes of length $32$\\nof this type were not known before.', 'Moreover, the binary residue codes of the\\nconstructed extremal $\\\\mathbb{Z}_8$-codes are optimal $[32,15]$ binary codes.']\n",
            "Chunks for abstract: We present a condition under which the thermal quasi-geostrophic (TQG) model\n",
            "possesses a solution that is holomorphic in time with values in the Gevrey\n",
            "space of complex analytic functions. This can be seen as the complex extension\n",
            "of the work by Levermore and Oliver (1997) for the generalized Euler equation\n",
            "but applied to the TQG model.\n",
            "['We present a condition under which the thermal quasi-geostrophic (TQG) model\\npossesses a solution that is holomorphic in time with values in the Gevrey\\nspace of complex analytic functions.', 'This can be seen as the complex extension\\nof the work by Levermore and Oliver (1997) for the generalized Euler equation\\nbut applied to the TQG model.']\n",
            "Chunks for abstract: Optimizing a text-to-image diffusion model with a given reward function is an\n",
            "important but underexplored research area. In this study, we propose Deep\n",
            "Reward Tuning (DRTune), an algorithm that directly supervises the final output\n",
            "image of a text-to-image diffusion model and back-propagates through the\n",
            "iterative sampling process to the input noise. We find that training earlier\n",
            "steps in the sampling process is crucial for low-level rewards, and deep\n",
            "supervision can be achieved efficiently and effectively by stopping the\n",
            "gradient of the denoising network input. DRTune is extensively evaluated on\n",
            "various reward models. It consistently outperforms other algorithms,\n",
            "particularly for low-level control signals, where all shallow supervision\n",
            "methods fail. Additionally, we fine-tune Stable Diffusion XL 1.0 (SDXL 1.0)\n",
            "model via DRTune to optimize Human Preference Score v2.1, resulting in the\n",
            "Favorable Diffusion XL 1.0 (FDXL 1.0) model. FDXL 1.0 significantly enhances\n",
            "image quality compared to SDXL 1.0 and reaches comparable quality compared with\n",
            "Midjourney v5.2.\n",
            "['Optimizing a text-to-image diffusion model with a given reward function is an\\nimportant but underexplored research area.', 'In this study, we propose Deep\\nReward Tuning (DRTune), an algorithm that directly supervises the final output\\nimage of a text-to-image diffusion model and back-propagates through the\\niterative sampling process to the input noise.', 'We find that training earlier\\nsteps in the sampling process is crucial for low-level rewards, and deep\\nsupervision can be achieved efficiently and effectively by stopping the\\ngradient of the denoising network input.', 'DRTune is extensively evaluated on\\nvarious reward models.', 'It consistently outperforms other algorithms,\\nparticularly for low-level control signals, where all shallow supervision\\nmethods fail.', 'Additionally, we fine-tune Stable Diffusion XL 1.0 (SDXL 1.0)\\nmodel via DRTune to optimize Human Preference Score v2.1, resulting in the\\nFavorable Diffusion XL 1.0 (FDXL 1.0) model.', 'FDXL 1.0 significantly enhances\\nimage quality compared to SDXL 1.0 and reaches comparable quality compared with\\nMidjourney v5.2.']\n",
            "Chunks for abstract: Composed Image Retrieval (CIR) is a complex task that retrieves images using\n",
            "a query, which is configured with an image and a caption that describes desired\n",
            "modifications to that image. Supervised CIR approaches have shown strong\n",
            "performance, but their reliance on expensive manually-annotated datasets\n",
            "restricts their scalability and broader applicability. To address these issues,\n",
            "previous studies have proposed pseudo-word token-based Zero-Shot CIR (ZS-CIR)\n",
            "methods, which utilize a projection module to map images to word tokens.\n",
            "However, we conjecture that this approach has a downside: the projection module\n",
            "distorts the original image representation and confines the resulting composed\n",
            "embeddings to the text-side. In order to resolve this, we introduce a novel\n",
            "ZS-CIR method that uses Spherical Linear Interpolation (Slerp) to directly\n",
            "merge image and text representations by identifying an intermediate embedding\n",
            "of both. Furthermore, we introduce Text-Anchored-Tuning (TAT), a method that\n",
            "fine-tunes the image encoder while keeping the text encoder fixed. TAT closes\n",
            "the modality gap between images and text, making the Slerp process much more\n",
            "effective. Notably, the TAT method is not only efficient in terms of the scale\n",
            "of the training dataset and training time, but it also serves as an excellent\n",
            "initial checkpoint for training supervised CIR models, thereby highlighting its\n",
            "wider potential. The integration of the Slerp-based ZS-CIR with a TAT-tuned\n",
            "model enables our approach to deliver state-of-the-art retrieval performance\n",
            "across CIR benchmarks.\n",
            "['Composed Image Retrieval (CIR) is a complex task that retrieves images using\\na query, which is configured with an image and a caption that describes desired\\nmodifications to that image.', 'Supervised CIR approaches have shown strong\\nperformance, but their reliance on expensive manually-annotated datasets\\nrestricts their scalability and broader applicability.', 'To address these issues,\\nprevious studies have proposed pseudo-word token-based Zero-Shot CIR (ZS-CIR)\\nmethods, which utilize a projection module to map images to word tokens.', 'However, we conjecture that this approach has a downside: the projection module\\ndistorts the original image representation and confines the resulting composed\\nembeddings to the text-side.', 'In order to resolve this, we introduce a novel\\nZS-CIR method that uses Spherical Linear Interpolation (Slerp) to directly\\nmerge image and text representations by identifying an intermediate embedding\\nof both.', 'Furthermore, we introduce Text-Anchored-Tuning (TAT), a method that\\nfine-tunes the image encoder while keeping the text encoder fixed.', 'TAT closes\\nthe modality gap between images and text, making the Slerp process much more\\neffective.', 'Notably, the TAT method is not only efficient in terms of the scale\\nof the training dataset and training time, but it also serves as an excellent\\ninitial checkpoint for training supervised CIR models, thereby highlighting its\\nwider potential.', 'The integration of the Slerp-based ZS-CIR with a TAT-tuned\\nmodel enables our approach to deliver state-of-the-art retrieval performance\\nacross CIR benchmarks.']\n",
            "Chunks for abstract: Relational database management systems (RDBMS) are widely used for the\n",
            "storage and retrieval of structured data. To derive insights beyond statistical\n",
            "aggregation, we typically have to extract specific subdatasets from the\n",
            "database using conventional database operations, and then apply deep neural\n",
            "networks (DNN) training and inference on these respective subdatasets in a\n",
            "separate machine learning system. The process can be prohibitively expensive,\n",
            "especially when there are a combinatorial number of subdatasets extracted for\n",
            "different analytical purposes. This calls for efficient in-database support of\n",
            "advanced analytical methods In this paper, we introduce LEADS, a novel\n",
            "SQL-aware dynamic model slicing technique to customize models for subdatasets\n",
            "specified by SQL queries. LEADS improves the predictive modeling of structured\n",
            "data via the mixture of experts (MoE) technique and maintains inference\n",
            "efficiency by a SQL-aware gating network. At the core of LEADS is the\n",
            "construction of a general model with multiple expert sub-models via MoE trained\n",
            "over the entire database. This SQL-aware MoE technique scales up the modeling\n",
            "capacity, enhances effectiveness, and preserves efficiency by activating only\n",
            "necessary experts via the gating network during inference. Additionally, we\n",
            "introduce two regularization terms during the training process of LEADS to\n",
            "strike a balance between effectiveness and efficiency. We also design and build\n",
            "an in-database inference system, called INDICES, to support end-to-end advanced\n",
            "structured data analytics by non-intrusively incorporating LEADS onto\n",
            "PostgreSQL. Our extensive experiments on real-world datasets demonstrate that\n",
            "LEADS consistently outperforms baseline models, and INDICES delivers effective\n",
            "in-database analytics with a considerable reduction in inference latency\n",
            "compared to traditional solutions.\n",
            "['Relational database management systems (RDBMS) are widely used for the\\nstorage and retrieval of structured data.', 'To derive insights beyond statistical\\naggregation, we typically have to extract specific subdatasets from the\\ndatabase using conventional database operations, and then apply deep neural\\nnetworks (DNN) training and inference on these respective subdatasets in a\\nseparate machine learning system.', 'The process can be prohibitively expensive,\\nespecially when there are a combinatorial number of subdatasets extracted for\\ndifferent analytical purposes.', 'This calls for efficient in-database support of\\nadvanced analytical methods In this paper, we introduce LEADS, a novel\\nSQL-aware dynamic model slicing technique to customize models for subdatasets\\nspecified by SQL queries.', 'LEADS improves the predictive modeling of structured\\ndata via the mixture of experts (MoE) technique and maintains inference\\nefficiency by a SQL-aware gating network.', 'At the core of LEADS is the\\nconstruction of a general model with multiple expert sub-models via MoE trained\\nover the entire database.', 'This SQL-aware MoE technique scales up the modeling\\ncapacity, enhances effectiveness, and preserves efficiency by activating only\\nnecessary experts via the gating network during inference.', 'Additionally, we\\nintroduce two regularization terms during the training process of LEADS to\\nstrike a balance between effectiveness and efficiency.', 'We also design and build\\nan in-database inference system, called INDICES, to support end-to-end advanced\\nstructured data analytics by non-intrusively incorporating LEADS onto\\nPostgreSQL.', 'Our extensive experiments on real-world datasets demonstrate that\\nLEADS consistently outperforms baseline models, and INDICES delivers effective\\nin-database analytics with a considerable reduction in inference latency\\ncompared to traditional solutions.']\n",
            "Chunks for abstract: Recently, many works have proposed various financial large language models\n",
            "(FinLLMs) by pre-training from scratch or fine-tuning open-sourced LLMs on\n",
            "financial corpora. However, existing FinLLMs exhibit unsatisfactory performance\n",
            "in understanding financial text when numeric variables are involved in\n",
            "questions. In this paper, we propose a novel LLM, called numeric-sensitive\n",
            "large language model (NumLLM), for Chinese finance. We first construct a\n",
            "financial corpus from financial textbooks which is essential for improving\n",
            "numeric capability of LLMs during fine-tuning. After that, we train two\n",
            "individual low-rank adaptation (LoRA) modules by fine-tuning on our constructed\n",
            "financial corpus. One module is for adapting general-purpose LLMs to financial\n",
            "domain, and the other module is for enhancing the ability of NumLLM to\n",
            "understand financial text with numeric variables. Lastly, we merge the two LoRA\n",
            "modules into the foundation model to obtain NumLLM for inference. Experiments\n",
            "on financial question-answering benchmark show that NumLLM can boost the\n",
            "performance of the foundation model and can achieve the best overall\n",
            "performance compared to all baselines, on both numeric and non-numeric\n",
            "questions.\n",
            "['Recently, many works have proposed various financial large language models\\n(FinLLMs) by pre-training from scratch or fine-tuning open-sourced LLMs on\\nfinancial corpora.', 'However, existing FinLLMs exhibit unsatisfactory performance\\nin understanding financial text when numeric variables are involved in\\nquestions.', 'In this paper, we propose a novel LLM, called numeric-sensitive\\nlarge language model (NumLLM), for Chinese finance.', 'We first construct a\\nfinancial corpus from financial textbooks which is essential for improving\\nnumeric capability of LLMs during fine-tuning.', 'After that, we train two\\nindividual low-rank adaptation (LoRA) modules by fine-tuning on our constructed\\nfinancial corpus.', 'One module is for adapting general-purpose LLMs to financial\\ndomain, and the other module is for enhancing the ability of NumLLM to\\nunderstand financial text with numeric variables.', 'Lastly, we merge the two LoRA\\nmodules into the foundation model to obtain NumLLM for inference.', 'Experiments\\non financial question-answering benchmark show that NumLLM can boost the\\nperformance of the foundation model and can achieve the best overall\\nperformance compared to all baselines, on both numeric and non-numeric\\nquestions.']\n",
            "Chunks for abstract: The emergence of multimodal data on social media platforms presents new\n",
            "opportunities to better understand user sentiments toward a given aspect.\n",
            "However, existing multimodal datasets for Aspect-Category Sentiment Analysis\n",
            "(ACSA) often focus on textual annotations, neglecting fine-grained information\n",
            "in images. Consequently, these datasets fail to fully exploit the richness\n",
            "inherent in multimodal. To address this, we introduce a new Vietnamese\n",
            "multimodal dataset, named ViMACSA, which consists of 4,876 text-image pairs\n",
            "with 14,618 fine-grained annotations for both text and image in the hotel\n",
            "domain. Additionally, we propose a Fine-Grained Cross-Modal Fusion Framework\n",
            "(FCMF) that effectively learns both intra- and inter-modality interactions and\n",
            "then fuses these information to produce a unified multimodal representation.\n",
            "Experimental results show that our framework outperforms SOTA models on the\n",
            "ViMACSA dataset, achieving the highest F1 score of 79.73%. We also explore\n",
            "characteristics and challenges in Vietnamese multimodal sentiment analysis,\n",
            "including misspellings, abbreviations, and the complexities of the Vietnamese\n",
            "language. This work contributes both a benchmark dataset and a new framework\n",
            "that leverages fine-grained multimodal information to improve multimodal\n",
            "aspect-category sentiment analysis. Our dataset is available for research\n",
            "purposes:\n",
            "https://github.com/hoangquy18/Multimodal-Aspect-Category-Sentiment-Analysis.\n",
            "['The emergence of multimodal data on social media platforms presents new\\nopportunities to better understand user sentiments toward a given aspect.', 'However, existing multimodal datasets for Aspect-Category Sentiment Analysis\\n(ACSA) often focus on textual annotations, neglecting fine-grained information\\nin images.', 'Consequently, these datasets fail to fully exploit the richness\\ninherent in multimodal.', 'To address this, we introduce a new Vietnamese\\nmultimodal dataset, named ViMACSA, which consists of 4,876 text-image pairs\\nwith 14,618 fine-grained annotations for both text and image in the hotel\\ndomain.', 'Additionally, we propose a Fine-Grained Cross-Modal Fusion Framework\\n(FCMF) that effectively learns both intra- and inter-modality interactions and\\nthen fuses these information to produce a unified multimodal representation.', 'Experimental results show that our framework outperforms SOTA models on the\\nViMACSA dataset, achieving the highest F1 score of 79.73%.', 'We also explore\\ncharacteristics and challenges in Vietnamese multimodal sentiment analysis,\\nincluding misspellings, abbreviations, and the complexities of the Vietnamese\\nlanguage.', 'This work contributes both a benchmark dataset and a new framework\\nthat leverages fine-grained multimodal information to improve multimodal\\naspect-category sentiment analysis.', 'Our dataset is available for research\\npurposes:\\nhttps://github.com/hoangquy18/Multimodal-Aspect-Category-Sentiment-Analysis.']\n",
            "Chunks for abstract: Global information about dynamical systems can be extracted by analysing\n",
            "associated infinite-dimensional transfer operators, such as Perron-Frobenius\n",
            "and Koopman operators as well as their infinitesimal generators. In practice,\n",
            "these operators typically need to be approximated from data. Popular\n",
            "approximation methods are extended dynamic mode decomposition (EDMD) and\n",
            "generator extended mode decomposition (gEDMD). We propose a unified framework\n",
            "that leverages Monte Carlo sampling to approximate the operator of interest on\n",
            "a finite-dimensional space spanned by a set of basis functions. Our framework\n",
            "contains EDMD and gEDMD as special cases, but can also be used to approximate\n",
            "more general operators. Our key contributions are proofs of the convergence of\n",
            "the approximating operator and its spectrum under non-restrictive conditions.\n",
            "Moreover, we derive explicit convergence rates and account for the presence of\n",
            "noise in the observations. Whilst all these results are broadly applicable,\n",
            "they also refine previous analyses of EDMD and gEDMD. We verify the analytical\n",
            "results with the aid of several numerical experiments.\n",
            "['Global information about dynamical systems can be extracted by analysing\\nassociated infinite-dimensional transfer operators, such as Perron-Frobenius\\nand Koopman operators as well as their infinitesimal generators.', 'In practice,\\nthese operators typically need to be approximated from data.', 'Popular\\napproximation methods are extended dynamic mode decomposition (EDMD) and\\ngenerator extended mode decomposition (gEDMD).', 'We propose a unified framework\\nthat leverages Monte Carlo sampling to approximate the operator of interest on\\na finite-dimensional space spanned by a set of basis functions.', 'Our framework\\ncontains EDMD and gEDMD as special cases, but can also be used to approximate\\nmore general operators.', 'Our key contributions are proofs of the convergence of\\nthe approximating operator and its spectrum under non-restrictive conditions.', 'Moreover, we derive explicit convergence rates and account for the presence of\\nnoise in the observations.', 'Whilst all these results are broadly applicable,\\nthey also refine previous analyses of EDMD and gEDMD.', 'We verify the analytical\\nresults with the aid of several numerical experiments.']\n",
            "Chunks for abstract: Recent advances in deep learning have promoted the advent of many\n",
            "computational systems capable of performing intelligent actions that, until\n",
            "then, were restricted to the human intellect. In the particular case of human\n",
            "languages, these advances allowed the introduction of applications like ChatGPT\n",
            "that are capable of generating coherent text without being explicitly\n",
            "programmed to do so. Instead, these models use large volumes of textual data to\n",
            "learn meaningful representations of human languages. Associated with these\n",
            "advances, concerns about copyright and data privacy infringements caused by\n",
            "these applications have emerged. Despite these concerns, the pace at which new\n",
            "natural language processing applications continued to be developed largely\n",
            "outperformed the introduction of new regulations. Today, communication barriers\n",
            "between legal experts and computer scientists motivate many unintentional legal\n",
            "infringements during the development of such applications. In this paper, a\n",
            "multidisciplinary team intends to bridge this communication gap and promote\n",
            "more compliant Portuguese NLP research by presenting a series of everyday NLP\n",
            "use cases, while highlighting the Portuguese legislation that may arise during\n",
            "its development.\n",
            "['Recent advances in deep learning have promoted the advent of many\\ncomputational systems capable of performing intelligent actions that, until\\nthen, were restricted to the human intellect.', 'In the particular case of human\\nlanguages, these advances allowed the introduction of applications like ChatGPT\\nthat are capable of generating coherent text without being explicitly\\nprogrammed to do so.', 'Instead, these models use large volumes of textual data to\\nlearn meaningful representations of human languages.', 'Associated with these\\nadvances, concerns about copyright and data privacy infringements caused by\\nthese applications have emerged.', 'Despite these concerns, the pace at which new\\nnatural language processing applications continued to be developed largely\\noutperformed the introduction of new regulations.', 'Today, communication barriers\\nbetween legal experts and computer scientists motivate many unintentional legal\\ninfringements during the development of such applications.', 'In this paper, a\\nmultidisciplinary team intends to bridge this communication gap and promote\\nmore compliant Portuguese NLP research by presenting a series of everyday NLP\\nuse cases, while highlighting the Portuguese legislation that may arise during\\nits development.']\n",
            "Chunks for abstract: In this paper, we develop an analytical approach for estimating brain\n",
            "connectivity networks that accounts for subject heterogeneity. More\n",
            "specifically, we consider a novel extension of a multi-subject Bayesian vector\n",
            "autoregressive model that estimates group-specific directed brain connectivity\n",
            "networks and accounts for the effects of covariates on the network edges. We\n",
            "adopt a flexible approach, allowing for (possibly) non-linear effects of the\n",
            "covariates on edge strength via a novel Bayesian nonparametric prior that\n",
            "employs a weighted mixture of Gaussian processes. For posterior inference, we\n",
            "achieve computational scalability by implementing a variational Bayes scheme.\n",
            "Our approach enables simultaneous estimation of group-specific networks and\n",
            "selection of relevant covariate effects. We show improved performance over\n",
            "competing two-stage approaches on simulated data. We apply our method on\n",
            "resting-state fMRI data from children with a history of traumatic brain injury\n",
            "and healthy controls to estimate the effects of age and sex on the group-level\n",
            "connectivities. Our results highlight differences in the distribution of parent\n",
            "nodes. They also suggest alteration in the relation of age, with peak edge\n",
            "strength in children with traumatic brain injury (TBI), and differences in\n",
            "effective connectivity strength between males and females.\n",
            "['In this paper, we develop an analytical approach for estimating brain\\nconnectivity networks that accounts for subject heterogeneity.', 'More\\nspecifically, we consider a novel extension of a multi-subject Bayesian vector\\nautoregressive model that estimates group-specific directed brain connectivity\\nnetworks and accounts for the effects of covariates on the network edges.', 'We\\nadopt a flexible approach, allowing for (possibly) non-linear effects of the\\ncovariates on edge strength via a novel Bayesian nonparametric prior that\\nemploys a weighted mixture of Gaussian processes.', 'For posterior inference, we\\nachieve computational scalability by implementing a variational Bayes scheme.', 'Our approach enables simultaneous estimation of group-specific networks and\\nselection of relevant covariate effects.', 'We show improved performance over\\ncompeting two-stage approaches on simulated data.', 'We apply our method on\\nresting-state fMRI data from children with a history of traumatic brain injury\\nand healthy controls to estimate the effects of age and sex on the group-level\\nconnectivities.', 'Our results highlight differences in the distribution of parent\\nnodes.', 'They also suggest alteration in the relation of age, with peak edge\\nstrength in children with traumatic brain injury (TBI), and differences in\\neffective connectivity strength between males and females.']\n",
            "Chunks for abstract: We show that, in ideal-spin hydrodynamics, the components of the spin tensor\n",
            "follow damped wave equations. The damping rate is related to nonlocal\n",
            "collisions of the particles in the fluid, which enter at first order in $\\hbar$\n",
            "in a semi-classical expansion. This rate provides an estimate for the timescale\n",
            "of spin equilibration and is computed by considering a system of spin-1/2\n",
            "fermions subject to a quartic self-interaction. It is found that the relaxation\n",
            "times of the components of the spin tensor can become very large compared to\n",
            "the usual dissipative timescales of the system. Our results suggest that the\n",
            "spin degrees of freedom in a heavy-ion collision may not be in equilibrium by\n",
            "the time of freeze-out, and thus should be treated dynamically.\n",
            "['We show that, in ideal-spin hydrodynamics, the components of the spin tensor\\nfollow damped wave equations.', 'The damping rate is related to nonlocal\\ncollisions of the particles in the fluid, which enter at first order in $\\\\hbar$\\nin a semi-classical expansion.', 'This rate provides an estimate for the timescale\\nof spin equilibration and is computed by considering a system of spin-1/2\\nfermions subject to a quartic self-interaction.', 'It is found that the relaxation\\ntimes of the components of the spin tensor can become very large compared to\\nthe usual dissipative timescales of the system.', 'Our results suggest that the\\nspin degrees of freedom in a heavy-ion collision may not be in equilibrium by\\nthe time of freeze-out, and thus should be treated dynamically.']\n",
            "Chunks for abstract: The present paper extends two previous one's on pure gravity dealing with\n",
            "Einstein-Hilbert and higher derivatives by including a massless scalar field as\n",
            "representative of matter. We study the renormalization to all orders of\n",
            "perturbation theory, provide the Slavnov-Taylor identity, symmetric partial\n",
            "differential equations and derive finiteness properties in the Landau gauge. It\n",
            "is shown that beginning with one-loop negative norm states originating from\n",
            "higher derivatives disappear.\n",
            "[\"The present paper extends two previous one's on pure gravity dealing with\\nEinstein-Hilbert and higher derivatives by including a massless scalar field as\\nrepresentative of matter.\", 'We study the renormalization to all orders of\\nperturbation theory, provide the Slavnov-Taylor identity, symmetric partial\\ndifferential equations and derive finiteness properties in the Landau gauge.', 'It\\nis shown that beginning with one-loop negative norm states originating from\\nhigher derivatives disappear.']\n",
            "Chunks for abstract: Hyperuniformity emerges generically in the coarsening regime of\n",
            "phase-separating fluids. Numerical studies of active and passive systems have\n",
            "shown that the structure factor $S(q)$ behaves as $q^\\varsigma$ for $q\\to 0$,\n",
            "with hyperuniformity exponent $\\varsigma = 4$. For passive systems, this result\n",
            "was explained in 1991 by a qualitative scaling analysis of Tomita, exploiting\n",
            "isotropy at scales much larger than the coarsening length $\\ell$. Here we\n",
            "reconsider and extend Tomita's argument to address cases of active phase\n",
            "separation and of non-constant mobility, again finding $\\varsigma=4$. We\n",
            "further show that dynamical noise of variance $D$ creates a transient\n",
            "$\\varsigma = 2$ regime for $\\hat q\\ll \\hat{q}_\\ast \\sim \\sqrt{D}\n",
            "t^{[1-(d+2)\\nu]/2}$, crossing over to $\\varsigma = 4$ at larger $\\hat{q}$.\n",
            "Here, $\\nu$ is the coarsening exponent, with $\\ell\\sim t^\\nu$, and $\\hat{q}\n",
            "\\propto q \\ell$ is the rescaled wavenumber. In diffusive coarsening, $\\nu=1/3$,\n",
            "so the rescaled crossover wavevector $\\hat{q}_\\ast$ vanishes at large times\n",
            "when $d\\geq 2$. The slowness of this decay suggests a natural explanation for\n",
            "experiments that observe a long-lived $\\varsigma = 2$ scaling in\n",
            "phase-separating active fluids (where noise is typically large). Conversely, in\n",
            "$d=1$, we demonstrate that with noise the $\\varsigma = 2$ regime survives as\n",
            "$t\\to\\infty$, with $\\hat{q}_\\ast\\sim D^{5/6}$. (The structure factor is not\n",
            "then determined by the zero-temperature fixed point.) We confirm our analytical\n",
            "predictions by numerical simulations of active and passive continuum theories\n",
            "in the deterministic case and of Model B for the stochastic case. We also\n",
            "compare them with related findings for a system near an absorbing-state\n",
            "transition rather than undergoing phase separation. A central role is played\n",
            "throughout by the presence or absence of a conservation law for the centre of\n",
            "mass position of the order parameter field.\n",
            "['Hyperuniformity emerges generically in the coarsening regime of\\nphase-separating fluids.', 'Numerical studies of active and passive systems have\\nshown that the structure factor $S(q)$ behaves as $q^\\\\varsigma$ for $q\\\\to 0$,\\nwith hyperuniformity exponent $\\\\varsigma = 4$.', 'For passive systems, this result\\nwas explained in 1991 by a qualitative scaling analysis of Tomita, exploiting\\nisotropy at scales much larger than the coarsening length $\\\\ell$.', \"Here we\\nreconsider and extend Tomita's argument to address cases of active phase\\nseparation and of non-constant mobility, again finding $\\\\varsigma=4$.\", 'We\\nfurther show that dynamical noise of variance $D$ creates a transient\\n$\\\\varsigma = 2$ regime for $\\\\hat q\\\\ll \\\\hat{q}_\\\\ast \\\\sim \\\\sqrt{D}\\nt^{[1-(d+2)\\\\nu]/2}$, crossing over to $\\\\varsigma = 4$ at larger $\\\\hat{q}$.', 'Here, $\\\\nu$ is the coarsening exponent, with $\\\\ell\\\\sim t^\\\\nu$, and $\\\\hat{q}\\n\\\\propto q \\\\ell$ is the rescaled wavenumber.', 'In diffusive coarsening, $\\\\nu=1/3$,\\nso the rescaled crossover wavevector $\\\\hat{q}_\\\\ast$ vanishes at large times\\nwhen $d\\\\geq 2$.', 'The slowness of this decay suggests a natural explanation for\\nexperiments that observe a long-lived $\\\\varsigma = 2$ scaling in\\nphase-separating active fluids (where noise is typically large).', 'Conversely, in\\n$d=1$, we demonstrate that with noise the $\\\\varsigma = 2$ regime survives as\\n$t\\\\to\\\\infty$, with $\\\\hat{q}_\\\\ast\\\\sim D^{5/6}$.', '(The structure factor is not\\nthen determined by the zero-temperature fixed point.)', 'We confirm our analytical\\npredictions by numerical simulations of active and passive continuum theories\\nin the deterministic case and of Model B for the stochastic case.', 'We also\\ncompare them with related findings for a system near an absorbing-state\\ntransition rather than undergoing phase separation.', 'A central role is played\\nthroughout by the presence or absence of a conservation law for the centre of\\nmass position of the order parameter field.']\n",
            "Chunks for abstract: Visual Question Answering (VQA) has emerged as a highly engaging field in\n",
            "recent years, attracting increasing research efforts aiming to enhance VQA\n",
            "accuracy through the deployment of advanced models such as Transformers.\n",
            "Despite this growing interest, there has been limited exploration into the\n",
            "comparative analysis and impact of textual modalities within VQA, particularly\n",
            "in terms of model complexity and its effect on performance. In this work, we\n",
            "conduct a comprehensive comparison between complex textual models that leverage\n",
            "long dependency mechanisms and simpler models focusing on local textual\n",
            "features within a well-established VQA framework. Our findings reveal that\n",
            "employing complex textual encoders is not invariably the optimal approach for\n",
            "the VQA-v2 dataset. Motivated by this insight, we introduce an improved model,\n",
            "ConvGRU, which incorporates convolutional layers to enhance the representation\n",
            "of question text. Tested on the VQA-v2 dataset, ConvGRU achieves better\n",
            "performance without substantially increasing parameter complexity.\n",
            "['Visual Question Answering (VQA) has emerged as a highly engaging field in\\nrecent years, attracting increasing research efforts aiming to enhance VQA\\naccuracy through the deployment of advanced models such as Transformers.', 'Despite this growing interest, there has been limited exploration into the\\ncomparative analysis and impact of textual modalities within VQA, particularly\\nin terms of model complexity and its effect on performance.', 'In this work, we\\nconduct a comprehensive comparison between complex textual models that leverage\\nlong dependency mechanisms and simpler models focusing on local textual\\nfeatures within a well-established VQA framework.', 'Our findings reveal that\\nemploying complex textual encoders is not invariably the optimal approach for\\nthe VQA-v2 dataset.', 'Motivated by this insight, we introduce an improved model,\\nConvGRU, which incorporates convolutional layers to enhance the representation\\nof question text.', 'Tested on the VQA-v2 dataset, ConvGRU achieves better\\nperformance without substantially increasing parameter complexity.']\n",
            "Chunks for abstract: Courcelle's Theorem is an important result in graph theory, proving the\n",
            "existence of linear-time algorithms for many decision problems on graphs whose\n",
            "tree-width is bounded by a constant. The purpose of this text is twofold: to\n",
            "provide an explanation and step-by-step proof of Courcelle's Theorem as applied\n",
            "to graphs of tree-width bounded by a constant, and to show explicitly (on the\n",
            "example of path-width) how to apply the same principles to other graph classes.\n",
            "We present these topics in a way that does not assume any particular knowledge\n",
            "on the part of the reader except a basic understanding of mathematics and\n",
            "possibly the fundamentals of graph theory. Our hope is to make the topic\n",
            "accessible to a broader mathematical audience, to which end we have included\n",
            "extensive explanations and pretty pictures.\n",
            "[\"Courcelle's Theorem is an important result in graph theory, proving the\\nexistence of linear-time algorithms for many decision problems on graphs whose\\ntree-width is bounded by a constant.\", \"The purpose of this text is twofold: to\\nprovide an explanation and step-by-step proof of Courcelle's Theorem as applied\\nto graphs of tree-width bounded by a constant, and to show explicitly (on the\\nexample of path-width) how to apply the same principles to other graph classes.\", 'We present these topics in a way that does not assume any particular knowledge\\non the part of the reader except a basic understanding of mathematics and\\npossibly the fundamentals of graph theory.', 'Our hope is to make the topic\\naccessible to a broader mathematical audience, to which end we have included\\nextensive explanations and pretty pictures.']\n",
            "Chunks for abstract: In recent years, neural ranking models (NRMs) have been shown to\n",
            "substantially outperform their lexical counterparts in text retrieval. In\n",
            "traditional search pipelines, a combination of features leads to well-defined\n",
            "behaviour. However, as neural approaches become increasingly prevalent as the\n",
            "final scoring component of engines or as standalone systems, their robustness\n",
            "to malicious text and, more generally, semantic perturbation needs to be better\n",
            "understood. We posit that the transformer attention mechanism can induce\n",
            "exploitable defects through positional bias in search models, leading to an\n",
            "attack that could generalise beyond a single query or topic. We demonstrate\n",
            "such defects by showing that non-relevant text--such as promotional\n",
            "content--can be easily injected into a document without adversely affecting its\n",
            "position in search results. Unlike previous gradient-based attacks, we\n",
            "demonstrate these biases in a query-agnostic fashion. In doing so, without the\n",
            "knowledge of topicality, we can still reduce the negative effects of\n",
            "non-relevant content injection by controlling injection position. Our\n",
            "experiments are conducted with simulated on-topic promotional text\n",
            "automatically generated by prompting LLMs with topical context from target\n",
            "documents. We find that contextualisation of a non-relevant text further\n",
            "reduces negative effects whilst likely circumventing existing content filtering\n",
            "mechanisms. In contrast, lexical models are found to be more resilient to such\n",
            "content injection attacks. We then investigate a simple yet effective\n",
            "compensation for the weaknesses of the NRMs in search, validating our\n",
            "hypotheses regarding transformer bias.\n",
            "['In recent years, neural ranking models (NRMs) have been shown to\\nsubstantially outperform their lexical counterparts in text retrieval.', 'In\\ntraditional search pipelines, a combination of features leads to well-defined\\nbehaviour.', 'However, as neural approaches become increasingly prevalent as the\\nfinal scoring component of engines or as standalone systems, their robustness\\nto malicious text and, more generally, semantic perturbation needs to be better\\nunderstood.', 'We posit that the transformer attention mechanism can induce\\nexploitable defects through positional bias in search models, leading to an\\nattack that could generalise beyond a single query or topic.', 'We demonstrate\\nsuch defects by showing that non-relevant text--such as promotional\\ncontent--can be easily injected into a document without adversely affecting its\\nposition in search results.', 'Unlike previous gradient-based attacks, we\\ndemonstrate these biases in a query-agnostic fashion.', 'In doing so, without the\\nknowledge of topicality, we can still reduce the negative effects of\\nnon-relevant content injection by controlling injection position.', 'Our\\nexperiments are conducted with simulated on-topic promotional text\\nautomatically generated by prompting LLMs with topical context from target\\ndocuments.', 'We find that contextualisation of a non-relevant text further\\nreduces negative effects whilst likely circumventing existing content filtering\\nmechanisms.', 'In contrast, lexical models are found to be more resilient to such\\ncontent injection attacks.', 'We then investigate a simple yet effective\\ncompensation for the weaknesses of the NRMs in search, validating our\\nhypotheses regarding transformer bias.']\n",
            "Chunks for abstract: Large Language Models (LLMs) have swiftly emerged as vital resources for\n",
            "different applications in the biomedical and healthcare domains; however, these\n",
            "models encounter issues such as generating inaccurate information or\n",
            "hallucinations. Retrieval-augmented generation provided a solution for these\n",
            "models to update knowledge and enhance their performance. In contrast to\n",
            "previous retrieval-augmented LMs, which utilize specialized cross-attention\n",
            "mechanisms to help LLM encode retrieved text, BiomedRAG adopts a simpler\n",
            "approach by directly inputting the retrieved chunk-based documents into the\n",
            "LLM. This straightforward design is easily applicable to existing retrieval and\n",
            "language models, effectively bypassing noise information in retrieved\n",
            "documents, particularly in noise-intensive tasks. Moreover, we demonstrate the\n",
            "potential for utilizing the LLM to supervise the retrieval model in the\n",
            "biomedical domain, enabling it to retrieve the document that assists the LM in\n",
            "improving its predictions. Our experiments reveal that with the tuned\n",
            "scorer,\\textsc{ BiomedRAG} attains superior performance across 5 biomedical NLP\n",
            "tasks, encompassing information extraction (triple extraction, relation\n",
            "extraction), text classification, link prediction, and question-answering,\n",
            "leveraging over 9 datasets. For instance, in the triple extraction task,\n",
            "\\textsc{BiomedRAG} outperforms other triple extraction systems with micro-F1\n",
            "scores of 81.42 and 88.83 on GIT and ChemProt corpora, respectively.\n",
            "['Large Language Models (LLMs) have swiftly emerged as vital resources for\\ndifferent applications in the biomedical and healthcare domains; however, these\\nmodels encounter issues such as generating inaccurate information or\\nhallucinations.', 'Retrieval-augmented generation provided a solution for these\\nmodels to update knowledge and enhance their performance.', 'In contrast to\\nprevious retrieval-augmented LMs, which utilize specialized cross-attention\\nmechanisms to help LLM encode retrieved text, BiomedRAG adopts a simpler\\napproach by directly inputting the retrieved chunk-based documents into the\\nLLM.', 'This straightforward design is easily applicable to existing retrieval and\\nlanguage models, effectively bypassing noise information in retrieved\\ndocuments, particularly in noise-intensive tasks.', 'Moreover, we demonstrate the\\npotential for utilizing the LLM to supervise the retrieval model in the\\nbiomedical domain, enabling it to retrieve the document that assists the LM in\\nimproving its predictions.', 'Our experiments reveal that with the tuned\\nscorer,\\\\textsc{ BiomedRAG} attains superior performance across 5 biomedical NLP\\ntasks, encompassing information extraction (triple extraction, relation\\nextraction), text classification, link prediction, and question-answering,\\nleveraging over 9 datasets.', 'For instance, in the triple extraction task,\\n\\\\textsc{BiomedRAG} outperforms other triple extraction systems with micro-F1\\nscores of 81.42 and 88.83 on GIT and ChemProt corpora, respectively.']\n",
            "Chunks for abstract: This paper introduces MMTryon, a multi-modal multi-reference VIrtual Try-ON\n",
            "(VITON) framework, which can generate high-quality compositional try-on results\n",
            "by taking as inputs a text instruction and multiple garment images. Our MMTryon\n",
            "mainly addresses two problems overlooked in prior literature: 1) Support of\n",
            "multiple try-on items and dressing styleExisting methods are commonly designed\n",
            "for single-item try-on tasks (e.g., upper/lower garments, dresses) and fall\n",
            "short on customizing dressing styles (e.g., zipped/unzipped, tuck-in/tuck-out,\n",
            "etc.) 2) Segmentation Dependency. They further heavily rely on\n",
            "category-specific segmentation models to identify the replacement regions, with\n",
            "segmentation errors directly leading to significant artifacts in the try-on\n",
            "results. For the first issue, our MMTryon introduces a novel multi-modality and\n",
            "multi-reference attention mechanism to combine the garment information from\n",
            "reference images and dressing-style information from text instructions.\n",
            "Besides, to remove the segmentation dependency, MMTryon uses a parsing-free\n",
            "garment encoder and leverages a novel scalable data generation pipeline to\n",
            "convert existing VITON datasets to a form that allows MMTryon to be trained\n",
            "without requiring any explicit segmentation. Extensive experiments on\n",
            "high-resolution benchmarks and in-the-wild test sets demonstrate MMTryon's\n",
            "superiority over existing SOTA methods both qualitatively and quantitatively.\n",
            "Besides, MMTryon's impressive performance on multi-items and style-controllable\n",
            "virtual try-on scenarios and its ability to try on any outfit in a large\n",
            "variety of scenarios from any source image, opens up a new avenue for future\n",
            "investigation in the fashion community.\n",
            "['This paper introduces MMTryon, a multi-modal multi-reference VIrtual Try-ON\\n(VITON) framework, which can generate high-quality compositional try-on results\\nby taking as inputs a text instruction and multiple garment images.', 'Our MMTryon\\nmainly addresses two problems overlooked in prior literature: 1) Support of\\nmultiple try-on items and dressing styleExisting methods are commonly designed\\nfor single-item try-on tasks (e.g., upper/lower garments, dresses) and fall\\nshort on customizing dressing styles (e.g., zipped/unzipped, tuck-in/tuck-out,\\netc.)', '2) Segmentation Dependency.', 'They further heavily rely on\\ncategory-specific segmentation models to identify the replacement regions, with\\nsegmentation errors directly leading to significant artifacts in the try-on\\nresults.', 'For the first issue, our MMTryon introduces a novel multi-modality and\\nmulti-reference attention mechanism to combine the garment information from\\nreference images and dressing-style information from text instructions.', 'Besides, to remove the segmentation dependency, MMTryon uses a parsing-free\\ngarment encoder and leverages a novel scalable data generation pipeline to\\nconvert existing VITON datasets to a form that allows MMTryon to be trained\\nwithout requiring any explicit segmentation.', \"Extensive experiments on\\nhigh-resolution benchmarks and in-the-wild test sets demonstrate MMTryon's\\nsuperiority over existing SOTA methods both qualitatively and quantitatively.\", \"Besides, MMTryon's impressive performance on multi-items and style-controllable\\nvirtual try-on scenarios and its ability to try on any outfit in a large\\nvariety of scenarios from any source image, opens up a new avenue for future\\ninvestigation in the fashion community.\"]\n",
            "Chunks for abstract: We have investigated the spin-orbital angular momentum correlations for the\n",
            "active quark inside the light and heavy mesons for both the spin-0 and spin-1\n",
            "cases. These correlations can be derived from the generalised transverse\n",
            "momentum dependent distributions (GTMDs) as well as the generalised parton\n",
            "distributions (GPDs). We employ the overlap representation of light-front wave\n",
            "functions in the light-front quark model (LFQM) to calculate our analytical\n",
            "results. The dependence of spin-orbit correlations (SOCs) on the longitudinal\n",
            "momentum fraction $x$ as well as the transverse momentum dependence\n",
            "$\\mathbf{k}_{\\perp}$ has been graphically presented. Even though the SOCs have\n",
            "already been studied for the spin-0 pions and kaons in other approaches, no\n",
            "calculations for the other light and heavy spin-0 mesons have been reported in\n",
            "literature. Further, the correlations for any of the light and heavy spin-1\n",
            "mesons have been studied for the first time in the present work.\n",
            "['We have investigated the spin-orbital angular momentum correlations for the\\nactive quark inside the light and heavy mesons for both the spin-0 and spin-1\\ncases.', 'These correlations can be derived from the generalised transverse\\nmomentum dependent distributions (GTMDs) as well as the generalised parton\\ndistributions (GPDs).', 'We employ the overlap representation of light-front wave\\nfunctions in the light-front quark model (LFQM) to calculate our analytical\\nresults.', 'The dependence of spin-orbit correlations (SOCs) on the longitudinal\\nmomentum fraction $x$ as well as the transverse momentum dependence\\n$\\\\mathbf{k}_{\\\\perp}$ has been graphically presented.', 'Even though the SOCs have\\nalready been studied for the spin-0 pions and kaons in other approaches, no\\ncalculations for the other light and heavy spin-0 mesons have been reported in\\nliterature.', 'Further, the correlations for any of the light and heavy spin-1\\nmesons have been studied for the first time in the present work.']\n",
            "Chunks for abstract: The success of Reinforcement Learning from Human Feedback (RLHF) in language\n",
            "model alignment is critically dependent on the capability of the reward model\n",
            "(RM). However, as the training process progresses, the output distribution of\n",
            "the policy model shifts, leading to the RM's reduced ability to distinguish\n",
            "between responses. This issue is further compounded when the RM, trained on a\n",
            "specific data distribution, struggles to generalize to examples outside of that\n",
            "distribution. These two issues can be united as a challenge posed by the\n",
            "shifted distribution of the environment. To surmount this challenge, we\n",
            "introduce MetaRM, a method leveraging meta-learning to align the RM with the\n",
            "shifted environment distribution. MetaRM is designed to train the RM by\n",
            "minimizing data loss, particularly for data that can improve the\n",
            "differentiation ability to examples of the shifted target distribution.\n",
            "Extensive experiments demonstrate that MetaRM significantly improves the RM's\n",
            "distinguishing ability in iterative RLHF optimization, and also provides the\n",
            "capacity to identify subtle differences in out-of-distribution samples.\n",
            "['The success of Reinforcement Learning from Human Feedback (RLHF) in language\\nmodel alignment is critically dependent on the capability of the reward model\\n(RM).', \"However, as the training process progresses, the output distribution of\\nthe policy model shifts, leading to the RM's reduced ability to distinguish\\nbetween responses.\", 'This issue is further compounded when the RM, trained on a\\nspecific data distribution, struggles to generalize to examples outside of that\\ndistribution.', 'These two issues can be united as a challenge posed by the\\nshifted distribution of the environment.', 'To surmount this challenge, we\\nintroduce MetaRM, a method leveraging meta-learning to align the RM with the\\nshifted environment distribution.', 'MetaRM is designed to train the RM by\\nminimizing data loss, particularly for data that can improve the\\ndifferentiation ability to examples of the shifted target distribution.', \"Extensive experiments demonstrate that MetaRM significantly improves the RM's\\ndistinguishing ability in iterative RLHF optimization, and also provides the\\ncapacity to identify subtle differences in out-of-distribution samples.\"]\n",
            "Chunks for abstract: The integration of new technology with cultural studies enhances our\n",
            "understanding of cultural heritage but often struggles to connect with diverse\n",
            "audiences. It is challenging to align personal interpretations with the\n",
            "intended meanings across different cultures. Our study investigates the\n",
            "important factors in appreciating art from a cross-cultural perspective. We\n",
            "explore the application of Large Language Models (LLMs) to bridge the cultural\n",
            "and language barriers in understanding Traditional Chinese Paintings (TCPs). We\n",
            "present CultiVerse, a visual analytics system that utilizes LLMs within a\n",
            "mixed-initiative framework, enhancing interpretative appreciation of TCP in a\n",
            "cross-cultural dialogue. CultiVerse addresses the challenge of translating the\n",
            "nuanced symbolism in art, which involves interpreting complex cultural\n",
            "contexts, aligning cross-cultural symbols, and validating cultural acceptance.\n",
            "CultiVerse integrates an interactive interface with the analytical capability\n",
            "of LLMs to explore a curated TCP dataset, facilitating the analysis of\n",
            "multifaceted symbolic meanings and the exploration of cross-cultural\n",
            "serendipitous discoveries. Empirical evaluations affirm that CultiVerse\n",
            "significantly improves cross-cultural understanding, offering deeper insights\n",
            "and engaging art appreciation.\n",
            "['The integration of new technology with cultural studies enhances our\\nunderstanding of cultural heritage but often struggles to connect with diverse\\naudiences.', 'It is challenging to align personal interpretations with the\\nintended meanings across different cultures.', 'Our study investigates the\\nimportant factors in appreciating art from a cross-cultural perspective.', 'We\\nexplore the application of Large Language Models (LLMs) to bridge the cultural\\nand language barriers in understanding Traditional Chinese Paintings (TCPs).', 'We\\npresent CultiVerse, a visual analytics system that utilizes LLMs within a\\nmixed-initiative framework, enhancing interpretative appreciation of TCP in a\\ncross-cultural dialogue.', 'CultiVerse addresses the challenge of translating the\\nnuanced symbolism in art, which involves interpreting complex cultural\\ncontexts, aligning cross-cultural symbols, and validating cultural acceptance.', 'CultiVerse integrates an interactive interface with the analytical capability\\nof LLMs to explore a curated TCP dataset, facilitating the analysis of\\nmultifaceted symbolic meanings and the exploration of cross-cultural\\nserendipitous discoveries.', 'Empirical evaluations affirm that CultiVerse\\nsignificantly improves cross-cultural understanding, offering deeper insights\\nand engaging art appreciation.']\n",
            "Chunks for abstract: Activity and parameter sparsity are two standard methods of making neural\n",
            "networks computationally more efficient. Event-based architectures such as\n",
            "spiking neural networks (SNNs) naturally exhibit activity sparsity, and many\n",
            "methods exist to sparsify their connectivity by pruning weights. While the\n",
            "effect of weight pruning on feed-forward SNNs has been previously studied for\n",
            "computer vision tasks, the effects of pruning for complex sequence tasks like\n",
            "language modeling are less well studied since SNNs have traditionally struggled\n",
            "to achieve meaningful performance on these tasks. Using a recently published\n",
            "SNN-like architecture that works well on small-scale language modeling, we\n",
            "study the effects of weight pruning when combined with activity sparsity.\n",
            "Specifically, we study the trade-off between the multiplicative efficiency\n",
            "gains the combination affords and its effect on task performance for language\n",
            "modeling. To dissect the effects of the two sparsities, we conduct a\n",
            "comparative analysis between densely activated models and sparsely activated\n",
            "event-based models across varying degrees of connectivity sparsity. We\n",
            "demonstrate that sparse activity and sparse connectivity complement each other\n",
            "without a proportional drop in task performance for an event-based neural\n",
            "network trained on the Penn Treebank and WikiText-2 language modeling datasets.\n",
            "Our results suggest sparsely connected event-based neural networks are\n",
            "promising candidates for effective and efficient sequence modeling.\n",
            "['Activity and parameter sparsity are two standard methods of making neural\\nnetworks computationally more efficient.', 'Event-based architectures such as\\nspiking neural networks (SNNs) naturally exhibit activity sparsity, and many\\nmethods exist to sparsify their connectivity by pruning weights.', 'While the\\neffect of weight pruning on feed-forward SNNs has been previously studied for\\ncomputer vision tasks, the effects of pruning for complex sequence tasks like\\nlanguage modeling are less well studied since SNNs have traditionally struggled\\nto achieve meaningful performance on these tasks.', 'Using a recently published\\nSNN-like architecture that works well on small-scale language modeling, we\\nstudy the effects of weight pruning when combined with activity sparsity.', 'Specifically, we study the trade-off between the multiplicative efficiency\\ngains the combination affords and its effect on task performance for language\\nmodeling.', 'To dissect the effects of the two sparsities, we conduct a\\ncomparative analysis between densely activated models and sparsely activated\\nevent-based models across varying degrees of connectivity sparsity.', 'We\\ndemonstrate that sparse activity and sparse connectivity complement each other\\nwithout a proportional drop in task performance for an event-based neural\\nnetwork trained on the Penn Treebank and WikiText-2 language modeling datasets.', 'Our results suggest sparsely connected event-based neural networks are\\npromising candidates for effective and efficient sequence modeling.']\n",
            "Chunks for abstract: This is the second part of the two-paper sequence, which aims to present a\n",
            "comprehensive study for compressible current-vortex sheets with or without\n",
            "surface tension in ideal compressible magnetohydrodynamics (MHD). The results\n",
            "of this paper are two-fold: First, we establish the zero-surface-tension limit\n",
            "of compressible current-vortex sheets under certain stability conditions on the\n",
            "free interface; Second, when the two-phase flows are isentropic and the density\n",
            "functions converge to the same constant as Mach number goes to zero, we can\n",
            "drop the boundedness assumption (with respect to Mach number) on high-order\n",
            "time derivatives by combining the paradifferential approach applied to the\n",
            "evolution equation of the free interface, the structure of wave equations for\n",
            "the total pressure and the anisotropic Sobolev spaces with suitable weights of\n",
            "Mach number. To our knowledge, this is the first result that rigorously\n",
            "justifies the incompressible limit for both compressible vortex sheets and\n",
            "free-surface ideal MHD flows.\n",
            "['This is the second part of the two-paper sequence, which aims to present a\\ncomprehensive study for compressible current-vortex sheets with or without\\nsurface tension in ideal compressible magnetohydrodynamics (MHD).', 'The results\\nof this paper are two-fold: First, we establish the zero-surface-tension limit\\nof compressible current-vortex sheets under certain stability conditions on the\\nfree interface; Second, when the two-phase flows are isentropic and the density\\nfunctions converge to the same constant as Mach number goes to zero, we can\\ndrop the boundedness assumption (with respect to Mach number) on high-order\\ntime derivatives by combining the paradifferential approach applied to the\\nevolution equation of the free interface, the structure of wave equations for\\nthe total pressure and the anisotropic Sobolev spaces with suitable weights of\\nMach number.', 'To our knowledge, this is the first result that rigorously\\njustifies the incompressible limit for both compressible vortex sheets and\\nfree-surface ideal MHD flows.']\n",
            "Chunks for abstract: In this paper, we investigate self-supervised pre-training methods for\n",
            "document text recognition. Nowadays, large unlabeled datasets can be collected\n",
            "for many research tasks, including text recognition, but it is costly to\n",
            "annotate them. Therefore, methods utilizing unlabeled data are researched. We\n",
            "study self-supervised pre-training methods based on masked label prediction\n",
            "using three different approaches -- Feature Quantization, VQ-VAE, and\n",
            "Post-Quantized AE. We also investigate joint-embedding approaches with VICReg\n",
            "and NT-Xent objectives, for which we propose an image shifting technique to\n",
            "prevent model collapse where it relies solely on positional encoding while\n",
            "completely ignoring the input image. We perform our experiments on historical\n",
            "handwritten (Bentham) and historical printed datasets mainly to investigate the\n",
            "benefits of the self-supervised pre-training techniques with different amounts\n",
            "of annotated target domain data. We use transfer learning as strong baselines.\n",
            "The evaluation shows that the self-supervised pre-training on data from the\n",
            "target domain is very effective, but it struggles to outperform transfer\n",
            "learning from closely related domains. This paper is one of the first\n",
            "researches exploring self-supervised pre-training in document text recognition,\n",
            "and we believe that it will become a cornerstone for future research in this\n",
            "area. We made our implementation of the investigated methods publicly available\n",
            "at https://github.com/DCGM/pero-pretraining.\n",
            "['In this paper, we investigate self-supervised pre-training methods for\\ndocument text recognition.', 'Nowadays, large unlabeled datasets can be collected\\nfor many research tasks, including text recognition, but it is costly to\\nannotate them.', 'Therefore, methods utilizing unlabeled data are researched.', 'We\\nstudy self-supervised pre-training methods based on masked label prediction\\nusing three different approaches -- Feature Quantization, VQ-VAE, and\\nPost-Quantized AE.', 'We also investigate joint-embedding approaches with VICReg\\nand NT-Xent objectives, for which we propose an image shifting technique to\\nprevent model collapse where it relies solely on positional encoding while\\ncompletely ignoring the input image.', 'We perform our experiments on historical\\nhandwritten (Bentham) and historical printed datasets mainly to investigate the\\nbenefits of the self-supervised pre-training techniques with different amounts\\nof annotated target domain data.', 'We use transfer learning as strong baselines.', 'The evaluation shows that the self-supervised pre-training on data from the\\ntarget domain is very effective, but it struggles to outperform transfer\\nlearning from closely related domains.', 'This paper is one of the first\\nresearches exploring self-supervised pre-training in document text recognition,\\nand we believe that it will become a cornerstone for future research in this\\narea.', 'We made our implementation of the investigated methods publicly available\\nat https://github.com/DCGM/pero-pretraining.']\n",
            "Chunks for abstract: In this paper, we present some enhanced error estimates for augmented\n",
            "subspace methods with the nonconforming Crouzeix-Raviart (CR) element. Before\n",
            "the novel estimates, we derive the explicit error estimates for the case of\n",
            "single eigenpair and multiple eigenpairs based on our defined spectral\n",
            "projection operators, respectively. Then we first strictly prove that the CR\n",
            "element based augmented subspace method exhibits the second-order convergence\n",
            "rate between the two steps of the augmented subspace iteration, which coincides\n",
            "with the practical experimental results. The algebraic error estimates of\n",
            "second order for the augmented subspace method explicitly elucidate the\n",
            "dependence of the convergence rate of the algebraic error on the coarse space,\n",
            "which provides new insights into the performance of the augmented subspace\n",
            "method. Numerical experiments are finally supplied to verify these new estimate\n",
            "results and the efficiency of our algorithms.\n",
            "['In this paper, we present some enhanced error estimates for augmented\\nsubspace methods with the nonconforming Crouzeix-Raviart (CR) element.', 'Before\\nthe novel estimates, we derive the explicit error estimates for the case of\\nsingle eigenpair and multiple eigenpairs based on our defined spectral\\nprojection operators, respectively.', 'Then we first strictly prove that the CR\\nelement based augmented subspace method exhibits the second-order convergence\\nrate between the two steps of the augmented subspace iteration, which coincides\\nwith the practical experimental results.', 'The algebraic error estimates of\\nsecond order for the augmented subspace method explicitly elucidate the\\ndependence of the convergence rate of the algebraic error on the coarse space,\\nwhich provides new insights into the performance of the augmented subspace\\nmethod.', 'Numerical experiments are finally supplied to verify these new estimate\\nresults and the efficiency of our algorithms.']\n",
            "Chunks for abstract: State machines play a pivotal role in augmenting the efficacy of protocol\n",
            "analyzing to unveil more vulnerabilities. However, the task of inferring state\n",
            "machines from network protocol implementations presents significant challenges.\n",
            "Traditional methods based on dynamic analysis often overlook crucial state\n",
            "transitions due to limited coverage, while static analysis faces difficulties\n",
            "with complex code structures and behaviors. To address these limitations, we\n",
            "propose an innovative state machine inference approach powered by Large\n",
            "Language Models (LLMs). Utilizing text-embedding technology, this method allows\n",
            "LLMs to dissect and analyze the intricacies of protocol implementation code.\n",
            "Through targeted prompt engineering, we systematically identify and infer the\n",
            "underlying state machines. Our evaluation across six protocol implementations\n",
            "demonstrates the method's high efficacy, achieving an accuracy rate exceeding\n",
            "90% and successfully delineating differences on state machines among various\n",
            "implementations of the same protocol. Importantly, integrating this approach\n",
            "with protocol fuzzing has notably enhanced AFLNet's code coverage by 10% over\n",
            "RFCNLP, showcasing the considerable potential of LLMs in advancing network\n",
            "protocol security analysis. Our proposed method not only marks a significant\n",
            "step forward in accurate state machine inference but also opens new avenues for\n",
            "improving the security and reliability of protocol implementations.\n",
            "['State machines play a pivotal role in augmenting the efficacy of protocol\\nanalyzing to unveil more vulnerabilities.', 'However, the task of inferring state\\nmachines from network protocol implementations presents significant challenges.', 'Traditional methods based on dynamic analysis often overlook crucial state\\ntransitions due to limited coverage, while static analysis faces difficulties\\nwith complex code structures and behaviors.', 'To address these limitations, we\\npropose an innovative state machine inference approach powered by Large\\nLanguage Models (LLMs).', 'Utilizing text-embedding technology, this method allows\\nLLMs to dissect and analyze the intricacies of protocol implementation code.', 'Through targeted prompt engineering, we systematically identify and infer the\\nunderlying state machines.', \"Our evaluation across six protocol implementations\\ndemonstrates the method's high efficacy, achieving an accuracy rate exceeding\\n90% and successfully delineating differences on state machines among various\\nimplementations of the same protocol.\", \"Importantly, integrating this approach\\nwith protocol fuzzing has notably enhanced AFLNet's code coverage by 10% over\\nRFCNLP, showcasing the considerable potential of LLMs in advancing network\\nprotocol security analysis.\", 'Our proposed method not only marks a significant\\nstep forward in accurate state machine inference but also opens new avenues for\\nimproving the security and reliability of protocol implementations.']\n",
            "Chunks for abstract: Social media abounds with multimodal sarcasm, and identifying sarcasm targets\n",
            "is particularly challenging due to the implicit incongruity not directly\n",
            "evident in the text and image modalities. Current methods for Multimodal\n",
            "Sarcasm Target Identification (MSTI) predominantly focus on superficial\n",
            "indicators in an end-to-end manner, overlooking the nuanced understanding of\n",
            "multimodal sarcasm conveyed through both the text and image. This paper\n",
            "proposes a versatile MSTI framework with a coarse-to-fine paradigm, by\n",
            "augmenting sarcasm explainability with reasoning and pre-training knowledge.\n",
            "Inspired by the powerful capacity of Large Multimodal Models (LMMs) on\n",
            "multimodal reasoning, we first engage LMMs to generate competing rationales for\n",
            "coarser-grained pre-training of a small language model on multimodal sarcasm\n",
            "detection. We then propose fine-tuning the model for finer-grained sarcasm\n",
            "target identification. Our framework is thus empowered to adeptly unveil the\n",
            "intricate targets within multimodal sarcasm and mitigate the negative impact\n",
            "posed by potential noise inherently in LMMs. Experimental results demonstrate\n",
            "that our model far outperforms state-of-the-art MSTI methods, and markedly\n",
            "exhibits explainability in deciphering sarcasm as well.\n",
            "['Social media abounds with multimodal sarcasm, and identifying sarcasm targets\\nis particularly challenging due to the implicit incongruity not directly\\nevident in the text and image modalities.', 'Current methods for Multimodal\\nSarcasm Target Identification (MSTI) predominantly focus on superficial\\nindicators in an end-to-end manner, overlooking the nuanced understanding of\\nmultimodal sarcasm conveyed through both the text and image.', 'This paper\\nproposes a versatile MSTI framework with a coarse-to-fine paradigm, by\\naugmenting sarcasm explainability with reasoning and pre-training knowledge.', 'Inspired by the powerful capacity of Large Multimodal Models (LMMs) on\\nmultimodal reasoning, we first engage LMMs to generate competing rationales for\\ncoarser-grained pre-training of a small language model on multimodal sarcasm\\ndetection.', 'We then propose fine-tuning the model for finer-grained sarcasm\\ntarget identification.', 'Our framework is thus empowered to adeptly unveil the\\nintricate targets within multimodal sarcasm and mitigate the negative impact\\nposed by potential noise inherently in LMMs.', 'Experimental results demonstrate\\nthat our model far outperforms state-of-the-art MSTI methods, and markedly\\nexhibits explainability in deciphering sarcasm as well.']\n",
            "Chunks for abstract: We examine the scattering of Ostrovsky wave packets, generated from an\n",
            "incident solitary wave, in a two layered waveguide with a delamination in the\n",
            "centre and soft (imperfect) bonding either side of the centre. The layers of\n",
            "the waveguide are assumed to consist of different materials, and the strains\n",
            "are described by a system of coupled Boussinesq equations. A semi-analytical\n",
            "approach consisting of matched asymptotic multiple-scale expansions is applied,\n",
            "leading to Ostrovsky equations in soft bonded regions and Korteweg-de Vries\n",
            "equations in the delaminated region. This semi-analytical method has good\n",
            "agreement with direct numerical simulations, validating the approach.\n",
            "  In the delaminated regions, Ostrovsky wave packets evolve into a train of\n",
            "solitary waves, which subsequently evolve into Ostrovsky wave packets in the\n",
            "second bonded region. Analysis of the phase shift in the wave packet,\n",
            "introduced from the delaminated region, allows us to predict both the position\n",
            "and the length of the delamination; the first time this has been achieved using\n",
            "nonlinear waves. These results motivate experiments to validate the theoretical\n",
            "results, with the aim of creating a tool to monitor the integrity of layered\n",
            "structures.\n",
            "['We examine the scattering of Ostrovsky wave packets, generated from an\\nincident solitary wave, in a two layered waveguide with a delamination in the\\ncentre and soft (imperfect) bonding either side of the centre.', 'The layers of\\nthe waveguide are assumed to consist of different materials, and the strains\\nare described by a system of coupled Boussinesq equations.', 'A semi-analytical\\napproach consisting of matched asymptotic multiple-scale expansions is applied,\\nleading to Ostrovsky equations in soft bonded regions and Korteweg-de Vries\\nequations in the delaminated region.', 'This semi-analytical method has good\\nagreement with direct numerical simulations, validating the approach.', 'In the delaminated regions, Ostrovsky wave packets evolve into a train of\\nsolitary waves, which subsequently evolve into Ostrovsky wave packets in the\\nsecond bonded region.', 'Analysis of the phase shift in the wave packet,\\nintroduced from the delaminated region, allows us to predict both the position\\nand the length of the delamination; the first time this has been achieved using\\nnonlinear waves.', 'These results motivate experiments to validate the theoretical\\nresults, with the aim of creating a tool to monitor the integrity of layered\\nstructures.']\n",
            "Chunks for abstract: The Bayes coding algorithm for context tree source is a successful example of\n",
            "Bayesian tree estimation in text compression in information theory. This\n",
            "algorithm provides an efficient parametric representation of the posterior tree\n",
            "distribution and exact updating of its parameters. We apply this algorithm to a\n",
            "clustering task in machine learning. More specifically, we apply it to Bayesian\n",
            "estimation of the tree-structured stick-breaking process (TS-SBP) mixture\n",
            "models. For TS-SBP mixture models, only Markov chain Monte Carlo methods have\n",
            "been proposed so far, but any variational Bayesian methods have not been\n",
            "proposed yet. In this paper, we propose a variational Bayesian method that has\n",
            "a subroutine similar to the Bayes coding algorithm for context tree sources. We\n",
            "confirm its behavior by a numerical experiment on a toy example.\n",
            "['The Bayes coding algorithm for context tree source is a successful example of\\nBayesian tree estimation in text compression in information theory.', 'This\\nalgorithm provides an efficient parametric representation of the posterior tree\\ndistribution and exact updating of its parameters.', 'We apply this algorithm to a\\nclustering task in machine learning.', 'More specifically, we apply it to Bayesian\\nestimation of the tree-structured stick-breaking process (TS-SBP) mixture\\nmodels.', 'For TS-SBP mixture models, only Markov chain Monte Carlo methods have\\nbeen proposed so far, but any variational Bayesian methods have not been\\nproposed yet.', 'In this paper, we propose a variational Bayesian method that has\\na subroutine similar to the Bayes coding algorithm for context tree sources.', 'We\\nconfirm its behavior by a numerical experiment on a toy example.']\n",
            "Chunks for abstract: In sufficiently clean materials where electron-electron interactions are\n",
            "strong compared to momentum-relaxing scattering processes, electron transport\n",
            "resembles the flow of a viscous fluid. We study hydrodynamic electron transport\n",
            "across density interfaces (n-n junctions) in a 2DEG in the Corbino geometry.\n",
            "From numerical simulations in COMSOL using realistic parameters, we show that\n",
            "we can produce tunable viscous layers at the density interface by varying the\n",
            "density ratio of charge carriers. We quantitatively explain this observation\n",
            "with simple analytic expressions together with boundary conditions at the\n",
            "interface. We also show signatures of these viscous layers in the\n",
            "magnetoresistance. Breaking down viscous and ohmic contributions, we find that\n",
            "when outer radial region of the Corbino has higher charge density compared to\n",
            "the inner region, the viscous layers at the interface serve to suppress the\n",
            "magneto-resistance produced by momentum-relaxing scattering. Conversely, the\n",
            "magneto-resistance is enhanced when the inner region has higher density than\n",
            "the outer. Our results add to the repertoire of techniques for engineering\n",
            "viscous electron flows, which hold a promise for applications in future\n",
            "electronic devices.\n",
            "['In sufficiently clean materials where electron-electron interactions are\\nstrong compared to momentum-relaxing scattering processes, electron transport\\nresembles the flow of a viscous fluid.', 'We study hydrodynamic electron transport\\nacross density interfaces (n-n junctions) in a 2DEG in the Corbino geometry.', 'From numerical simulations in COMSOL using realistic parameters, we show that\\nwe can produce tunable viscous layers at the density interface by varying the\\ndensity ratio of charge carriers.', 'We quantitatively explain this observation\\nwith simple analytic expressions together with boundary conditions at the\\ninterface.', 'We also show signatures of these viscous layers in the\\nmagnetoresistance.', 'Breaking down viscous and ohmic contributions, we find that\\nwhen outer radial region of the Corbino has higher charge density compared to\\nthe inner region, the viscous layers at the interface serve to suppress the\\nmagneto-resistance produced by momentum-relaxing scattering.', 'Conversely, the\\nmagneto-resistance is enhanced when the inner region has higher density than\\nthe outer.', 'Our results add to the repertoire of techniques for engineering\\nviscous electron flows, which hold a promise for applications in future\\nelectronic devices.']\n",
            "Chunks for abstract: There has been growing interest in audio-language retrieval research, where\n",
            "the objective is to establish the correlation between audio and text\n",
            "modalities. However, most audio-text paired datasets often lack rich expression\n",
            "of the text data compared to the audio samples. One of the significant\n",
            "challenges facing audio-text datasets is the presence of similar or identical\n",
            "captions despite different audio samples. Therefore, under many-to-one mapping\n",
            "conditions, audio-text datasets lead to poor performance of retrieval tasks. In\n",
            "this paper, we propose a novel approach to tackle the data imbalance problem in\n",
            "audio-language retrieval task. To overcome the limitation, we introduce a\n",
            "method that employs a distance sampling-based paraphraser leveraging ChatGPT,\n",
            "utilizing distance function to generate a controllable distribution of\n",
            "manipulated text data. For a set of sentences with the same context, the\n",
            "distance is used to calculate a degree of manipulation for any two sentences,\n",
            "and ChatGPT's few-shot prompting is performed using a text cluster with a\n",
            "similar distance defined by the Jaccard similarity. Therefore, ChatGPT, when\n",
            "applied to few-shot prompting with text clusters, can adjust the diversity of\n",
            "the manipulated text based on the distance. The proposed approach is shown to\n",
            "significantly enhance performance in audio-text retrieval, outperforming\n",
            "conventional text augmentation techniques.\n",
            "['There has been growing interest in audio-language retrieval research, where\\nthe objective is to establish the correlation between audio and text\\nmodalities.', 'However, most audio-text paired datasets often lack rich expression\\nof the text data compared to the audio samples.', 'One of the significant\\nchallenges facing audio-text datasets is the presence of similar or identical\\ncaptions despite different audio samples.', 'Therefore, under many-to-one mapping\\nconditions, audio-text datasets lead to poor performance of retrieval tasks.', 'In\\nthis paper, we propose a novel approach to tackle the data imbalance problem in\\naudio-language retrieval task.', 'To overcome the limitation, we introduce a\\nmethod that employs a distance sampling-based paraphraser leveraging ChatGPT,\\nutilizing distance function to generate a controllable distribution of\\nmanipulated text data.', \"For a set of sentences with the same context, the\\ndistance is used to calculate a degree of manipulation for any two sentences,\\nand ChatGPT's few-shot prompting is performed using a text cluster with a\\nsimilar distance defined by the Jaccard similarity.\", 'Therefore, ChatGPT, when\\napplied to few-shot prompting with text clusters, can adjust the diversity of\\nthe manipulated text based on the distance.', 'The proposed approach is shown to\\nsignificantly enhance performance in audio-text retrieval, outperforming\\nconventional text augmentation techniques.']\n",
            "Chunks for abstract: This work continues the investigation in two recent papers on the quantum\n",
            "thermodynamics of spacetimes, 1) placing what was studied in [1] for thermal\n",
            "quantum fields in the context of early universe cosmology, and 2) extending the\n",
            "considerations of vacuum compressibility of dynamical spaces treated in [2] to\n",
            "dynamical spacetimes with thermal quantum fields. We begin with a warning that\n",
            "thermal equilibrium condition is not guaranteed to exist or maintained in a\n",
            "dynamical setting and thus finite temperature quantum field theory in\n",
            "cosmological spacetimes needs more careful considerations than what is often\n",
            "described in textbooks. A full description requires nonequilibrium quantum\n",
            "field theory in dynamical spacetimes using `in-in' techniques. A more\n",
            "manageable subclass of dynamics is where thermal equilibrium conditions are\n",
            "established at both the beginning and the end of evolution are both well\n",
            "defined. Here we shall assume an in-vacuum state. It has been shown that if the\n",
            "intervening dynamics has an initial period of exponential expansion, such as in\n",
            "inflationary cosmology, particles created from the parametric amplification of\n",
            "the vacuum fluctuations in the initial vacuum will have a thermal spectrum\n",
            "measured at the out-state. Under these conditions finite temperature field\n",
            "theory can be applied to calculate the quantum thermodynamic quantities. Here\n",
            "we consider a massive conformal scalar field in a closed four-dimensional\n",
            "Friedmann-Lemaitre-Robertson-Walker universe based on the simple analytically\n",
            "solvable Bernard-Duncan model. We calculate the energy density of particles\n",
            "created from an in-vacuum and derive the partition function. From the free\n",
            "energy we then derive the heat capacity and the quantum compressibility of the\n",
            "spacetimes with thermal particle creation. We end with some discussions and\n",
            "suggestions for further work in this program of studies.\n",
            "['This work continues the investigation in two recent papers on the quantum\\nthermodynamics of spacetimes, 1) placing what was studied in [1] for thermal\\nquantum fields in the context of early universe cosmology, and 2) extending the\\nconsiderations of vacuum compressibility of dynamical spaces treated in [2] to\\ndynamical spacetimes with thermal quantum fields.', 'We begin with a warning that\\nthermal equilibrium condition is not guaranteed to exist or maintained in a\\ndynamical setting and thus finite temperature quantum field theory in\\ncosmological spacetimes needs more careful considerations than what is often\\ndescribed in textbooks.', \"A full description requires nonequilibrium quantum\\nfield theory in dynamical spacetimes using `in-in' techniques.\", 'A more\\nmanageable subclass of dynamics is where thermal equilibrium conditions are\\nestablished at both the beginning and the end of evolution are both well\\ndefined.', 'Here we shall assume an in-vacuum state.', 'It has been shown that if the\\nintervening dynamics has an initial period of exponential expansion, such as in\\ninflationary cosmology, particles created from the parametric amplification of\\nthe vacuum fluctuations in the initial vacuum will have a thermal spectrum\\nmeasured at the out-state.', 'Under these conditions finite temperature field\\ntheory can be applied to calculate the quantum thermodynamic quantities.', 'Here\\nwe consider a massive conformal scalar field in a closed four-dimensional\\nFriedmann-Lemaitre-Robertson-Walker universe based on the simple analytically\\nsolvable Bernard-Duncan model.', 'We calculate the energy density of particles\\ncreated from an in-vacuum and derive the partition function.', 'From the free\\nenergy we then derive the heat capacity and the quantum compressibility of the\\nspacetimes with thermal particle creation.', 'We end with some discussions and\\nsuggestions for further work in this program of studies.']\n",
            "Chunks for abstract: Pre-trained vision-language models (VLMs), exemplified by CLIP, demonstrate\n",
            "remarkable adaptability across zero-shot classification tasks without\n",
            "additional training. However, their performance diminishes in the presence of\n",
            "domain shifts. In this study, we introduce CLIP Adaptation duRing Test-Time\n",
            "(CLIPArTT), a fully test-time adaptation (TTA) approach for CLIP, which\n",
            "involves automatic text prompts construction during inference for their use as\n",
            "text supervision. Our method employs a unique, minimally invasive text prompt\n",
            "tuning process, wherein multiple predicted classes are aggregated into a single\n",
            "new text prompt, used as pseudo label to re-classify inputs in a transductive\n",
            "manner. Additionally, we pioneer the standardization of TTA benchmarks (e.g.,\n",
            "TENT) in the realm of VLMs. Our findings demonstrate that, without requiring\n",
            "additional transformations nor new trainable modules, CLIPArTT enhances\n",
            "performance dynamically across non-corrupted datasets such as CIFAR-10,\n",
            "corrupted datasets like CIFAR-10-C and CIFAR-10.1, alongside synthetic datasets\n",
            "such as VisDA-C. This research underscores the potential for improving VLMs'\n",
            "adaptability through novel test-time strategies, offering insights for robust\n",
            "performance across varied datasets and environments. The code can be found at:\n",
            "https://github.com/dosowiechi/CLIPArTT.git\n",
            "['Pre-trained vision-language models (VLMs), exemplified by CLIP, demonstrate\\nremarkable adaptability across zero-shot classification tasks without\\nadditional training.', 'However, their performance diminishes in the presence of\\ndomain shifts.', 'In this study, we introduce CLIP Adaptation duRing Test-Time\\n(CLIPArTT), a fully test-time adaptation (TTA) approach for CLIP, which\\ninvolves automatic text prompts construction during inference for their use as\\ntext supervision.', 'Our method employs a unique, minimally invasive text prompt\\ntuning process, wherein multiple predicted classes are aggregated into a single\\nnew text prompt, used as pseudo label to re-classify inputs in a transductive\\nmanner.', 'Additionally, we pioneer the standardization of TTA benchmarks (e.g.,\\nTENT) in the realm of VLMs.', 'Our findings demonstrate that, without requiring\\nadditional transformations nor new trainable modules, CLIPArTT enhances\\nperformance dynamically across non-corrupted datasets such as CIFAR-10,\\ncorrupted datasets like CIFAR-10-C and CIFAR-10.1, alongside synthetic datasets\\nsuch as VisDA-C.', \"This research underscores the potential for improving VLMs'\\nadaptability through novel test-time strategies, offering insights for robust\\nperformance across varied datasets and environments.\", 'The code can be found at:\\nhttps://github.com/dosowiechi/CLIPArTT.git']\n",
            "Chunks for abstract: We propose a novel computational approach to automatically analyze the\n",
            "physical process behind printing of early modern letterpress books via\n",
            "clustering the running titles found at the top of their pages. Specifically, we\n",
            "design and compare custom neural and feature-based kernels for computing\n",
            "pairwise visual similarity of a scanned document's running titles and cluster\n",
            "the titles in order to track any deviations from the expected pattern of a\n",
            "book's printing. Unlike body text which must be reset for every page, the\n",
            "running titles are one of the static type elements in a skeleton forme i.e. the\n",
            "frame used to print each side of a sheet of paper, and were often re-used\n",
            "during a book's printing. To evaluate the effectiveness of our approach, we\n",
            "manually annotate the running title clusters on about 1600 pages across 8 early\n",
            "modern books of varying size and formats. Our method can detect potential\n",
            "deviation from the expected patterns of such skeleton formes, which helps\n",
            "bibliographers understand the phenomena associated with a text's transmission,\n",
            "such as censorship. We also validate our results against a manual bibliographic\n",
            "analysis of a counterfeit early edition of Thomas Hobbes' Leviathan (1651).\n",
            "['We propose a novel computational approach to automatically analyze the\\nphysical process behind printing of early modern letterpress books via\\nclustering the running titles found at the top of their pages.', \"Specifically, we\\ndesign and compare custom neural and feature-based kernels for computing\\npairwise visual similarity of a scanned document's running titles and cluster\\nthe titles in order to track any deviations from the expected pattern of a\\nbook's printing.\", 'Unlike body text which must be reset for every page, the\\nrunning titles are one of the static type elements in a skeleton forme i.e.', \"the\\nframe used to print each side of a sheet of paper, and were often re-used\\nduring a book's printing.\", 'To evaluate the effectiveness of our approach, we\\nmanually annotate the running title clusters on about 1600 pages across 8 early\\nmodern books of varying size and formats.', \"Our method can detect potential\\ndeviation from the expected patterns of such skeleton formes, which helps\\nbibliographers understand the phenomena associated with a text's transmission,\\nsuch as censorship.\", \"We also validate our results against a manual bibliographic\\nanalysis of a counterfeit early edition of Thomas Hobbes' Leviathan (1651).\"]\n",
            "Chunks for abstract: Learning never ends, and there is no age limit to grow yourself. However, the\n",
            "educational landscape may face challenges in effectively catering to students'\n",
            "inclusion and diverse learning needs. These students should have access to\n",
            "state-of-the-art methods for lecture delivery, online resources, and technology\n",
            "needs. However, with all the diverse learning sources, it becomes harder for\n",
            "students to comprehend a large amount of knowledge in a short period of time.\n",
            "Traditional assistive technologies and learning aids often lack the dynamic\n",
            "adaptability required for individualized education plans. Large Language Models\n",
            "(LLM) have been used in language translation, text summarization, and content\n",
            "generation applications. With rapid growth in AI over the past years,\n",
            "AI-powered chatbots and virtual assistants have been developed. This research\n",
            "aims to bridge this gap by introducing an innovative study buddy we will be\n",
            "calling the 'SAMCares'. The system leverages a Large Language Model (LLM) (in\n",
            "our case, LLaMa-2 70B as the base model) and Retriever-Augmented Generation\n",
            "(RAG) to offer real-time, context-aware, and adaptive educational support. The\n",
            "context of the model will be limited to the knowledge base of Sam Houston State\n",
            "University (SHSU) course notes. The LLM component enables a chat-like\n",
            "environment to interact with it to meet the unique learning requirements of\n",
            "each student. For this, we will build a custom web-based GUI. At the same time,\n",
            "RAG enhances real-time information retrieval and text generation, in turn\n",
            "providing more accurate and context-specific assistance. An option to upload\n",
            "additional study materials in the web GUI is added in case additional knowledge\n",
            "support is required. The system's efficacy will be evaluated through controlled\n",
            "trials and iterative feedback mechanisms.\n",
            "['Learning never ends, and there is no age limit to grow yourself.', \"However, the\\neducational landscape may face challenges in effectively catering to students'\\ninclusion and diverse learning needs.\", 'These students should have access to\\nstate-of-the-art methods for lecture delivery, online resources, and technology\\nneeds.', 'However, with all the diverse learning sources, it becomes harder for\\nstudents to comprehend a large amount of knowledge in a short period of time.', 'Traditional assistive technologies and learning aids often lack the dynamic\\nadaptability required for individualized education plans.', 'Large Language Models\\n(LLM) have been used in language translation, text summarization, and content\\ngeneration applications.', 'With rapid growth in AI over the past years,\\nAI-powered chatbots and virtual assistants have been developed.', \"This research\\naims to bridge this gap by introducing an innovative study buddy we will be\\ncalling the 'SAMCares'.\", 'The system leverages a Large Language Model (LLM) (in\\nour case, LLaMa-2 70B as the base model) and Retriever-Augmented Generation\\n(RAG) to offer real-time, context-aware, and adaptive educational support.', 'The\\ncontext of the model will be limited to the knowledge base of Sam Houston State\\nUniversity (SHSU) course notes.', 'The LLM component enables a chat-like\\nenvironment to interact with it to meet the unique learning requirements of\\neach student.', 'For this, we will build a custom web-based GUI.', 'At the same time,\\nRAG enhances real-time information retrieval and text generation, in turn\\nproviding more accurate and context-specific assistance.', 'An option to upload\\nadditional study materials in the web GUI is added in case additional knowledge\\nsupport is required.', \"The system's efficacy will be evaluated through controlled\\ntrials and iterative feedback mechanisms.\"]\n",
            "Chunks for abstract: This work is motivated by a question whether it is possible to calculate a\n",
            "chaotic sequence efficiently, e.g., is it possible to get the $n$-th bit of a\n",
            "bit sequence generated by a chaotic map, such as $\\beta$-expansion, tent map\n",
            "and logistic map in $\\mathrm{o}(n)$ time/space? This paper gives an affirmative\n",
            "answer to the question about the space complexity of a tent map. We show that\n",
            "the decision problem of whether a given bit sequence is a valid tent code is\n",
            "solved in $\\mathrm{O}(\\log^{2} n)$ space in a sense of the smoothed complexity.\n",
            "['This work is motivated by a question whether it is possible to calculate a\\nchaotic sequence efficiently, e.g., is it possible to get the $n$-th bit of a\\nbit sequence generated by a chaotic map, such as $\\\\beta$-expansion, tent map\\nand logistic map in $\\\\mathrm{o}(n)$ time/space?', 'This paper gives an affirmative\\nanswer to the question about the space complexity of a tent map.', 'We show that\\nthe decision problem of whether a given bit sequence is a valid tent code is\\nsolved in $\\\\mathrm{O}(\\\\log^{2} n)$ space in a sense of the smoothed complexity.']\n",
            "Chunks for abstract: Information access systems are getting complex, and our understanding of user\n",
            "behavior during information seeking processes is mainly drawn from qualitative\n",
            "methods, such as observational studies or surveys. Leveraging the advances in\n",
            "sensing technologies, our study aims to characterize user behaviors with\n",
            "physiological signals, particularly in relation to cognitive load, affective\n",
            "arousal, and valence. We conduct a controlled lab study with 26 participants,\n",
            "and collect data including Electrodermal Activities, Photoplethysmogram,\n",
            "Electroencephalogram, and Pupillary Responses. This study examines\n",
            "informational search with four stages: the realization of Information Need\n",
            "(IN), Query Formulation (QF), Query Submission (QS), and Relevance Judgment\n",
            "(RJ). We also include different interaction modalities to represent modern\n",
            "systems, e.g., QS by text-typing or verbalizing, and RJ with text or audio\n",
            "information. We analyze the physiological signals across these stages and\n",
            "report outcomes of pairwise non-parametric repeated-measure statistical tests.\n",
            "The results show that participants experience significantly higher cognitive\n",
            "loads at IN with a subtle increase in alertness, while QF requires higher\n",
            "attention. QS involves demanding cognitive loads than QF. Affective responses\n",
            "are more pronounced at RJ than QS or IN, suggesting greater interest and\n",
            "engagement as knowledge gaps are resolved. To the best of our knowledge, this\n",
            "is the first study that explores user behaviors in a search process employing a\n",
            "more nuanced quantitative analysis of physiological signals. Our findings offer\n",
            "valuable insights into user behavior and emotional responses in information\n",
            "seeking processes. We believe our proposed methodology can inform the\n",
            "characterization of more complex processes, such as conversational information\n",
            "seeking.\n",
            "['Information access systems are getting complex, and our understanding of user\\nbehavior during information seeking processes is mainly drawn from qualitative\\nmethods, such as observational studies or surveys.', 'Leveraging the advances in\\nsensing technologies, our study aims to characterize user behaviors with\\nphysiological signals, particularly in relation to cognitive load, affective\\narousal, and valence.', 'We conduct a controlled lab study with 26 participants,\\nand collect data including Electrodermal Activities, Photoplethysmogram,\\nElectroencephalogram, and Pupillary Responses.', 'This study examines\\ninformational search with four stages: the realization of Information Need\\n(IN), Query Formulation (QF), Query Submission (QS), and Relevance Judgment\\n(RJ).', 'We also include different interaction modalities to represent modern\\nsystems, e.g., QS by text-typing or verbalizing, and RJ with text or audio\\ninformation.', 'We analyze the physiological signals across these stages and\\nreport outcomes of pairwise non-parametric repeated-measure statistical tests.', 'The results show that participants experience significantly higher cognitive\\nloads at IN with a subtle increase in alertness, while QF requires higher\\nattention.', 'QS involves demanding cognitive loads than QF.', 'Affective responses\\nare more pronounced at RJ than QS or IN, suggesting greater interest and\\nengagement as knowledge gaps are resolved.', 'To the best of our knowledge, this\\nis the first study that explores user behaviors in a search process employing a\\nmore nuanced quantitative analysis of physiological signals.', 'Our findings offer\\nvaluable insights into user behavior and emotional responses in information\\nseeking processes.', 'We believe our proposed methodology can inform the\\ncharacterization of more complex processes, such as conversational information\\nseeking.']\n",
            "Chunks for abstract: Denoising diffusion models have recently gained prominence as powerful tools\n",
            "for a variety of image generation and manipulation tasks. Building on this, we\n",
            "propose a novel tool for real-time editing of images that provides users with\n",
            "fine-grained region-targeted supervision in addition to existing prompt-based\n",
            "controls. Our novel editing technique, termed Layered Diffusion Brushes,\n",
            "leverages prompt-guided and region-targeted alteration of intermediate\n",
            "denoising steps, enabling precise modifications while maintaining the integrity\n",
            "and context of the input image. We provide an editor based on Layered Diffusion\n",
            "Brushes modifications, which incorporates well-known image editing concepts\n",
            "such as layer masks, visibility toggles, and independent manipulation of\n",
            "layers; regardless of their order. Our system renders a single edit on a\n",
            "512x512 image within 140 ms using a high-end consumer GPU, enabling real-time\n",
            "feedback and rapid exploration of candidate edits. We validated our method and\n",
            "editing system through a user study involving both natural images (using\n",
            "inversion) and generated images, showcasing its usability and effectiveness\n",
            "compared to existing techniques such as InstructPix2Pix and Stable Diffusion\n",
            "Inpainting for refining images. Our approach demonstrates efficacy across a\n",
            "range of tasks, including object attribute adjustments, error correction, and\n",
            "sequential prompt-based object placement and manipulation, demonstrating its\n",
            "versatility and potential for enhancing creative workflows.\n",
            "['Denoising diffusion models have recently gained prominence as powerful tools\\nfor a variety of image generation and manipulation tasks.', 'Building on this, we\\npropose a novel tool for real-time editing of images that provides users with\\nfine-grained region-targeted supervision in addition to existing prompt-based\\ncontrols.', 'Our novel editing technique, termed Layered Diffusion Brushes,\\nleverages prompt-guided and region-targeted alteration of intermediate\\ndenoising steps, enabling precise modifications while maintaining the integrity\\nand context of the input image.', 'We provide an editor based on Layered Diffusion\\nBrushes modifications, which incorporates well-known image editing concepts\\nsuch as layer masks, visibility toggles, and independent manipulation of\\nlayers; regardless of their order.', 'Our system renders a single edit on a\\n512x512 image within 140 ms using a high-end consumer GPU, enabling real-time\\nfeedback and rapid exploration of candidate edits.', 'We validated our method and\\nediting system through a user study involving both natural images (using\\ninversion) and generated images, showcasing its usability and effectiveness\\ncompared to existing techniques such as InstructPix2Pix and Stable Diffusion\\nInpainting for refining images.', 'Our approach demonstrates efficacy across a\\nrange of tasks, including object attribute adjustments, error correction, and\\nsequential prompt-based object placement and manipulation, demonstrating its\\nversatility and potential for enhancing creative workflows.']\n",
            "Chunks for abstract: Speech emotion recognition (SER) has garnered increasing attention due to its\n",
            "wide range of applications in various fields, including human-machine\n",
            "interaction, virtual assistants, and mental health assistance. However,\n",
            "existing SER methods often overlook the information gap between the\n",
            "pre-training speech recognition task and the downstream SER task, resulting in\n",
            "sub-optimal performance. Moreover, current methods require much time for\n",
            "fine-tuning on each specific speech dataset, such as IEMOCAP, which limits\n",
            "their effectiveness in real-world scenarios with large-scale noisy data. To\n",
            "address these issues, we propose an active learning (AL)-based fine-tuning\n",
            "framework for SER, called \\textsc{After}, that leverages task adaptation\n",
            "pre-training (TAPT) and AL methods to enhance performance and efficiency.\n",
            "Specifically, we first use TAPT to minimize the information gap between the\n",
            "pre-training speech recognition task and the downstream speech emotion\n",
            "recognition task. Then, AL methods are employed to iteratively select a subset\n",
            "of the most informative and diverse samples for fine-tuning, thereby reducing\n",
            "time consumption. Experiments demonstrate that our proposed method\n",
            "\\textsc{After}, using only 20\\% of samples, improves accuracy by 8.45\\% and\n",
            "reduces time consumption by 79\\%. The additional extension of \\textsc{After}\n",
            "and ablation studies further confirm its effectiveness and applicability to\n",
            "various real-world scenarios. Our source code is available on Github for\n",
            "reproducibility. (https://github.com/Clearloveyuan/AFTER).\n",
            "['Speech emotion recognition (SER) has garnered increasing attention due to its\\nwide range of applications in various fields, including human-machine\\ninteraction, virtual assistants, and mental health assistance.', 'However,\\nexisting SER methods often overlook the information gap between the\\npre-training speech recognition task and the downstream SER task, resulting in\\nsub-optimal performance.', 'Moreover, current methods require much time for\\nfine-tuning on each specific speech dataset, such as IEMOCAP, which limits\\ntheir effectiveness in real-world scenarios with large-scale noisy data.', 'To\\naddress these issues, we propose an active learning (AL)-based fine-tuning\\nframework for SER, called \\\\textsc{After}, that leverages task adaptation\\npre-training (TAPT) and AL methods to enhance performance and efficiency.', 'Specifically, we first use TAPT to minimize the information gap between the\\npre-training speech recognition task and the downstream speech emotion\\nrecognition task.', 'Then, AL methods are employed to iteratively select a subset\\nof the most informative and diverse samples for fine-tuning, thereby reducing\\ntime consumption.', 'Experiments demonstrate that our proposed method\\n\\\\textsc{After}, using only 20\\\\% of samples, improves accuracy by 8.45\\\\% and\\nreduces time consumption by 79\\\\%.', 'The additional extension of \\\\textsc{After}\\nand ablation studies further confirm its effectiveness and applicability to\\nvarious real-world scenarios.', 'Our source code is available on Github for\\nreproducibility.', '(https://github.com/Clearloveyuan/AFTER).']\n",
            "Chunks for abstract: Large language models (LLMs) can generate long-form and coherent text, but\n",
            "they still frequently hallucinate facts, thus limiting their reliability. To\n",
            "address this issue, inference-time methods that elicit truthful responses have\n",
            "been proposed by shifting LLM representations towards learned \"truthful\n",
            "directions\". However, applying the truthful directions with the same intensity\n",
            "fails to generalize across different question contexts. We propose LITO, a\n",
            "Learnable Intervention method for Truthfulness Optimization that automatically\n",
            "identifies the optimal intervention intensity tailored to a specific context.\n",
            "LITO explores a sequence of model generations based on increasing levels of\n",
            "intervention intensities. It selects the most accurate response or refuses to\n",
            "answer when the predictions are highly uncertain. Experiments on multiple LLMs\n",
            "and question-answering datasets demonstrate that LITO improves truthfulness\n",
            "while preserving task accuracy. The adaptive nature of LITO counters issues\n",
            "with one-size-fits-all intervention-based solutions, maximizing model\n",
            "truthfulness by reflecting internal knowledge only when the model is confident.\n",
            "['Large language models (LLMs) can generate long-form and coherent text, but\\nthey still frequently hallucinate facts, thus limiting their reliability.', 'To\\naddress this issue, inference-time methods that elicit truthful responses have\\nbeen proposed by shifting LLM representations towards learned \"truthful\\ndirections\".', 'However, applying the truthful directions with the same intensity\\nfails to generalize across different question contexts.', 'We propose LITO, a\\nLearnable Intervention method for Truthfulness Optimization that automatically\\nidentifies the optimal intervention intensity tailored to a specific context.', 'LITO explores a sequence of model generations based on increasing levels of\\nintervention intensities.', 'It selects the most accurate response or refuses to\\nanswer when the predictions are highly uncertain.', 'Experiments on multiple LLMs\\nand question-answering datasets demonstrate that LITO improves truthfulness\\nwhile preserving task accuracy.', 'The adaptive nature of LITO counters issues\\nwith one-size-fits-all intervention-based solutions, maximizing model\\ntruthfulness by reflecting internal knowledge only when the model is confident.']\n",
            "Chunks for abstract: In many practical applications, it is often difficult and expensive to obtain\n",
            "large-scale labeled data to train state-of-the-art deep neural networks.\n",
            "Therefore, transferring the learned knowledge from a separate, labeled source\n",
            "domain to an unlabeled or sparsely labeled target domain becomes an appealing\n",
            "alternative. However, direct transfer often results in significant performance\n",
            "decay due to domain shift. Domain adaptation (DA) aims to address this problem\n",
            "by aligning the distributions between the source and target domains.\n",
            "Multi-source domain adaptation (MDA) is a powerful and practical extension in\n",
            "which the labeled data may be collected from multiple sources with different\n",
            "distributions. In this survey, we first define various MDA strategies. Then we\n",
            "systematically summarize and compare modern MDA methods in the deep learning\n",
            "era from different perspectives, followed by commonly used datasets and a brief\n",
            "benchmark. Finally, we discuss future research directions for MDA that are\n",
            "worth investigating.\n",
            "['In many practical applications, it is often difficult and expensive to obtain\\nlarge-scale labeled data to train state-of-the-art deep neural networks.', 'Therefore, transferring the learned knowledge from a separate, labeled source\\ndomain to an unlabeled or sparsely labeled target domain becomes an appealing\\nalternative.', 'However, direct transfer often results in significant performance\\ndecay due to domain shift.', 'Domain adaptation (DA) aims to address this problem\\nby aligning the distributions between the source and target domains.', 'Multi-source domain adaptation (MDA) is a powerful and practical extension in\\nwhich the labeled data may be collected from multiple sources with different\\ndistributions.', 'In this survey, we first define various MDA strategies.', 'Then we\\nsystematically summarize and compare modern MDA methods in the deep learning\\nera from different perspectives, followed by commonly used datasets and a brief\\nbenchmark.', 'Finally, we discuss future research directions for MDA that are\\nworth investigating.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Semantic Splitter"
      ],
      "metadata": {
        "id": "kwGjDiVmCnQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index-embeddings-huggingface\n",
        "\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.core import Settings\n",
        "\n",
        "# Initialize a HuggingFace Embedding model\n",
        "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
        "\n",
        "# Specify the embedding model into LlamaIndex's settings\n",
        "Settings.embed_model = embed_model"
      ],
      "metadata": {
        "id": "JTfYWaqoCxgn",
        "outputId": "86aa3492-286a-45dc-9e8c-82895a87ce1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "3956a53d77de4134b49c0f9c03ab7ffc",
            "5a8fa5d5725c4548bf3dd9fe1ef9e941",
            "d766bdfec09c4798b2f68bf86e8768a5",
            "aee3483504a040e38728188d526ef9c0",
            "4a247cd16ef943c9a4cce013b756323c",
            "42d519fb89194f518c324a0f87aa9207",
            "1dfdb860acc74d4c856ef4559f034c3a",
            "357d13272468457ba824fe4718a19176",
            "d03b850ab0964326981e69f9771f7156",
            "e7a35c62f8f64202b11736c41c773a76",
            "045c24221ba5424f9636186abab68951",
            "bc6eb243da1943c78c3066f2544ff164"
          ]
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3956a53d77de4134b49c0f9c03ab7ffc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5a8fa5d5725c4548bf3dd9fe1ef9e941"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.readers.file import FlatReader\n",
        "from llama_index.core.node_parser import SemanticSplitterNodeParser\n",
        "from pathlib import Path  # for finding the file\n",
        "\n",
        "\n",
        "# Define embed model (replace with your actual model)\n",
        "# You'll likely need to install the specific model package\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "embed_model_name = \"allenai/scibert_scivocab_uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(embed_model_name)\n",
        "embed_model = AutoModel.from_pretrained(embed_model_name)\n",
        "\n",
        "semantic_ram_nodes = []\n",
        "for index, row in df.iterrows():\n",
        "  abstract = row[\"abstract\"]\n",
        "  tokens = tokenizer(abstract, return_tensors=\"pt\")\n",
        "\n",
        "  # Create parser with your embed model\n",
        "  parser = SemanticSplitterNodeParser(\n",
        "      buffer_size=1,\n",
        "      breakpoint_percentile_threshold=90,\n",
        "      embed_model=embed_model\n",
        "  )\n",
        "\n",
        "  # Get semantic nodes from the tokens\n",
        "  nodes = parser.get_nodes_from_documents([tokens])\n",
        "\n",
        "  # Append nodes to the list (might need further processing)\n",
        "  semantic_ram_nodes.extend(nodes)\n"
      ],
      "metadata": {
        "id": "n0lUEnB_DIor",
        "outputId": "c94836a8-96f7-47db-a6b6-ea53659592d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValidationError",
          "evalue": "1 validation error for SemanticSplitterNodeParser\nembed_model\n  value is not a valid dict (type=type_error.dict)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-32ec60420846>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0;31m# Create parser with your embed model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m   parser = SemanticSplitterNodeParser(\n\u001b[0m\u001b[1;32m     23\u001b[0m       \u001b[0mbuffer_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0mbreakpoint_percentile_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydantic/v1/main.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__pydantic_self__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalidation_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mobject_setattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__pydantic_self__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__dict__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValidationError\u001b[0m: 1 validation error for SemanticSplitterNodeParser\nembed_model\n  value is not a valid dict (type=type_error.dict)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have our data we will create embedings of the abstracts (encoding) using sentence level [DistilBERT](https://huggingface.co/docs/transformers/en/model_doc/distilbert). DistilBERT is a smaller version of classic BERT, designed to have similar performance with 40% fewer parameters (so faster)."
      ],
      "metadata": {
        "id": "tkW52C6OIbcu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the sentence-level DistilBERT\n",
        "model = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')\n",
        "\n",
        "# Convert abstracts to vectors\n",
        "embeddings = model.encode(df.abstract.to_list(), show_progress_bar=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525,
          "referenced_widgets": [
            "7e5c60f237924fd883b9caa11306bb26",
            "6514d435f48b43b298c9f853ff4c1022",
            "02503b25e36047a780855202016b04e1",
            "5fecb76c99894a50b2ebb9a9e7984fed",
            "4133d081843148c09e39200a46cb65ae",
            "5a729f07ec5c4240b95fd66a82d1b979",
            "a48b7f25dd984b0e9ab5597ef8022b43",
            "9e46338424a34a8eb7c0da41d4897943",
            "c897a57d9f964ba39d0561efc2b75e1a",
            "ce69c40eb78a4821aed8906c7a0e40b2",
            "b87e99ad8c1542578a6181ad2ee72904",
            "f60e28f10ec64ed88ad312b76e8152da",
            "ab988c3f6a754b41b693319a12d29a23",
            "dbcdaa0912b449a0956c725e744ed0c6",
            "9f4f074c3d5b46cb8cf1a8a99b509687",
            "3bada3d393fa4116ac03de73d9040d6e",
            "b56fd794203f47a58955e5c32aef882c",
            "6070e6b13174446aa9938a5bdced563c",
            "93def84c0a184f56b6275b05f281a937",
            "c9a977348e7e40b2a8bd6a8a392429a3",
            "80224599f589464bb4f8fa68642ca2db",
            "a63472973b51470fbd015d152191b5b7",
            "345d52aaff324e2ba4c7b086a04606af",
            "43c23c69bee341358ab1d60baa7dc06e",
            "7a0d3056b824428195f196f3c298c696",
            "081e4872155a400abdb280215147284e",
            "0e79f7185f754670b7ed09b59a4fdbf9",
            "d1a6eb309e164e8896591daacc05ec42",
            "4aa293ef792244929c05ec8d7589cf1a",
            "b235d7c9efa8434c9a7d44345ee2b39c",
            "9dab5684af1a48ccbda3262c0db8a13f",
            "84dc407e65e442e494efe8c122b7d3e4",
            "2a98df0172a14d6c98181d5784467294",
            "a6c6ac33319c42a7a60a594160aa1826",
            "e5606b9930224498a5bce66d436d191d",
            "51d769418a9249b7850db345df6614cc",
            "9513d9d0caea4155a10d9eca786c4daa",
            "91647c2c230f4354ae5378e46d5413fb",
            "d638a58af3dc4c99808c9f39915509e8",
            "1625cfe2eaae4dcabf305fafac07084f",
            "a49c75ecf467442887f30043be868615",
            "68444ccb1aae4472bbbfe9713b550f64",
            "2daf4f21aa62484e902de6866a196ca0",
            "401574edc4a045e494cc7e27d650e689",
            "2b4296ecaf5c4b669782ef9362a03a04",
            "a756aab39e2a4c0fb9c783d829c43fce",
            "9118a48ab34b4fec90e5c5f1872bfa29",
            "c068b984576343edad16a2c0b6cffbd7",
            "69722ad9acf941089e7f37270c856db7",
            "e2ce9ada450c439ca7113c1ee4a89b51",
            "7bf2191774804e1fa8e498d189a482c2",
            "b51cad4bad364d769ff112d1e32c9716",
            "54166ca064f9416bbb4230791dadc012",
            "bf0e114acc1447e8a6ee9c5ed82b3e37",
            "95f8d1d4dd24459f93ffddff1d6618be",
            "56b27091daa545578682199a744dc8dc",
            "024bd084d07c4a8eb6f4d28824b93001",
            "4ea2d9b8dcbb4f9c93defe68b258dc77",
            "d7ea985dd05f44a5b472a2f01719737f",
            "fd44a9d05a754683842c58c2c5272547",
            "48e7220e04bc4733a784ee41751133a6",
            "cb8bed304d9442e0a0e55d0151db9e7f",
            "44f9c18836e44086aba9ad4fa2d1a804",
            "930813d3bc0247a9a340ac1f0ee8e75c",
            "012040b25ced43d2bef0fe8bf0875414",
            "cc4f925ef10b4453aa186d29bd92477c",
            "885b985e19244a4ab9ab3d257ec42a97",
            "52fe622ce7bb4b85a3183dfbb8c31359",
            "b1f8c1397e9b4e1aafa28aa76763cce4",
            "5cf229d463c4414f937b745d838f348c",
            "bb824f0985744d1fb2d4870bcdb5343a",
            "471792a8d9034665992e820da0109352",
            "ee8f5d1171a147bcab12eb073415529a",
            "cfccf61e5484460490250f2da948ba65",
            "6d7db75ebc194360bfe0422acd0f7274",
            "fc17f440f94f4e489254e891e70e2086",
            "dab33df0913346658c69fccc9585f614",
            "33b1a274123c46f094a6aea9abe81e73",
            "a4706cde0ab04e1aa6eef5a064117e37",
            "fe055fc9290e4568aaf6324dd3eb1d17",
            "813808db9fe8419693108ac527cb6de4",
            "1ba79150f84344798df84d2e34b20f19",
            "df1969b3e54e49cf8f81140df740cfed",
            "67416fd2cc734e29b475f1871bf0439d",
            "60aec2ec14f94753bc36ac0682757a5b",
            "2960c7fd80944df68375bba239df95c2",
            "f8602cc103f145fc806eb59732209e92",
            "b5488f4555cf48b3bfea825e6994dacb",
            "5816d519590b408a9b73891df665ef02",
            "821113cf0bfd4ad0825af46f45957deb",
            "8eb0c786928b46588e8ad7c6f149de8c",
            "264c848002814fe7a28df7d48d90ce39",
            "8e5eaa7dc0ff44ebab133eeb7874e933",
            "30c9e48e0d884d7094864f5c59a5e556",
            "e01aa29fb64a411fa5079c3b5b03cd9e",
            "3624aaff5cc8461e81156b00fc309c3a",
            "e2740cd037b641a6938482a2621b1e80",
            "b2733d3a07d448ad8a2e602ca9bb2500",
            "42e9294c43834f598706f9d74e1e062c",
            "019d1a4862b74846bb649144edadbb7b",
            "f29887bf49334eeca5caaeb2e0dcfd42",
            "3d36ef1f6f874115ad1876da47b6534d",
            "effbbe915bf24b0ca957e0a6acec0306",
            "17ed088235784529a70e90765d207410",
            "69cc002d7ab34a0b81a6e501544e72dd",
            "afc0852428e543258e6409221a0dd315",
            "85460a6ba17448f48ce9d7787fea6340",
            "f871f5830f954a21a972860f080149fb",
            "c37665e5594545b0a1930953e1947ded",
            "b0f813bb72544709a2ec018dcb00a7c3",
            "da1463ce69c74596b0d56770f2d821ad",
            "ebfa9baa6188486b8cce8cab3b1f26fb",
            "f6396fa38cd54e05b69b46e70d923653",
            "4a0817ec2cd14bffb73e06fed182c719",
            "a27a33b471794f06bb1cff4f5b5aaecd",
            "093638954f8549499bd81711ce9ff48c",
            "247861146f3f41d89e7e95f5f1acd8ad",
            "307e861e1b9c42e597ec5d6dc6c85850",
            "083ba16904f44efb9424b4cb62849b39",
            "edf8a68c20694ae99aae6cb746ecda3c",
            "cfc7cf2a65f442fe85e30da6fe7fb034",
            "dd8693bae25a477ba2f51cfd9faba6a2",
            "8dad89889c85493a9913f33227d5605f",
            "9c28aa2ff0c64a989b34208cee5f49e6",
            "b81b644fb63e46cd9d4c3a2ee08f2737",
            "46420180f5fd47ca8689a728485f0689",
            "9c866a1ed3ea4a47bcb4c97810845215",
            "2cf3986ed0714438af8fbb16bcec5af8",
            "6f2b44a1805c40bbbf5acd1ea5878d97",
            "e7f3cc29c5a3418b96300239c4d04cac",
            "d6fad0c2514040989e00f5fbfc557e83",
            "f0ce0ab3ce4f42118f3ad4efa1f3e975"
          ]
        },
        "id": "IDOAl4TBFswT",
        "outputId": "4b84e3e8-e2fe-464d-accc-079ab8a850f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7e5c60f237924fd883b9caa11306bb26"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f60e28f10ec64ed88ad312b76e8152da"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/4.05k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "345d52aaff324e2ba4c7b086a04606af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a6c6ac33319c42a7a60a594160aa1826"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/555 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b4296ecaf5c4b669782ef9362a03a04"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/265M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "56b27091daa545578682199a744dc8dc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/505 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "885b985e19244a4ab9ab3d257ec42a97"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33b1a274123c46f094a6aea9abe81e73"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5816d519590b408a9b73891df665ef02"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "019d1a4862b74846bb649144edadbb7b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "da1463ce69c74596b0d56770f2d821ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/16 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd8693bae25a477ba2f51cfd9faba6a2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check the shape of the vectorised abstracts to ensure everything worked:"
      ],
      "metadata": {
        "id": "9Ycndu8h8shW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Shape of the vectorised abstract: {embeddings.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUwGmDoCLuSp",
        "outputId": "1b0f7c17-14bf-4e62-ef32-aea3b4803da0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the vectorised abstract: (500, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we expected, we have 500 records (matching our earlier query) by 768 dimensions (our embedding space). We this complete we can populate our database. The data will be the custom IDs we created and the 768 dimensions of the embedding space."
      ],
      "metadata": {
        "id": "M3SqzTmg8zzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Change data type to float32\n",
        "embeddings = np.array([embedding for embedding in embeddings]).astype(\"float32\")\n",
        "\n",
        "# Step 2: Create the index based on the column shape of the embeddings (# of columns)\n",
        "index = faiss.IndexFlatIP(embeddings.shape[1]) # cosine similarity\n",
        "\n",
        "# Step 3: Pass the index to IndexIDMap - allows us to map vectors to the ID\n",
        "index = faiss.IndexIDMap(index)\n",
        "\n",
        "# Step 4: Add vectors and their IDs\n",
        "index.add_with_ids(embeddings, df.uid.values)\n",
        "\n",
        "print(f\"Number of vectors in the Faiss index: {index.ntotal}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TK2RnLGzL9oz",
        "outputId": "081e3c83-1192-4bda-f2fb-e71d32644252"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of vectors in the Faiss index: 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's have a look at one of the abstracts we loaded:"
      ],
      "metadata": {
        "id": "dVJbcRBFVRPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[54, 2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "-_nq1g0QLoyp",
        "outputId": "79c33e6e-1e96-4ac0-815d-5224fcf08642"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Large language models (LLMs) increasingly serve as the backbone for\\nclassifying text associated with distinct domains and simultaneously several\\nlabels (classes). When encountering domain shifts, e.g., classifier of movie\\nreviews from IMDb to Rotten Tomatoes, adapting such an LLM-based multi-label\\nclassifier is challenging due to incomplete label sets at the target domain and\\ndaunting training overhead. The existing domain adaptation methods address\\neither image multi-label classifiers or text binary classifiers. In this paper,\\nwe design DALLMi, Domain Adaptation Large Language Model interpolator, a\\nfirst-of-its-kind semi-supervised domain adaptation method for text data models\\nbased on LLMs, specifically BERT. The core of DALLMi is the novel variation\\nloss and MixUp regularization, which jointly leverage the limited positively\\nlabeled and large quantity of unlabeled text and, importantly, their\\ninterpolation from the BERT word embeddings. DALLMi also introduces a\\nlabel-balanced sampling strategy to overcome the imbalance between labeled and\\nunlabeled data. We evaluate DALLMi against the partial-supervised and\\nunsupervised approach on three datasets under different scenarios of label\\navailability for the target domain. Our results show that DALLMi achieves\\nhigher mAP than unsupervised and partially-supervised approaches by 19.9% and\\n52.2%, respectively.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using this abstract as a query, let's search our database for similar papers. We'll use cosine distance as our distance measure:"
      ],
      "metadata": {
        "id": "qfgCY3kkVWOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve the 10 nearest neighbours\n",
        "cosine_similarity, similar = index.search(np.array([embeddings[54]]), k=10)\n",
        "cosine_similarity = cosine_similarity.flatten().tolist()\n",
        "similar = similar.flatten().tolist()\n",
        "print(f'Cosine similarity: {cosine_similarity}')\n",
        "print(f'Top papers: {similar}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EhOtEcuL0Bp",
        "outputId": "17306cf6-6880-4756-8008-e9abaed090f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine similarity: [159.4054412841797, 123.85952758789062, 119.92066192626953, 118.6053237915039, 118.54507446289062, 118.35850524902344, 118.09319305419922, 118.04651641845703, 117.84342193603516, 116.38523864746094]\n",
            "Top papers: [54, 142, 90, 240, 68, 316, 403, 287, 417, 338]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obviously the closest match is the abstract itself (#36). Let's have a look at the next two closest results:"
      ],
      "metadata": {
        "id": "A3WT7j12VJmm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[similar[1], 2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "_gIQV4c2L5yv",
        "outputId": "38910579-09c4-44f4-b76b-f792d5e4b63e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Large Language Models (LLMs) have enabled new ways to satisfy information\\nneeds. Although great strides have been made in applying them to settings like\\ndocument ranking and short-form text generation, they still struggle to compose\\ncomplete, accurate, and verifiable long-form reports. Reports with these\\nqualities are necessary to satisfy the complex, nuanced, or multi-faceted\\ninformation needs of users. In this perspective paper, we draw together\\nopinions from industry and academia, and from a variety of related research\\nareas, to present our vision for automatic report generation, and -- critically\\n-- a flexible framework by which such reports can be evaluated. In contrast\\nwith other summarization tasks, automatic report generation starts with a\\ndetailed description of an information need, stating the necessary background,\\nrequirements, and scope of the report. Further, the generated reports should be\\ncomplete, accurate, and verifiable. These qualities, which are desirable -- if\\nnot required -- in many analytic report-writing settings, require rethinking\\nhow to build and evaluate systems that exhibit these qualities. To foster new\\nefforts in building these systems, we present an evaluation framework that\\ndraws on ideas found in various evaluations. To test completeness and accuracy,\\nthe framework uses nuggets of information, expressed as questions and answers,\\nthat need to be part of any high-quality generated report. Additionally,\\nevaluation of citations that map claims made in the report to their source\\ndocuments ensures verifiability.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[similar[2], 2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "UuZ8M47_MJ8z",
        "outputId": "3fafeae6-4595-4cf8-981a-d46558e1fb18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Large-scale Text-to-Image (T2I) diffusion models demonstrate significant\\ngeneration capabilities based on textual prompts. Based on the T2I diffusion\\nmodels, text-guided image editing research aims to empower users to manipulate\\ngenerated images by altering the text prompts. However, existing image editing\\ntechniques are prone to editing over unintentional regions that are beyond the\\nintended target area, primarily due to inaccuracies in cross-attention maps. To\\naddress this problem, we propose Localization-aware Inversion (LocInv), which\\nexploits segmentation maps or bounding boxes as extra localization priors to\\nrefine the cross-attention maps in the denoising phases of the diffusion\\nprocess. Through the dynamic updating of tokens corresponding to noun words in\\nthe textual input, we are compelling the cross-attention maps to closely align\\nwith the correct noun and adjective words in the text prompt. Based on this\\ntechnique, we achieve fine-grained image editing over particular objects while\\npreventing undesired changes to other regions. Our method LocInv, based on the\\npublicly available Stable Diffusion, is extensively evaluated on a subset of\\nthe COCO dataset, and consistently obtains superior results both quantitatively\\nand qualitatively.The code will be released at\\nhttps://github.com/wangkai930418/DPL'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that we have two similar looking abstracts! Both clearly discussing RAG much like our reference abstract.\n",
        "\n",
        "We can also visualise this similarity via a 3D scatter graph. However, we need to reduce down to 3 dimensions. For this we can use [$t$-SNE](https://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf), basically a similar approach as PCA (dimension reduction) but better suited to non-linear relationships in data."
      ],
      "metadata": {
        "id": "BX7xZ_-WOX4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_components = 3 # 3D visualisation\n",
        "\n",
        "# create an empty list\n",
        "viz_embeddings = []\n",
        "\n",
        "# add the closest 10 embeddings to the list\n",
        "for embedding in similar:\n",
        "  viz_embeddings.append(embeddings[embedding])\n",
        "\n",
        "# convert to a np array\n",
        "viz_array = np.array(viz_embeddings)\n",
        "\n",
        "# reduce the embeddings to n_components (3) dimensions using TSNE\n",
        "tsne = TSNE(n_components=n_components, random_state=42, perplexity=5)\n",
        "reduced_vectors = tsne.fit_transform(viz_array) # transform the data\n",
        "reduced_vectors[0:5] # show the first 5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9GE2hwBN5sv",
        "outputId": "5d43f8d8-761f-40c7-942c-c627b2ba38de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ -96.76133 ,  -16.78268 ,  -12.690235],\n",
              "       [-109.19027 ,  -88.27165 ,  -75.16752 ],\n",
              "       [ -19.696934,  -84.72847 ,   94.33796 ],\n",
              "       [-179.14848 ,  -19.984583,   68.73254 ],\n",
              "       [  79.20754 ,   24.442919,   63.034298]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code adapted from: Afzal(2024)\n",
        "# https://medium.com/@sarmadafzalj/visualize-vector-embeddings-in-a-rag-system-89d0c44a3be4\n",
        "\n",
        "import plotly.graph_objs as go\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.io as pio\n",
        "\n",
        "# Create a 3D scatter plot\n",
        "scatter_plot = go.Scatter3d(\n",
        "    x=reduced_vectors[:, 0],\n",
        "    y=reduced_vectors[:, 1],\n",
        "    z=reduced_vectors[:, 2],\n",
        "    mode='markers',\n",
        "    marker=dict(size=5, color='grey', opacity=0.5, line=dict(color='lightgray', width=1)),\n",
        "    text=[f\"Point {i}\" for i in range(len(reduced_vectors))],\n",
        "    name=\"Abstracts\"\n",
        ")\n",
        "\n",
        "# Highlight the first point with a different colour (red)\n",
        "highlighted_point = go.Scatter3d(\n",
        "    x=[reduced_vectors[0, 0]],\n",
        "    y=[reduced_vectors[0, 1]],\n",
        "    z=[reduced_vectors[0, 2]],\n",
        "    mode='markers',\n",
        "    marker=dict(size=8, color='red', opacity=0.8, line=dict(color='lightgray', width=1)),\n",
        "    text=[\"Question\"],\n",
        "    name=\"Query abstract\"\n",
        "\n",
        ")\n",
        "\n",
        "# Highlight the closest two points with a different colour again (blue)\n",
        "blue_points = go.Scatter3d(\n",
        "    x=reduced_vectors[1:3, 0],\n",
        "    y=reduced_vectors[1:3, 1],\n",
        "    z=reduced_vectors[1:3, 2],\n",
        "    mode='markers',\n",
        "    marker=dict(size=8, color='blue', opacity=0.8,  line=dict(color='black', width=1)),\n",
        "    text=[\"Top 1 Document\",\"Top 2 Document\"],\n",
        "    name=\"Closest abstracts\"\n",
        ")\n",
        "\n",
        "# Create the layout for the plot\n",
        "layout = go.Layout(\n",
        "    scene=dict(\n",
        "        xaxis=dict(title='X'),\n",
        "        yaxis=dict(title='Y'),\n",
        "        zaxis=dict(title='Z'),\n",
        "    ),\n",
        "    title=f'3D Representation after t-SNE (Perplexity=5)'\n",
        ")\n",
        "\n",
        "\n",
        "fig = make_subplots(rows=1, cols=1, specs=[[{'type': 'scatter3d'}]])\n",
        "\n",
        "# Add the scatter plots to the Figure\n",
        "fig.add_trace(scatter_plot)\n",
        "fig.add_trace(highlighted_point)\n",
        "fig.add_trace(blue_points)\n",
        "\n",
        "fig.update_layout(layout)\n",
        "\n",
        "pio.write_html(fig, 'interactive_plot.html')\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "t1Dl7zErJfw7",
        "outputId": "2b58e5ba-df53-4386-fd0f-c0ba4aee5df0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"185f3ac5-b7eb-4f4d-8bc1-bfe9a84574ee\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"185f3ac5-b7eb-4f4d-8bc1-bfe9a84574ee\")) {                    Plotly.newPlot(                        \"185f3ac5-b7eb-4f4d-8bc1-bfe9a84574ee\",                        [{\"marker\":{\"color\":\"grey\",\"line\":{\"color\":\"lightgray\",\"width\":1},\"opacity\":0.5,\"size\":5},\"mode\":\"markers\",\"name\":\"Abstracts\",\"text\":[\"Point 0\",\"Point 1\",\"Point 2\",\"Point 3\",\"Point 4\",\"Point 5\",\"Point 6\",\"Point 7\",\"Point 8\",\"Point 9\"],\"x\":[-96.7613296508789,-109.19026947021484,-19.69693374633789,-179.1484832763672,79.2075424194336,-80.23575592041016,-13.512996673583984,-25.310192108154297,33.423744201660156,63.243072509765625],\"y\":[-16.78268051147461,-88.27165222167969,-84.72846984863281,-19.984582901000977,24.44291877746582,46.83983612060547,41.564979553222656,48.49284362792969,9.268596649169922,-91.98780822753906],\"z\":[-12.690235137939453,-75.16751861572266,94.33795928955078,68.73253631591797,63.034297943115234,181.78128051757812,-125.99609375,50.743507385253906,-51.026771545410156,-46.01524353027344],\"type\":\"scatter3d\"},{\"marker\":{\"color\":\"red\",\"line\":{\"color\":\"lightgray\",\"width\":1},\"opacity\":0.8,\"size\":8},\"mode\":\"markers\",\"name\":\"Query abstract\",\"text\":[\"Question\"],\"x\":[-96.7613296508789],\"y\":[-16.78268051147461],\"z\":[-12.690235137939453],\"type\":\"scatter3d\"},{\"marker\":{\"color\":\"blue\",\"line\":{\"color\":\"black\",\"width\":1},\"opacity\":0.8,\"size\":8},\"mode\":\"markers\",\"name\":\"Closest abstracts\",\"text\":[\"Top 1 Document\",\"Top 2 Document\"],\"x\":[-109.19026947021484,-19.69693374633789],\"y\":[-88.27165222167969,-84.72846984863281],\"z\":[-75.16751861572266,94.33795928955078],\"type\":\"scatter3d\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"scene\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"xaxis\":{\"title\":{\"text\":\"X\"}},\"yaxis\":{\"title\":{\"text\":\"Y\"}},\"zaxis\":{\"title\":{\"text\":\"Z\"}}},\"title\":{\"text\":\"3D Representation after t-SNE (Perplexity=5)\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('185f3ac5-b7eb-4f4d-8bc1-bfe9a84574ee');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see in 3-dimensional space, our query abstract is relatively close to our two papers, and further from the remaining 7.\n",
        "\n",
        "How about if we query with new text (rather than using an existing abstract in the database). Let's get ChatGPT to create something similar to the paper we found:"
      ],
      "metadata": {
        "id": "z3lc2AB2PTfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rag_text = \"Large language models (LLMs) are increasingly pivotal in supporting \\\n",
        "text categorization across various specialized areas while managing multiple \\\n",
        "labels concurrently. Adapting these LLM-based multi-label classifiers to domain \\\n",
        "shifts, such as transitioning a news sentiment classifier from financial to \\\n",
        "political news, presents significant challenges. These challenges stem from \\\n",
        "incomplete label sets in the new domain and the considerable burden of retraining. \""
      ],
      "metadata": {
        "id": "Utrh-MxlP9fw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can embedd our text, as before, and use it to search the database:"
      ],
      "metadata": {
        "id": "8ug8lcYdTfw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert RAG text to vectors\n",
        "rag_embedding = model.encode(rag_text, show_progress_bar=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "18e6ce328fc14a5e88f2d165a9db30da",
            "21584ef3bcd94ec6be396de345146ea4",
            "00240c2fad544ca89aeded3254136779",
            "bf1b0ef46f8244d5bb8c5ca8e1c911cf",
            "5f4ae3a9bd73439d86b8f1f214f4743c",
            "8535350283e44e76b1180df82707323e",
            "d213d4a705aa412fbba7b5bde7a75b0c",
            "7bacf946f1e842edabc8ad1b0a61015a",
            "47be727efeb24a9ea0f03165be1af9b1",
            "1595ae47a27b44b282dedb3f9efc3979",
            "097b9d7d7e9c48428701ed138c68a367"
          ]
        },
        "id": "q0CxRi5-QSC3",
        "outputId": "3bbd7b0e-40db-46b6-bfde-0d0b9457f526"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "18e6ce328fc14a5e88f2d165a9db30da"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve the 10 nearest neighbours\n",
        "cs_similarity_two, similar_two = index.search(np.array([rag_embedding]), k=10)\n",
        "similar_two = similar_two.flatten().tolist()\n",
        "print(f'Original search: {similar}')\n",
        "print(f'New search: {similar_two}')\n",
        "common_elements = set(similar) # change similar to a set\n",
        "# print the documents in common (the intersection of the sets of the two lists)\n",
        "print(f'Common documents: {common_elements.intersection(set(similar_two))}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRd7oLNAQcRZ",
        "outputId": "22ddd2b9-0baf-4f33-e8fe-59640fa0913e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original search: [54, 142, 90, 240, 68, 316, 403, 287, 417, 338]\n",
            "New search: [142, 54, 240, 93, 338, 445, 13, 55, 166, 90]\n",
            "Common documents: {142, 240, 338, 54, 90}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, we get similar results, with many similar papers found as found in the original search. Great work!\n",
        "\n",
        "Let's also, as a bit of foreshadowing, try finding documents to support a more standard Q&A prompt:"
      ],
      "metadata": {
        "id": "-j5hVI-kRrJA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q&A prompt\n",
        "qna_prompt = \"what is sentiment analysis?\"\n",
        "\n",
        "# Convert Q&A prompt to vectors\n",
        "rag_embedding = model.encode(qna_prompt, show_progress_bar=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "ed89601230ee4adfb67ab92ed7c7b11a",
            "31b40ad3e0d6461da26be7c999e51d32",
            "c6c88264a3204ca99c0b1f22bcbb1c7d",
            "3a2a12f6486346908e378c0218bcbf81",
            "a04afa9e339f4be59c00172f500c21da",
            "eeec079649604176a623537ba422914b",
            "8d8831b9c9094e4e96fae3e046ae11c1",
            "70c28d2251104537b69589684fa11d92",
            "309294dd68d546c4a87f9572a36c3bef",
            "5f9e921d376143f6a6b1881132a12652",
            "711255360189422e962698ce3a37fb97"
          ]
        },
        "id": "Ep3m-K3in9P3",
        "outputId": "2f6695f4-58ea-4e5b-9d0e-e87e6608d150"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed89601230ee4adfb67ab92ed7c7b11a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can find the best two abstracts related to this query:"
      ],
      "metadata": {
        "id": "-iAQsfzToQkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve the top nearest neighbour\n",
        "cs_similarity_three, similar_three = index.search(np.array([rag_embedding]), k=1)\n",
        "similar_three = similar_three.flatten().tolist()\n",
        "\n",
        "# Print the result\n",
        "print(f'Top result: {df.iloc[similar_three[0], 2]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iH-Z0CLZoVSQ",
        "outputId": "79de0d0d-f5a0-4767-dcb5-b9fa5f5357de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top result: Text summarization models have typically focused on optimizing aspects of\n",
            "quality such as fluency, relevance, and coherence, particularly in the context\n",
            "of news articles. However, summarization models are increasingly being used to\n",
            "summarize diverse sources of text, such as social media data, that encompass a\n",
            "wide demographic user base. It is thus crucial to assess not only the quality\n",
            "of the generated summaries, but also the extent to which they can fairly\n",
            "represent the opinions of diverse social groups. Position bias, a long-known\n",
            "issue in news summarization, has received limited attention in the context of\n",
            "social multi-document summarization. We deeply investigate this phenomenon by\n",
            "analyzing the effect of group ordering in input documents when summarizing\n",
            "tweets from three distinct linguistic communities: African-American English,\n",
            "Hispanic-aligned Language, and White-aligned Language. Our empirical analysis\n",
            "shows that although the textual quality of the summaries remains consistent\n",
            "regardless of the input document order, in terms of fairness, the results vary\n",
            "significantly depending on how the dialect groups are presented in the input\n",
            "data. Our results suggest that position bias manifests differently in social\n",
            "multi-document summarization, severely impacting the fairness of summarization\n",
            "models.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A seemingly relevant result!"
      ],
      "metadata": {
        "id": "VaGZUMwholSc"
      }
    }
  ]
}